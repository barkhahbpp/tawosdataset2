Name,Title,Description,Type,Priority,Status,Creation_Date,Estimation_Date,Story_Point
"Sonatype Nexus","Conan integration in 3.22.0 does not handle Header Only packages","I am unable to upload header only conan pacakges, I get the following error:         Those files are not generaed with header only packages. If I touch them in the package local cache (to create empty ones), the upload works.    I was using the community supported plugin previsously and I never had the problem.",Bug,Major,Closed,"2020-03-30 19:44:27","2020-03-30 18:44:27",0
"Sonatype Nexus","Problem proxying NuGet packages hosted by GitHub Packages","* ,create a new NuGet (proxy) repository   ** name it agents-net   ** use [https://nuget.pkg.github.com/agents-net/index.json] as Remote storage URL   ** configure authentication with GitHub username / personal access token    => repo is available at [http://SERVERURL/repository/agents-net/|https://serverurl/repository/agents-net/]   * add NuGet package source in Visual Studio   ** [http://SERVERURL/repository/agents-net/index.json|https://serverurl/repository/agents-net/index.json]   * create new project in Visual Studio or use an existing one   ** Manage NuGet Packages for the project   ** select new package source   ** select browse tab   *** check include prerelease     => VS shows error   * in Output / Package Manager the following error is shown   [Agents.Net] Failed to retrieve metadata from source 'http://.../repository/agents-net/v3/query/1?q=&skip=0&take=26&prerelease=true&semVerLevel=2.0.0'.   Response status code does not indicate success: 500 (javax.servlet.ServletException: java.lang.NullPointerException).   * Log View shows stacktrace to NullPointerException (see also attached log file)          ",Bug,Major,Closed,"2020-03-05 07:56:25","2020-03-05 07:56:25",1
"Sonatype Nexus","Update h.s.c docs to make it clear which formats do/don't have HA-C support","*Acceptance criteria*  * The following section needs updating to include the latest formats [https://help.sonatype.com/repomanager3/high-availability#HighAvailability-KnownIssuesandLimitations |https://help.sonatype.com/repomanager3/high-availability#HighAvailability-KnownIssuesandLimitations ] (Missing formats: Cocoapods, Conda, R, Helm, P2, Conan)  * Add a new column to https://help.sonatype.com/repomanager3/formats that says whether the format has HA-C support or not. (Formats without HA-C: Apt, Go, Cocoapods, Conda, R, Helm, P2, Conan)  ",Story,Major,Done,"2020-02-10 13:00:06","2020-02-10 13:00:06",1
"Sonatype Nexus","NullPointer appears if run cleanup for hosted created via REST","*Steps to reproduce:*   1. Create repository using REST e.g. for helm    2. Run cleanup policy task    *Expected:* No errors appear   *Actual results:* NullPointer appears in the log.   ",Bug,Major,Closed,"2019-12-24 10:16:23","2019-12-24 10:16:23",1
"Sonatype Nexus","REST API for R repositories",,Story,Major,Done,"2019-12-12 14:57:33","2019-12-12 14:57:33",3
"Sonatype Nexus","[R format] regression test full format","Regression test full R format when all tickets are finished.    *Technical notes*  * Merged into master of nexus-repository-r  * Merged into master of nexus-internal",Task,Major,Closed,"2019-10-15 14:05:16","2019-10-15 13:05:16",3
"Sonatype Nexus","[Helm Features] Cleanup policy facet should be added for hosted and proxy Helm repositories","Accepted criteria:  * User should be able to set up a cleanup policy for hosted/proxy Helm repository",Story,Major,Done,"2019-08-27 15:14:11","2019-08-27 14:14:11",2
"Sonatype Nexus","zero-byte layers uploaded using docker push fail strict content type validation","Docker push may upload zero-byte layers - *this is normal.* This is allowed according to Docker API and a variation of which was allowed in NEXUS-9847.    When NXRM has Strict Content Type Validation enabled for the hosted Docker repository, then the content type of the layer cannot be interpreted and therefore evaluated by NXRM. The docker push will fail on a zero byte layer and docker push will report an error.    regular log levels reveal:        Failures at TRACE level logging reveals:        The examined file in the tmp directory is zero-bytes and the Content-Length header for the docker push is also zero.",Bug,Major,Closed,"2019-08-13 01:09:16","2019-08-13 00:09:16",3
"Sonatype Nexus","Deleting a nuget package from a proxy repository removes its version from group level metadata","Create a proxy repository to [https://www.powershellgallery.com/api/v2/]   Create a nuget group repository nuget-group and add the proxy repository into it.    Download:    [http://localhost:8081/repository/nuget-group/FindPackagesById()?id=%27PowerShellGet%27&$skip=0&$top=40]    Observe that version 2.0.0 is in the metadata.    Download:    [http://localhost:8081/repository/nuget-group/PowerShellGet/2.0.0]    Now delete the PowerShell-2.0.0.nupkg repository from the proxy, and download the group level metadata again:    [http://localhost:8081/repository/nuget-group/FindPackagesById()?id=%27PowerShellGet%27&$skip=0&$top=40]    Notice that version 2.0.0 is no longer present in the metadata.  This will make subequent download attempts of that version through the group using NuGet client fail.    Expiring the group level cache fixes this problem.    *Expected*:  Removing a nuget package from a proxy repository should not remove its version from the metadata     ",Bug,Major,Closed,"2019-08-09 23:13:07","2019-08-09 22:13:07",1
"Sonatype Nexus","Group metadata not updated when a yum proxy repository's remote URL is changed.","# Set up a yum proxy with an incorrect URL, and put it in a yum group repository.      # Add a yum hosted repository to the group with metadata depth of 0.    # Upload an rpm to the hosted repository.     # Retrieve the repomd/repodata.xml file through the group.   # Fix the proxy's remote URL, and download the repomd.xml file through the proxy.    Now try retrieving the the repomd/repodata.xml file through the group again. Observe that the metadata is not updated. Invalidating the group's cache does not fix this.    Expiring cache in either the proxy or group repository does not fix this.  Not sure if that is a separate bug, or if it is another symptom of the same bug.    The only workaround I have been able to find is to delete the group repository and recreate it.    I've attached an NXRM 3.18.0 work directory that is in this state.",Bug,Major,Open,"2019-08-02 19:37:12","2019-08-02 18:37:12",1
"Sonatype Nexus","Upgrade wizard always prompts to disable anonymous access","When upgrading to Nexus 3.18.0 from a previously configured version, the upgrade wizard always prompts about enabling anonymous access.  Why is this done? If the instance was previously configured to allow anonymous, we should respect that setting.  Someone who isn't looking closely or doesn't understand could accidentally disable anonymous access. In most organizations, this would result in a ton of builds breaking.    *Expected:* In the wizard, if anonymous access had been enabled prior to the upgrade, then the wizard should default to having anonymous access enabled (and should be disabled if anonymous access had been disabled). For new installs, anonymous access can be defaulted to disabled.         ",Bug,Major,Closed,"2019-08-01 23:32:04","2019-08-01 22:32:04",0
"Sonatype Nexus","pypi proxy remote simple indexes with absolute URLs are not rewritten correctly causing the pip client to bypass nxrm","1. Create a PyPi proxy repository to https://pypi.rasa.com  2. Execute an install:      The problem is the pip client tries to access other hosts ( Downloading https://pypi.rasa.com/api/package/rasa-x/rasa-x-0.19.5.tar.gz ) to install packages.    Loading this page: http://localhost:8081/repository/rasa/simple/rasa-x    Will return HTML with absolute URLs to other hosts:        h4. Expected    A pip client properly configured to access NXRM PyPi repos should always send requests for packages to the configured index/indexUrl repository.     The simple index that NXRM returns to the client should contain URLs mapped to repository from which it is served.        ",Bug,Major,Closed,"2019-08-01 20:41:33","2019-08-01 19:41:33",1
"Sonatype Nexus","docker proxy outbound socket connection not reclaimed in a timely manner","The full extent / impact of this apparent bug is not yet known, but what is happening is certainly not desired.    1. Using 3.18.0, with SSL configured, create a docker proxy repo named docker-mcr with remote URL to https://mcr.microsoft.com with NXRM https proxy repo port 8085. Leave all other proxy repo settings at the default.  2. Using docker CLI on Mac OS, try this pull command against docker-mcr repo:      3. After the docker command is finished, take a NXRM thread dump. You will see a RUNNABLE qtp thread still in use waiting on Socket read:      4. Now stop the NXRM process. Stopping the NXRM process will hang, trying to clean up the stuck threads. Eventually you see:        As evidenced by the above logging statements, the stuck thread seems to remain until the server is stopped.    Worse, the more requests that are made for the same manifest, the more cooperating threads stack up, stealing a thread for the limited Jetty thread pool and the outbound connection pool as well.    Lastly, the request.log never contains the original request that hung ( the request logging stopped before the thread finished )    ",Bug,Major,Open,"2019-07-30 19:59:41","2019-07-30 18:59:41",0
"Sonatype Nexus","docker push may fail with blob upload unknown due to race condition","We have several reports, that in rare cases, docker pushes to NXRM hosted repos may fail with messages similar to:    {quote}  48983fe960c3: Preparing   128dd347f60c: Preparing   e1a204bf4760: Preparing   28f6517e2463: Preparing   d9ff549177a9: Preparing   28f6517e2463: Layer already exists   128dd347f60c: Layer already exists   d9ff549177a9: Layer already exists   e1a204bf4760: Layer already exists   48983fe960c3: Pushed   *blob upload unknown*  ##[error]blob upload unknown   ##[error]/usr/bin/docker failed with return code: 1  {quote}    {noformat:title=3.16.1 nexus.log messages}  2019-07-25 16:47:13,420-0700 WARN  [qtp884065834-20671]  username org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access soft-deleted blob path$nexus-repository-docker/b7654fa4-5b64-4db2-adab-7f5d1159b658/0 (F:\nexus3\blobs\primary blob store\content\directpath\nexus-repository-docker\b7654fa4-5b64-4db2-adab-7f5d1159b658\0.properties), reason: Docker upload cleaned up.  2019-07-25 16:47:13,420-0700 WARN  [qtp884065834-20671]  username org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access soft-deleted blob path$nexus-repository-docker/b7654fa4-5b64-4db2-adab-7f5d1159b658/1564098432951 (F:\nexus3\blobs\primary blob store\content\directpath\nexus-repository-docker\b7654fa4-5b64-4db2-adab-7f5d1159b658\1564098432951.properties), reason: Docker upload cleaned up.  2019-07-25 16:47:13,420-0700 WARN  [qtp884065834-20671]  username org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access soft-deleted blob path$nexus-repository-docker/b7654fa4-5b64-4db2-adab-7f5d1159b658/1564098433295 (F:\nexus3\blobs\primary blob store\content\directpath\nexus-repository-docker\b7654fa4-5b64-4db2-adab-7f5d1159b658\1564098433295.properties), reason: Docker upload cleaned up.  2019-07-25 16:47:13,420-0700 WARN  [qtp884065834-20671]  username org.sonatype.nexus.repository.docker.internal.DockerHostedFacetImpl - Failed to complete upload  java.lang.IllegalStateException: Missing upload with uuid: b7654fa4-5b64-4db2-adab-7f5d1159b658   at org.sonatype.nexus.repository.docker.internal.UploadManagerImpl.ensureGetUpload(UploadManagerImpl.java:126)   at org.sonatype.nexus.repository.docker.internal.UploadManagerImpl.complete(UploadManagerImpl.java:85)   at org.sonatype.nexus.repository.docker.internal.DockerHostedFacetImpl.completeBlobUpload(DockerHostedFacetImpl.java:585)   at org.sonatype.nexus.repository.docker.internal.DockerHostedFacetImpl$$EnhancerByGuice$$43e6bc99.CGLIB$completeBlobUpload$15(<generated>)   at org.sonatype.nexus.repository.docker.internal.DockerHostedFacetImpl$$EnhancerByGuice$$43e6bc99$$FastClassByGuice$$b3a8c7a0.invoke(<generated>)   at com.google.inject.internal.cglib.proxy.$MethodProxy.invokeSuper(MethodProxy.java:228)   at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:76)   at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:56)   at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:54)   at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:77)   at com.google.inject.internal.InterceptorStackCallback.intercept(InterceptorStackCallback.java:55)   at org.sonatype.nexus.repository.docker.internal.DockerHostedFacetImpl$$EnhancerByGuice$$43e6bc99.completeBlobUpload(<generated>)   at org.sonatype.nexus.repository.docker.internal.DockerHostedFacet$completeBlobUpload$8.call(Unknown Source)   at org.sonatype.nexus.repository.docker.internal.V2Handlers$_closure5.doCall(V2Handlers.groovy:150)   at sun.reflect.GeneratedMethodAccessor423.invoke(Unknown Source)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:498)   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:98)   at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325)   at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:264)   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1034)   at groovy.lang.Closure.call(Closure.java:418)   at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:54)   at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:124)   at com.sun.proxy.$Proxy181.handle(Unknown Source)   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)   at org.sonatype.nexus.repository.storage.UnitOfWorkHandler.handle(UnitOfWorkHandler.java:39)   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)   at org.sonatype.nexus.repository.security.SecurityHandler.handle(SecurityHandler.java:52)   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)   at org.sonatype.nexus.repository.view.Context$proceed.call(Unknown Source)   at org.sonatype.nexus.repository.docker.internal.V2Handlers$_closure18.doCall(V2Handlers.groovy:298)   at sun.reflect.GeneratedMethodAccessor128.invoke(Unknown Source)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:498)   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:98)   at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325)   at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:264)   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1034)   at groovy.lang.Closure.call(Closure.java:418)   at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:54)   at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:124)   at com.sun.proxy.$Proxy181.handle(Unknown Source)   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)   at org.sonatype.nexus.repository.view.Context$proceed.call(Unknown Source)   at org.sonatype.nexus.repository.docker.internal.V2Handlers$_closure1.doCall(V2Handlers.groovy:90)   at sun.reflect.GeneratedMethodAccessor127.invoke(Unknown Source)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:498)   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:98)   at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325)   at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:264)   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1034)   at groovy.lang.Closure.call(Closure.java:418)   at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:54)   at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:124)   at com.sun.proxy.$Proxy181.handle(Unknown Source)   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)   at org.sonatype.nexus.repository.view.handlers.TimingHandler.handle(TimingHandler.java:46)   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)   at org.sonatype.nexus.repository.view.Context.start(Context.java:114)   at org.sonatype.nexus.repository.view.Router.dispatch(Router.java:64)   at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:52)   at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:43)   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.dispatchAndSend(ViewServlet.java:212)   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.doService(ViewServlet.java:174)   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.service(ViewServlet.java:126)   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:286)   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:276)   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:181)   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:71)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85)   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61)   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)   at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85)   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)   at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101)   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at org.sonatype.nexus.repository.httpbridge.internal.ExhaustRequestFilter.doFilter(ExhaustRequestFilter.java:80)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:108)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:112)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:68)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:101)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at org.sonatype.nexus.internal.web.HeaderPatternFilter.doFilter(HeaderPatternFilter.java:98)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104)   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:135)   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73)   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1602)   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:540)   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)   at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1588)   at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1345)   at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:480)   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1557)   at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1247)   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:239)   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)   at org.eclipse.jetty.server.Server.handle(Server.java:502)   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)   at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)   at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)   at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)   at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)   at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)   at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)   at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)   at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)   at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)   at java.lang.Thread.run(Thread.java:748)  {noformat}      {code:title=3.161 Audit Log entries}  {timestamp:2019-07-25 16:47:13,388-0700,nodeId:A15B4527-0B17ADD5-D28C7AC1-EF2D5D16-ADAE52AE,initiator:username/172.20.8.6,domain:repository.asset,type:created,context:v2/-/blobs/sha256:a4ff2e7a414c9476f7edcdb69a93ba0f81f975912a7e51db8173784c50b2a7b4,attributes:{repository.name:docker-internal,format:docker,name:v2/-/blobs/sha256:a4ff2e7a414c9476f7edcdb69a93ba0f81f975912a7e51db8173784c50b2a7b4}}    {timestamp:2019-07-25 16:47:13,748-0700,nodeId:A15B4527-0B17ADD5-D28C7AC1-EF2D5D16-ADAE52AE,initiator:username/172.20.8.6,domain:repository.asset,type:updated,context:v2/-/blobs/sha256:a4ff2e7a414c9476f7edcdb69a93ba0f81f975912a7e51db8173784c50b2a7b4,attributes:{repository.name:docker-internal,format:docker,name:v2/-/blobs/sha256:a4ff2e7a414c9476f7edcdb69a93ba0f81f975912a7e51db8173784c50b2a7b4}}  {code}    h4. Initial Analysis    This appears to occur when two zero byte chunks for two different layers are uploaded to the same image namespace at the exact same time. Predicting when this could happen is near impossible.    h4. Workaround    The only workaround at this time is to repeat the same docker push - in the case of CI builds this is especially troublesome, but has been reported to workaround the initial failure.",Bug,Major,Closed,"2019-07-26 15:17:29","2019-07-26 14:17:29",0
"Sonatype Nexus","nxrm3:staging-deploy goal fails when using maven password encryption","Configure Maven to use password encryption as described here:    https://maven.apache.org/guides/mini/guide-encryption.html     Configure a maven project to use the nxrm3-maven-plugin for deployment as described here:    https://help.sonatype.com/display/NXI/Repository+Manager+for+Maven+Plugin    For the serverId parameter, be sure to use a server that has an encrypted password.      Then run the deploy goal.  This will fail:    {quote}  Caused by: java.lang.ClassNotFoundException: org.codehaus.plexus.util.xml.XmlStreamReader      at org.codehaus.plexus.classworlds.strategy.SelfFirstStrategy.loadClass (SelfFirstStrategy.java:50)      at org.codehaus.plexus.classworlds.realm.ClassRealm.unsynchronizedLoadClass (ClassRealm.java:271)      at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass (ClassRealm.java:247)      at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass (ClassRealm.java:239)      at org.sonatype.plexus.components.sec.dispatcher.SecUtil.read (SecUtil.java:58)      at org.sonatype.plexus.components.sec.dispatcher.DefaultSecDispatcher.getSec (DefaultSecDispatcher.java:206)      at org.sonatype.plexus.components.sec.dispatcher.DefaultSecDispatcher.decrypt (DefaultSecDispatcher.java:90)      at org.sonatype.maven.mojo.settings.MavenSettings.decrypt (MavenSettings.java:157)      at org.sonatype.maven.mojo.settings.MavenSettings.decrypt (MavenSettings.java:111)      at org.sonatype.nexus.maven.staging.StagingMojo.getServerConfiguration (StagingMojo.java:93)      at org.sonatype.nexus.maven.staging.StagingDeployMojo.doExecute (StagingDeployMojo.java:94)      at org.sonatype.nexus.maven.staging.StagingDeployMojo.execute (StagingDeployMojo.java:90)  {quote}    A deploy using the same setup with the maven-deploy-plugin succeeds.      Tested using:    * Apache Maven 3.6.1  * nxrm3-maven-plugin:1.0.2          ",Bug,Major,Open,"2019-07-25 20:50:47","2019-07-25 19:50:47",0
"Sonatype Nexus","Repair - Reconcile component database from blobstore task dry run option can block download of hosted assets which do not have an owning component","h4. Problem Summary    Some repository formats allow storing asset records without an owning component. When the Dry Run option of the Repair - Reconcile component database from blobstore task is used, logic is triggered that incorrectly deletes such asset records from the component database. The related blobs are seemingly not deleted from the blobstore ( ie. they are recoverable ) but the assets are no longer downloadable after being deleted from the database.    Recover the incorrectly deleted asset records by running a Repair - Reconcile component database from blobstore task, without the Dry Run option enabled.    h4. Sample Reproduce for Yum Hosted repo    1. Create a yum-hosted repo at zero depth   2. Deploy an rpm file into it. I used [http://mirror.centos.org/centos/7/os/x86_64/Packages/389-ds-base-1.3.8.4-15.el7.x86_64.rpm] and this command:    3. Attempt to download the RPM file at the same path you uploaded it. This should work with 200 response.   4. After 60 seconds)expected), the Browse and Search views show the repodata/* files are generated. Attempt to download these metadata files - it works.   5. Create a Repair - Reconcile component database from blobstore task. *Select the Dry Run option.* Run the task.   6. *Bug 1*: Logging reports that an RPM file would have been restored by the task:    Why would it restore that file? The file downloads fine, is a valid RPM and there are no inconsistencies between blobstore and database.   7. 60 seconds after the reconcile task finishes, the YUM metadata is rebuilt automatically - supposedly from the manipulation which did not happen? ( ie dry run ):    8. Now you are in the following state:   * the RPM blob file is still in the blob store, not marked soft-deleted or changed in any way from when it was first uploaded   * the Browse view only shows os/x86_64/Packages empty node ( normal according to docs after running reconcile )   * the Search view for yum-hosted is empty ( normal according to docs after running reconcile )   * *Bug 2:* attempts to download yum-hosted metadata files or the rpm file all fail with 404    9. Run the Reconcile component database from blobstore task again, this time without the Dry Run option selected. After 60 seconds yum metadata is rebuilt and repodata files and the rpm is downloadable.    The dry run option is essentially acting like it is manipulating the database in the inverse of reconciling.    h4. Expected   - dry run should not trigger any other tasks, or act like it actually did anything other than log what it would do   - reconcile task had no business manipulating a perfectly good and working RPM, even if this was not dry run   - rpms that are not soft-deleted or manipulated visibly should still be downloadable from the yum-hosted repo, regardless of the presence of metadata",Bug,Critical,Closed,"2019-07-23 14:51:15","2019-07-23 13:51:15",2
"Sonatype Nexus","java.io.IOException: Write end dead occurs when group members do not use the same blobstore","When requesting components from a group repository that contains member repos configured with different blob stores, an org.sonatype.nexus.blobstore.api.BlobStoreException: java.io.IOException: Write end dead, Cause: Write end dead error can randomly occur causing build/install failure.    *Reproduce (using NPM):*   1. Create 2 (file-based) blob stores e.g. store_A and store_B   2. Create the following repo setup:   NPM_Group (store_A): [NPM_Hosted (store_A), NPM_Proxy (store_B)]    3. Upload some components to the hosted repo.   4. Perform an npm install against the group repo that will request components from both member repos.    *Expected:*   Install completes with all required components served.    *Actual:*   Install fails with org.sonatype.nexus.blobstore.api.BlobStoreException: java.io.IOException: Write end dead, Cause: Write end dead e.g.        Issue not observed when repos are using the same blob store.",Bug,Major,Closed,"2019-06-19 12:27:03","2019-06-19 11:27:03",5
"Sonatype Nexus","clarify which databases are exported per NXRM version by task Admin - Export databases for backup","After updating from Nexus 3.15.2 to version 3.16.1 I discovered that only 4 databases are exported by the task _Admin - Export databases for backup_:   * security   * acccesslog   * config   * component    But the [help.sonatype|https://help.sonatype.com/repomanager3/backup-and-restore/configure-and-run-the-backup-task] page says that the task should also export databases:   * audit   * analytics         All of the 6 databases were exported by the same task before the update to Nexus 3.16.1.         *For the Nexus 3.16.1 is exporting only 4 databases is an issue or a feautre?*         Task log:     ",Bug,Medium,Closed,"2019-06-17 16:45:19","2019-06-17 15:45:19",1
"Sonatype Nexus","nxrm3-maven-plugin does not deploy pom","When using the plugin with {{mvn install nxrm3:staging-deploy -Dtag=1.2.3}} I see that the actual artifact (jar file) of my project is uploaded to my Nexus repository. However, the {{pom.xml}} of my project is missing in the Nexus repository and it looks like it was not uploaded.    Is this a bug or am I missing something in my configuration (I haven't specified a {{packaging}} type in my pom)?    For reference, I'm using the plugin with the following configuration:  ",Bug,Major,Closed,"2019-05-29 07:36:11","2019-05-29 06:36:11",5
"Sonatype Nexus","Enable HealthCheck button errors when clicked (with limited permission)","I noticed if I have only repository admin privileges (e.g. just ) when editing a repository, the Enable HealthCheck button is enabled and clickable but when I do so, I get the below error in JS console as well as the attached screen.  I was able to reproduce this reliably after clearing my browser cache.  Beforehand, I noticed an unhandled JS console error (was unable to repro so no screen) and later permissions seemed checked correctly, so this may not be an easy one to reproduce without cache clear (reiterate, seemed to repro 100% of the time post-cache clear).    Console error:      Despite the error, nothing happens with RHC, so marking minor.    I was surprised the button was enabled with lack of permission (contrary to the rest of the app) but maybe that is part of the problem rather than a solution.",Bug,Minor,Open,"2019-05-27 22:20:22","2019-05-27 21:20:22",3
"Sonatype Nexus","GroupFacetImpl#isStale should not fail request if CacheInfo is missing","GroupFacetImpl#isStale should be more lenient in its checking of whether CacheInfo is missing. Instead, it should assume in both group/proxy code that the asset is stale if CacheInfo is missing, and log a warning.    [https://github.com/sonatype/nexus-public/blob/f4316cbb68f776d4af2dafe1aca146c138783e50/components/nexus-repository/src/main/java/org/sonatype/nexus/repository/group/GroupFacetImpl.java#L242]    Example of failed request:  {quote}org.sonatype.nexus.repository.httpbridge.internal.ViewServlet - Failure servicing: GET /repository/xxx/yyy    java.lang.IllegalStateException: Missing: org.sonatype.nexus.repository.cache.CacheInfojava.lang.IllegalStateException: Missing: org.sonatype.nexus.repository.cache.CacheInfo at com.google.common.base.Preconditions.checkState(Preconditions.java:504) at org.sonatype.nexus.common.collect.AttributesMap.require(AttributesMap.java:207) at org.sonatype.nexus.repository.group.GroupFacetImpl.isStale(GroupFacetImpl.java:243) at org.sonatype.nexus.repository.npm.internal.NpmGroupFacet.getFromCache(NpmGroupFacet.java:222) at org.sonatype.nexus.repository.npm.internal.NpmGroupFacet$getFromCache.call(Unknown Source) at org.sonatype.nexus.repository.npm.internal.NpmGroupPackageHandler.buildMergedPackageRoot(NpmGroupPackageHandler.groovy:68)  {quote}  *Update*:  I've attached a patch which fixes this issue for Nexus Repo 3.18.1-01.  To apply this patch, download the attached jar and replace  this file in the installation with it:  {quote}   nexus-3.18.1-01/system/org/sonatype/nexus/nexus-repository/3.18.1-01/nexus-repository-3.18.1-01.jar  {quote}  Then restart Nexus Repo.    The sha1 checksum of the attached jar is:     fc6d69a387e60370aed07d15fb8c6318602351ea",Bug,Major,Closed,"2019-05-17 16:51:29","2019-05-17 15:51:29",0
"Sonatype Nexus","Cleanup service task failing with NPE","Cleanup service task fails consistently on our nexus repository. I have tried deleting it and restarting the service to recreate it. It always end up in the same state         Log from the general log    Log from the specific task execution log file    I realize this is not a support channel, but I hope this is something that can help getting the bug we are seeing fixed.",Bug,Major,Closed,"2019-05-08 09:56:54","2019-05-08 08:56:54",0
"Sonatype Nexus","Yum repository configured through script API cache not working","when creating a yum proxy; according to [https://support.sonatype.com/hc/en-us/articles/115010182627-Understanding-Caching-Configuration] setting *maximum metadata age to 0* should make sure that new versions are always found.    I have ran the following tests scenario:   * create a small repository with *my.1.rpm*   * create proxy in nexus   * install using this proxy: works fine   * now add *my.2.rpm* in the repository   * try to update; yum/zypper says no new versions are to be found (not even after forcing refresh,...)    -Note that when I set *maximum metadata age to 1* and I wait one minute, then yum/zypper does find the new package. However I would like to set this to 0 in order to never have to wait a minute. Yet that configuration does not seem to work; the nexus cache is never invalidated somehow.-    *EDIT*    I have been able to pin down the problem more specifically: I create the proxy in nexus using the script API (a major hassle by the way). The repository seems correctly created but doesn't seem to work perfectly well unless I change something manually. The exact same configuration entered manually in the UI works fine.   * API configured repo:   ** I use python to do something similar to this:    *** curl -X POST -u admin:admin123 --header 'Content-Type: application/json' [http://localhost:8081/service/rest/v1/script] -d '\{name:test,type:groovy,content:repository.createYumProxy('\''test'\'', '\''http://repository:8080/'\'')}'   *** curl -X POST -u admin:admin123 --header Content-Type: text/plain '[http://127.0.0.1:8081/service/rest/v1/script/test/run']   ** the exact script that I post (more readable here than with all those escaped quotes):   *** repository.createYumProxy('\{name}', '\{url}');   *** repository.getRepositoryManager().get('\{name}').getConfiguration().getAttributes().'proxy'.'contentMaxAge' = 0;   *** repository.getRepositoryManager().get('\{name}').getConfiguration().getAttributes().'proxy'.'metadataMaxAge' = 0;   *** repository.getRepositoryManager().get('\{name}').getConfiguration().getAttributes().'negativeCache'.'timeToLive' = 0;   *** repository.getRepositoryManager().get('\{name}').getConfiguration().getAttributes().'cleanup' = ['policyName': null];   * manually configured repo:   ** *create yum (proxy)*   ** name: test   ** url: [http://repository:8080|http://repository:8080/]   ** maximum component age: 0   ** maximum metadata age: 0   ** not found cache TTL: 0   ** *create repository*    I don't see a single difference between the manually configured repository and the one I configured using the script API. Yet the manually configured repository is correctly functional.    *EDIT2*    using the script API again to fetch the repository attributes I found that a manually configured repository was slightly different from the one configured through the API:   * API configured repo:   ** httpclient:[connection:[blocked:false, autoBlock:true]],   proxy:[remoteUrl:http://repository:8080/, contentMaxAge:0, metadataMaxAge:0],    negativeCache:[enabled:true, timeToLive:0],    storage:[blobStoreName:default, strictContentTypeValidation:true]   * manually configured repo:   ** httpclient:[blocked:false, autoBlock:true],   proxy:[remoteUrl:http://repository:8080/, contentMaxAge:0.0, metadataMaxAge:0.0],    routingRules:[routingRuleId:null],    negativeCache:[enabled:true, timeToLive:0.0],    storage:[blobStoreName:default, strictContentTypeValidation:true],    cleanup:[policyName:None]   * so I enhanced my script to create a proxy repository through the API like this:   ** repository.createYumProxy('\{name}', '\{url}')   ** repository.getRepositoryManager().get('\{name}').getConfiguration().getAttributes().'httpclient' = repository.getRepositoryManager().get('\{name}').getConfiguration().getAttributes().'httpclient'.'connection'   ** repository.getRepositoryManager().get('\{name}').getConfiguration().getAttributes().'routingRules' = ['routingRuleId':'null']   ** repository.getRepositoryManager().get('\{name}').getConfiguration().getAttributes().'proxy'.'contentMaxAge' = 0.0   ** repository.getRepositoryManager().get('\{name}').getConfiguration().getAttributes().'proxy'.'metadataMaxAge' = 0.0   ** repository.getRepositoryManager().get('\{name}').getConfiguration().getAttributes().'negativeCache'.'timeToLive' = 0.0   ** repository.getRepositoryManager().get('\{name}').getConfiguration().getAttributes().'cleanup' = ['policyName':'None']   * now both a manually configured repository give exactly the same response (except for the order of the attributes). Yet still the cache of the repository configured through the API seems never to expire...    *EDIT3:*    **I have attached a complete test scenario to this ticket; running *docker-compose up* ** will run the tests. The tests will fail because the newest version of the rpm cannot be installed.  If you want to inspect and/or run the tests manually; then change the COMMAND in the Dockerfile to sleep; and you can then run the tests manually and inspect the test container.",Bug,Major,Closed,"2019-05-07 10:19:50","2019-05-07 09:19:50",0
"Sonatype Nexus","Confirmation when promoting a blob store","Fire up Nexus 3.16.1 with default configuration, go to repository --> blob stores.    Click on the default blob store, and then hit promote to group.    No warning is given, the blob store is immediately promoted.  This operation cannot be undone because the new group blobstore is in use by 7 repositories, and the promoted blobstore is a member of the group.      It is entirely too easy to make this irreversible configuration change by mistake.    *Expected*:  A confirmation should be given before performing an operation which cannot be undone.",Improvement,Major,Closed,"2019-05-01 20:13:29","2019-05-01 19:13:29",2
"Sonatype Nexus","nxrm3-maven-plugin when invoked using debug -X will log HTTP wire level traffic","Maven -X debug option is useful to examine HTTP traffic, in particular HTTP headers being sent and received by the nxrm3 maven plugin. This is logged by *org.apache.http* at *DEBUG* level.    Argument -X also seems to also log *org.apache.http.wire* level logging. This is not desired, duplicates log statements for *org.apache.http* at *DEBUG* level and makes Maven debug logs extremely verbose and <USER>to parse as all binary content is dumped to the maven log.    h4. Expected    When Maven execution is passed -X, all nxrm3-maven-plugin HTTP traffic:   * SHOULD NOT log *org.apache.http.wire* logger *DEBUG* level and below log statements   * should log *org.apache.http* logger *DEBUG* level and below statements    This is how the nexus-staging-maven-plugin worked.  ",Bug,Major,Open,"2019-05-01 19:55:35","2019-05-01 18:55:35",0
"Sonatype Nexus","nxrm3-maven-plugin has no documentation for most parameters","Run:    {quote}  mvn help:describe -Dplugin=org.sonatype.plugins:nxrm3-maven-plugin -Ddetail  {quote}    You'll see that most parameters have no documentation.  Example:               ",Bug,Trivial,Open,"2019-04-30 17:24:54","2019-04-30 16:24:54",1
"Sonatype Nexus","nxrm3-maven-plugin requires explicitly disabling the deploy plugin in order to work","In order to make the nxrm3-maven-plugin plugin work, you need to explicitly disable the deploy plugin:        This shouldn't be necessary, the nxrm2 staging plugin automatically takes over the deploy in Maven 3 builds, there was no need to have the above configuration.    The configuration where this was observed was:        ",Bug,Minor,Open,"2019-04-30 16:17:56","2019-04-30 15:17:56",2
"Sonatype Nexus","/service/metrics/healthcheck returns 500 status code if a single healthcheck fails","NXRM 3 implements server *status* checks using dropwizard metrics library and and exposes these at the /service/metrics/healthcheck endpoint.    The purpose of this endpoint is to report server health status from the perspective of all implemented Server Status checks ( the same list of statuses one sees in the UI under Adminsitration -> Support Tools -> Status ).    h4. Problem    If a single status check fails, the resource returns a 500 status code.    h4. Expected    If this resource can render a JSON response ( code that processes status checks is active, connector is on ) it should NOT return a 500 status code, even if one or more status checks fails.    A 200 status code is a more appropriate code for the NXRM3 use case of this endpoint if a JSON response can be rendered.    All exceptions thrown by a single status check must be caught ( expected to include indication of the caught error in the JSON response, per status check ), and therefore a single status check should never render this entire endpoint broken.    h4. Additional Info    Do not rely on this endpoint for node and cluster health, say for a load balancer, or for triggering automatic node host restarts, as may be the case if Kubernetes deployment is being used. That is not the intended use case of this endpoint.  ",Bug,Major,Closed,"2019-04-29 20:17:51","2019-04-29 19:17:51",2
"Sonatype Nexus","Offline/Misconfigured blob store should be flagged in UI","Follow on to NEXUS-18103.  When a blob store can't start correctly NXRM now starts correctly and allows reconfiguration.  However, it's not apparent from the UI that the blob store has a problem.  NXRM should flag the blob store in the UI as offline.",Improvement,Major,Closed,"2019-04-25 16:55:25","2019-04-25 15:55:25",1
"Sonatype Nexus","Exception thrown in metadata rebuild stops snapshot removal task completely.","     I can't tell what the exact cause of this was, but this exception caused the maven metadata rebuild at the end of a snapshot removal task to stop entirely.      The task should not stop because it wasn't able to rebuild one maven-metadata.xml file.    The task should properly log the file(s) involved in the failure if an exception occurs so we can find out the cause.     {quote}  2019-04-20 09:02:22,325-0400 ERROR [quartz-2-thread-11]  *SYSTEM org.sonatype.nexus.repository.maven.tasks.RemoveSnapshotsTask - Failed to run task 'Remove Maven snapshots from maven-snapshots' on repository 'maven-snapshots'  java.lang.RuntimeException: java.io.EOFException: input contained no data   at org.sonatype.nexus.repository.maven.internal.hosted.metadata.MetadataUpdater.update(MetadataUpdater.java:111)   at org.sonatype.nexus.repository.maven.internal.hosted.metadata.MetadataUpdater.processMetadata(MetadataUpdater.java:72)   at org.sonatype.nexus.repository.maven.internal.hosted.metadata.MetadataRebuilder$Worker.lambda$2(MetadataRebuilder.java:461)   at org.sonatype.nexus.transaction.OperationPoint.proceed(OperationPoint.java:64)   at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:56)   at org.sonatype.nexus.transaction.Operations.transactional(Operations.java:200)   at org.sonatype.nexus.transaction.Operations.call(Operations.java:146)   at org.sonatype.nexus.repository.maven.internal.hosted.metadata.MetadataRebuilder$Worker.rebuildMetadataInner(MetadataRebuilder.java:415)   at org.sonatype.nexus.repository.maven.internal.hosted.metadata.MetadataRebuilder$Worker.rebuildMetadata(MetadataRebuilder.java:382)   at org.sonatype.nexus.repository.maven.internal.hosted.metadata.MetadataRebuilder.rebuild(MetadataRebuilder.java:120)   at org.sonatype.nexus.repository.maven.internal.hosted.metadata.MetadataRebuilder.deleteAndRebuild(MetadataRebuilder.java:240)   at org.sonatype.nexus.repository.maven.internal.hosted.MavenHostedFacetImpl.deleteMetadata(MavenHostedFacetImpl.java:129)   at org.sonatype.nexus.repository.maven.internal.RemoveSnapshotsFacetImpl.removeSnapshots(RemoveSnapshotsFacetImpl.java:141)   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39)   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:272)   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53)   at org.sonatype.nexus.repository.maven.tasks.RemoveSnapshotsTask.execute(RemoveSnapshotsTask.java:72)   at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)   at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)   at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374)   at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)   at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)   at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)   at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)   at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)   at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)   at org.sonatype.nexus.repository.maven.tasks.RemoveSnapshotsTask.execute(RemoveSnapshotsTask.java:61)   at org.sonatype.nexus.repository.RepositoryTaskSupport.execute(RepositoryTaskSupport.java:73)   at org.sonatype.nexus.scheduling.TaskSupport.call(TaskSupport.java:93)   at org.sonatype.nexus.quartz.internal.task.QuartzTaskJob.doExecute(QuartzTaskJob.java:145)   at org.sonatype.nexus.quartz.internal.task.QuartzTaskJob.execute(QuartzTaskJob.java:108)   at org.quartz.core.JobRunShell.run(JobRunShell.java:202)   at org.sonatype.nexus.thread.internal.MDCAwareRunnable.run(MDCAwareRunnable.java:40)   at org.apache.shiro.subject.support.SubjectRunnable.doRun(SubjectRunnable.java:120)   at org.apache.shiro.subject.support.SubjectRunnable.run(SubjectRunnable.java:108)   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   at java.util.concurrent.FutureTask.run(FutureTask.java:266)   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)   at java.lang.Thread.run(Thread.java:748)  Caused by: java.io.EOFException: input contained no data   at org.codehaus.plexus.util.xml.pull.MXParser.fillBuf(MXParser.java:3037)   at org.codehaus.plexus.util.xml.pull.MXParser.more(MXParser.java:3080)   at org.codehaus.plexus.util.xml.pull.MXParser.parseProlog(MXParser.java:1451)   at org.codehaus.plexus.util.xml.pull.MXParser.nextImpl(MXParser.java:1436)   at org.codehaus.plexus.util.xml.pull.MXParser.next(MXParser.java:1131)   at org.apache.maven.artifact.repository.metadata.io.xpp3.MetadataXpp3Reader.read(MetadataXpp3Reader.java:913)   at org.apache.maven.artifact.repository.metadata.io.xpp3.MetadataXpp3Reader.read(MetadataXpp3Reader.java:519)   at org.apache.maven.artifact.repository.metadata.io.xpp3.MetadataXpp3Reader.read(MetadataXpp3Reader.java:548)   at org.sonatype.nexus.repository.maven.internal.MavenModels.readMetadata(MavenModels.java:83)   at org.sonatype.nexus.repository.maven.internal.hosted.metadata.MetadataUtils.read(MetadataUtils.java:84)   at org.sonatype.nexus.repository.maven.internal.hosted.metadata.MetadataUpdater.lambda$0(MetadataUpdater.java:93)   at org.sonatype.nexus.transaction.OperationPoint.proceed(OperationPoint.java:64)   at org.sonatype.nexus.transaction.Operations.transactional(Operations.java:196)   at org.sonatype.nexus.transaction.Operations.call(Operations.java:146)   at org.sonatype.nexus.repository.maven.internal.hosted.metadata.MetadataUpdater.update(MetadataUpdater.java:89)   ... 39 common frames omitted  {quote}     ",Bug,Major,Closed,"2019-04-24 18:52:19","2019-04-24 17:52:19",3
"Sonatype Nexus","Tar dependancies not working with bower resolver","Reported here:  https://github.com/sonatype/bower-nexus3-resolver/issues/27    PR suggestion:  https://github.com/sonatype/bower-nexus3-resolver/pull/28    Submitter notes test was unable to be fixed, so that needs looked at.  Suspect we need additional tests as well.",Bug,Major,Open,"2019-04-18 16:34:45","2019-04-18 15:34:45",0
"Sonatype Nexus","UnsupportedOperationException: Maintenance method 'getDatabaseStatus' or 'getDatabaseRole' is only supported in clustered mode when generating support zip","Generating a support zip in 3.16.0 puts 2 giant stack traces in logs. Don't do that.    ",Bug,Major,Closed,"2019-04-18 14:30:37","2019-04-18 13:30:37",2
"Sonatype Nexus","Regression: Yum metadata leaks between trees in a hosted yum repository.","     Set up a hosted yum repository in Nexus Repo 3.16.0 with repodata depth of 1.    Deploy rpm files to it under two separate directories, such as:    Now download the primary.xml.gz file from the tools/repodata directory.  You'll find that it contains all of the rpm files.    *Expected*: Only rpm files in the same tree as the repodata directory should be included in its metadata.    I also tested on 3.11.0, and this bug does not occur in that version.",Bug,Major,Closed,"2019-04-15 18:54:55","2019-04-15 17:54:55",1
"Sonatype Nexus","java.lang.NumberFormatException When Configuring IQ Server via Capabilities","When configuring IQ Server settings via 'Capabilities --> IQ: Server Configuration', a java.lang.NumberFormatException is thrown when saving the settings form.    1. To reproduce, configure an 'IQ: Server Configuration' capability.    2. Fill in all the required fields but leave the 'request timeout' field blank.     3. Save config.    *Expected*:    Config should be saved and Request Timeout should take default global settings.    *Actual*:    java.lang.NumberFormatException is thrown:  {quote}2019-04-09 13:45:10,319+0100 ERROR [qtp1648621026-5318] admin org.sonatype.nexus.extdirect.internal.ExtDirectExceptionHandler - Failed to invoke action method: capability_Capability.update, java-method: org.sonatype.nexus.coreui.internal.capability.CapabilityComponent.update   java.lang.NumberFormatException: For input string:    at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)   at java.lang.Integer.parseInt(Integer.java:592)   at java.lang.Integer.valueOf(Integer.java:766)   at com.sonatype.nexus.clm.ClmConfiguration.parseTimeout(ClmConfiguration.java:198)   at com.sonatype.nexus.clm.ClmConfiguration.<init>(ClmConfiguration.java:85)   at com.sonatype.nexus.clm.internal.capability.ClmCapabilityDescriptor.createConfig(ClmCapabilityDescriptor.java:164)   at com.sonatype.nexus.clm.internal.capability.ClmCapabilityDescriptor.createConfig(ClmCapabilityDescriptor.java:1)   at org.sonatype.nexus.capability.CapabilityDescriptorSupport.validateConfig(CapabilityDescriptorSupport.java:154)   at org.sonatype.nexus.capability.CapabilityDescriptorSupport.validate(CapabilityDescriptorSupport.java:125)   at org.sonatype.nexus.internal.capability.DefaultCapabilityRegistry.update(DefaultCapabilityRegistry.java:208)   at org.sonatype.nexus.capability.CapabilityRegistry$update$1.call(Unknown Source)   at org.sonatype.nexus.coreui.internal.capability.CapabilityComponent.update(CapabilityComponent.groovy:151)  {quote}  *Workaround/Alternative*    Configure IQ Server via the IQ Server -> Server UI page.     ",Bug,Minor,Open,"2019-04-09 14:10:01","2019-04-09 13:10:01",1
"Sonatype Nexus","Expensive, error prone check done for content validation of checksums","Currently, the validation of checksum file content is going through the tika mime type evaluation layer.  This is an expensive check, and is error prone for checksums, since they can potentially start with the same magic byte patterns as many different file formats.  See -NEXUS-19018- for a specific example of this.    We should simply do a check that the file contains only hex digits, and the right number of them.  A simple regex match would work for this.    Example: When a Remove Maven snapshots task runs ( or any administrative task like Cleanup Policies) , rebuilds the checksum for a rebuilt maven-metadata.xml file, the generated md5, can fail the entire task:    h4. Expected   - A failure processing a single asset inside the RemoveSnapshotsTask should not stop/fail the entire task. It should keep going and process as many assets as it can ( possible separate issue ).   - We certainly should *not be performing any validation* of our own generated hash files.   - do not do mime type of any hash files, even proxied remotes or uploaded into NXRM - instead use a simpler hash file format detection validation algorithm using a regex or similar - NXRM 2 did that, NXRM 3 should adopt something similar",Bug,Major,Closed,"2019-04-08 20:20:43","2019-04-08 19:20:43",0
"Sonatype Nexus","NullPointerException in NugetLocalGalleryFacetSupport.maintainAggregateInfo","The following exception was noticed in an HA 3.15.2 environment - unclear if this can happen in a non HA-C environment.        h4. Expected    NPE should be avoided.",Bug,Major,Closed,"2019-04-05 18:03:13","2019-04-05 17:03:13",1
"Sonatype Nexus","InvalidContentException for *.der","Attempting to deploy a DER-encoded certificate file to a Maven repository using {{mvn deploy:deploy-file -Dfile=file.der -Dpackaging=der}} (plus other appropriate property defines) fails. The Nexus Repository logs show  {{org.sonatype.nexus.repository.InvalidContentException: Detected content type [text/plain], but expected [application/x-x509-ca-cert]: com/example/certs/MyCA/1.0.0-SNAPSHOT/MyCA.der}}    I am not sure if this bug originates in Maven or Nexus.",Bug,Major,Open,"2019-04-04 17:32:43","2019-04-04 16:32:43",3
"Sonatype Nexus","Go specific search","Although there is no format specific data available for Go support the format should still enable the format specific feature to be consistent with other core formats.",Story,Major,Done,"2019-04-03 06:27:28","2019-04-03 05:27:28",2
"Sonatype Nexus","Multithread S3 blob store upload","The current MultipartUploader is single threaded ([https://github.com/sonatype/nexus-public/blob/master/plugins/nexus-blobstore-s3/src/main/java/org/sonatype/nexus/blobstore/s3/internal/MultipartUploader.java]) and uploads chunks sequentially.    For files larger than 5mb, this introduces a considerable slowdown in upload times. In a local test with a 1gb file, comparing against the S3 command line: uploading via S3 CLI took 21 seconds, NXRM took 680 seconds. Much of this time difference appears to be due the the sequential 5mb chunks.    If the uploader utilizes multiple threads, it should be considerably faster.",Improvement,Major,Closed,"2019-04-02 17:17:07","2019-04-02 16:17:07",2
"Sonatype Nexus","Provide mechanism to test S3 permissions on Blobstore","When using an S3 blobstore, the user is required to define a policy in AWS, following our documentation, and ensure they have the correct permissions.    When things go wrong, we see errors in the log, but don't have an easy way to see any AWS information.    There would be value in having a 'Verify connection' or similar button on an S3 Blobstore that would ensure Nexus has the correct permissions for the various actions, and in case of error, detailing what is missing (if possible).    *Acceptance Criteria*  When provisioning or connecting with S3 fails then an appropriate and more exact error message should be reported to the user. Exception cases should consider invalid access id/access token, insufficient permissions or other policy issues such as kms.",Improvement,Major,Closed,"2019-03-21 16:12:45","2019-03-21 16:12:45",5
"Sonatype Nexus","On first admin login ask user to choose anonymous access configuration","As part of the onboarding process, possibly as part of NEXUS-19461 ask the admin user to choose whether anonymous access should be enabled.    Acceptance   * Don't bug existing users   * Tests continue to pass, ensure there's a development-friendly mode   * Anonymous access should be the default   * Don't impair REST-provisioned instances    Notes   * This feature should explain the two choices clearly so users understand which one they should choose.     ",Story,Major,Done,"2019-03-19 20:41:46","2019-03-19 20:41:46",2
"Sonatype Nexus","HTTP 500 error using search API for objects with ~ in the name","We have an object with a ~ in it's name, if you search for that object Nexus responds with a 500 error e.g     curl 'https://username:<EMAIL>/service/rest/v1/search?group=&repository=apt&format=raw&name=test/foo~bar' -v     Returns:     > GET /service/rest/v1/search?group=&repository=apt&format=raw&name=test/foo~bar HTTP/2   > Host: nexus.test.com   > User-Agent: curl/7.58.0   > Accept: */*   >   * Connection state changed (MAX_CONCURRENT_STREAMS updated)!   < HTTP/2 500    < server: nginx/1.15.2   < date: Wed, 27 Feb 2019 14:50:18 GMT   < content-type: text/plain;charset=utf-8   < content-length: 98   < x-content-type-options: nosniff   < x-siesta-faultid: 5f9e0e84-e77d-46f5-bd1a-3d063864d0bf   <   * Connection #0 to host nexus.test.com left intact   ERROR: (ID 5f9e0e84-e77d-46f5-bd1a-3d063864d0bf) java.lang.IllegalArgumentException: Invalid query        We are running Nexus 3.15",Bug,Minor,Open,"2019-03-18 09:26:08","2019-03-18 09:26:08",1
"Sonatype Nexus","Error while running task Docker - Delete unused manifests and images on hosted Repository","Hello          When running the task Docker - Delete unused manifests and images, I have since recently the following error:    2019-03-15 07:42:00,733+0000 ERROR [quartz-3-thread-1] *SYSTEM org.sonatype.nexus.repository.docker.tasks.DockerGCTask - Failed to run task 'Docker - Delete unused manifests and images' on repository 'gto-docker-hosted'  java.lang.NullPointerException: null   at org.sonatype.nexus.repository.docker.internal.DockerGCFacetImpl.handleV1Assets(DockerGCFacetImpl.java:116)   at org.sonatype.nexus.repository.docker.internal.DockerGCFacetImpl.processRepository(DockerGCFacetImpl.java:91)   at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:56)   at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:54)   at org.sonatype.nexus.repository.docker.internal.DockerGCFacetImpl.deleteUnusedManifestsAndImages(DockerGCFacetImpl.java:75)   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39)   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:272)   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53)   at org.sonatype.nexus.repository.docker.tasks.DockerGCTask.execute(DockerGCTask.java:44)   at org.sonatype.nexus.repository.RepositoryTaskSupport.execute(RepositoryTaskSupport.java:73)   at org.sonatype.nexus.scheduling.TaskSupport.call(TaskSupport.java:93)   at org.sonatype.nexus.quartz.internal.task.QuartzTaskJob.doExecute(QuartzTaskJob.java:145)   at org.sonatype.nexus.quartz.internal.task.QuartzTaskJob.execute(QuartzTaskJob.java:108)   at org.quartz.core.JobRunShell.run(JobRunShell.java:202)   at org.sonatype.nexus.quartz.internal.QuartzThreadPool.lambda$0(QuartzThreadPool.java:143)   at org.sonatype.nexus.thread.internal.MDCAwareRunnable.run(MDCAwareRunnable.java:40)   at org.apache.shiro.subject.support.SubjectRunnable.doRun(SubjectRunnable.java:120)   at org.apache.shiro.subject.support.SubjectRunnable.run(SubjectRunnable.java:108)   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   at java.util.concurrent.FutureTask.run(FutureTask.java:266)   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   at java.lang.Thread.run(Thread.java:745)  2019-03-15 07:42:00,734+0000 WARN [quartz-3-thread-1] *SYSTEM org.sonatype.nexus.quartz.internal.task.QuartzTaskJob - Task 6a9d42f4-8fd8-45c0-a0ed-5437703cb5b9 : 'Docker - Delete unused Manifests and Images ' [repository.docker.gc] execution failure  org.sonatype.goodies.common.MultipleFailures$MultipleFailuresException: Failed to run task 'Docker - Delete unused manifests and images'; 1 failure   at org.sonatype.goodies.common.MultipleFailures.maybePropagate(MultipleFailures.java:95)   at org.sonatype.nexus.repository.RepositoryTaskSupport.execute(RepositoryTaskSupport.java:84)   at org.sonatype.nexus.scheduling.TaskSupport.call(TaskSupport.java:93)   at org.sonatype.nexus.quartz.internal.task.QuartzTaskJob.doExecute(QuartzTaskJob.java:145)   at org.sonatype.nexus.quartz.internal.task.QuartzTaskJob.execute(QuartzTaskJob.java:108)   at org.quartz.core.JobRunShell.run(JobRunShell.java:202)   at org.sonatype.nexus.quartz.internal.QuartzThreadPool.lambda$0(QuartzThreadPool.java:143)   at org.sonatype.nexus.thread.internal.MDCAwareRunnable.run(MDCAwareRunnable.java:40)   at org.apache.shiro.subject.support.SubjectRunnable.doRun(SubjectRunnable.java:120)   at org.apache.shiro.subject.support.SubjectRunnable.run(SubjectRunnable.java:108)   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   at java.util.concurrent.FutureTask.run(FutureTask.java:266)   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   at java.lang.Thread.run(Thread.java:745)   Suppressed: java.lang.NullPointerException: null   at org.sonatype.nexus.repository.docker.internal.DockerGCFacetImpl.handleV1Assets(DockerGCFacetImpl.java:116)   at org.sonatype.nexus.repository.docker.internal.DockerGCFacetImpl.processRepository(DockerGCFacetImpl.java:91)   at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:56)   at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:54)   at org.sonatype.nexus.repository.docker.internal.DockerGCFacetImpl.deleteUnusedManifestsAndImages(DockerGCFacetImpl.java:75)   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39)   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:272)   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53)   at org.sonatype.nexus.repository.docker.tasks.DockerGCTask.execute(DockerGCTask.java:44)   at org.sonatype.nexus.repository.RepositoryTaskSupport.execute(RepositoryTaskSupport.java:73)   ... 13 common frames omitted  2019-03-15 07:42:00,734+0000 INFO [quartz-3-thread-1] *SYSTEM org.sonatype.nexus.quartz.internal.task.QuartzTaskInfo - Task 'Docker - Delete unused Manifests and Images ' [repository.docker.gc] state change RUNNING -> WAITING (FAILED)              The error is not clear at all, and ideally at least we would  expect more guideline in fixing the issue.    Best Regards ",Bug,Major,Open,"2019-03-15 07:52:13","2019-03-15 07:52:13",3
"Sonatype Nexus","Add ability to cleanup by Never downloaded","We have a repositories (Docker and Maven) with assigned cleanup policy with only Last Downloaded Before field specified in Criteria    And scheduled task of type Admin - Cleanup repositories using their associated policies to apply those policies    But looks like this criteria is not working properly, because I see dozens of maven artifacts and docker tags that haven't been downloaded at all, and created months ago    In repository browser I can see something like this  {code}  Blob created   Thu Jan 17 2019 14:35:20 GMT+0300 (Moscow Standard Time)  Blob updated   Thu Jan 17 2019 14:35:20 GMT+0300 (Moscow Standard Time)  Last downloaded   has not been downloaded  {code}    When I examine task logs, I see something like this  {code:java}  2019-03-14 20:01:37,871+0000 INFO  [quartz-3-thread-19]  *SYSTEM org.sonatype.nexus.cleanup.internal.service.CleanupServiceImpl - Deleting components in repository docker-snapshots using policy Clean_not_in_use_for_2_weeks  2019-03-14 20:01:37,879+0000 INFO  [quartz-3-thread-19]  *SYSTEM org.sonatype.nexus.cleanup.internal.service.CleanupServiceImpl - 2 components cleaned up for repository docker-snapshots  {code}  ",Improvement,Major,Closed,"2019-03-14 20:09:27","2019-03-14 20:09:27",5
"Sonatype Nexus","Conditional GET requests for repodata/repomd.xml files always return 304 unmodified","Conditional GET requests made to repodata/repomd.xml files in a Nexus Repo 2.x yum enabled hosted repository always return 304 unmodified.     This breaks proxying of these repositories from Nexus Repo 3.x.    Reproduce case:    # Enable yum metadata creation on a snapshot maven repository in 2.14.12  # Deploy an rpm into it  # Configure a yum proxy repository in Nexus Repo 3, set the remote to the snapshot repository in Nexus Repo 2  # Retreive 'repodata/repomd.xml through the proxy  # Deploy a new snapshot rpm into Nexus Repo 2  # Verify that yum metadata was regenerated  # Invalidate cache in the Repo 3 proxy  # Retreive 'repodata/repomd.xml through the proxy    Observe that in the Nexus Repo 2 log a 304 unmodified response is sent for the repodata/repomd.xml file.    {quote}  192.168.1.78 - - [13/Mar/2019:13:26:25 -0500] GET /nexus/content/repositories/snapshots/repodata/repomd.xml HTTP/1.1 304 0 3  {quote}    Replaying the same request (with the same headers) through curl shows the same result.            But that file has been modified.  I'm in GMT-5, btw.         ",Bug,Major,Closed,"2019-03-13 18:54:04","2019-03-13 18:54:04",2
"Sonatype Nexus","NPM Group fails to forward requests for updating to members","When proxying NPM packages, the metadata max-age does not work, resulting in new versions of a package not to be downloaded.    To reproduce:    1. Create an NPM proxy repo, proxying to a hosted NPM repo on another NXRM 3 instance _(this can be any NPM registry, a remote Nexus 3 is only for the sake of convenience)._   2. Create an NPM group repo and the add the NPM proxy repo to it.    3. Upload v1.0.0 of NPM package to the remote hosted NPM repo.   4. run _npm i <package>@1.0.0_ against group repo - install works (expected).   5. run _npm i <package>@2.0.0_ against group repo - install fails (expected).    6. Upload v2.0.0 of NPM package to the remote hosted NPM repo.    7. Invalidate the proxy repo cache or wait for 'metadata max-age' time to pass.   8 run _npm i <package>@2.0.0_ against group repo - install fails (unexpected).    9. Invalidate the group repo cache.   10. run _npm i <package>@2.0.0_ against group repo - this time install works.",Bug,Blocker,Closed,"2019-03-12 14:32:11","2019-03-12 14:32:11",3
"Sonatype Nexus","PyPi hosted repository doesn't update index file after uploading new version of existing component","In the latest 3.15.2 version some changes were made to PyPiHostedFacetImpl to store the simple index html file in the blobstore instead of creating the file on the fly.    This introduced a bug.  When uploading a new version of an existing component the deleteIndex function does not delete the file.  This causes the file to remain in the initial state when it was created and fetching the latest version of a component does not work correctly.    *3.15.2-01 Patch*:    A patch is attached to this issue which fixes this problem for 3.15.2-01.  Note that this patch is only applicable to that version, do not try to install it in any other version.    To apply this patch, shut down Nexus, and replace the following jar file with the one attached on this issue which has the same file name.    {{nexus-3.15.2-01/system/org/sonatype/nexus/plugins/nexus-repository-pypi/3.15.2-01/nexus-repository-pypi-3.15.2-01.jar}}    *3.16.0-01 Patch*:    A patch is attached to this issue which fixes this problem for 3.16.0-01.  Note that this patch is only applicable to that version, do not try to install it in any other version.    To apply this patch, shut down Nexus, and replace the following jar file with the one attached on this issue which has the same file name.    {{nexus-3.16.0-01/system/org/sonatype/nexus/plugins/nexus-repository-pypi/3.16.0-01/nexus-repository-pypi-3.16.0-01.jar}}    *3.16.1-02 Patch*    A patch is attached to this issue which fixes this problem for 3.16.1-02.  Note that this patch is only applicable to that version, do not try to install it in any other version.    To apply this patch, shut down Nexus, and replace the following jar file with the one attached on this issue which has the same file name.    {{nexus-3.16.1-02/system/org/sonatype/nexus/plugins/nexus-repository-pypi/3.16.1-02/nexus-repository-pypi-3.16.1-02.jar}}    *3.16.2-01 Patch*    A patch is attached to this issue which fixes this problem for 3.16.2-01.  Note that this patch is only applicable to that version, do not try to install it in any other version.    To apply this patch, shut down Nexus, and replace the following jar file with the one attached on this issue which has the same file name.    {{nexus-3.16.1-02/system/org/sonatype/nexus/plugins/nexus-repository-pypi/3.16.1-02/nexus-repository-pypi-3.16.1-02.jar}}    h4. Diagnosis    We found that this was caused by characters in the package names that needed to be normalized (https://www.python.org/dev/peps/pep-0503/#normalized-names). The caching mechanism works be generating and saving the index when it is fetched and then deleting the index file whenever the contents of the repository change. In some cases the delete failed because it was looking for an index using a non-normalized name.    Once this fix is released changes to the repository will correctly remove the index and the updated index will be available on the next fetch. After upgrade there may be a small number of cases where new packages (that contain . or _ characters in there name) have been uploaded and the index hasn't been invalidated, this will be obvious because the latest version of that package won't be available. Both uploading a new version of the package or deleting the index file in these cases will fix the problem.    To delete an index use the browse function in the UI and find the corresponding index file under the /simple/ tree node and then delete the asset.",Bug,Blocker,Closed,"2019-03-06 08:26:27","2019-03-06 08:26:27",0
"Sonatype Nexus","Nexus generated yum metadata doesn't match mirror.centos.org","We have a team using Nexus to mirror an upstream centos yum repository (using a proxy style repo is not an option because they need complete control over the rpms). After synching a number of repos, including [http://mirror.centos.org/centos/7.6.1810/os/] and [http://mirror.centos.org/centos/7.6.1810/updates/], the directory structure in Nexus is as follows:    The repodata depth is set to 5. We've setup a single test repo on a test machine:    We then attempt to install the perl-Test-Harness package. With the baseurls pointed to the centos mirror the package dependencies resolve correctly and yum install everything just fine. If we then flip the baseurls to point to our Nexus instance (as in the snippet above) we receive the following error:    Looking at the error (running the command with a higher level of output confirms) that the epoch is missing from some metadata somewhere. Looking through the rpms and metadata reveals that the primary.xml file generated by Nexus doesn't match what's upstream (everything else is consistent). Specifically the requires section for perl-Test-Harness:      I was able to reproduce these results by putting the rpm in question in its own directory and running createrepo which results in metadata that matches the centos mirror. I then put the rpm into it's own Nexus hosted yum repo, and the metadata matches what we're seeing in the other Nexus repo.    The rpm is available at [http://mirror.centos.org/centos/7.6.1810/os/x86_64/Packages/perl-Test-Harness-3.28-3.el7.noarch.rpm]. I tried attaching the file here, as well as some of the metadata files, but getting a token missing error from Jira. Here's the sha256:  ",Bug,Major,Open,"2019-03-05 19:06:46","2019-03-05 19:06:46",0
"Sonatype Nexus","Proxy to a Nexus firewall proxy repos returns 404 for quarantined artifacts","A proxy in Nexus A, which points to a proxy repo on Nexus B. The proxy on Nexus B has firewall enabled with quarantine.    When a request comes in, for a component that has been quarantined, Nexus B will return a 403, but the proxy in Nexus A will then return a 404.    Expectation is that Nexus A proxy should also return a 403, so that it is clear why the build failed to the end developer.    Many customers will use a layered approach with Nexus instances, where Nexus instance used by builds do not have direct access to outside internet and firewall is enabled on the Nexus instance that does have outside access.",Bug,Major,Closed,"2019-03-01 11:40:18","2019-03-01 11:40:18",3
"Sonatype Nexus","Anonymous docker access does not work if anonymous user is changed from default","Configure a docker repository to allow anonymous access, and make sure the docker bearer token security realm is enabled.    Verify that anonymous docker access works.    Now create a new default realm user, and grant them the nx-anonymous role.     Go to security/anonymous, and set this new user as the anonymous user.    You will find that docker anonymous access no longer works. ",Bug,Medium,Open,"2019-02-26 18:58:02","2019-02-26 18:58:02",2
"Sonatype Nexus","Invalid JSON input error when loading some NPM packages","I try to install protoduck@5.0.1 ([https://www.npmjs.com/package/protoduck)] from my Nexus OSS 3.14.0-04 configured as NPM proxy.    NPM responds with error npm ERR! 404 Not Found: protoduck@latest and Nexus logs Invalid JSON input (complete stack-trace in attachment).    This package is successfully installed when directly calling registry.npmjs.org         Related issue [https://github.com/zkat/protoduck/issues/6]",Bug,Critical,Closed,"2019-02-26 11:42:59","2019-02-26 11:42:59",0
"Sonatype Nexus","Blob store promotion leads to persistent class cast exception in UI","When trying to promote a blob store the follow exception occurs and leads to a persistent error in the UI that doesn't allow blob stores to be viewed or repos created since the blob store drop down is empty.    Reproduce steps:   # Create a blob store, set a soft quota of 50   # Attempt to promote the blob store   # Observe that the blob store UI no longer works due to class cast exception   # Reboot Nexus Repo.... observe that the blob store UI is still broken",Bug,Major,Closed,"2019-02-26 00:08:34","2019-02-26 00:08:34",1
"Sonatype Nexus","Add REST API to Reset User Token","In order to facilitate administrating NXRM we need a REST endpoint which can be used to reset the user token for a given user.",Story,Major,Done,"2019-02-21 18:50:14","2019-02-21 18:50:14",1
"Sonatype Nexus","Add REST API Endpoint for Content Selector CRUD","In order to support managing teams we need to be able to support CRUD operations for Content Selectors.",Story,Major,Done,"2019-02-19 15:09:16","2019-02-19 15:09:16",3
"Sonatype Nexus","Add REST API to Configure IQ Server","As part of initial server configuration some administrators may need to configure the IQ server used by NXRM. We may want a separate endpoint to enable/disable the server.",Story,Major,Done,"2019-02-19 15:07:26","2019-02-19 15:07:26",2
"Sonatype Nexus","Add REST API to Set NXRM License","As part of initial server configuration some administrators may need to upload a license file.",Story,Major,Done,"2019-02-19 15:04:28","2019-02-19 15:04:28",2
"Sonatype Nexus","Add REST API Endpoint for LDAP CRUD Operations","As part of initial server configuration some administrators may need to configure the LDAP server(s) used by NXRM. They would also need to be able to change the order of the LDAP servers which would be a separate endpoint.",Story,Major,Done,"2019-02-19 15:02:56","2019-02-19 15:02:56",5
"Sonatype Nexus","Add REST API to Set Email Server & Enable/Disable","As part of initial server configuration some administrators may need to configure the email server used by NXRM. They would also need to be able to enable & disable the server which may be separate endpoint(s).",Story,Major,Done,"2019-02-19 14:46:20","2019-02-19 14:46:20",2
"Sonatype Nexus","Add REST API Endpoints for User CRUD Operations","Add REST endpoints to perform CRUD operations on users.",Story,Major,Done,"2019-02-19 14:42:53","2019-02-19 14:42:53",3
"Sonatype Nexus","Docker pull from mcr.microsoft.com results in 403 due to normalization of 307 redirect URLs removing double slash","Pulling from 'mcr.microsoft.com' via a proxy repository results in a 403, whilst pulling directly from 'mcr.microsoft.com' does not:    pull directly:         pulling via proxy repo *(remote URL set to: [https://mcr.microsoft.com|https://mcr.microsoft.com/]):*    *Expected*:    Pulling via proxy repo should behave in the same way as pulling directly from mcr.microsoft.com.",Bug,Major,Closed,"2019-02-15 14:25:38","2019-02-15 14:25:38",3
"Sonatype Nexus","Delete of component or asset from PyPi proxy repository fails","Select a component or an asset in a pypi proxy repository in Nexus Repo 3.15.2, and try to delete it in the UI.  This will fail.    Expected: It should be possible to delete cached content from pypi proxy repositories.    {quote}  2019-02-14 12:46:20,165-0600 ERROR [qtp125386036-232] admin org.sonatype.nexus.extdirect.internal.ExtDirectExceptionHandler - Failed to invoke action method: coreui_Component.deleteAsset, java-method: org.sonatype.nexus.coreui.ComponentComponent.deleteAsset  org.sonatype.nexus.repository.MissingFacetException: No facet of type PyPiHostedFacet attached to repository pypi-proxy   at org.sonatype.nexus.repository.manager.internal.RepositoryImpl.facet(RepositoryImpl.java:322)   at org.sonatype.nexus.repository.pypi.internal.PyPiHostedComponentMaintenance.deleteRootIndex(PyPiHostedComponentMaintenance.java:94)   at org.sonatype.nexus.repository.pypi.internal.PyPiHostedComponentMaintenance.deleteAssetTx(PyPiHostedComponentMaintenance.java:59)   at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:56)   at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:54)   at org.sonatype.nexus.repository.storage.DefaultComponentMaintenanceImpl.deleteAsset(DefaultComponentMaintenanceImpl.java:93)   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39)   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:272)   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53)   at org.sonatype.nexus.repository.storage.DefaultComponentMaintenanceImpl.deleteAsset(DefaultComponentMaintenanceImpl.java:84)   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39)   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:272)   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53)   at org.sonatype.nexus.repository.maintenance.internal.MaintenanceServiceImpl.deleteAsset(MaintenanceServiceImpl.java:85)   at org.sonatype.nexus.repository.maintenance.MaintenanceService$deleteAsset$0.call(Unknown Source)   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:116)   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:136)   at org.sonatype.nexus.coreui.ComponentComponent.deleteAsset(ComponentComponent.groovy:318)   at com.palominolabs.metrics.guice.ExceptionMeteredInterceptor.invoke(ExceptionMeteredInterceptor.java:49)   at com.palominolabs.metrics.guice.TimedInterceptor.invoke(TimedInterceptor.java:47)   at org.sonatype.nexus.validation.internal.ValidationInterceptor.invoke(ValidationInterceptor.java:53)   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49)   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68)   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36)   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:498)   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142)   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133)   at org.sonatype.nexus.extdirect.internal.ExtDirectDispatcher.invokeMethod(ExtDirectDispatcher.java:82)   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63)   at com.softwarementors.extjs.djn.router.processor.standard.StandardRequestProcessorBase.dispatchStandardMethod(StandardRequestProcessorBase.java:73)   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:502)   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequestsInThisThread(JsonRequestProcessor.java:150)   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.process(JsonRequestProcessor.java:133)   at com.softwarementors.extjs.djn.router.RequestRouter.processJsonRequest(RequestRouter.java:83)   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.processRequest(DirectJNgineServlet.java:632)   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.doPost(DirectJNgineServlet.java:595)   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet.doPost(ExtDirectServlet.java:130)   at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:286)   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:276)   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:181)   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:71)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85)   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61)   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)   at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85)   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)   at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101)   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:108)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:68)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:101)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at org.sonatype.nexus.internal.web.HeaderPatternFilter.doFilter(HeaderPatternFilter.java:98)   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104)   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:135)   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73)   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)   at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)   at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1317)   at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)   at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1219)   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175)   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)   at org.eclipse.jetty.server.Server.handle(Server.java:531)   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:352)   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)   at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:281)   at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:102)   at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)   at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)   at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)   at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)   at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)   at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:762)   at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:680)   at java.lang.Thread.run(Thread.java:748)  2019-02-14 12:46:33,683-0600 ERROR [qtp125386036-233] admin org.sonatype.nexus.extdirect.internal.ExtDirectExceptionHandler - Failed to invoke action method: coreui_Component.deleteComponent, java-method: org.sonatype.nexus.coreui.ComponentComponent.deleteComponent  org.sonatype.nexus.repository.MissingFacetException: No facet of type PyPiHostedFacet attached to repository pypi-proxy   at org.sonatype.nexus.repository.manager.internal.RepositoryImpl.facet(RepositoryImpl.java:322)   at org.sonatype.nexus.repository.pypi.internal.PyPiHostedComponentMaintenance.deleteRootIndex(PyPiHostedComponentMaintenance.java:94)   at org.sonatype.nexus.repository.pypi.internal.PyPiHostedComponentMaintenance.deleteComponentTx(PyPiHostedComponentMaintenance.java:85)   at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:56)   at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:54)   at org.sonatype.nexus.repository.storage.DefaultComponentMaintenanceImpl.deleteComponent(DefaultComponentMaintenanceImpl.java:60)   at org.sonatype.nexus.repository.storage.DefaultComponentMaintenanceImpl.deleteComponent(DefaultComponentMaintenanceImpl.java:49)   at org.sonatype.nexus.repository.maintenance.internal.MaintenanceServiceImpl.deleteComponent(MaintenanceServiceImpl.java:97)   at org.sonatype.nexus.repository.maintenance.MaintenanceService$deleteComponent$2.call(Unknown Source)   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:116)   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:136)   at org.sonatype.nexus.coreui.ComponentComponent.deleteComponent(ComponentComponent.groovy:276)   at com.palominolabs.metrics.guice.ExceptionMeteredInterceptor.invoke(ExceptionMeteredInterceptor.java:49)   at com.palominolabs.metrics.guice.TimedInterceptor.invoke(TimedInterceptor.java:47)   at org.sonatype.nexus.validation.internal.ValidationInterceptor.invoke(ValidationInterceptor.java:53)   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49)   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68)   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36)   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:498)   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142)   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133)   at org.sonatype.nexus.extdirect.internal.ExtDirectDispatcher.invokeMethod(ExtDirectDispatcher.java:82)   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63)  {quote}",Bug,Major,Closed,"2019-02-14 18:49:02","2019-02-14 18:49:02",2
"Sonatype Nexus","Components and assets deleted by cleanup policies should be logged only to Cleanup service task log","Post NEXUS-18731, Cleanup Policies log details about what they delete to the nexus.log and Cleanup task log.  h4. Expected    Specific components and assets deleted by cleanup policies should be logged at default levels _only_ to the Cleanup service task log.",Bug,Major,Closed,"2019-02-12 15:37:10","2019-02-12 15:37:10",0.5
"Sonatype Nexus","Unable to proxy private Azure (ACR) registry","Hello,    We are trying to use Nexus 3 as Proxy for a Private ACR registry (for caching), we set the URL and authentication on configuration but I seem that Nexus is not able to correctly authenticate on ACR. See bellow the logs    Using version 3.15-2 of Nexus        Seems a bug to me         A docker login work directly with ACR url and provider username/password    Regards,",Bug,Major,Closed,"2019-02-12 13:03:53","2019-02-12 13:03:53",3
"Sonatype Nexus","NullPointerException in QuartzSchedulerSPI.recoverInterruptedJobs can prevent startup","A NullPointerException can be thrown on nexus startup trying to recover scheduled tasks - this will prevent Nexus from even starting:        h4. Workaround    Edit $data-dir/etc/nexus.properties and add a new line like this:        Then try to start Nexus.",Bug,Critical,Open,"2019-02-12 10:24:50","2019-02-12 10:24:50",2
"Sonatype Nexus","Log spam when remote docker repository returns 400 or 401 and no credentials are configured or remote requires bearer token","Configure a docker proxy repository with a remote URL of https://gcr.io. Then request a manifest that does not exist on the remote through the proxy repository:    [https://localhost:8081/repository/docker-gcr-proxy/v2/abcd/efgh/manifests/1472|https://localhost:8081/repository/repository/docker-gcr/-proxy/v2/abcd/efgh/manifests/1472]    This will result in a warning in the log along with a stack trace because the bearer token can't be retrieved.  The https://gcr.io allows anonymous access, but it will return 401 rather than 404 for images that don't exist on it.  I believe the official docker registry also behaves this way.  The result of this is that you get extremely noisy logs if you are requesting docker images through a group repository, since inevitably some of them won't exist on the remote.    *Expected*:  A 401 should be logged at as it currently does, with no stack trace.    {quote}2019-02-11 00:04:50,847-0700 WARN [qtp-952548213-606] admin org.sonatype.nexus.repository.docker.internal.V2Handlers - Error: GET /v2/abcd/efgh/manifests/1472: 401 - org.sonatype.nexus.repository.docker.internal.V2Exception: authentication required   2019-02-11 00:04:51,117-0700 WARN [qtp-952548213-513] admin org.sonatype.nexus.repository.docker.internal.auth.BearerScheme - Failed to retrieve docker bearer token   org.apache.http.auth.AuthenticationException: Could not retrieve token from [https://gcr.io/v2/token]. Status code: 401   at org.sonatype.nexus.repository.docker.internal.DockerProxyFacetImpl.executeOK(DockerProxyFacetImpl.java:514)   at org.sonatype.nexus.repository.docker.internal.DockerProxyFacetImpl.retrieveBearerToken(DockerProxyFacetImpl.java:457)   at org.sonatype.nexus.repository.docker.internal.DockerProxyFacetImpl.access$3(DockerProxyFacetImpl.java:442)   at org.sonatype.nexus.repository.docker.internal.DockerProxyFacetImpl$2.retrieveBearerToken(DockerProxyFacetImpl.java:841)   at org.sonatype.nexus.repository.docker.internal.auth.DockerAuthHttpClientContext$2.getToken(DockerAuthHttpClientContext.java:76)   at org.sonatype.nexus.repository.docker.internal.auth.BearerScheme.authenticate(BearerScheme.java:105)   at org.apache.http.impl.auth.HttpAuthenticator.doAuth(HttpAuthenticator.java:239)   at org.apache.http.impl.auth.HttpAuthenticator.generateAuthResponse(HttpAuthenticator.java:202)   at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:263)   at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)   at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)   at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)   at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)   at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:72)   at org.sonatype.nexus.repository.httpclient.FilteredHttpClientSupport.lambda$0(FilteredHttpClientSupport.java:56)   at org.sonatype.nexus.repository.httpclient.FilteredHttpClientSupport$$Lambda$377.00000000042A7760.call(Unknown Source)   at org.sonatype.nexus.repository.httpclient.internal.BlockingHttpClient.filter(BlockingHttpClient.java:123)   at org.sonatype.nexus.repository.httpclient.FilteredHttpClientSupport.doExecute(FilteredHttpClientSupport.java:56)   at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)   at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)   at org.sonatype.nexus.repository.docker.internal.DockerProxyFacetImpl.execute(DockerProxyFacetImpl.java:325)   at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.fetch(ProxyFacetSupport.java:405)   at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.fetch(ProxyFacetSupport.java:375)   at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.doGet(ProxyFacetSupport.java:245)   at org.sonatype.nexus.repository.docker.internal.DockerProxyFacetImpl.doGet(DockerProxyFacetImpl.java:859)   at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.lambda$1(ProxyFacetSupport.java:234)   at org.sonatype.nexus.repository.proxy.ProxyFacetSupport$$Lambda$376.00000000042A6A20.call(Unknown Source)   at org.sonatype.nexus.common.io.CooperatingFuture.performCall(CooperatingFuture.java:122)   at com.sonatype.nexus.hazelcast.internal.io.DistributedCooperatingFuture.performCall(DistributedCooperatingFuture.java:50)   at org.sonatype.nexus.common.io.CooperatingFuture.call(CooperatingFuture.java:64)   at org.sonatype.nexus.common.io.ScopedCooperationFactorySupport$ScopedCooperation.cooperate(ScopedCooperationFactorySupport.java:99)   at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.get(ProxyFacetSupport.java:225)   at org.sonatype.nexus.repository.proxy.ProxyHandler.handle(ProxyHandler.java:50)   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)   at org.sonatype.nexus.repository.view.handlers.LastDownloadedHandler.handle(LastDownloadedHandler.java:54)   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)   at org.sonatype.nexus.repository.storage.UnitOfWorkHandler.handle(UnitOfWorkHandler.java:39)   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)   at org.sonatype.nexus.repository.view.Context$proceed.call(Unknown Source)   at org.sonatype.nexus.repository.docker.internal.V2Handlers$_closure16.doCall(V2Handlers.groovy:269)   at sun.reflect.GeneratedMethodAccessor245.invoke(Unknown Source)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)   at java.lang.reflect.Method.invoke(Method.java:508)   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:98)   at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325)   at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:264)   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1034)   at groovy.lang.Closure.call(Closure.java:418)  {quote}  A 400 response may also be logged with a similar large stack trace at WARN level:  ",Bug,Major,Closed,"2019-02-11 21:49:32","2019-02-11 21:49:32",1
"Sonatype Nexus","NPE When Installing Gem with no Date Attribute","When attempting to install a gem that does not contain a date attribute in its spec file a NullPointerException is thrown e.g.    To reproduce with example linux-kstat v0.2.1 gem:   # Configure proxy repo for [https://rubygems.org|https://rubygems.org/]   # On a linux env, run gem install e.g.   #       Expected:    Nexus should handle cases where gem spec does not contain expected values.",Bug,Major,Closed,"2019-02-11 11:08:24","2019-02-11 11:08:24",1
"Sonatype Nexus","S3 Blobstore expiration is at Bucket level - ignores path prefix","When creating an S3 Blobstore, the expiration days can be set.    This is tied to a lifecycle policy on the S3 bucket.    When multiple S3 Blobstores are created in the same bucket - using different path prefixes - they each allow a separate setting for expiration days, however, they simply overwrite the common lifecycle policy.    Either:    1) It should be clear from the UI that they share a single lifecycle policy, and cannot be separately set.    or    2) The lifecycle policy should be maintained with appropriate filters when path prefixes are in place.         Steps to reproduce:   * Create an S3 Blobstore with path prefix of test1 and expiration days set to 10   * Run aws s3api get-bucket-lifecycle-configuration --bucket <bucketName>   * Create a second S3 Blobstore in the same bucket with path prefix of test2 and expiration days set to 20   * Run aws s3api get-bucket-lifecycle-configuration --bucket <bucketName>   * Note that the single expiration rule now has changed to 20 days.",Bug,Major,Closed,"2019-02-11 10:05:02","2019-02-11 10:05:02",3
"Sonatype Nexus","staging promotion move of more than 500 components may fail with IllegalStateException Unable to find component by id","A staging move operation may return a 500 status code:            Reporter that experienced the issue claims this happens when trying to move 5000 components at once. When the move attempts to move less than 500 components at one time, it succeeded.    ",Bug,Major,Closed,"2019-02-08 19:12:09","2019-02-08 19:12:09",3
"Sonatype Nexus","Many threads blocked in Elasticsearch while updating LastDownloaded attribute","The attached thread dump shows 291 threads blocked with the stack trace below.    The method org.sonatype.nexus.repository.view.handlers.LastDownloadedHandler.maybeUpdateLastDownloaded sometimes initiates a database transaction. When this transaction completes, the post-commit hook triggers an event that normally triggers an asynchronous elasticsearch update. However if the event thread pool is totally depleted then it will fall back to dispatching the update on the calling thread, in other words the update will become synchronous (due to a lack of threads).    The database connection will only be released back to the pool once the post-commit hook is complete, so if elasticsearch is also running slow then this can result in the database connection being held open for a long time.    In the case of the user this thread dump came from there is evidence that the disk elasticsearch is as running on is slow, and so this caused a massive backup of database connections.       {quote}qtp540936684-234 #234 prio=5 os_prio=0 tid=0x00007f3480013000 nid=0x170 waiting for monitor entry [0x00007f31f8f49000]   java.lang.Thread.State: BLOCKED (on object monitor)   at org.elasticsearch.action.bulk.BulkProcessor.internalAdd(BulkProcessor.java:283)   - waiting to lock <0x00000006cbbeb6c0> (a org.elasticsearch.action.bulk.BulkProcessor)   at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:268)   at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:264)   at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:250)   at org.sonatype.nexus.repository.search.SearchServiceImpl.lambda$0(SearchServiceImpl.java:321)   at org.sonatype.nexus.repository.search.SearchServiceImpl$$Lambda$289/275393005.accept(Unknown Source)   at java.lang.Iterable.forEach(Iterable.java:75)   at org.sonatype.nexus.repository.search.SearchServiceImpl.bulkPut(SearchServiceImpl.java:315)   at org.sonatype.nexus.repository.search.SearchFacetImpl.bulkPut(SearchFacetImpl.java:133)   at org.sonatype.nexus.repository.search.SearchFacetImpl$$EnhancerByGuice$$7cd025a2.CGLIB$bulkPut$3(<generated>)   at org.sonatype.nexus.repository.search.SearchFacetImpl$$EnhancerByGuice$$7cd025a2$$FastClassByGuice$$753cd40b.invoke(<generated>)   at com.google.inject.internal.cglib.proxy.$MethodProxy.invokeSuper(MethodProxy.java:228)   at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:76)   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39)   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:272)   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53)   at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:77)   at com.google.inject.internal.InterceptorStackCallback.intercept(InterceptorStackCallback.java:55)   at org.sonatype.nexus.repository.search.SearchFacetImpl$$EnhancerByGuice$$7cd025a2.bulkPut(<generated>)   at org.sonatype.nexus.repository.search.IndexRequest.bulkApply(IndexRequest.java:92)   at org.sonatype.nexus.repository.search.IndexRequestProcessor.lambda$0(IndexRequestProcessor.java:139)   at org.sonatype.nexus.repository.search.IndexRequestProcessor$$Lambda$406/297358118.accept(Unknown Source)   at java.util.Optional.ifPresent(Optional.java:159)   at org.sonatype.nexus.repository.search.IndexRequestProcessor.doUpdateSearchIndex(IndexRequestProcessor.java:135)   at org.sonatype.nexus.repository.search.IndexRequestProcessor.maybeUpdateSearchIndex(IndexRequestProcessor.java:115)   at org.sonatype.nexus.repository.search.IndexRequestProcessor$$Lambda$385/1669743823.accept(Unknown Source)   at java.util.HashMap.forEach(HashMap.java:1289)   at org.sonatype.nexus.repository.search.IndexBatchRequest.apply(IndexBatchRequest.java:93)   at org.sonatype.nexus.repository.search.IndexRequestProcessor.process(IndexRequestProcessor.java:99)   at org.sonatype.nexus.repository.search.IndexRequestProcessor.on(IndexRequestProcessor.java:88)   at sun.reflect.GeneratedMethodAccessor235.invoke(Unknown Source)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:498)   at com.google.common.eventbus.Subscriber.invokeSubscriberMethod(Subscriber.java:87)   at com.google.common.eventbus.Subscriber$1.run(Subscriber.java:72)   at org.sonatype.nexus.internal.event.AffinityBarrier.lambda$1(AffinityBarrier.java:91)   at org.sonatype.nexus.internal.event.AffinityBarrier$$Lambda$384/1417277946.run(Unknown Source)   at org.sonatype.nexus.thread.internal.MDCAwareRunnable.run(MDCAwareRunnable.java:40)   at org.apache.shiro.subject.support.SubjectRunnable.doRun(SubjectRunnable.java:120)   at org.apache.shiro.subject.support.SubjectRunnable.run(SubjectRunnable.java:108)   at org.sonatype.nexus.internal.event.EventExecutor.lambda$0(EventExecutor.java:72)   at org.sonatype.nexus.internal.event.EventExecutor$$Lambda$24/155969703.rejectedExecution(Unknown Source)   at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)   at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)   at org.apache.shiro.concurrent.SubjectAwareExecutor.execute(SubjectAwareExecutor.java:129)   at org.sonatype.nexus.internal.event.AffinityBarrier.execute(AffinityBarrier.java:89)   at org.sonatype.nexus.internal.event.EventExecutor.execute(EventExecutor.java:215)   at com.google.common.eventbus.Subscriber.dispatchEvent(Subscriber.java:67)   at com.google.common.eventbus.Dispatcher$ImmediateDispatcher.dispatch(Dispatcher.java:186)   at com.google.common.eventbus.EventBus.post(EventBus.java:212)   at org.sonatype.nexus.internal.event.EventManagerImpl.lambda$0(EventManagerImpl.java:132)   at org.sonatype.nexus.internal.event.EventManagerImpl$$Lambda$213/1347710971.run(Unknown Source)   at org.sonatype.nexus.internal.event.AffinityBarrier.lambda$0(AffinityBarrier.java:75)   at org.sonatype.nexus.internal.event.AffinityBarrier$$Lambda$252/1880833496.run(Unknown Source)   at com.google.common.util.concurrent.SequentialExecutor$1.run(SequentialExecutor.java:120)   at com.google.common.util.concurrent.SequentialExecutor$QueueWorker.workOnQueue(SequentialExecutor.java:227)   at com.google.common.util.concurrent.SequentialExecutor$QueueWorker.run(SequentialExecutor.java:171)   at org.sonatype.nexus.thread.internal.MDCAwareRunnable.run(MDCAwareRunnable.java:40)   at org.apache.shiro.subject.support.SubjectRunnable.doRun(SubjectRunnable.java:120)   at org.apache.shiro.subject.support.SubjectRunnable.run(SubjectRunnable.java:108)   at org.sonatype.nexus.internal.event.EventExecutor.lambda$0(EventExecutor.java:72)   at org.sonatype.nexus.internal.event.EventExecutor$$Lambda$24/155969703.rejectedExecution(Unknown Source)   at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)   at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)   at org.apache.shiro.concurrent.SubjectAwareExecutor.execute(SubjectAwareExecutor.java:129)   at com.google.common.util.concurrent.SequentialExecutor.execute(SequentialExecutor.java:128)   at org.sonatype.nexus.internal.event.AffinityBarrier.coordinate(AffinityBarrier.java:71)   at org.sonatype.nexus.internal.event.EventExecutor.executeWithAffinity(EventExecutor.java:199)   at org.sonatype.nexus.internal.event.EventManagerImpl.post(EventManagerImpl.java:132)   at org.sonatype.nexus.orient.entity.EntityHook.postEvents(EntityHook.java:325)   at org.sonatype.nexus.orient.entity.EntityHook.flushEvents(EntityHook.java:289)   at org.sonatype.nexus.orient.entity.EntityHook.onAfterTxCommit(EntityHook.java:174)   at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.commit(ODatabaseDocumentTx.java:2949)   at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.commit(ODatabaseDocumentTx.java:2870)   at org.sonatype.nexus.repository.storage.StorageTxImpl.commit(StorageTxImpl.java:183)   at sun.reflect.GeneratedMethodAccessor181.invoke(Unknown Source)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:498)   at org.sonatype.nexus.common.stateguard.SimpleMethodInvocation.proceed(SimpleMethodInvocation.java:53)   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39)   at org.sonatype.nexus.common.stateguard.StateGuard$TransitionImpl.run(StateGuard.java:193)   at org.sonatype.nexus.common.stateguard.TransitionsInterceptor.invoke(TransitionsInterceptor.java:56)   at org.sonatype.nexus.common.stateguard.StateGuardAspect$1.invoke(StateGuardAspect.java:66)   at com.sun.proxy.$Proxy218.commit(Unknown Source)   at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:67)   at org.sonatype.nexus.transaction.Operations.transactional(Operations.java:200)   at org.sonatype.nexus.transaction.Operations.call(Operations.java:146)   at org.sonatype.nexus.repository.view.handlers.LastDownloadedHand.maybeUpdateLastDownloaded(LastDownloadedHandler.java:107){quote}",Bug,Major,Closed,"2019-02-08 19:04:35","2019-02-08 19:04:35",3
"Sonatype Nexus","Analytics documentation unchanged after feature removal","In 3.15.0 we removed analytics from NXRM3.  However, the h.s.c documentation has no indication of this whatsoever.  See https://help.sonatype.com/display/NXRM3/Support+Features#SupportFeatures-Analytics.",Bug,Minor,Closed,"2019-02-07 23:01:34","2019-02-07 23:01:34",1
"Sonatype Nexus","Yum Metadata being impartially regenerated.","We have a fairly large yum repository for our <USER>builds.  Our repodata folder rarely seems to be consistent.    It appears that the primary.xml.gz is being updated and repomd.xml but not the -other.xml.gz and -filelists.xml.gz.      I believe this inconsistency is primarily due to NEXUS-18737, but i'm creating this bug as the repomd.xml file shouldn't be changed, and the old metadata should never be deleted, until the new metadata files are written.    I.e. the workflow that I believe should be occuring:    1) User uploads new rpm.    2) Partial Metadata update regenerates primary, filelists, other, persists with new filenames.    3) repomd.xml is updated to the new files.    4) old metadata primary, filelists, other files are deleted.         I believe what is actually occuring:    1) User uploads new rpm.    2) repomd.xml is updated to point to new, uncreated files.    3) primary gets created, written, old primary is deleted    4) NEXUS-18737 occurs, -filelists & -other don't get updated.    5) A full metadata regeneration occurs, which corrects the corrupt metadata.",Bug,Major,Open,"2019-02-07 14:36:53","2019-02-07 14:36:53",2
"Sonatype Nexus","500 error thrown if script is uploaded that already exists","If you upload a script using a name of an existing script an 500 error response is returned, and a scary looking stack trace is logged.    *Expected*: Uploading a script using a name that already exist should return a 409 (conflict) response code, and a message indicating what the problem is.  {quote}2019-02-06 09:52:01,732-0600 WARN [qtp1878281728-67] admin org.sonatype.nexus.siesta.internal.UnexpectedExceptionMapper - (ID 1c90c56c-bdae-41c1-8a7f-b4f5a5b0c821) Unexpected exception: com.orientechnologies.orient.core.storage.ORecordDuplicatedException: Cannot index record #86:0: found duplicated key 'helloWorld' in index 'script_name_idx' previously assigned to the record #85:0   DB name=config INDEX=script_name_idx RID=#85:0   com.orientechnologies.orient.core.storage.ORecordDuplicatedException: Cannot index record #86:0: found duplicated key 'helloWorld' in index 'script_name_idx' previously assigned to the record #85:0   DB name=config   at com.orientechnologies.orient.core.index.OIndexUnique$1.validate(OIndexUnique.java:47)   at com.orientechnologies.orient.core.index.OIndexUnique$1.validate(OIndexUnique.java:37)   at com.orientechnologies.orient.core.index.sbtree.local.OSBTree.put(OSBTree.java:855)   at com.orientechnologies.orient.core.index.sbtree.local.OSBTree.validatedPut(OSBTree.java:261)   at com.orientechnologies.orient.core.index.engine.OSBTreeIndexEngine.validatedPut(OSBTreeIndexEngine.java:169)   at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.doValidatedPutIndexValue(OAbstractPaginatedStorage.java:2519)   at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.validatedPutIndexValue(OAbstractPaginatedStorage.java:2488)   at com.orientechnologies.orient.core.index.OIndexUnique.put(OIndexUnique.java:82)   at com.orientechnologies.orient.core.index.OIndexUnique.put(OIndexUnique.java:35)   at com.orientechnologies.orient.core.index.OIndexAbstract.putInSnapshot(OIndexAbstract.java:956)   at com.orientechnologies.orient.core.index.OIndexAbstract.applyIndexTxEntry(OIndexAbstract.java:790)   at com.orientechnologies.orient.core.index.OIndexAbstract.addTxOperation(OIndexAbstract.java:762)  {quote}",Bug,Major,Open,"2019-02-06 19:24:18","2019-02-06 19:24:18",1
"Sonatype Nexus","Early EOF exception when pushing large files to LFS repository behind nginx","Git-lfs repository configured on nexus 3.14.0-04 behind nginx. The only additional configuration on reverse proxy is client_max_body_size increase to accomodate larger uploads. Git lfs push seems to loop on same file. Nexus log shows the following exceptions:              Turns out nginx proxy request buffering was an issue ([similar issue|https://gitlab.com/gitlab-org/gitlab-ce/issues/31871#note_29478568] is reported against git-lfs backend in gitlab).    Fix is to add the following to location section describing the the proxy definition:    Applying this configuration fixed the issue.         Since git-lfs is commonly used for large files, you may want to amend nexus documentation for reverse proxy configuration.     ",Bug,Minor,Open,"2019-02-06 13:57:59","2019-02-06 13:57:59",0.5
"Sonatype Nexus","Request for artifacts sometimes returns invalid Last-Modified header","Sometimes randomly we get the wrong timezone (CET) in the `Last-Modified` header for artifacts    The header should always be in GMT according to discussion here: [https://stackoverflow.com/a/1639028/2122701] (inc links to RFCs)    Here is a bash loop on the vm hosting nexus for the same artifact. Depending on the frequency it has taken hours to show itself.         You can see generally this is the correct timezone, but sometimes oddly not. See request made at 15:19:00 GMT    I've seen this affecting raw and maven repositories    This runs into issues specifically with Akka HTTP library in our case which expects the header to be correctly formed          ",Bug,Major,Closed,"2019-02-05 15:36:03","2019-02-05 15:36:03",2
"Sonatype Nexus","Format casing not correct","Noticed that in /v1/tags/associate/\{tagName} some of the formats do not match their non NXRM counterparts:    * Nuget (vs NuGet)  * NPM (vs npm)  * PyPi (vs PyPI)    /v1/search seems to have the same issue.  I am guessing this is across the API but I didn't hunt further.",Bug,Trivial,Open,"2019-01-29 21:49:05","2019-01-29 21:49:05",1
"Sonatype Nexus","Expose additional configuration to control AWS SDK connection properties","The AWS SDK for S3 defaults to a max of 50 connections. If more than 50 connections are leased in the pool it will lead to exceptions. One observed case of this leads to a permanent state where the connections are stuck. We should expose options to increase the connection pool limit, change failure behavior, retry policies and/or timeout configuration.    *Acceptance criteria*  * Advanced client configuration options are exposed and used    Other notes: Each S3 blob store creates its own client with corresponding connection pool. httpcomponents documentation (admittedly version 3 and not 4) specifies to try and share the HttpClient in a single application. http://hc.apache.org/httpclient-3.x/performance.html",Story,Major,Raw,"2019-01-25 21:40:23","2019-01-25 21:40:23",2
"Sonatype Nexus","High CPU usage observed caused by a bug in older Jetty version","Customer complained of high CPU usage in Nexus Repo 3.14.0.  A thread dump from their instance showed the following active Jetty threads:         This is due to a bug in Jetty 9.4.11:    [https://github.com/eclipse/jetty.project/issues/2233#issuecomment-404082685]    This has been fixed in 9.4.12:    [https://github.com/eclipse/jetty.project/commit/17b6eee5aca00460913a2b7847325b6e3df39fd2]    So bumping our Jetty version should prevent future occurrences of this.",Bug,Major,Closed,"2019-01-24 21:54:42","2019-01-24 21:54:42",1
"Sonatype Nexus","/service/rest/v1/status returns 200 status code when node is read-only","http://<hostname>:<port>/service/rest/v1/status currently returns 200 status code if the specific node being accessed is in a read-only state.    The main use case of adding this endpoint was to determine the availability of a node that is in an HA-C cluster.    Given an HA-C node is not fully functional unless it is writable, there needs to be an endpoint that returns 503 service unavailable if:    - *the node is read-only*  - all other criteria of a valid HA-C node participant are satisfied    By meeting these requirements, a load balancer can more accurately represent if a node is ready to server ALL types of requests.    Note: _A side benefit_ of this endpoint may have been to see if a node is alive at all ie. is up, but is read-only. We need to answer what endpoint should be used for this use case - should it be this endpoint or something else?            ",Bug,Major,Closed,"2019-01-24 18:19:39","2019-01-24 18:19:39",3
"Sonatype Nexus","Yum duplicates with Disable redeploy setting.","It is possible to upload the same rpm to different paths in Yum hosted repository, even though the metadata version is the same and deployment policy is set to disable redeploy.     Steps to reproduce:    1. curl -v --user 'admin:admin123' --upload-file ./test.rpm [http://localhost:8081/repository/yumhost/1.0/test.rpm]   Uploaded successfully    2. curl -v --user 'admin:admin123' --upload-file ./test.rpm [http://localhost:8081/repository/yumhost/2.0/test.rpm]   Uploaded successfully         Why test.rpm is allowing to upload into /repository/yumhost/2.0 because it is already uploaded in 1.0? - the metadata version is the same.    When I am deleting test.rpm from 2.0 it is also deleting from 1.0 and vice versa. So if did want to removed a duplicate, it removes both. It would better it Nexus prevented the second upload.",Bug,Major,New,"2019-01-24 13:06:52","2019-01-24 13:06:52",0
"Sonatype Nexus","Cleanup tasks fail with No search context found for id error","On three occasions now we've seen the repository cleanup tasks fail with an error like the one below. This seems to occur when the elasticsearch query takes too long to complete.    We've had users work around this by reducing the amount of components selected by the cleanup policy.  But I think this points to a flaw in our code.  If the machine that Nexus Repo is running on is slow, or the cleanup policy is selecting a large number of components it should cause the cleanup to run slowly, not fail entirely.       {quote}2019-01-18 12:20:26,371-0500 WARN [quartz-2-thread-20] *SYSTEM org.sonatype.nexus.quartz.internal.task.QuartzTaskJob - Task 080a3b05-ada1-45a0-91e1-8b715fbc3dc4 : 'Cleanup service' [repository.cleanup] execution failure   org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed   at org.elasticsearch.action.search.SearchScrollQueryAndFetchAsyncAction.onPhaseFailure(SearchScrollQueryAndFetchAsyncAction.java:155)   at org.elasticsearch.action.search.SearchScrollQueryAndFetchAsyncAction.access$300(SearchScrollQueryAndFetchAsyncAction.java:41)   at org.elasticsearch.action.search.SearchScrollQueryAndFetchAsyncAction$1.onFailure(SearchScrollQueryAndFetchAsyncAction.java:142)   at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46)   at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:874)   at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:852)   at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:389)   at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)   at java.lang.Thread.run(Thread.java:748)   Caused by: org.elasticsearch.transport.RemoteTransportException: [03BE0352-264E5695-7C25F189-A53EC373-372DEEDA][local[1]][indices:data/read/search[phase/query+fetch/scroll]]   Caused by: org.elasticsearch.search.SearchContextMissingException: No search context found for id [7]   at org.elasticsearch.search.SearchService.findContext(SearchService.java:626)   at org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:553)   at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchScrollTransportHandler.messageReceived(SearchServiceTransportAction.java:416)   at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryFetchScrollTransportHandler.messageReceived(SearchServiceTransportAction.java:413)   at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)   at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:77)   at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:378)   at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)   at java.lang.Thread.run(Thread.java:748)  {quote}   ",Bug,Major,Closed,"2019-01-18 18:47:28","2019-01-18 18:47:28",3
"Sonatype Nexus","repository-content-selector privileges using paths do not get applied to /tags/associate","1. Create a content selector named test-selector      2. Create a Content selector privilege:  Name: test-priv  Selector: test-selector  Repository: maven-releases  Actions: *    3. Create a test-role, that has the following privs:    nx-tags-associate  test-priv    4. Create a test user that has the test-role    5. Create a test-tag as the test user - it works as expected        6. Upload a component to maven-releases hosted maven 2 repository  groupId: com.example  artifactId: example  version 1.0.0  Create POM? yes, packaging: jar    7. Try to associate the test-tag to the example components as the test user - *it doesn't work*          h4. Expected    Given the content selector path matches the path of the components, and the user has the required permissions, the components should be found and tagged.",Bug,Major,Open,"2019-01-17 22:13:01","2019-01-17 22:13:01",1
"Sonatype Nexus","/tags/associate does not return JSON if repository cannot be found","Try to associate a tag to a set of components in *a repository that does not exist*. The response body is not JSON, but the response status code is 404.    Try to associate a tag to a set of components in *a repository that does exist*, but the other search criteria do not match a valid component. The response body is JSON:    {noformat:title=Valid repo, but other search criteria do not find components}  {    status : 404,    message : No components found  }      ",Bug,Major,Closed,"2019-01-17 15:05:39","2019-01-17 15:05:39",2
"Sonatype Nexus","Slow delete performance when using REST API","Deletions of yum components are taking 60 seconds and sometimes failing with 500.    We can see database query reaching 60 second timeout.  {quote}2019-01-10 04:51:29,684+0000 WARN  [qtp1990821672-1160244]  xxxxx org.sonatype.nexus.siesta.internal.UnexpectedExceptionMapper - (ID f3abb01b-7dda-4c74-8f03-4eeb03d78911) Unexpected exception: java.lang.IllegalStateException: Timed out reading query result from queue 11e742fa after 60 seconds    java.lang.IllegalStateException: Timed out reading query result from queue 11e742fa after 60 seconds     at org.sonatype.nexus.repository.storage.OrientAsyncHelper$QueueConsumingIterable.hasNext(OrientAsyncHelper.java:201)     at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811)     at java.util.stream.ReferencePipeline.forEachWithCancel(ReferencePipeline.java:126)     at java.util.stream.AbstractPipeline.copyIntoWithCancel(AbstractPipeline.java:498)     at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:485)     at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)     at java.util.stream.FindOps$FindOp.evaluateSequential(FindOps.java:152)     at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)     at java.util.stream.ReferencePipeline.findFirst(ReferencePipeline.java:464)     at org.sonatype.nexus.repository.browse.internal.BrowseServiceImpl.getById(BrowseServiceImpl.java:309)     at org.sonatype.nexus.repository.browse.internal.BrowseServiceImpl.getComponentById(BrowseServiceImpl.java:282)     at org.sonatype.nexus.repository.rest.internal.resources.ComponentsResource.getComponent(ComponentsResource.java:210)     at org.sonatype.nexus.repository.rest.internal.resources.ComponentsResource.deleteComponent(ComponentsResource.java:228)  {quote}       We can also see the the following thread is taking time:  {quote}*event-6-thread-2281* - priority:5 - threadId:0x00007fe298055800 - nativeId:0x7e23 - nativeId (decimal):32291 - state:*RUNNABLE*  stackTrace:  java.lang.Thread.State: RUNNABLE  at java.util.zip.Inflater.inflateBytes(Native Method)  at java.util.zip.Inflater.inflate(Inflater.java:259)  - locked *<0x0000000707ae4788>* (a java.util.zip.ZStreamRef)  at org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream.read(GzipCompressorInputStream.java:311)  at java.io.BufferedInputStream.read1(BufferedInputStream.java:284)  at java.io.BufferedInputStream.read(BufferedInputStream.java:345)  - locked *<0x0000000707aec6a8>* (a java.io.BufferedInputStream)  at com.google.common.io.CountingInputStream.read(CountingInputStream.java:63)  at org.sonatype.nexus.common.hash.MultiHashingInputStream.read(MultiHashingInputStream.java:66)  at java.io.FilterInputStream.read(FilterInputStream.java:107)  at com.google.common.io.ByteStreams.copy(ByteStreams.java:109)  at org.sonatype.nexus.repository.yum.internal.utils.YumMetadataUtils.readCompressedMetadata(YumMetadataUtils.java:79)  at org.sonatype.nexus.repository.yum.internal.utils.YumMetadataUtils.readCompressedMetadata(YumMetadataUtils.java:59)  at org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoServiceImpl.readMetadataAndAppendToRepomd(CreateRepoServiceImpl.java:371)  at org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoServiceImpl.writeRepomd(CreateRepoServiceImpl.java:355)  at org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoServiceImpl.convertDirectoriesToMetadata(CreateRepoServiceImpl.java:184)  at org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoServiceImpl.buildMetadata(CreateRepoServiceImpl.java:150)  at org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoServiceImpl.buildMetadata(CreateRepoServiceImpl.java:134)  at org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoServiceImpl.buildMetadataUsingCaching(CreateRepoServiceImpl.java:120)  at org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoServiceImpl$$EnhancerByGuice$$7fce96dd.CGLIB$buildMetadataUsingCaching$0(*<generated>*)  at org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoServiceImpl$$EnhancerByGuice$$7fce96dd$$FastClassByGuice$$6d83d52f.invoke(*<generated>*)  at com.google.inject.internal.cglib.proxy.$MethodProxy.invokeSuper(MethodProxy.java:228)  at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:76)  at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:56)  at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:54)  at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:77)  at com.google.inject.internal.InterceptorStackCallback.intercept(InterceptorStackCallback.java:55)  at org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoServiceImpl$$EnhancerByGuice$$7fce96dd.buildMetadataUsingCaching(*<generated>*)  at org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoFacetImpl.buildMetadata(CreateRepoFacetImpl.java:190)  at org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoFacetImpl.on(CreateRepoFacetImpl.java:175)  at sun.reflect.GeneratedMethodAccessor274.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:498)  at com.google.common.eventbus.Subscriber.invokeSubscriberMethod(Subscriber.java:87)  at com.google.common.eventbus.Subscriber$SynchronizedSubscriber.invokeSubscriberMethod(Subscriber.java:144)  - locked *<0x00000006cec7b2a8>* (a com.google.common.eventbus.Subscriber$SynchronizedSubscriber)  at com.google.common.eventbus.Subscriber$1.run(Subscriber.java:72)  at org.sonatype.nexus.thread.internal.MDCAwareRunnable.run(MDCAwareRunnable.java:40)  at org.apache.shiro.subject.support.SubjectRunnable.doRun(SubjectRunnable.java:120)  at org.apache.shiro.subject.support.SubjectRunnable.run(SubjectRunnable.java:108)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)  at java.lang.Thread.run(Thread.java:748)  Locked ownable synchronizers:  - *<0x00000006ec0c4ee8>* (a java.util.concurrent.ThreadPoolExecutor$Worker)  {quote}",Bug,Major,Closed,"2019-01-11 12:46:19","2019-01-11 12:46:19",3
"Sonatype Nexus","System check for node count","*Acceptance*   * Add a health check that fails if a cluster doesn't have three nodes",Story,Major,Done,"2019-01-03 23:28:24","2019-01-03 23:28:24",1
"Sonatype Nexus","allow scoped NPM package name parts that start with '.' or '_'","Currently, Nexus will not proxy NPM packages which begin with a leading '.' or '_'; attempting to pull these results in:    {{2019-01-03 11:22:25,450-0800 WARN  [qtp799270832-391]  admin org.sonatype.nexus.repository.npm.internal.NpmHandlers - Error: GET /@angular-toolkit/_utils_: Status\{successful=false, code=400, message='null'} - Name starts with '.' or '_': _}}   {{utils}}   {{java.lang.IllegalArgumentException: Name starts with '.' or '_': _utils}}   {{        at com.google.common.base.Preconditions.checkArgument(Preconditions.java:210)}}   {{        at org.sonatype.nexus.repository.npm.internal.NpmPackageId.<init>(NpmPackageId.java:63)}}   {{        at org.sonatype.nexus.repository.npm.internal.NpmHandlers.packageId(NpmHandlers.java:83)}}   {{        at org.sonatype.nexus.repository.npm.internal.NpmProxyFacetImpl.getCachedContent(NpmProxyFacetImpl.java:100)}}   {{        at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.maybeGetCachedContent(ProxyFacetSupport.java:342)}}   {{        at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.get(ProxyFacetSupport.java:218)}}   {{        at org.sonatype.nexus.repository.proxy.ProxyHandler.handle(ProxyHandler.java:50)}}   {{        ...}}    This aligns with the advice provided by NPM:  [https://docs.npmjs.com/files/package.json#name]    {{Some rules:}}   * {{The name must be less than or equal to 214 characters. This includes the scope for scoped packages.}}   * {{_*The name can’t start with a dot or an underscore.*_}}    Unfortunately, packages with such names exist in the NPM registry ([http://registry.npmjs.org/@angular-toolkit/_utils|http://registry.npmjs.org/@angular-toolkit/_utils).] ).  Affected customers are therefore prevented from bringing them down through Nexus.  Since the de facto naming restrictions at the NPM registry apparently allow these characters, Nexus should follow suit.    h4. Expected    - _unscoped package names are not allowed to start with underscore or period_  - a scope is part of the complete package name, so _the non-scoped name part of a scoped package name is allowed to start with a period or a dot_  - current package name validation logic should reference [the official npm validation logic|https://github.com/npm/validate-npm-package-name/blob/9ee8d54e28204b762f11451cf01207a3dc6be679/index.js#L37-L39]",Bug,Minor,Closed,"2019-01-03 20:42:26","2019-01-03 20:42:26",2
"Sonatype Nexus","System Status check failures are prominent in the UI","*Background*    We have a small-but-growing number of automated system status checks, but they are not prominent in the UI. Some reflect critical problems (e.g. NEXUS-18706), but there's no warning whatsoever unless an admin generates a support zip or digs into the UI.    *Acceptance*   * When a health check is failing, raise a visible alarm in the admin UI   * We don't want failing system status check alerts visible to non-admin users.    *Note*    This will trigger the need to schedule system status checks being run on a periodic basis, since they are currently run on demand.",Story,Major,Done,"2019-01-02 18:48:01","2019-01-02 18:48:01",3
"Sonatype Nexus","need cleanup policy permissions to view UI repository list","I am using OSS nexus-3.14.0-04 version where I have created a user and gave admin privileges, as in the screen shot, to create repositories alone. When I logged in as that user and whenever I navigate to admin repositories page, Danger alert box with 'User is not permitted: nexus:repository-admin' message is getting displayed. If I give full admin privileges like nx-repository-admin-*-*-*, then the message is not appearing but for my use I cannot give full admin privileges.    What should I do to get rid of the alert message or is it a bug in nexus-3.14?    Thanks in advance.    h4. Cause    Related to cleanup policies.        h4. Expected     Should not need cleanup policy permissions to view the repository list.",Bug,Medium,Closed,"2018-12-29 05:14:17","2018-12-29 05:14:17",2
"Sonatype Nexus","/atlas/security-diagnostic api returns 500 halfway through response.","Hello,    We've been using the /atlas/security diagnostics API in Nexus OSS 3.3.1-01. However, after an upgrade to 3.11.0-01 (and we tried 3.14.0-04 as well) we faced issues with the API. It had been moved, and it wasn't working correctly after the move.    We have created a fake user to test if our ldap configuration is working correctly. When trying to request the details of this user, the API crashes when trying to expand the users permissions.    Like this:    [root@someserver /]# curl -k --silent --write-out HTTPSTATUS:%\{http_code} -u admin:admin123 https://nexus.url/nexus/service/rest/atlas/security-diagnostic/user/fakeusr    user : \{      userId : fakeusr,      status : active,      firstName : fake user,      version : 1,      lastName : User,      emailAddress : <EMAIL>,      readOnly : false,      source : default,      name : fake user,      roles : \{        nx-admin : \{          version : null,          description : Administrator Role,          readOnly : true,          source : default,          name : null,          privileges : \{            nx-all : \{              type : wildcard,              properties : \{                pattern : nexus:*              },              version : null,              description : All permissions,              permission            }          }        }      }    }  }ERROR: (ID 1d7ee5f4-3c65-4dad-8a3a-61d812aab041) com.fasterxml.jackson.databind.exc.InvalidDefinitionException: No serializer found for class org.sonatype.nexus.security.authz.WildcardPermission2 and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: java.util.LinkedHashMap[user]->java.util.LinkedHashMap[roles]->java.util.LinkedHashMap[nx-admin]->java.util.LinkedHashMap[privileges]->java.util.LinkedHashMap[nx-all]->java.util.LinkedHashMap[permission])  HTTPSTATUS:500",Bug,Critical,Closed,"2018-12-20 07:33:21","2018-12-20 07:33:21",1
"Sonatype Nexus","jetty-http-redirect-to-https.xml overrides the default Jetty security filter allowing TRACE requests","By default Nexus does not allow HTTP TRACE requests.    However, if you add the jetty-http-redirect-to-https.xml file to the nexus-args in nexus.properties TRACE requests will succeed. I think this is because that configuration file is setting a new securityHandler without calling the existing one.",Bug,Major,Closed,"2018-12-19 22:35:28","2018-12-19 22:35:28",2
"Sonatype Nexus","Collect all three support zips from a single node","*Background*    Currently, when HA-C customers generate a support zip, they almost always fetch a single support zip. Also, in some cases the admin trying to obtain the support zip doesn't have the ability to reach specific nodes to fetch all three manually.    *Acceptance*   * There a method in the UI for users to generate and fetch support zips for their entire cluster.   * This should not fail if some nodes are down! Best effort is necessary. (Inability to get a support zip from the one working node is worse than not getting all three.)",Story,Major,Done,"2018-12-19 21:48:19","2018-12-19 21:48:19",5
"Sonatype Nexus","log blob deleted reason for s3 based deleted blobs","Note the file-based blobstore explicitly logs the deleted reason when it unexpectedly encounters a soft-deleted blob:    [https://github.com/sonatype/nexus-public/blob/release-3.14.0-04/components/nexus-blobstore-file/src/main/java/org/sonatype/nexus/blobstore/file/FileBlobStore.java#L437]    Whereas the S3 blobstore logs the {{S3BlobAttributes}}:    [https://github.com/sonatype/nexus-public/blob/release-3.14.0-04/plugins/nexus-blobstore-s3/src/main/java/org/sonatype/nexus/blobstore/s3/internal/S3BlobStore.java#L321]    Unfortunately that delegates to {{S3PropertiesFile.toString()}} which just dumps the bucket and key, not the actual attributes.    *Acceptance*    The path or bucket-key pair and the attributes for an accessed soft-deleted blob shall be logged in the warning msg.           ",Bug,Critical,Closed,"2018-12-10 17:20:41","2018-12-10 17:20:41",1
"Sonatype Nexus","redeploy of same rpm version corrupts repodata","I have a CI/CD pipeline to build various rpm packages.    Some packages are rebuilt from exactly the same source version as these are used as dependencies for building other packages (eg, gRPC requires Protobuf).    At the end of the CI/CD pipeline all RPM packages are uploaded to the Hosted repository.    This has the effect of redeploying the nearly the same RPM packages, their binary checksums can be different (eg, embedded timestamp in binaries) but most RPM metadata remains the same (package version)    I first noticed that I had problems when I hosted RPMs and SRPMs sharing the same repodata folder (NEXUS-17884), I then re-created the repository and set a different repodepth so RPM and SRPM folders have their own repodata.    Upon the first upload of a package everything works fine, but after a package is uploaded again clients get :         [91mhttps://.../repository/linux/master/RPMS/x86_64/grpc-1.15.1-1.x86_64.rpm: [Errno -1] Package does not match intended download. Suggestion: run yum --enablerepo=linux clean metadata  [0m[91mTrying other mirror.        Note that there was no cached metadata, this occurs in a pristine centos 7 docker container.         I'm using the latest OSS version. I unfortunately did not save the (corrupt) repodata, but it should be easy enough to reproduce.     ",Bug,Minor,Closed,"2018-12-06 13:58:56","2018-12-06 13:58:56",5
"Sonatype Nexus","- messes up filter feature in cleanup policy preview","Hello.    When I setup a Cleanup Policy and use the preview feature.   I can select the target repository and I can see all artifact impacted by the policy.    In the window, there is a textbox where I can put a filter. I imagine it is based on the artifact name. Screen capture filter without -.png shows an example.    But, when I put a value with character -, then nothing is displayed, even if I have some, as shown in filter with -.png         Regards         Etienne",Bug,Minor,Open,"2018-12-05 13:28:02","2018-12-05 13:28:02",3
"Sonatype Nexus","GET requests against Docker group repository returning duplicate headers","While testing NEXUS-12684, it was discovered that issuing a GET request for a manifest in a docker group repository returned duplicate headers for Docker-Distribution-Api-Version, ETag, and Last-Modified.    Example request:     Example Response Headers:  ",Bug,Minor,Closed,"2018-12-04 02:36:43","2018-12-04 02:36:43",1
"Sonatype Nexus","allow multipart copy for AWS S3 blob storage","Hey there,    Can multipart upload for aws s3 blob storage be enabled through some setting?    I get the following in the nexus logs, when trying to upload artifacts larger than 5GB:  {quote}com.amazonaws.services.s3.model.AmazonS3Exception: The specified copy source is larger than the maximum allowable size for a copy source: 5368709120 (Service: Amazon S3; Status Code: 400; Error Code: InvalidRequest;  {quote}  Thanks in advance",Bug,Major,Closed,"2018-12-03 16:16:50","2018-12-03 16:16:50",2
"Sonatype Nexus","Cannot resolve artifact with packaging and classifier","Hello,    We have this issue with Nexus 3.13.0 but we are not sure if it is a setup error at our side or a real bug in Nexus. Can you please confirm?    With Nexus having a proxy to Maven Central, running     gives an error saying the artifact is missing.    Changing mvn settings.xml to directly reach repository central on the Internet, and the artifact can be downloaded fine.    Can you please test on your side and confirm if it works fine for you?    Many thanks in advance",Bug,Major,Open,"2018-12-03 16:03:49","2018-12-03 16:03:49",3
"Sonatype Nexus","Drop beta rest endpoints.","Drop deprecated <USER>enpoints.","Technical Debt",Major,Closed,"2018-11-26 16:06:48","2018-11-26 16:06:48",1
"Sonatype Nexus","assetdownloadcount.internal.CacheRemovalListener.accept NullPointerException","A 3 node HA cluster started recording running 3.14.0 started capturing 2366 NullPointerException across nodes with the following log message.    very oddly, one node logs these as WARN messages, while another logs these as ERROR - even though both are on the same version of Nexus?        h4. Expected    NullPointerExceptions should not be triggered during normal operation. Determine cause and mitigate.  Explain why one is WARN and one is ERROR.",Bug,Critical,Closed,"2018-11-21 22:15:09","2018-11-21 22:15:09",1
"Sonatype Nexus","support zips are deleted from the downloads directory in HA environment","NEXUS-15163 implemented in 3.13.0 moves support zips into the default blobstore and then DELETES them from the $data-dir/downloads directory after they are moved.    This is not desired. Support zips are to be treated contextually like log files, specific to a node, and should not need to be moved into a shared blobstore to be accessible by all nodes.    h4. Expected    Do not delete a support zip from the original generated downloads directory on the node it was created.    There is also no customer use case to move support zips into the shared blob store. It appears the original reason for reporting NEXUS-15163 was because HTTP sessions were not sticky.",Bug,Major,Closed,"2018-11-20 16:46:00","2018-11-20 16:46:00",2
"Sonatype Nexus","repository.rebuild-index task TagsComponentEntityAdapterExtension.readFields NullPointerException","A maven2-hosted repository with the following config:        Encountered a problem when the RebuildIndexTask was run against it:        h4. Expected    NullPointerException should not happen. Code should be defensive.",Bug,Major,Closed,"2018-11-19 21:52:59","2018-11-19 21:52:59",2
"Sonatype Nexus","NAR files can't be uploaded when Strict Content Validation is enabled on a repository","Hello!    Since the release of Nexus 3.14.0, uploads of Apache Nifi Archives (NAR files) are rejected by Maven repositories when strict content validation is enabled. These files are generated by the {{nifi-nar-maven-plugin}} and are used for deploying features to Apache Nifi instances. (You can find lots of examples of these NAR files in Maven Central.)    In previous versions of Nexus this worked fine; when NAR files are uploaded to a 3.14.0 repository, however, they are detected as having content type {{application/vnd.iptc.g2.newsmessage+xml}} and are rejected.    I believe this is a result of an upgrade from Tika {{1.14}} to {{1.19}} as part of [this commit|https://github.com/sonatype/nexus-public/commit/1ad19d8775bccab03f038c9d45a9f8021d3cb0a5]; Tika added support for that content type as part of TIKA-2527 for a different file that _also_ has the {{.nar}} extension.    This should be a relatively quick fix and I've created a [pull request |https://github.com/sonatype/nexus-public/pull/44] that should fix the issue. ",Bug,Minor,Open,"2018-11-16 13:48:58","2018-11-16 13:48:58",2
"Sonatype Nexus","Support zip generation fails without a blobstore","Nexus admins cannot create a support zip if there is no blobstore present. Per the nexus.log:    2018-11-12 16:10:10,285+0000 INFO [qtp1301159914-189] admin com.sonatype.nexus.hazelcast.internal.BlobStoreDownloadServiceImpl - Move: support-20181112-161009-3.zip  2018-11-12 16:10:10,286+0000 ERROR [qtp1301159914-189] admin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: atlas_SupportZip.create, java-method: org.sonatype.nexus.coreui.internal.atlas.SupportZipComponent.create  java.util.NoSuchElementException: null   at com.google.common.collect.AbstractIndexedListIterator.next(AbstractIndexedListIterator.java:75)   at com.sonatype.nexus.hazelcast.internal.BlobStoreDownloadServiceImpl.move(BlobStoreDownloadServiceImpl.java:108)*   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:498)   at org.codehaus.groovy.runtime.callsite.PojoMetaMethodSite$PojoCachedMethodSiteNoUnwrap.invoke(PojoMetaMethodSite.java:213)   at org.codehaus.groovy.runtime.callsite.PojoMetaMethodSite.call(PojoMetaMethodSite.java:56)   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:136)   at org.sonatype.nexus.internal.atlas.SupportZipGeneratorImpl.generate(SupportZipGeneratorImpl.groovy:151)   at org.sonatype.nexus.supportzip.SupportZipGenerator$generate.call(Unknown Source)   at org.sonatype.nexus.coreui.internal.atlas.SupportZipComponent.create(SupportZipComponent.groovy:57)    New Nexus HA-C environments don't have blobstores, which means we can't get support zips to troubleshoot issues encountered early on.",Bug,Major,Closed,"2018-11-13 23:29:54","2018-11-13 23:29:54",1
"Sonatype Nexus","Scripting API allows invalid Roles","The addRole() method in security scripting API allows for creation of a role that contains itself.  This is not valid, and causes stack overflows in Nexus when the role is traversed.         The API should validate that no cycles are created in roles, and ensure that any other required validation is applied regardless of whether the input comes from REST/UI/etc.     ",Bug,Major,Closed,"2018-11-13 18:20:53","2018-11-13 18:20:53",1
"Sonatype Nexus","REST API list repositories to provide the remote url.","Improvement request for REST API of listing repositories to show the remote URL.",Improvement,Major,Closed,"2018-11-07 10:20:54","2018-11-07 10:20:54",1
"Sonatype Nexus","Support zip generation fails if nexus.log file is not called nexus.log","If the name of the nexus.log file is changed in the logback.xml file:         Then this will prevent generation of a support zip file:  {quote}2018-11-06 17:08:59,672+0000 WARN [qtp1032748576-49] admin org.sonatype.nexus.internal.atlas.customizers.InstallConfigurationCustomizer - Skipping: /var/lib/nexus3/etc/fabric/hazelcast-network.xml   2018-11-06 17:09:00,926+0000 WARN [qtp1032748576-49] admin org.sonatype.nexus.internal.log.LogbackLogManager - Log file does not exist: nexus.log   2018-11-06 17:09:00,936+0000 ERROR [qtp1032748576-49] admin org.sonatype.nexus.internal.atlas.SupportZipGeneratorImpl - Failed to create support ZIP   java.lang.NullPointerException: Cannot invoke method withStream() on null object   at org.codehaus.groovy.runtime.NullObject.invokeMethod(NullObject.java:91)   at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:47)   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)   at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:34)   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:116)   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:128)   at org.sonatype.nexus.internal.atlas.customizers.LogCustomizer$1.generate(LogCustomizer.groovy:63)   at org.sonatype.nexus.supportzip.GeneratedContentSourceSupport.prepare(GeneratedContentSourceSupport.java:51)   at org.sonatype.nexus.supportzip.SupportBundle$ContentSource$prepare.call(Unknown Source)   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)   at org.sonatype.nexus.supportzip.SupportBundle$ContentSource$prepare.call(Unknown Source)   at org.sonatype.nexus.internal.atlas.SupportZipGeneratorImpl$_generate_closure3.doCall(SupportZipGeneratorImpl.groovy:181)   at sun.reflect.GeneratedMethodAccessor167.invoke(Unknown Source)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:498)   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:98)  {quote}   *Expected*:  The support zip code should take the name of the log file from the logback configuration, and use that when attempting to open the file.",Bug,Major,Closed,"2018-11-06 18:21:01","2018-11-06 18:21:01",2
"Sonatype Nexus","Docker content validation against certain Etag header value formats may fail","The content validation added via ----NEXUS-16242---- uses the ETag header.    Dockerhub always returns ETag in the algorithm:checksum format.  But in general the format of the Etag header cannot be relied on, it's just a generic identifier.  This causes our validation to break when the ETag is in a format which is not compatible with Docker digests:    Example received header:  {quote}2018-11-01 18:24:37,850+0000 DEBUG [qtp639366847-55651]  example org.apache.http.headers - http-outgoing-42 << _ETag: b558e108382f75d3cb440cec3bdaca8fa4bbfe30_  {quote}  The exception caused by this in a Docker proxy repository:  {quote}2018-11-01 18:24:37,861+0000 WARN [qtp639366847-55651] example org.sonatype.nexus.repository.docker.internal.V2Handlers - Error: GET /v2/build/asap/manifests/latest   java.lang.IllegalArgumentException: Digest must be formed as 'alg:hex': b558e108382f75d3cb440cec3bdaca8fa4bbfe30   at com.google.common.base.Preconditions.checkArgument(Preconditions.java:210)   at org.sonatype.nexus.repository.docker.internal.DockerDigest.parse(DockerDigest.java:71)   at org.sonatype.nexus.repository.docker.internal.DockerProxyFacetImpl.fetchTagDigestByContentDigest(DockerProxyFacetImpl.java:916)  {quote}  FWIW, it seems the Docker-Content-Digest's format can be relied on:    [https://docs.docker.com/registry/spec/api/#content-digests]  {quote}2018-11-01 18:24:37,851+0000 DEBUG [qtp639366847-55651] example org.apache.http.headers - http-outgoing-42 << Docker-Content-Digest: sha256:9030d11b2bf8181a39b010c27359a7557c753c7f5272211ca2c12ec02656a25b  {quote}  *Note that this problem causes a Docker proxy which has Artifactory as its remote to fail*, since Artifactory does not use the algorithm:checksum format in its ETag headers.",Bug,Major,Closed,"2018-11-01 19:34:57","2018-11-01 19:34:57",3
"Sonatype Nexus","Nexus Platform Plugin for Jenkins fails to send any authorization headers over HTTPS to Nexus Repository Manager","Configure Nexus Platform Plugin for Jenkins failing to connect and perform operations against a Nexus Repository manager version 3.x server at a URL using HTTPS instead of plain HTTP. Operations will *fail to send* the configured credentials, even though the credentials are valid.    This affects all versions of the Jenkins Platform Plugin from 3.2.20180724-142843.2f5144d to 3.3.20181025-134249.614c5f4 ( see https://wiki.jenkins.io/display/JENKINS/Nexus+Platform+Plugin ).  ",Bug,Major,Closed,"2018-10-29 18:22:06","2018-10-29 18:22:06",2
"Sonatype Nexus","docker proxy repositories configured with a remote URL including extra path info will not proxy correctly","h4. Problem    Docker proxy repositories in Nexus 3.14.0 do not successfully proxy content in a docker hosted repository in Nexus 3.14.0 when the remote URL of the proxy repository includes extra path info.    Example:    Docker Proxy Remote URL: http://192.168.2.73:8081/repository/docker-hosted    {noformat:title=Logging from Nexus 3.13.0 which shows a successful proxy of docker content}  2018-10-24 13:14:00,822-0300 INFO  [qtp2079105816-225] admin org.sonatype.nexus.repository.docker.internal.DockerProxyFacetImpl - Invalidating proxy caches of docker-proxy  2018-10-24 13:14:07,622-0300 DEBUG [qtp2079105816-186] admin org.sonatype.nexus.httpclient.outbound - http://192.168.2.73:8081/repository/docker-hosted/v2/hello-world/manifests/latest > GET /repository/docker-hosted/v2/hello-world/manifests/latest HTTP/1.1  2018-10-24 13:14:07,630-0300 DEBUG [qtp2079105816-186] admin org.sonatype.nexus.httpclient.outbound - http://192.168.2.73:8081/repository/docker-hosted/v2/hello-world/manifests/latest < HTTP/1.1 200 OK @ 7.711 ms  2018-10-24 13:14:07,630-0300 INFO  [qtp2079105816-186] admin org.sonatype.nexus.repository.httpclient.internal.HttpClientFacetImpl - Repository status for docker-proxy changed from READY to AVAILABLE - reason n/a for n/a  2018-10-24 13:14:07,682-0300 INFO  [elasticsearch[3A375783-7FDD90D8-4B372B08-E9E9D13D-0E5F7F54][clusterService#updateTask][T#1]] *SYSTEM org.elasticsearch.cluster.metadata - [3A375783-7FDD90D8-4B372B08-E9E9D13D-0E5F7F54] [2e558aa1029f36cea9ed93e744bf70bea008fe46] update_mapping [component]  2018-10-24 13:14:17,489-0300 DEBUG [qtp2079105816-61] admin org.sonatype.nexus.httpclient.outbound - http://192.168.2.73:8081/repository/docker-hosted/v2/hello-world/manifests/8.11.2-slim > GET /repository/docker-hosted/v2/hello-world/manifests/8.11.2-slim HTTP/1.1  2018-10-24 13:14:17,497-0300 DEBUG [qtp2079105816-61] admin org.sonatype.nexus.httpclient.outbound - http://192.168.2.73:8081/repository/docker-hosted/v2/hello-world/manifests/8.11.2-slim < HTTP/1.1 200 OK @ 8.334 ms      h4. Diagnosis    The issue seems to be the extra path info of {{/repository/docker-hosted/}} in the docker proxy repository URL is stripped off before the outbound request for the layer manifest is retrieved. This means it receives HTML content from a 400 error response instead of the actual docker content.    h4. Workaround    If possible, change the Proxy repository Remote URL to not use extra path info. ie.    1. Setup the remote repository to listen on a specific connector port so that it can be accessed at a root path context  2. Change the proxy repository URL to that remote specific port and remove the extra path info.    When implementing the workaround, be cautious of the potential performance penalty of extra HTTP connectors in the remote Nexus 3 as described in NEXUS-16565.",Bug,Critical,Closed,"2018-10-24 17:35:50","2018-10-24 16:35:50",5
"Sonatype Nexus","Nexus Platform Plugin repository manager compatibility check does not use Jenkins configured HTTP proxy server","Configure an HTTP proxy server in Jenkins  Try to add a new Nexus 3 connection inside Jenkins. After you enter the Server URL and tab or click away, an HTTP request is sent to /service/rest/wonderland/status  However the request is NOT sent through the configured Jenkins HTTP proxy server.    h4. Expected    The Nexus Platform Plugin should respect the HTTP proxy settings of the Jenkins server in all outbound HTTP requests it makes.    This could be caused indirectly by it using URLConnection instead of the built in HTTPClient library.    Also relevant is the value in the check itself: NEXUS-18260",Bug,Major,Closed,"2018-10-23 23:59:07","2018-10-23 22:59:07",3
"Sonatype Nexus","Hosted yum metadata not rebuilding due to parsing issues in the path being queried","The metadata for a hosted yum repo is not rebuilding. Errors are recorded in the Nexus log which indicate a problem parsing a Windows directory name within the SQL query:               ",Bug,Major,Closed,"2018-10-23 23:53:24","2018-10-23 22:53:24",3
"Sonatype Nexus","Nexus Platform Plugin cannot determine Nexus 3 status when Anonymous access is disabled","# Start 3.13.0   # *Disable Anonymous access by unchecking the Enabled checkbox*   # Using Jenkins 2.121.1 + Nexus Platform Plugin 3.3.2, try to configure the nexus 3 connection.   ## Enter the Server name   ## Enter the Server ID   ## Enter the server URL ( [http://localhost:8081|http://localhost:8081/] ) and tab away from or click away from the Server URL field.    The platform plugin sends a request to Nexus without credentials and gets a 403 response from Nexus.    As a result, The jenkins plugin displays a yellow warning in the UI.    Now choose valid credentials in order to correct the problem:    1. Choose valid credentials in the credential dropdown or create these on the fly.   2. Choose Test Connection. The Connection should work. *Meanwhile the yellow warning text remains.*   3. Click inside the Server URL field. Change the value to [http://localhost:123|http://localhost:123/] ( invalid) . Tab or click away. Yellow message remains.   4. Correct the server URL back to [http://localhost:8081|http://localhost:8081/]. Tab or click away. Nexus receives another request like this which does not use you already verified valid credentials.    h4. Expected    One of the Notes in -NEXUS-17303- was version info should be available without auth. When Nexus has anonymous disabled ( reproduce step 2 ) this requirement is not satisfied.    Also see NEXUS-18274 for interaction redesign proposals.",Bug,Major,Closed,"2018-10-23 23:39:58","2018-10-23 22:39:58",3
"Sonatype Nexus","Allow blobstore configuration updates when changes are necessary","Currently, blobstore configuration is immutable. However, there are situations where the blobstore configuration needs to be changed. For instance, if the NXRM admin configured an S3 blobstore with a set of access keys that have been compromised. In this case, the admin would need to update the access keys in the blobstore configuration.     As an NXRM admin, I need to be able to make changes to the blobstore configuration so that I can correct potential configuration errors so that I can bring a blobstore back online.     *Acceptance Criteria*  * if a blobstore is offline, the configuration of the blobstore can be updated  * Quota config should only be editable when the user selects editing mode per NEXUS-18317",Story,Major,Done,"2018-10-23 15:33:22","2018-10-23 14:33:22",2
"Sonatype Nexus","repository manager will not start on blobstore problems or errors","As an admin, I need for NXRM to launch even in the event that a blobstore is unavailable.     Currently, if you are using an S3 blobstore and AWS is unavailable or your access keys have expired, then NXRM will not launch. S3 is not the only potential problem, if a blobstore is configured to point to an NFS mount point that is not mounted, then NXRM may fail to launch.     *Acceptance Criteria*  * NXRM launches even if blobstores are not available",Bug,Major,Closed,"2018-10-23 15:29:55","2018-10-23 14:29:55",2
"Sonatype Nexus","provide a health endpoint for an individual node in an HA-C cluster","HA-C consists of nodes, each node being an Nexus instance.    It is common practice to put a load balancer in front of an HA-C cluster. It is anticipated one node may be deliberately brought offline while the others remain functioning.    A load balancer needs to reliably determine the health of an individual node in order to reroute requests to available nodes.    Our [documentation|https://help.sonatype.com/repomanager3/high-availability/operating-your-cluster#Operatingyourcluster-MonitoringNodeHealth] currently suggests using:    http://<serveripaddress>:<port>/service/metrics/data    but that endpoint    - requires authentication, unless the anonymous user is granted access  - returns a lot of data irrelevant to server health and not appropriate for an anonymous user    h4. Expected    Each node in an HA-C cluster should expose an endpoint that can be used by a load balancer to determine the health of the node with regards to its ability to participate in spreading the work of incoming cluster load.    As a guideline, the endpoint should meet the requirements for health checks as defined by common load balancers such as ELB and nginx:    https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html  https://docs.nginx.com/nginx/admin-guide/load-balancer/http-health-check/  https://httpd.apache.org/docs/2.4/mod/mod_proxy_hcheck.html    Example  - anything other than a HTTP 200 status code indicates the node is not ready to do work  - require no authentication by default, but MAY have a privilege specific to the endpoint  - the endpoint MAY provide a response body that provides information about health, but in order to determine health, it MUST NOT be required that the client actually parse this response body  - HTTP should be the primary protocol, on the main HTTP(S) connector of the Nexus instance, used to check node health, since this greatly simplifies navigating firewalls  - if the cluster/node is read-only, document if this affects the status code as far as a load balancer is concerned",Bug,Major,Closed,"2018-10-18 18:54:46","2018-10-18 17:54:46",3
"Sonatype Nexus","RPMs with non-zero epoch are incorrectly recorded in primary.xml in hosted repositories","RPMs with non-zero epoch have missing epoch attribute in <rpm:provides>  element of the primary.xml database. This causes yum to fail during depsolve when such packages are being used.     Specific case: I have a subset of packages from official centos7 repositories that I keep in a hosted yum repository. The failing package is dhclient (which uses epoch value 12), resolved as a dependency of NetworkManager.    Comparsion of primary.xml from nexus with the one created by createrepo shows the differences. Both files are attached.",Bug,Major,Closed,"2018-10-17 12:50:30","2018-10-17 11:50:30",2
"Sonatype Nexus","ArrayIndexOutOfBoundsException when uploading large POM","Deploy fails when parsing (large) pom due to ArrayIndexOutOfBoundsException:  {quote}org.sonatype.nexus.repository.httpbridge.internal.ViewServlet - Failure servicing: PUT /repository/maven-releases/x123/x123/0.0.1/x123-0.0.1.pom    java.lang.ArrayIndexOutOfBoundsException: 8213    at org.codehaus.plexus.util.xml.pull.MXParser.parsePI(MXParser.java:2502)    at org.codehaus.plexus.util.xml.pull.MXParser.nextImpl(MXParser.java:1283)    at org.codehaus.plexus.util.xml.pull.MXParser.next(MXParser.java:1131)    at org.apache.maven.model.io.xpp3.MavenXpp3Reader.nextTag(MavenXpp3Reader.java:528)    at org.apache.maven.model.io.xpp3.MavenXpp3Reader.parsePluginExecution(MavenXpp3Reader.java:2888)    at org.apache.maven.model.io.xpp3.MavenXpp3Reader.parsePlugin(MavenXpp3Reader.java:2701)    at org.apache.maven.model.io.xpp3.MavenXpp3Reader.parseBuildBase(MavenXpp3Reader.java:1069)    at org.apache.maven.model.io.xpp3.MavenXpp3Reader.parseProfile(MavenXpp3Reader.java:3069)    at org.apache.maven.model.io.xpp3.MavenXpp3Reader.parseModel(MavenXpp3Reader.java:2257)    at org.apache.maven.model.io.xpp3.MavenXpp3Reader.read(MavenXpp3Reader.java:3807)    at org.apache.maven.model.io.xpp3.MavenXpp3Reader.read(MavenXpp3Reader.java:557)    at org.apache.maven.model.io.xpp3.MavenXpp3Reader.read(MavenXpp3Reader.java:586)    at org.sonatype.nexus.repository.maven.internal.MavenModels.readModel(MavenModels.java:133)    at org.sonatype.nexus.repository.maven.internal.MavenFacetImpl.fillInFromModel(MavenFacetImpl.java:376)    at org.sonatype.nexus.repository.maven.internal.MavenFacetImpl.putArtifact(MavenFacetImpl.java:327)    at org.sonatype.nexus.repository.maven.internal.MavenFacetImpl.doPutAssetBlob(MavenFacetImpl.java:296)    at org.sonatype.nexus.repository.maven.internal.MavenFacetImpl.doPut(MavenFacetImpl.java:249)    at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:56)    at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:54)    at org.sonatype.nexus.repository.maven.internal.MavenFacetImpl.put(MavenFacetImpl.java:201)  {quote}  To reproduce deploy the attached pom file to a maven repo on a 3.13 instance:    {{mvn deploy:deploy-file -DgeneratePom=false -DrepositoryId=nexus -Durl=[http://localhost:8081/repository/maven-releases] -DpomFile=pom.xml -Dfile=pom.xml}}    +Acceptance+     Looks to be related/caused by [https://issues.apache.org/jira/browse/MNG-6216] and [https://github.com/codehaus-plexus/plexus-utils/issues/22] and an update is needed to plexus-util 3.1.0",Bug,Major,Closed,"2018-10-12 14:15:50","2018-10-12 13:15:50",3
"Sonatype Nexus","Pypi proxy of https://bloomberg.bintray.com/pip does not work","    Create a pypi proxy of [https://bloomberg.bintray.com/pip] in Nexus Repo 3.13.0, and try to download the blpapi package from it using pip.    This will fail. The nexus.log shows:  {quote}2018-10-11 14:02:55,123-0300 WARN [qtp370829994-301] *UNKNOWN org.sonatype.nexus.repository.pypi.internal.PyPiIndexUtils - Found unexpected PyPI link format, skipping: blpapi-3.9.2-cp27-cp27m-win32.whl   2018-10-11 14:02:55,124-0300 WARN [qtp370829994-301] *UNKNOWN org.sonatype.nexus.repository.pypi.internal.PyPiIndexUtils - Found unexpected PyPI link format, skipping: blpapi-3.9.2-cp27-cp27m-win_amd64.whl   2018-10-11 14:02:55,124-0300 WARN [qtp370829994-301] *UNKNOWN org.sonatype.nexus.repository.pypi.internal.PyPiIndexUtils - Found unexpected PyPI link format, skipping: blpapi-3.9.2-cp35-cp35m-win32.whl  {quote}       The issue can be seen in the HTML source of [https://bloomberg.bintray.com/pip/simple/blpapi:]    Note that the packages are not under a /packages directory. Our code is explicitly looking for that, and will not download anything that is not in a /packages location:    [https://github.com/sonatype/nexus-public/blob/release-3.13.0-01/plugins/nexus-repository-pypi/src/main/java/org/sonatype/nexus/repository/pypi/internal/PyPiIndexUtils.java#L130]    *Expected*: A Nexus Repo 3 pypi proxy should be able to proxy anything pip can download.",Bug,Major,Closed,"2018-10-11 18:42:45","2018-10-11 17:42:45",5
"Sonatype Nexus"," The blobStore.getBlobStoreManager().delete() API allows for deleting blob stores that are in use","Reproduce steps:   # Fire up Nexus 3.13.0 with default configuration.   # Go to system/tasks, and create a new execute script task.   # For the script text use: blobStore.getBlobStoreManager().delete('default')   # Run the script    Observe that the default blob store is deleted, even though it is in use by many repositories.    *Expected*:  The API should make the same validation checks the UI does, and prevent deleting blob stores that are in use by repositories.",Bug,Major,Closed,"2018-10-01 19:11:03","2018-10-01 18:11:03",1
"Sonatype Nexus","specially crafted ldap queries can blacklist LDAP servers on javax.naming.directory.InvalidSearchFilterException","It is possible that a specially crafted LDAP user lookup can invoke the built in blacklisting of configured LDAP servers in Nexus 3, triggering an outage period equivalent to the retry delay configured for the LDAP server. When the server is in this temporary blacklisted state, all LDAP queries are bypassed for that server configuration, thereby affecting LDAP authentication and authorization requests for that server.    h4.     h4. Expected    A configured LDAP server should not be blacklisted due to a scenario where no LDAP connection attempt was made, as is the case when client side LDAP query validation determines that the attempted query is syntactically invalid and an *javax.naming.directory.InvalidSearchFilterException* is thrown.           ",Bug,Major,Closed,"2018-10-01 15:38:25","2018-10-01 14:38:25",1
"Sonatype Nexus","PyPI ignoring python_requires metadata","The full details are discussed in this github issue: [https://github.com/Azure/azure-sdk-for-python/issues/3447].    PyPI uses `python_requires` metadata to communicate that a python package is only required for a particular version of python. It appears that nexus is not acting on this metadata so when I do a pip install packages are being pulled which shouldn't be which prevents the install from completing.    As detailed in the github issue there's a relatively simple workaround for my current problem. However I'm unsure these workarounds will work with more complex dependencies.",Bug,Minor,Closed,"2018-09-28 10:17:02","2018-09-28 09:17:02",0
"Sonatype Nexus","LDAP UI does not reflect configuration","The option 'Use certificates stored in the Nexus truststore to connect to external systems' does not get reflected correctly in the UI.    Steps to reproduce:  1. Create a new LDAP connection and check the box to 'Use certificates stored in the Nexus truststore to connect to external systems'  2. Save the connection  3. Refresh the page  4. View that the box is no longer checked but the data in orientdb is correct.    The side effect of this is if you try to verify the connection it uses the state from the UI to test the connection and not the state on the backend so it will fail for SSL connections.",Bug,Major,Closed,"2018-09-24 17:17:31","2018-09-24 16:17:31",2
"Sonatype Nexus","potential slow processing of concurrent nuget requests using FindPackagesById()","Concurrent processing of Nuget gallery types of requests using FindPackagesById() queries may become increasingly slow, potentially failing builds.    These types of queries have at least two impacts.    # They lease all of the available HTTP outbound connections per route ( proxy repository remote host, currently 20 per route as of 3.13.0), impacting any other inbound requests that will also require an outbound HTTP request for that same proxy repository route in order to complete work.  # They potentially steal all of the available component database connections available for the entire repository instance ( currently 25 as of 3.13.0 ), impacting other non-related requests that also need a database connection to perform work.    The problem is exasperated when    * the parallel processing feature of a NuGet or MSBuild client is used so that concurrent requests are sent to the same Nexus instance from the same build  * a Nuget build is configured with more than one source gallery instead of just a single Nexus group repository or single proxy repository  * the nexus host is a virtual machine or one with limited I/O resources such as one being run in a cloud service - the network I/O capacity could have considerable impact on triggering this issue    {code:title=Example Request Format}  GET /repository/nuget-group/FindPackagesById()?id='Microsoft.AspNetCore.Hosting' HTTP/1.0  {code}    Examining Nexus thread dumps taken at the time of concurrent requests may reveal two types of bottlenecks.    h4. Bottleneck 1: HTTPClient Connection Pool Leases    A high number of waiting threads trying to lease an outbound HTTP connection from the Nuget proxy repository outbound HTTP connection pool. The 20 available connections are already leased by running threads.    {noformat:title=Example waiting thread on outbound Nuget HTTP connections}  qtp993807585-20058 id=20058 state=TIMED_WAITING      - waiting on <0x106a98ec> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)      - locked <0x106a98ec> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)      at sun.misc.Unsafe.park(Native Method)      at java.util.concurrent.locks.LockSupport.parkUntil(Unknown Source)      at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitUntil(Unknown Source)      at org.apache.http.pool.AbstractConnPool.getPoolEntryBlocking(AbstractConnPool.java:378)      at org.apache.http.pool.AbstractConnPool.access$200(AbstractConnPool.java:69)      at org.apache.http.pool.AbstractConnPool$2.get(AbstractConnPool.java:246)      at org.apache.http.pool.AbstractConnPool$2.get(AbstractConnPool.java:193)      at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.leaseConnection(PoolingHttpClientConnectionManager.java:303)      at org.apache.http.impl.conn.PoolingHttpClientConnectionManager$1.get(PoolingHttpClientConnectionManager.java:279)      at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:191)      at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)      at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)      at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)      at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)      at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:72)      at org.sonatype.nexus.repository.httpclient.FilteredHttpClientSupport.lambda$0(FilteredHttpClientSupport.java:56)      at org.sonatype.nexus.repository.httpclient.FilteredHttpClientSupport$$Lambda$406/1505474857.call(Unknown Source)      at org.sonatype.nexus.repository.httpclient.internal.BlockingHttpClient.filter(BlockingHttpClient.java:116)      at org.sonatype.nexus.repository.httpclient.FilteredHttpClientSupport.doExecute(FilteredHttpClientSupport.java:56)      at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)      at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)      at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)      at com.sonatype.nexus.repository.nuget.internal.NugetFeedFetcher.getPayload(NugetFeedFetcher.java:160)      at com.sonatype.nexus.repository.nuget.internal.NugetFeedFetcher.cachePackageFeed(NugetFeedFetcher.java:77)      at com.sonatype.nexus.repository.nuget.internal.NugetRemoteGalleryFacetSupport$FeedLoader.call(NugetRemoteGalleryFacetSupport.java:392)      at com.sonatype.nexus.repository.nuget.internal.NugetRemoteGalleryFacetSupport.passQueryToRemoteRepos(NugetRemoteGalleryFacetSupport.java:327)      at com.sonatype.nexus.repository.nuget.internal.NugetRemoteGalleryFacetSupport.feed(NugetRemoteGalleryFacetSupport.java:206)      at com.sonatype.nexus.repository.nuget.internal.NugetFeedHandler.feed(NugetFeedHandler.java:69)      at com.sonatype.nexus.repository.nuget.internal.NugetFeedHandler.doHandle(NugetFeedHandler.java:49)      at com.sonatype.nexus.repository.nuget.internal.AbstractNugetHandler.handle(AbstractNugetHandler.java:46)      at com.sonatype.nexus.repository.nuget.internal.NugetFeedHandler.handle(NugetFeedHandler.java:1)        {noformat:title=Nuget Gallery Database WAITING Orderby Thread}  qtp993807585-20116 <command>sql.select from asset where (component.ci_name = :p0) and (bucket=#13:0 or bucket=#13:25) ORDER BY attributes.nuget.download_count DESC, component.ci_name ASC, component.version ASC LIMIT 40</command> id=20116 state=RUNNABLE      at java.util.WeakHashMap.hash(Unknown Source)      at java.util.WeakHashMap.get(Unknown Source)      at com.orientechnologies.orient.core.cache.ORecordCacheWeakRefs.get(ORecordCacheWeakRefs.java:44)      at com.orientechnologies.orient.core.cache.OLocalRecordCache.updateRecord(OLocalRecordCache.java:66)      at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.executeReadRecord(ODatabaseDocumentTx.java:2034)      at com.orientechnologies.orient.core.tx.OTransactionOptimistic.loadRecord(OTransactionOptimistic.java:187)      at com.orientechnologies.orient.core.tx.OTransactionOptimistic.loadRecord(OTransactionOptimistic.java:162)      at com.orientechnologies.orient.core.tx.OTransactionOptimistic.loadRecord(OTransactionOptimistic.java:291)      at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.load(ODatabaseDocumentTx.java:1725)      at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.load(ODatabaseDocumentTx.java:103)      at com.orientechnologies.orient.core.id.ORecordId.getRecord(ORecordId.java:329)      at com.orientechnologies.orient.core.sql.method.misc.OSQLMethodField.execute(OSQLMethodField.java:62)      at com.orientechnologies.orient.core.sql.method.OSQLMethodRuntime.execute(OSQLMethodRuntime.java:139)      at com.orientechnologies.orient.core.sql.filter.OSQLFilterItemAbstract.transformValue(OSQLFilterItemAbstract.java:140)      at com.orientechnologies.orient.core.sql.filter.OSQLFilterItemField.getValue(OSQLFilterItemField.java:138)      at com.orientechnologies.orient.core.sql.filter.OSQLFilterCondition.evaluate(OSQLFilterCondition.java:379)      at com.orientechnologies.orient.core.sql.filter.OSQLFilterCondition.evaluate(OSQLFilterCondition.java:88)      at com.orientechnologies.orient.core.sql.filter.OSQLFilterCondition.evaluate(OSQLFilterCondition.java:384)      at com.orientechnologies.orient.core.sql.filter.OSQLFilterCondition.evaluate(OSQLFilterCondition.java:88)      at com.orientechnologies.orient.core.sql.filter.OSQLFilter.evaluate(OSQLFilter.java:105)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLResultsetAbstract.evaluateRecord(OCommandExecutorSQLResultsetAbstract.java:414)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLResultsetAbstract.filter(OCommandExecutorSQLResultsetAbstract.java:404)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.executeSearchRecord(OCommandExecutorSQLSelect.java:609)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.serialIterator(OCommandExecutorSQLSelect.java:1638)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.fetchFromTarget(OCommandExecutorSQLSelect.java:1585)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.executeSearch(OCommandExecutorSQLSelect.java:522)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.execute(OCommandExecutorSQLSelect.java:485)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLDelegate.execute(OCommandExecutorSQLDelegate.java:70)      at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.executeCommand(OAbstractPaginatedStorage.java:3400)      at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.command(OAbstractPaginatedStorage.java:3318)      at com.orientechnologies.orient.core.command.OCommandRequestTextAbstract.execute(OCommandRequestTextAbstract.java:69)      at org.sonatype.nexus.repository.storage.MetadataNodeEntityAdapter.browseByQuery(MetadataNodeEntityAdapter.java:202)      at org.sonatype.nexus.repository.storage.MetadataNodeEntityAdapter.browseByQuery(MetadataNodeEntityAdapter.java:170)      at org.sonatype.nexus.repository.storage.StorageTxImpl.findAssets(StorageTxImpl.java:371)      at org.sonatype.nexus.repository.storage.StorageTxImpl.findAssets(StorageTxImpl.java:377)      at sun.reflect.GeneratedMethodAccessor268.invoke(Unknown Source)      at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)      at java.lang.reflect.Method.invoke(Unknown Source)      at org.sonatype.nexus.common.stateguard.SimpleMethodInvocation.proceed(SimpleMethodInvocation.java:53)      at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39)      at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:270)      at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53)      at org.sonatype.nexus.common.stateguard.StateGuardAspect$1.invoke(StateGuardAspect.java:63)      at com.sun.proxy.$Proxy225.findAssets(Unknown Source)      at com.sonatype.nexus.repository.nuget.internal.NugetLocalGalleryFacetSupport.findAssetsForQuery(NugetLocalGalleryFacetSupport.java:244)      at com.sonatype.nexus.repository.nuget.internal.NugetLocalGalleryFacetSupport.queryFeed(NugetLocalGalleryFacetSupport.java:211)      at com.sonatype.nexus.repository.nuget.internal.NugetGroupGalleryFacet$$EnhancerByGuice$$e42c13d9.CGLIB$queryFeed$27(<generated>)      at com.sonatype.nexus.repository.nuget.internal.NugetGroupGalleryFacet$$EnhancerByGuice$$e42c13d9$$FastClassByGuice$$8717b62f.invoke(<generated>)      at com.google.inject.internal.cglib.proxy.$MethodProxy.invokeSuper(MethodProxy.java:228)      at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:76)      at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:56)      at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:54)      at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:77)      at com.google.inject.internal.InterceptorStackCallback.intercept(InterceptorStackCallback.java:55)      at com.sonatype.nexus.repository.nuget.internal.NugetGroupGalleryFacet$$EnhancerByGuice$$e42c13d9.queryFeed(<generated>)      at com.sonatype.nexus.repository.nuget.internal.NugetRemoteGalleryFacetSupport.feed(NugetRemoteGalleryFacetSupport.java:211)      at com.sonatype.nexus.repository.nuget.internal.NugetFeedHandler.feed(NugetFeedHandler.java:69)      at com.sonatype.nexus.repository.nuget.internal.NugetFeedHandler.doHandle(NugetFeedHandler.java:49)      at com.sonatype.nexus.repository.nuget.internal.AbstractNugetHandler.handle(AbstractNugetHandler.java:46)      at com.sonatype.nexus.repository.nuget.internal.NugetFeedHandler.handle(NugetFeedHandler.java:1)      {noformat:title=Acquiring exclusive lock}  qtp993807585-20180 <command>sql.select from component where (ci_name = :p0 AND version = :p1) and (bucket=#13:25)</command> id=20180 state=WAITING      - waiting on <0x7aac32e3> (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)      - locked <0x7aac32e3> (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)      at sun.misc.Unsafe.park(Native Method)      at java.util.concurrent.locks.LockSupport.park(Unknown Source)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(Unknown Source)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(Unknown Source)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(Unknown Source)      at java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.lock(Unknown Source)      at com.orientechnologies.common.concur.lock.OPartitionedLockManager.acquireExclusiveLock(OPartitionedLockManager.java:213)      at com.orientechnologies.common.concur.lock.OPartitionedLockManager.acquireExclusiveLocksInBatch(OPartitionedLockManager.java:266)      at com.orientechnologies.orient.core.storage.cache.local.twoq.O2QCache.doLoad(O2QCache.java:355)      at com.orientechnologies.orient.core.storage.cache.local.twoq.O2QCache.load(O2QCache.java:294)      at com.orientechnologies.orient.core.storage.impl.local.paginated.base.ODurableComponent.loadPage(ODurableComponent.java:145)      at com.orientechnologies.orient.core.storage.impl.local.paginated.OPaginatedCluster.readRecordBuffer(OPaginatedCluster.java:766)      at com.orientechnologies.orient.core.storage.impl.local.paginated.OPaginatedCluster.readRecord(OPaginatedCluster.java:742)      at com.orientechnologies.orient.core.storage.impl.local.paginated.OPaginatedCluster.readRecord(OPaginatedCluster.java:721)      at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.doReadRecord(OAbstractPaginatedStorage.java:4220)      at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.readRecord(OAbstractPaginatedStorage.java:3807)      at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.readRecord(OAbstractPaginatedStorage.java:1410)      at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx$SimpleRecordReader.readRecord(ODatabaseDocumentTx.java:3395)      at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.executeReadRecord(ODatabaseDocumentTx.java:2008)      at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.load(ODatabaseDocumentTx.java:656)      at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.load(ODatabaseDocumentTx.java:103)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.executeSearchRecord(OCommandExecutorSQLSelect.java:585)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.serialIterator(OCommandExecutorSQLSelect.java:1638)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.fetchFromTarget(OCommandExecutorSQLSelect.java:1585)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.fetchValuesFromIndexCursor(OCommandExecutorSQLSelect.java:2466)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.searchForIndexes(OCommandExecutorSQLSelect.java:2280)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.searchInClasses(OCommandExecutorSQLSelect.java:1017)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLResultsetAbstract.assignTarget(OCommandExecutorSQLResultsetAbstract.java:203)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.assignTarget(OCommandExecutorSQLSelect.java:527)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.executeSearch(OCommandExecutorSQLSelect.java:509)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.execute(OCommandExecutorSQLSelect.java:485)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLDelegate.execute(OCommandExecutorSQLDelegate.java:70)      at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.executeCommand(OAbstractPaginatedStorage.java:3400)      at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.command(OAbstractPaginatedStorage.java:3318)      at com.orientechnologies.orient.core.command.OCommandRequestTextAbstract.execute(OCommandRequestTextAbstract.java:69)      at org.sonatype.nexus.repository.storage.MetadataNodeEntityAdapter.browseByQuery(MetadataNodeEntityAdapter.java:202)      at org.sonatype.nexus.repository.storage.MetadataNodeEntityAdapter.browseByQuery(MetadataNodeEntityAdapter.java:170)      at org.sonatype.nexus.repository.storage.StorageTxImpl.findComponents(StorageTxImpl.java:449)      at org.sonatype.nexus.repository.storage.StorageTxImpl.findComponents(StorageTxImpl.java:455)    --disable-parallel    -DisableParallelProcessing  {noformat}    Reference: https://docs.microsoft.com/en-us/nuget/tools/cli-ref-restore    Related: https://github.com/NuGet/Home/issues/1556  https://docs.microsoft.com/en-us/nuget/tools/cli-ref-restore#options  https://docs.microsoft.com/en-us/nuget/tools/cli-ref-install#options    Also only configure your builds to access a single nuget group per Nexus instance used.  ",Bug,Major,Closed,"2018-09-20 17:30:10","2018-09-20 16:30:10",0
"Sonatype Nexus","NuGet metadata does not display consistently","NEXUS-17712 provided two calls to NuGet metadata:  http://localhost:8081/repository/nuget.org-proxy/Packages(Id='Microsoft.Web.Infrastructure',Version='1.0.0.0')  and   http://localhost:8081/repository/nuget.org-proxy/Packages(Id='Microsoft.Web.Infrastructure',Version='1.0.0')    On test of NEXUS-17712 I found the first one not working (404ing) and the second one working; the inverse of what is stated in NEXUS-17712.  Both of these work on nuget.org.  Since installs of both work, which was the primary concern over there, creating a sibling ticket.",Bug,Minor,Open,"2018-09-19 20:20:52","2018-09-19 19:20:52",2
"Sonatype Nexus","Dynamic Storage - Blob store incorrectly displays Enable Soft Quota as checked","Blob stores show that Soft Quota is enabled when they are not. This happens when a periodic quota check job runs and tires to access the config from the blob stores attributes. Calling the attributes method on the BlobStoreConfiguration object has a side effect of changing the backing map. Our view objects determine if it is enabled by simply evaluating if the config is null.    Possible solutions:  * Calling attributes should not have side effects. (This seems like the best route)  * Checking to see if the option is enabled could check for more than null  * Save the enabled state separate from the config",Bug,Major,Closed,"2018-09-19 18:58:06","2018-09-19 17:58:06",1
"Sonatype Nexus","Firewall Audit: re-evaluate when no transaction exists for pending asset","When a pending asset does not have a corresponding firewall transaction, create one and continue with evaluation.",Bug,Major,Closed,"2018-09-14 18:18:49","2018-09-14 17:18:49",2
"Sonatype Nexus","Snapshot removal task progress doesn't take into account maven-metadata.xml file updates","When the snapshot removal task is run it first deletes all snapshots, and while it is doing that it gathers up all the maven-metadata.xml files that need updating.  When this is done the progress reaches 99.99%.    After this, it then updates all the maven-metadata.xml files.    [https://github.com/sonatype/nexus-internal/blob/release-3.8.0-02/plugins/nexus-repository-maven/src/main/java/org/sonatype/nexus/repository/maven/internal/RemoveSnapshotsFacetImpl.java#L138]    Progress isn't recorded for this last step.  But on a slow file system it can take a long time to update the maven-metadata.xml files.  This results in the task being stuck at 99.9% for a very long time, which makes it look broken.         +ACCEPTANCE+    - add logging to show progress when updating metadata",Bug,Major,Open,"2018-09-14 15:01:40","2018-09-14 14:01:40",3
"Sonatype Nexus","REST API upload that fails due to lack of permissions returns 404 (not found)","*Background*    1. Start up Nexus 3.13.0 with default configuration   2. Create a user test that does not have read or browse permissions to the nuget-hosted repository   3. Attempt to upload a nuget component to nuget-hosted using the REST API   4. Observe that this fails with 404 (not found)    Bizarrely, if I grant the test user read access to the nuget-hosted repository the request fails with a 403, but if they have both read and browse privileges it fails with a 400!    *Acceptance*    If the REST API upload fails due to permissions Nexus should always return 403 (forbidden).      ",Story,Major,Done,"2018-09-10 15:34:16","2018-09-10 14:34:16",1
"Sonatype Nexus","Deleting an rpm via DELETE to /repository does not update metadata","Reproduce case:    Upload two rpm's which have the same artifact ID but different versions into a hosted yum repository in Nexus Repo 3.13.0. I've attached the two i used in testing to make this easy to reproduce.      Wait for yum metadata to be generated, then verify both versions are in the primary.xml.gz file.    Delete the newer version via rest:    Request.log will show it has been successfully deleted:  {quote}127.0.0.1 - admin [07/Sep/2018:16:52:21 -0500] DELETE /repository/platform-centos7/my-webapp2-3.1.5-1.noarch.rpm HTTP/1.1 200 - 0 6 curl/7.54.0  {quote}  The nexus.log shows the yum metadata rebuilds 60 seconds later:  {quote}2018-09-07 16:53:21,255-0500 INFO  [event-9-thread-32] admin org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoFacetImpl - Rebuilding yum metadata for repository platform-centos7    2018-09-07 16:53:21,330-0500 INFO  [event-9-thread-32] admin org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoFacetImpl - Finished rebuilding yum metadata for repository platform-centos7  {quote}  Download the primary.xml.gz file, and observe both versions are still listed:  ",Bug,Major,Closed,"2018-09-07 23:13:00","2018-09-07 22:13:00",1
"Sonatype Nexus","Swagger generated curl command for POST /v1/components can be incorrect","1. Using the API Swagger interface for POST /v1/components, Try it Out by entering the following information:    repository: nuget-hosted    nuget.asset: Choose a valid nuget package off your local file system.    2. Execute the call    3. The call should be successful. The problem is the example curl command generated is wrong:         Executing this results in an error, even if you correct the file location and add the user/password:              The correct command would be:       ",Bug,Major,Closed,"2018-09-07 20:39:24","2018-09-07 19:39:24",1
"Sonatype Nexus","Tag association may intermittently fail for new artifact","Attempting to associate a tag with a newly-uploaded artifact can sometimes result in a 404, No components found error.  The core issue appears to be a race condition involving the Elasticsearch subsystem which stores the tag associations.",Bug,Major,Closed,"2018-09-05 20:08:17","2018-09-05 19:08:17",2
"Sonatype Nexus","Prevent Analytics collection from being enabled by default in HA mode","Prevent Analytics collection from being enabled by default in HA mode. The user can still opt to turn the capabilities on.","Technical Debt",Major,Closed,"2018-09-04 18:11:05","2018-09-04 17:11:05",1
"Sonatype Nexus","concurrent requests for large npm metadata can lead to OutOfMemory during serialization","1. Install nexus 3.13.0   2. Create npm-proxy for [https://registry.npmjs.org|https://registry.npmjs.org/]   3. Create npm-group group repo containing npm-proxy as member.   4. Make concurrent requests to GET [http://localhost:8081/repository/npm-group/npm] ( example of 20 concurrent requests was tested )   At the time of this report, the anticipated response size was 8MB of JSON:     5. Within a short time frame, Nexus will start throwing OutOfMemory errors - either:   OutOfMemoryError: Java heap space   OutOfmemoryError: GC overhead limit exceeded    The stack trace in the application log may take the following forms:      Other symptoms may include gradually slowing requests to the same package metadata.",Bug,Major,Closed,"2018-09-04 17:25:35","2018-09-04 16:25:35",13
"Sonatype Nexus","Yum metadata from unrelated folder incorrectly removed when regenerating a folder","I have two nexus repository (oss) servers, trying to host RPMs.  There seems to be an issue in generating the repodata, as most of the time, i only end up with a repomd.xml file, and none of the files referenced from within repomd.xml.  I've got this happening in two different servers, with similar, but unique RPMs.    The only unique thing we are doing is having multiple yum repositories (repodata's) in a single nexus repository.  So we would have centos/6/ and centos/7/ inside the same nexus repository.  Which should create (with repo depth of 2) centos/6/repodata/ and centos/7/repodata/.      In the log files, there are no errors, just lines like this:    {{2018-08-31 21:00:17,412-0400 INFO [event-9-thread-474] anonymous org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoFacetImpl - Rebuilding yum metadata for repository tempyum}}  {{2018-08-31 21:00:18,515-0400 INFO [event-9-thread-483] anonymous org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoFacetImpl - Scheduling rebuild of yum metadata to start in 60 seconds}}  {{2018-08-31 21:00:20,507-0400 INFO [event-9-thread-474] anonymous org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoFacetImpl - Finished rebuilding yum metadata for repository tempyum}}  {{2018-08-31 21:01:20,507-0400 INFO [event-9-thread-486] anonymous org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoFacetImpl - Rebuilding yum metadata for repository tempyum}}  {{2018-08-31 21:01:26,006-0400 INFO [event-9-thread-486] anonymous org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoFacetImpl - Finished rebuilding yum metadata for repository tempyum}}  {{2018-08-31 21:01:26,221-0400 INFO [event-9-thread-512] anonymous org.sonatype.nexus.repository.yum.internal.createrepo.CreateRepoFacetImpl - Scheduling rebuild of yum metadata to start in 60 seconds}}",Bug,Major,Closed,"2018-09-01 02:05:08","2018-09-01 01:05:08",2
"Sonatype Nexus","upload of source rpm fails in yum hosted","I uploaded a src rpm to a up to date nexus3 (3.13.0-01 OSS). And it worked fine:   {quote}  > PUT /repository/Test/SRPMS/7/ngcurl-7.61.0-2.src.rpm HTTP/1.1   ...   < HTTP/1.1 200 OK   < Date: Fri, 31 Aug 2018 12:52:48 GMT   < Server: Nexus/3.13.0-01 (OSS)   < X-Content-Type-Options: nosniff   < Content-Security-Policy: sandbox allow-forms allow-modals allow-popups allow-presentation allow-scripts allow-top-navigation   < Content-Length: 0   < Keep-Alive: timeout=5   < Connection: Keep-Alive   < Content-Type: application/x-rpm  {quote}  But the the content of <hash>-primary.xml.gz is wrong:  {quote}  curl -k [https://nexus.XXX.com/repository/Test/SRPMS/7/repodata/338c845819a87d70703b3ffbbfe763b15bf325c7c017229997621899f7c04b89-primary.xml.gz|https://nexus.xxx.com/repository/Test/SRPMS/7/repodata/338c845819a87d70703b3ffbbfe763b15bf325c7c017229997621899f7c04b89-primary.xml.gz] | gunzip | xmllint --format /dev/fd/0   {quote}    returns:  {quote}  <metadata xmlns=[http://linux.duke.edu/metadata/common] xmlns:rpm=[http://linux.duke.edu/metadata/rpm] packages=1>   <package type=rpm>   <name>ngcurl</name>   <arch>x86_64</arch>   ...  {quote}    Look at the arch attribute, it says x86_64.    I created a local yum repo with createro (0.9.9) on Centos7 (7.5.1804)   With exactly the same rpm, running:   {quote}  $ createrepo -o $PWD -p $PWD -s sha --database --workers 4  {quote}    The equivalent file says:   {quote}  <metadata xmlns=[http://linux.duke.edu/metadata/common] xmlns:rpm=[http://linux.duke.edu/metadata/rpm] packages=1>   <package type=rpm>   <name>ngcurl</name>   <arch>src</arch>  {quote}    The arch is now src    A diff after formatting both with xmllint --format returns:  {quote}  5c5   < <arch>x86_64</arch>   ---   > <arch>src</arch>   7c7   < <checksum type=sha256 pkgid=YES>b2a7e8d1a5ff56c9028493ba7103488323578187d4c282e4711199b04509319d</checksum>   ---   > <checksum type=sha pkgid=YES>49d3b8b28b256d65f7cafc94d2a6ed16456bd024</checksum>   17c17   < <time file=1535719990576 build=1535623528/>   ---   > <time file=1535623528 build=1535623528/>  {quote}    The only real problem is indeed the arch.",Bug,Major,Closed,"2018-08-31 16:36:23","2018-08-31 15:36:23",2
"Sonatype Nexus","log to build log the start and end of each build step","When a Nexus Platform Plugin for Jenkins repository manager build step starts and ends, provide log message demarcation.    *Acceptance*  An INFO level message should be logged to the Jenkins Project/Pipeline build log stating:    - the step name  - whether it is starting or ending  - a summary of configured step values at start message    *Notes*  Note that Pipeline style jobs demarcate usually the start and end of steps ( but not necessarily the step configuration being used ) - however Project steps ( those selected from a drop down and inserted manually ) usually rely entirely on the logging provided by the step itself - hence this ticket.",Story,Major,"Ready for Development","2018-08-29 19:28:42","2018-08-29 18:28:42",3
"Sonatype Nexus","Errors logged from firewall migration for new/updated maven-metadata.xml files","Set up Nexus Repo 2.14.9 with firewall enabled on the maven-central proxy repository.   Run an upgrade to Nexus Repo 3.13.0, and  proceed with this until you get to the synchronize phase, where it's looking for updates in Nexus 2.x.  Now request a new (not previously cached) maven-metadata.xml file through Nexus Repo 2:     [http://localhost:8081/nexus/content/repositories/central/org/apache/httpcomponents/httpclient/maven-metadata.xml]    Observe that Nexus Repo 3 gets an error logged for this:       {quote}2018-08-29 12:45:09,592-0500 ERROR [plan-executor-10-thread-3] admin com.sonatype.nexus.migration.repository.ProcessChangesStep - Failed processing of CREATE central:/org/apache/httpcomponents/httpclient/maven-metadata.xml, will ignore and move on. null   java.lang.NullPointerException: null   at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:882)   at com.sonatype.nexus.migration.repository.migrators.Maven2RepositoryMigratorSupport.getIngestedContent(Maven2RepositoryMigratorSupport.java:206)   at com.sonatype.nexus.migration.repository.migrators.RepositoryMigratorSupport.lambda$0(RepositoryMigratorSupport.java:172)   at com.sonatype.nexus.migration.firewall.EnabledFirewallMigrationFacadeImpl.updateAssetAttributes(EnabledFirewallMigrationFacadeImpl.java:225)   at com.sonatype.nexus.migration.firewall.EnabledFirewallMigrationFacadeImpl.lambda$2(EnabledFirewallMigrationFacadeImpl.java:209)   at org.sonatype.nexus.transaction.OperationPoint.lambda$0(OperationPoint.java:53)   at org.sonatype.nexus.transaction.OperationPoint.proceed(OperationPoint.java:64)   at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:56)   at org.sonatype.nexus.transaction.Operations.transactional(Operations.java:200)   at org.sonatype.nexus.transaction.Operations.run(Operations.java:155)   at com.sonatype.nexus.migration.firewall.EnabledFirewallMigrationFacadeImpl.maybeRecordAssetAttributes(EnabledFirewallMigrationFacadeImpl.java:208)   at com.sonatype.nexus.migration.repository.migrators.RepositoryMigratorSupport.createOrUpdate(RepositoryMigratorSupport.java:170)   at com.sonatype.nexus.migration.repository.migrators.RepositoryMigratorSupport.processChange(RepositoryMigratorSupport.java:146)   at com.sonatype.nexus.migration.repository.migrators.Maven2ProxyRepositoryMigrator.processChange(Maven2ProxyRepositoryMigrator.java:118)   at com.sonatype.nexus.migration.repository.RepositoryMigrator$processChange$3.call(Unknown Source)   at com.sonatype.nexus.migration.repository.ProcessChangesStep$_submit_closure2.doCall(ProcessChangesStep.groovy:333)   at com.sonatype.nexus.migration.repository.ProcessChangesStep$_submit_closure2.doCall(ProcessChangesStep.groovy)   at sun.reflect.GeneratedMethodAccessor350.invoke(Unknown Source)  {quote}       This is because the firewall migration is attempting to find the GAV coordinates of the file:    [https://github.com/sonatype/nexus-internal/blob/release-3.13.0-01/private/plugins/nexus-migration-plugin/src/main/java/com/sonatype/nexus/migration/repository/migrators/Maven2RepositoryMigratorSupport.java#L206]    The good news is that the affected file is migrated.  And since they are maven-metadata.xml files there isn't anything the firewall migration needed to do with them anyhow.    So this seem to only cause log noise. ",Bug,Minor,Closed,"2018-08-29 18:56:32","2018-08-29 17:56:32",3
"Sonatype Nexus","Restore npm database from blobstore could miss packages that are cached locally but removed from the remote","We changed the behaviour of NXRM to continue to serve up locally cached npm packages even if those packages are removed from the remote (see https://issues.sonatype.org/browse/NEXUS-15714). However this leaves a potential gap with the CMA restore task because there can be packages in NXRM that don't exist in the remote and the restore task is order dependent. The package root is only restored if it doesn't already exist, therefore if it has been refetched the package root containing the deleted package will not be restored.    # Create an npm-hosted repository.  # Upload two versions of the same package.  # Create an npm-proxy repository that proxies the hosted repository.  # Pull one version through the proxy so that it is cached.  # Run database backup task  # Pull the metadata through the proxy so that it is cached.  # Pull the second version through the proxy so now you should have both versions and the metadata cached and in the blobstore.  # Delete one of the versions from the *hosted* repository (simulating it being removed from the remote  # Shutdown NXRM and follow the documented steps to restore from database backup. You will now have a database for npm-proxy that contains a single package, but the blobstore will contain two packages.  # Pull the metadata through the proxy a second time so that it is cached again, now it should only list the one package that was remaining in the npm-hosted repository  # Run the Repair - reconcile component database from blobstore task.  # You should now see both versions in repository browse, however if you look at the metadata there is a chance only one package is listed.    Technical Direction  * Possible solution 1: Go to remote, get most up to date package.json and restore from the remote then merge in packages from the blob restore.  * Possible solution 2: Loop through the blobstore, find the package.json that matches and restore them.  Then go through the blobstore and restore the packages afterwards.  * May be other solutions, are leaving to developer who grabs this to evaluate/decide best course.",Bug,Minor,Open,"2018-08-27 19:02:39","2018-08-27 18:02:39",8
"Sonatype Nexus","Problem connecting to LDAP server root cause is not logged at default log levels"," The exception handling in DefaultLdapConnector and FailoverLdapConnector provides no information at all as to what actually went wrong:    [https://github.com/sonatype/nexus-internal/blob/release-3.13.0-01/private/plugins/nexus-ldap-plugin/src/main/java/org/sonatype/nexus/ldap/internal/connector/DefaultLdapConnector.java#L241]    [https://github.com/sonatype/nexus-internal/blob/release-3.13.0-01/private/plugins/nexus-ldap-plugin/src/main/java/org/sonatype/nexus/ldap/internal/connector/FailoverLdapConnector.java#L248]    This results in useless messages logged at INFO level:  {quote}2018-08-27 07:55:17,511-0600 WARN  [qtp389114725-397394] node3 SCH1844 org.sonatype.nexus.ldap.internal.connector.FailoverLdapConnector - Problem connecting to LDAP server: org.sonatype.nexus.ldap.internal.connector.dao.LdapDAOException: Failed to retrieve ldap information for users.   2018-08-27 07:55:23,582-0600 WARN  [qtp389114725-397122] node3 SCH1844 org.sonatype.nexus.ldap.internal.connector.FailoverLdapConnector - Problem connecting to LDAP server: org.sonatype.nexus.ldap.internal.connector.dao.LdapDAOException: Failed to retrieve ldap information for users.   2018-08-27 07:55:25,237-0600 WARN  [qtp389114725-397304] node3 *UNKNOWN org.sonatype.nexus.ldap.internal.connector.FailoverLdapConnector - Problem connecting to LDAP server: org.sonatype.nexus.ldap.internal.connector.dao.LdapDAOException: Failed to retrieve ldap information for users.   2018-08-27 07:55:29,548-0600 WARN  [qtp389114725-397405] node3 SCH1844 org.sonatype.nexus.ldap.internal.connector.FailoverLdapConnector - Problem connecting to LDAP server: org.sonatype.nexus.ldap.internal.connector.dao.LdapDAOException: Failed to retrieve ldap information for users.   2018-08-27 07:55:35,954-0600 WARN  [qtp389114725-397248] node3 SCH1844 org.sonatype.nexus.ldap.internal.connector.FailoverLdapConnector - Problem connecting to LDAP server: org.sonatype.nexus.ldap.internal.connector.dao.LdapDAOException: Failed to retrieve ldap information for users.  {quote}  Please pass the caused by messages up the chain at INFO.  Note that this applies to all the exceptions thrown in DefaultLdapConnector, not just the one I highlighted above.",Bug,Major,Closed,"2018-08-27 18:04:10","2018-08-27 17:04:10",2
"Sonatype Nexus","API does not validate contents of content selectors. Invalid content selectors can lead to failed upgrade.","The SelectorManager.create(SelectorConfiguration config) method does not validate the contents passed into it. This allows the creation of invalid content selectors that have no attributes.    These invalid content selectors do not show up in the UI, and therefore cannot be removed by the users.  Furthermore, when an upgrade to a new version of Nexus is performed these invalid records cause a failure, the upgraded instance cannot be started.    *Expected*: The API should protect against invalid content.    Example of invalid record that can be created via API:          Example of failure that occurs when this record is encountered during upgrade:  {quote}2018-08-26 08:15:32,634-0500 INFO [FelixStartLevel] NexusHDQ-One *SYSTEM org.sonatype.nexus.upgrade.internal.UpgradeServiceImpl - Upgrade rubygems from 1.0 to 1.1   2018-08-26 08:15:32,821-0500 WARN [FelixStartLevel <command>sql.update selector_selector set attributes.expression = attributes.expression.replace('//','/')</command>] NexusHDQ-One *SYSTEM com.orientechnologies.orient.core.serialization.serializer.record.binary.ORecordSerializerBinary - $ANSI\{green \{db=config}} Error deserializing record with id #39:5 send this data for debugging: ACJzZWxlY3Rvcl9zZWxlY3RvcgEAAAAoJQAAADZvAAAAO3EAAABMABpjb20uYWEuZG9nYWRzCENTRUwgVGVzdGluZyBieSBOaWhhcgIHFGV4cHJlc3Npb24AAABeFLoBY29tLm9yaWVudGVjaG5vbG9naWVzLm9yaWVudC5jb3JlLnNlcmlhbGl6YXRpb24uc2VyaWFsaXplci5yZWNvcmQuYmluYXJ5Lk9TZXJpYWxpemFibGVXcmFwcGVyzgSs7QAFc3IAJ29yZy5jb2RlaGF1cy5ncm9vdnkucnVudGltZS5HU3RyaW5nSW1wbDGzS2f7fekSAgABWwAHc3RyaW5nc3QAE1tMamF2YS9sYW5nL1N0cmluZzt4cgATZ3Jvb3Z5LmxhbmcuR1N0cmluZ9tj3naQywjNAgABWwAGdmFsdWVzdAATW0xqYXZhL2xhbmcvT2JqZWN0O3hwdXIAE1tMamF2YS5sYW5nLk9iamVjdDuQzlifEHMpbAIAAHhwAAAAAXQADS8vLy8vLy8vLy8vLy91cgATW0xqYXZhLmxhbmcuU3RyaW5nO63SVufpHXtHAgAAeHAAAAACdAAhZm9ybWF0ID09ICdtYXZlbjInIGFuZCBwYXRoID1+ICdedAADLion    2018-08-26 08:15:32,835-0500 ERROR [FelixStartLevel <command>sql.update selector_selector set attributes.expression = attributes.expression.replace('//','/')</command>] NexusHDQ-One *SYSTEM com.orientechnologies.orient.core.storage.impl.local.paginated.OLocalPaginatedStorage - Exception `2F976A01` in storage `plocal:/opt/sonatype-work/nexus3/db/config`: 2.2.36 (build d3beb772c02098ceaea89779a7afd4b7305d3788, branch 2.2.x)   com.orientechnologies.orient.core.exception.OCommandExecutionException: Error on execution of command: sql.select from selector_selector   DB name=config   at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.executeCommand(OAbstractPaginatedStorage.java:3421)   at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.command(OAbstractPaginatedStorage.java:3318)   at com.orientechnologies.orient.core.sql.query.OSQLQuery.run(OSQLQuery.java:78)   at com.orientechnologies.orient.core.sql.query.OSQLAsynchQuery.run(OSQLAsynchQuery.java:74)   at com.orientechnologies.orient.core.query.OQueryAbstract.execute(OQueryAbstract.java:33)   at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.query(ODatabaseDocumentTx.java:756)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLUpdate.execute(OCommandExecutorSQLUpdate.java:291)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLDelegate.execute(OCommandExecutorSQLDelegate.java:70)   at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.executeCommand(OAbstractPaginatedStorage.java:3400)   at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.command(OAbstractPaginatedStorage.java:3318)   at com.orientechnologies.orient.core.command.OCommandRequestTextAbstract.execute(OCommandRequestTextAbstract.java:69)   at org.sonatype.nexus.repository.rubygems.upgrade.RubygemsUpgrade_1_1.updateContentSelectorExpressions(RubygemsUpgrade_1_1.java:115)   at org.sonatype.nexus.repository.rubygems.upgrade.RubygemsUpgrade_1_1.apply(RubygemsUpgrade_1_1.java:79)   at org.sonatype.nexus.upgrade.internal.UpgradeServiceImpl.lambda$3(UpgradeServiceImpl.java:193)   at java.util.ArrayList.forEach(ArrayList.java:1257)   at org.sonatype.nexus.upgrade.internal.UpgradeServiceImpl.doUpgrade(UpgradeServiceImpl.java:135)   at org.sonatype.nexus.upgrade.internal.UpgradeServiceImpl.doStart(UpgradeServiceImpl.java:91)   at org.sonatype.nexus.common.stateguard.StateGuardLifecycleSupport.start(StateGuardLifecycleSupport.java:67)   at org.sonatype.nexus.upgrade.internal.UpgradeServiceImpl$$EnhancerByGuice$$dbe05174.CGLIB$start$4(<generated>)   at org.sonatype.nexus.upgrade.internal.UpgradeServiceImpl$$EnhancerByGuice$$dbe05174$$FastClassByGuice$$2ae549d6.invoke(<generated>)   at com.google.inject.internal.cglib.proxy.$MethodProxy.invokeSuper(MethodProxy.java:228)   at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:76)   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39)   at org.sonatype.nexus.common.stateguard.StateGuard$TransitionImpl.run(StateGuard.java:191)   at org.sonatype.nexus.common.stateguard.TransitionsInterceptor.invoke(TransitionsInterceptor.java:56)   at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:77)   at com.google.inject.internal.InterceptorStackCallback.intercept(InterceptorStackCallback.java:55)   at org.sonatype.nexus.upgrade.internal.UpgradeServiceImpl$$EnhancerByGuice$$dbe05174.start(<generated>)   at org.sonatype.nexus.extender.NexusLifecycleManager.startComponent(NexusLifecycleManager.java:155)   at org.sonatype.nexus.extender.NexusLifecycleManager.to(NexusLifecycleManager.java:95)   at org.sonatype.nexus.extender.NexusContextListener.frameworkEvent(NexusContextListener.java:191)   at org.apache.felix.framework.Felix.setActiveStartLevel(Felix.java:1429)   at org.apache.felix.framework.FrameworkStartLevelImpl.run(FrameworkStartLevelImpl.java:308)   at java.lang.Thread.run(Thread.java:748)   Caused by: java.lang.RuntimeException: com.orientechnologies.orient.core.exception.ODatabaseException: Error on deserialization of Serializable   DB name=config   at com.orientechnologies.orient.core.serialization.serializer.record.binary.ORecordSerializerBinaryV0.deserializeValue(ORecordSerializerBinaryV0.java:497)   at com.orientechnologies.orient.core.serialization.serializer.record.binary.ORecordSerializerBinaryV0.readEmbeddedMap(ORecordSerializerBinaryV0.java:576)   at com.orientechnologies.orient.core.serialization.serializer.record.binary.ORecordSerializerBinaryV0.deserializeValue(ORecordSerializerBinaryV0.java:472)   at com.orientechnologies.orient.core.serialization.serializer.record.binary.ORecordSerializerBinaryV0.deserializePartial(ORecordSerializerBinaryV0.java:148)   at com.orientechnologies.orient.core.serialization.serializer.record.binary.ORecordSerializerBinary.fromStream(ORecordSerializerBinary.java:78)   at com.orientechnologies.orient.core.record.impl.ODocument.deserializeFields(ODocument.java:1854)   at com.orientechnologies.orient.core.record.impl.ODocument.checkForFields(ODocument.java:2626)   at com.orientechnologies.orient.core.record.impl.ODocument.rawField(ODocument.java:773)   at com.orientechnologies.orient.core.sql.filter.OSQLFilterItemField.getValue(OSQLFilterItemField.java:129)   at com.orientechnologies.orient.core.sql.OSQLHelper.resolveFieldValue(OSQLHelper.java:310)   at com.orientechnologies.orient.core.sql.OSQLHelper.bindParameters(OSQLHelper.java:401)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLUpdate.handleSetEntries(OCommandExecutorSQLUpdate.java:614)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLUpdate.result(OCommandExecutorSQLUpdate.java:348)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLResultsetAbstract.pushResult(OCommandExecutorSQLResultsetAbstract.java:279)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.addResult(OCommandExecutorSQLSelect.java:759)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.handleResult(OCommandExecutorSQLSelect.java:670)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.executeSearchRecord(OCommandExecutorSQLSelect.java:627)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.serialIterator(OCommandExecutorSQLSelect.java:1638)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.fetchFromTarget(OCommandExecutorSQLSelect.java:1585)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.executeSearch(OCommandExecutorSQLSelect.java:522)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.execute(OCommandExecutorSQLSelect.java:485)   at com.orientechnologies.orient.core.sql.OCommandExecutorSQLDelegate.execute(OCommandExecutorSQLDelegate.java:70)   at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.executeCommand(OAbstractPaginatedStorage.java:3400)   ... 33 common frames omitted   Caused by: com.orientechnologies.orient.core.exception.ODatabaseException: Error on deserialization of Serializable   DB name=config   at com.orientechnologies.orient.core.serialization.serializer.record.binary.OSerializableWrapper.fromStream(OSerializableWrapper.java:48)   at com.orientechnologies.orient.core.serialization.serializer.record.binary.ORecordSerializerBinaryV0.deserializeValue(ORecordSerializerBinaryV0.java:491)   ... 55 common frames omitted   Caused by: java.lang.ClassNotFoundException: org.codehaus.groovy.runtime.GStringImpl   at java.net.URLClassLoader.findClass(URLClassLoader.java:381)   at java.lang.ClassLoader.loadClass(ClassLoader.java:424)   at java.lang.ClassLoader.loadClass(ClassLoader.java:357)   at org.apache.felix.framework.BundleWiringImpl.doImplicitBootDelegation(BundleWiringImpl.java:1764)   at org.apache.felix.framework.BundleWiringImpl.searchDynamicImports(BundleWiringImpl.java:1693)   at org.apache.felix.framework.BundleWiringImpl.findClassOrResourceByDelegation(BundleWiringImpl.java:1528)   at org.apache.felix.framework.BundleWiringImpl.access$200(BundleWiringImpl.java:79)   at org.apache.felix.framework.BundleWiringImpl$BundleClassLoader.loadClass(BundleWiringImpl.java:1958)   at java.lang.ClassLoader.loadClass(ClassLoader.java:357)   at java.lang.Class.forName0(Native Method)   at java.lang.Class.forName(Class.java:348)   at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:683)   at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1863)   at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1746)   at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2037)   at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)   at java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)  {quote}",Bug,Major,Closed,"2018-08-27 17:33:40","2018-08-27 16:33:40",1
"Sonatype Nexus","deployment policy conflicts are logged as ERROR","Set a hosted maven repo with Deployment policy Disable redeploy.    When a conflicting upload is made, an ERROR log message is recorded with full stack trace.        h4. Expected    - Log this conflict as a WARN instead of ERROR  - Do not include the stack trace unless org.sonatype.nexus.extdirect.internal.ExtDirectServlet log level is set to DEBUG or lower.  - the message should be improved to mention deployment policy created the problem so the user can correlate that with the UI setting.  ",Bug,Medium,Open,"2018-08-24 21:19:12","2018-08-24 20:19:12",0.5
"Sonatype Nexus","nexus platform plugin repository manager operations do not include an appropriate user agent","1. Global Configuration of Jenkins, try to add a new Nexus Repository Manager 3 Connection for the Nexus Platform Plugin for Jenkins.  2. After entering the Server URL, the server is validated. Nexus RM receives this request:        The user agent is Java/1.8.0_152.    Pipeline script that includes staging operations for NXRM 3, for example         When this is run, Nexus receives this request:        The user agent is Apache-HttpClient/4.5.3 (Java/1.8.0_152).    The user agent in both cases does not include the version of the Nexus platform plugin sending the request.    In contrast, when IQ Server pipeline operations are performed, requests like this are sent with a more useful user agent value:        h4. Use Case    The user agent helps both support and the customer verify what specific versions of our products are accessing our server products.    Some customers even have use cases where http requests are filtered through firewalls and proxies based on user agent values.    h4. Expected    ALL HTTP operations by the Nexus Platform Plugin should include the same user agent.  The user agent should reflect the client product and version regardless of the server being accessed.     Historically the user agent has been a merging of <Sonatype Product ID>/<Sonatype Product version> (<technology user agent>).  ",Bug,Major,Open,"2018-08-23 14:59:57","2018-08-23 13:59:57",2
"Sonatype Nexus","create tag pipeline operation appends ? to POST url","Put this in a Jenkins pipeline script:        When the script is run, the request that Nexus receives is:        h4. Expected    There are no query parameters sent. The trailing ? is superfluous and should not be appended to the URL.",Bug,Trivial,Open,"2018-08-23 14:43:02","2018-08-23 13:43:02",2
"Sonatype Nexus","Jenkins Platform Plugin unable to determine Nexus Repository Manager version using Server URL with trailing slash","Create a nexus repository manager 3.x global connection in Jenkins using a Server url of *http://localhost:8081/*. Tab or click away from the field. The field is validated and a request is sent to your Nexus 3 instance.    An error displays in the Jenkins UI:    {quote}Unable to determine Nexus Repository Manager version. Certain operations may not be compatible with your server which could result in failed builds.  {quote}    Your jenkins log will contain the cause:        The request is sent to http://localhost:8081//service/rest/wonderland/status instead of http://localhost:8081/service/rest/wonderland/status. Nexus 3 returns 404.    h4. Expected    Trailing slashes should be handled better by this field and ALL outbound requests ( see NEXUS-17756 for alternates )  to NXRM made using this value, either at the configuration screen or during builds. An end user can't be expected to readily know the semantic differences between http://localhost:8081 and http://localhost:8081/ .",Bug,Blocker,Closed,"2018-08-23 14:28:17","2018-08-23 13:28:17",3
"Sonatype Nexus","Can not upload binary to Nexus Repo Raw Repository - Detected content type","When I try to upload a binary component to Nexus Repo Raw Repository (NRM3.11 pro), I get an error. I tried uploading a  tgz, dmg and a nupkg and received similar errors.    What I would expect is that the component would be uploaded and be made available as a http link for users to be able to download.    I would expect to be able to upload any binary as per [https://help.sonatype.com/repomanager3/user-interface/uploading-components#app]         Reproduced in 3.11 and 3.13    error messages    [https://files.slack.com/files-pri/T0LE5769K-FCDPBKVEW/image.png]    [https://files.slack.com/files-pri/T0LE5769K-FCEQF6AT1/image.png]    [https://files.slack.com/files-pri/T0LE5769K-FCD6QSND7/image.png]         Error message:     Detected content type [application/zlib, application/x-deflate], but expected [application/x-apple-diskimage]: intellij/ideaIC-2018.2.2.dmg               ",Bug,Medium,Closed,"2018-08-23 10:53:02","2018-08-23 09:53:02",2
"Sonatype Nexus","NpmProxyFacetImpl.mergeNewRootWithExistingRoot should handle when an existing root disappears","{{NpmProxyFacetImpl.mergeNewRootWithExistingRoot}} was added in 3.13.0 under NEXUS-15714 to handle situations where we have previously proxied NPM packages that no longer exist on the remote. It does this by iterating over versions that no longer appear in the new package root, checking to see if any records exist for them locally. To do this it needs to load any existing package root.    Unfortunately this introduces a window where the proxy facet could load an existing package root record, only to find that the referenced blob has since been replaced by another thread. This can happen in HA when the package root is being updated from multiple nodes. This will cause a retry whereas before the new package root would simply be replaced.    The reason we'd prefer to retry is so we don't lose any cached NPM package versions that no longer exist in the upstream package root. If we never retried and just saved the (un-merged) upstream package root then we could potentially lose that cached information. That said, removal of upstream package versions should be rare - and failing to proxy the package root just because the existing root went away between loading the record and fetching the blob is not very robust.    One option is to always ignore when an existing package root's blob is not available.    Another option would be to allow retries, but if we reach the retry limit (you can tell this by catching {{RetryDeniedException}}) then go ahead and cache the upstream package root without merging.",Bug,Medium,Closed,"2018-08-18 17:56:44","2018-08-18 16:56:44",5
"Sonatype Nexus","Nuget package version behaviour different from www.nuget.org ","For package NUnitTestAdaptor, Nuget site shows version is '1.2.0   [https://www.nuget.org/packages/NUnitTestAdapter/]    Request for 1.2.0 through Nexus returns a 404    {{curl -v -u admin:admin123 http://localhost:8081/repository/nuget-test/Packages(Id='NUnitTestAdapter',Version='1.2.0') -o /dev/null}}    Request for 1.2 returns 200    {{curl -v -u admin:admin123 http://localhost:8081/repository/nuget-test/Packages(Id='NUnitTestAdapter',Version='1.2') -o /dev/null}}    Both calls work fine when going directly to [https://www.nuget.org/api/v2]    {{curl -v https://www.nuget.org/api/v2/Packages(Id='NUnitTestAdapter',Version='1.2.0') -o /dev/null}}    {{curl -v https://www.nuget.org/api/v2/Packages(Id='NUnitTestAdapter',Version='1.2') -o /dev/null}}         The behavior is different when connected to Nexus. Nexus should handle the same way as if connected to nuget site directly       Looking at what is returned, it seems that the version is set to 1.2       {{ <content type=application/zip src=https://www.nuget.org/api/v2/package/NUnitTestAdapter/1.2.0/> <m:properties>}}   {{  <d:Id>NUnitTestAdapter</d:Id>}}   {{  <d:Version>1.2</d:Version>}}   {{  <d:NormalizedVersion>1.2.0</d:NormalizedVersion>}}   {{  <d:Authors>NUnit Software</d:Authors>}}         Looking at version 2.1.0, I see that the version is correctly set to 2.1.0        {{ <content type=application/zip src=https://www.nuget.org/api/v2/package/NUnitTestAdapter/2.1.0/>}}   {{ <m:properties>}}   {{  <d:Id>NUnitTestAdapter</d:Id>}}   {{  <d:Version>2.1.0</d:Version>}}   {{  <d:NormalizedVersion>2.1.0</d:NormalizedVersion>}}   {{  <d:Authors>NUnit Software</d:Authors>}}     ",Bug,Major,Open,"2018-08-15 14:15:47","2018-08-15 13:15:47",3
"Sonatype Nexus","No provision to provide server side encryption kms key details while creating s3 type blobstore","We are testing Nexus-3 PRO 3.12.1-01 & S3 Integration and hit a road block w.r.t creating the S3 based Blob store.. We use the Bring your own key i.e aws-kms  and not the default aws provided kms key as part of Server side encryption on the S3 buckets for obvious security reasons in our organisation.         Current policy mandates that the request header should have the Server side encryption kms-keyId for the PUT’s to succeed and when I am trying to create a blobstore by specifying the existing bucket details it throws Access denied error because of the missing kms keyId in the request.         I don’t see any field exposed to provide this configuration details i.e listed below on the Nexus-3 PRO 3.12.1-01 or on 3.13 version and was suggested to raise a enhancement request by the support team as this is preventing us to use the s3 for HA configuration.         a.       SSE Alogirthm type (Example : aws:kms)    b.      SSE KMS key Id  (Example : 6fxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx)    c.       Storage Class (Example : Standard)         *_Example arg params i.e sent from the aws Cli to upload any objects to s3:_*    --sse aws:kms --storage-class STANDARD --sse-kms-key-id : 6fxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx     ",Story,Major,Done,"2018-08-15 13:11:22","2018-08-15 12:11:22",2
"Sonatype Nexus","Log noise when clicking on an npm package root in the tree UI","If you click on an npm package node in the tree UI a very verbose warning is printed in the log.  There is no need for this to be a warning, it should be logged at DEBUG.     {quote}  2018-08-14 15:21:38,728-0400 ERROR [qtp545619715-42]  nexusadmin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: healthcheck_AssetDetail.identify, java-method: com.sonatype.nexus.plugins.healthcheck.pro.internal.ui.HealthCheckAssetDetailComponent.identify  java.lang.IllegalArgumentException: Malformed npm component with path ajv. If this is packageRoot, try selecting the tarball instead.   at com.google.common.base.Preconditions.checkArgument(Preconditions.java:210)   at com.sonatype.nexus.plugins.healthcheck.pro.internal.ui.AssetIdentificationService.getNpmComponentIdentifier(AssetIdentificationService.java:163)   at com.sonatype.nexus.plugins.healthcheck.pro.internal.ui.AssetIdentificationService.getComponentIdentifier(AssetIdentificationService.java:137)   at com.sonatype.nexus.plugins.healthcheck.pro.internal.ui.AssetIdentificationService.identify(AssetIdentificationService.java:100)   at com.sonatype.nexus.plugins.healthcheck.pro.internal.ui.AssetIdentificationService$identify.call(Unknown Source)   at com.sonatype.nexus.plugins.healthcheck.pro.internal.ui.HealthCheckAssetDetailComponent.identify(HealthCheckAssetDetailComponent.groovy:47)   at com.palominolabs.metrics.guice.ExceptionMeteredInterceptor.invoke(ExceptionMeteredInterceptor.java:49)   at com.palominolabs.metrics.guice.TimedInterceptor.invoke(TimedInterceptor.java:47)   at org.sonatype.nexus.validation.internal.ValidationInterceptor.invoke(ValidationInterceptor.java:53)   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49)   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68)   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36)   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:497)   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142)   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133)   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet$3.invokeMethod(ExtDirectServlet.java:236)   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63)   at com.softwarementors.extjs.djn.router.processor.standard.StandardRequestProcessorBase.dispatchStandardMethod(StandardRequestProcessorBase.java:73)   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:502)   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequestsInThisThread(JsonRequestProcessor.java:150)   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.process(JsonRequestProcessor.java:133)   at com.softwarementors.extjs.djn.router.RequestRouter.processJsonRequest(RequestRouter.java:83)   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.processRequest(DirectJNgineServlet.java:630)   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.doPost(DirectJNgineServlet.java:593)   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet.doPost(ExtDirectServlet.java:141)    {quote}     ",Bug,Major,Closed,"2018-08-14 23:32:28","2018-08-14 22:32:28",1
"Sonatype Nexus","Repair - Reconcile component database from blob store failure","A user ran the Repair - Reconcile component database from blob store task this failed with the exception seen below.  From the stack, it seems a maven-metadata.xml file was being restored and the file already existed in the target repository.   This is logged as a warning, which is fine, but there are two big problems with the way this was handled:   # The repository and path of the failed asset are not printed   # The task should not stop just because one file couldn't be restored       ",Bug,Major,Closed,"2018-08-14 16:45:38","2018-08-14 15:45:38",2
"Sonatype Nexus","Maven proxy repository download of exe artifact fails","2018-08-14 10:15:45,262+0800 WARN [qtp1501796269-2439] *UNKNOWN org.sonatype.nexus.repository.view.handlers.ExceptionHandler - Invalid content: GET /com/google/protobuf/protoc/3.6.0/protoc-3.6.0-linux-x86_64.exe: org.sonatype.nexus.repository.InvalidContentException: Detected content type [application/x-executable], but expected [application/x-dosexec]: com/google/protobuf/protoc/3.6.0/protoc-3.6.0-linux-x86_64.exe  2018-08-14 10:15:45,479+0800 WARN [qtp1501796269-2439] *UNKNOWN org.sonatype.nexus.repository.view.handlers.ExceptionHandler - Invalid content: GET /com/google/protobuf/protoc/3.6.0/protoc-3.6.0-linux-x86_64.exe: org.sonatype.nexus.repository.InvalidContentException: Detected content type [application/x-executable], but expected [application/x-dosexec]: com/google/protobuf/protoc/3.6.0/protoc-3.6.0-linux-x86_64.exe  2018-08-14 10:16:57,386+0800 WARN [qtp1501796269-2437] *UNKNOWN org.sonatype.nexus.repository.view.handlers.ExceptionHandler - Invalid content: GET /com/google/protobuf/protoc/3.6.0/protoc-3.6.0-linux-x86_64.exe: org.sonatype.nexus.repository.InvalidContentException: Detected content type [application/x-executable], but expected [application/x-dosexec]: com/google/protobuf/protoc/3.6.0/protoc-3.6.0-linux-x86_64.exe  2018-08-14 10:16:57,712+0800 WARN [qtp1501796269-2437] *UNKNOWN org.sonatype.nexus.repository.view.handlers.ExceptionHandler - Invalid content: GET /com/google/protobuf/protoc/3.6.0/protoc-3.6.0-linux-x86_64.exe: org.sonatype.nexus.repository.InvalidContentException: Detected content type [application/x-executable], but expected [application/x-dosexec]: com/google/protobuf/protoc/3.6.0/protoc-3.6.0-linux-x86_64.exe",Bug,Major,Closed,"2018-08-14 03:33:39","2018-08-14 02:33:39",1
"Sonatype Nexus","Createrepo run simultaneously across multiple repositories can fill the events queue blocking further uploads","If the wait interval is too high and too many repositories each schedule a createrepo at the same time then there is a chance that the event thread pool will get filled up blocking the rest of the application and further uploads.    *Steps to reproduce*  # Set nexus.yum.createrepo.interval to a large number in etc/nexus.properties ( try 60000000)  # Create a large number of yum repositories (I had 1000 but 50 should do it)  # Upload a single RPM to each one  # Eventually your uploads will fail because events from across the system are blocked because all threads in the event pool are used up waiting for https://github.com/sonatype/nexus-internal/blob/f1a057acd48746090bddcf47db6fe29da1e90ff7/private/plugins/nexus-repository-yum/src/main/java/org/sonatype/nexus/repository/yum/internal/createrepo/CreateRepoFacetImpl.java#L203 ",Bug,Major,Open,"2018-08-13 17:54:18","2018-08-13 16:54:18",3
"Sonatype Nexus","Nexus Jenkins plugin fails requests when repository manager is not at base webapp context path","Front Nexus repository manager 3 with a webapp context path that is not /. For example is /nexus instead.    In this scenario, connections to list repositories from the Nexus Platform Plugin for Jenkins fail.        h4. Expected    Nexus may be hosted at any level of webapp context path ( ie. /nexus/server/1/ - connections to it must expect this and handle it normally.",Bug,Major,Closed,"2018-08-08 17:55:10","2018-08-08 16:55:10",2
"Sonatype Nexus","Cannot clone from git-lfs repository using role with only read rights","I cannot clone (403 HTTP code) git repository which have Git LFS enabled as user with only read role (nx-repository-view-*--*-browse, nx-repository-view*--*-read privileges). When nx-repository-view*-*-add privilege is added, I can clone without any problems.    We use git-lfs-authenticate command to add Authorization header to requests sent to Nexus.",Bug,Major,Open,"2018-08-02 15:49:30","2018-08-02 14:49:30",0
"Sonatype Nexus","2 bundler requested endpoints are problematic","I just updated from 3.10.0 to 3.12.1 and gem resolution is problematic.  It wasn't perfect in 3.10.0 either (if you want a seperate ticket, let me know).    I have a rubygems group repository called 'gems' that contains hosted and proxied repositories.  The following behavior was determined by running bundle update --verbose with bundler version 1.16.1, ruby 2.5.1.    In 3.10.0, the first request to [https://nexus.example.com/nexus/repository/gems/versions] yields a 400 with no error in the nexus.log.  This causes a second request to [https://nexus.example.com/nexus/repository/gems/api/v1/dependencies,] which works correctly.         In 3.12.1, [https://nexus.example.com/nexus/repository/gems/versions] leads to a 400 and [https://nexus.example.com/nexus/repository/gems/api/v1/dependencies] gives a 404 (again, nothing concerning in nexus.log).  This causes bundler to download the specs and check each gemspec, which is a slow process.         The ideal behavior is that bundler can use [https://nexus.example.com/nexus/repository/gems/versions].",Bug,Major,Open,"2018-07-17 15:44:57","2018-07-17 14:44:57",0
"Sonatype Nexus","Rubygems metadata shows {} when empty","I noticed that when Rubygems has no metadata it shows {}.  This is in contrast to other fields around it (e.g. requirements and executables) as well as I believe browse wide that when empty show nothing.  See attached.    Seems the same for both hosted and proxy.",Bug,Trivial,Closed,"2018-07-16 19:02:14","2018-07-16 18:02:14",1
"Sonatype Nexus","On browse w/ LDAP, if no perms, a bunch of warns are fired","With an LDAP user with just analytics permission, I logged in and clicked Browse (as it was clickable) and while nothing showed (proper since I have no permission), I noticed a bunch of WARNs in the nexus.log (see below, for example, attached for full nexus.log snip).  It seems to be looking through various groups, not sure why.  I didn't think this was all of them but looking at the size, it might be.        While not a functional issue, I left minor given the unknown of how much log bloat this would cause.  It's a lot for the number it seemed to hit here.",Bug,Minor,Closed,"2018-07-13 21:52:55","2018-07-13 20:52:55",1
"Sonatype Nexus","404s returned for packages containing build-metadata in version","A 404 is returned from nuget.org when attempting to get a package containing build-metadata in it's version e.g. 1.0.0+githash (see [SemVer 2.0.0|https://docs.microsoft.com/en-us/nuget/reference/package-versioning#semantic-versioning-200])    For example [https://www.nuget.org/packages/NuGet.Frameworks/4.7.0]    To reproduce:   # Setup proxy repo, proxying to [https://www.nuget.org/api/v2] (i.e. nuget.org-proxy)   # Enable DEBUG logging on com.sonatype.nexus.repository.nuget.internal   # Via a nuget client attempt to install package e.g.     _nuget install NuGet.Frameworks -Version 4.7.0 -source [http://localhost:8081/repository/nuget.org-proxy]_         *Expected:*    Package metadata and package are located and installed.    *Actual:*    Package is not installed and a 404 is returned. Following observed in logs showing 404 returned from nuget:  {quote}2018-07-13 15:22:08,672+0100 DEBUG [qtp784640267-626]  *UNKNOWN com.sonatype.nexus.repository.nuget.internal.NugetFeedFetcher - Fetching: GET [https://www.nuget.org/api/v2/Packages(Id='NuGet.Build.Tasks.Pack',Version='4.8.0-preview3.5278+c3240b16fcf3276246fc8c610771d14ab94fdc02]') HTTP/1.1    2018-07-13 15:22:08,792+0100 DEBUG [qtp784640267-626]  *UNKNOWN com.sonatype.nexus.repository.nuget.internal.NugetFeedFetcher - Response: HttpResponseProxy\{HTTP/1.1 404 Not Found [Cache-Control: private, Transfer-Encoding: chunked, Content-Type: text/html; charset=utf-8, Content-Security-Policy: frame-ancestors 'none', X-Frame-Options: deny, X-XSS-Protection: 1; mode=block, X-Content-Type-Options: nosniff, Strict-Transport-Security: max-age=31536000, Date: Fri, 13 Jul 2018 14:22:03 GMT, Connection: close] ResponseEntityProxy\{[Content-Type: text/html; charset=utf-8,Chunked: true]}}    2018-07-13 15:22:08,792+0100 DEBUG [qtp784640267-626]  *UNKNOWN com.sonatype.nexus.repository.nuget.internal.NugetFeedFetcher - Status: HTTP/1.1 404 Not Found    2018-07-13 15:22:08,793+0100 WARN  [qtp784640267-626]  *UNKNOWN com.sonatype.nexus.repository.nuget.internal.NugetFeedFetcher - Status code 404 contacting [https://www.nuget.org/api/v2/Packages(Id='NuGet.Build.Tasks.Pack',Version='4.8.0-preview3.5278+c3240b16fcf3276246fc8c610771d14ab94fdc02]')    2018-07-13 15:22:08,901+0100 DEBUG [qtp784640267-626]  *UNKNOWN com.sonatype.nexus.repository.nuget.internal.proxy.NugetProxyFacet - Proxy repo nuget.org-proxy found no package entry for NuGet.Build.Tasks.Pack 4.8.0-preview3.5278+c3240b16fcf3276246fc8c610771d14ab94fdc02 at remote  {quote}       The request being made is [https://www.nuget.org/api/v2/Packages(Id='NuGet.Frameworks',Version='4.7.0+9245481f357ae542f92e6bc5e504fc898cfe5fc0')] which fails.     Request omitting the build-metadata is successful:  [https://www.nuget.org/api/v2/Packages(Id='NuGet.Frameworks',Version='4.7.0')] and [https://www.nuget.org/api/v2/package/NuGet.Frameworks/4.7.0]    Installing the package directly against nuget.org is successful and it is observed the build-metadata is being omitted i.e. _nuget install NuGet.Frameworks -Version 4.7.0 -source [https://nuget.org/api/v2] -Verbosity detailed_     ",Bug,Major,Closed,"2018-07-13 16:19:46","2018-07-13 15:19:46",2
"Sonatype Nexus","Docker proxy repositories auto-block for images that don't exist","Create a proxy repository to docker hub.  Put this in a group repository.    Then request a manifest from through the group repository that doesn't exist on docker hub:    [http://localhost:8081/repository/docker-group/v2/fff/ggg/manifests/4.0.8r0]    The remote will return an authorization error, causing the repository to auto-block:       {quote}2018-07-06 14:40:20,433-0500 WARN  [qtp335821775-248] admin org.sonatype.nexus.repository.docker.internal.V2Handlers - Error: GET /v2/fff/ggg/manifests/4.0.8r0: 401 - org.sonatype.nexus.repository.docker.internal.V2Exception: authentication required   2018-07-06 14:40:41,441-0500 INFO  [elasticsearch[441A7C2A-D43F4D99-9C18AFA3-F4D24CC1-BA03CB4F][management][T#2|#2]] *SYSTEM org.elasticsearch.cluster.routing.allocation.decider - [441A7C2A-D43F4D99-9C18AFA3-F4D24CC1-BA03CB4F] low disk watermark [85%] exceeded on [ggbWczR0QgqEeYJBh3TOpg][441A7C2A-D43F4D99-9C18AFA3-F4D24CC1-BA03CB4F][/Users/<USER>temp/foo/sonatype-work/nexus3/elasticsearch/nexus/nodes/0] free: 67.8gb[14.5%], replicas will not be assigned to this node   2018-07-06 14:41:00,609-0500 INFO  [Check Status https://registry-1.docker.io] admin org.sonatype.nexus.repository.httpclient.internal.HttpClientFacetImpl - Repository status for docker-io changed from AUTO_BLOCKED_UNAVAILABLE to AVAILABLE - reason n/a for n/a   2018-07-06 14:41:11,451-0500 INFO  [elasticsearch[441A7C2A-D43F4D99-9C18AFA3-F4D24CC1-BA03CB4F][management][T#3|#3]] *SYSTEM org.elasticsearch.cluster.routing.allocation.decider - [441A7C2A-D43F4D99-9C18AFA3-F4D24CC1-BA03CB4F] low disk watermark [85%] exceeded on [ggbWczR0QgqEeYJBh3TOpg][441A7C2A-D43F4D99-9C18AFA3-F4D24CC1-BA03CB4F][/Users/<USER>temp/foo/sonatype-work/nexus3/elasticsearch/nexus/nodes/0] free: 67.8gb[14.5%], replicas will not be assigned to this node  {quote}       I'm not entirely sure why the remote returns unauthorized when it should return 404.  It seems to be some sort of misguided attempt at security?    But the current behavior of auto-blocking potentially makes them unavailable for subsequent requests.       This behavior might be OK for a direct request to to a docker proxy repository (maybe). But it causes a real problem for group repositories. They can contain many docker proxy repositories, so it is expected that requests will be coming into them frequently be for images that don't exist on at least some of the remotes of their contained proxy repositories.     ",Bug,Major,Closed,"2018-07-06 20:40:41","2018-07-06 19:40:41",3
"Sonatype Nexus","clarify intent when no components found for REST API","The REST call to associate a tag with components may return a 200 status code indicating the operation was successful, but the response body may not contain any components the tag was associated with.    {    status: 200,    message: Association successful,    data: {      components associated: []    }  }    One user of the REST API was confused by this. Their usage pattern was:    1. create tag - 204  2. associate tag with components - 200  3. move components with tag  - 404    At step 2, the status code implies some components were associated with the tag, when in fact there were no components found matching the criteria submitted.    The script moved to step 3 and failed curiously because there were no components fou d with the tag applied in step 2.    So while the API seems to be acting as designed, there may be a slight disconnect between tagging and staging here.     h4. Expected    Clarify why the associate tag API returns 200 status code even though no components VS the staging move API which returns 404 for no components.    Add this type of caveat or clarity to our documentation.  ",Bug,Major,Closed,"2018-07-03 14:28:59","2018-07-03 13:28:59",1
"Sonatype Nexus","Content validation message does not log which repository the invalid content is coming from","When a proxy repository gets a file that fails content validation it logs a message like this:  {quote}2018-06-29 00:00:23,232-0600 WARN [qtp194194304-13484] *UNKNOWN org.sonatype.nexus.repository.view.handlers.ExceptionHandler - Invalid content: GET /net/jcip/annotations/1.0/annotations-1.0.pom: org.sonatype.nexus.repository.InvalidContentException: Detected content type [text/html], but expected [application/xml, text/xml, application/x-xml]: net/jcip/annotations/1.0/annotations-1.0.pom.xml  {quote}  Note that it does *not* say which repository has the problem. This makes it very difficult to track the problem down. A problem which could have been solved in seconds requires enabling http debug logging, and then laboriously scanning the output to determine where the bad content is coming from.  This can take a considerable amount of time.    *Expected:* The log message should clearly log which repository the invalid content was received in.",Bug,Major,Closed,"2018-06-29 19:23:52","2018-06-29 18:23:52",1
"Sonatype Nexus","Caching of NuGet metadata causes thread serialization, query slowdowns under load","Threads updating NuGet metadata are getting be serialized, as can be seen in the examples below.  This is causing a slowdown in processing of NuGet queries.      This was observed in Nexus Repo 3.8.0-02.    Full thread dump is attached.  In that thread dump there are 5 threads waiting on the one that is running.        Example blocked thread:      ",Bug,Major,Closed,"2018-06-29 18:10:47","2018-06-29 17:10:47",3
"Sonatype Nexus","option to generate URL-safe user tokens for URL based authentication","Certain primitive repository formats only support URL based authentication of the form:    [http://user:password@localhost:8081|http://user:password@localhost:8081/artifactory/api/pypi/pypi-virtual/simple]    For example PyPI is known to have this problem:    [https://github.com/pypa/pip/issues/4315]    YUM auth has a similar problem.    Admins may want to enforce authenticated access to repo manager using our User Tokens feature.    Currently User Tokens may be generated with non-url safe characters which prevent using the above URL based authentication mechanism.  h4. Expected    To support primitive url based auth, there should be an optional option to generate user tokens which only contain url safe characters.    h4. Possible Workaround Some Formats    Take the user token name and value generated by Nexus and URL Encode them manually first, before adding them to the URL being used in your tool.    For example, Nexus generates these tokens:    Name Code: {{/pKsRLhn}}   Pass Code: {{/HAx3rBkdsQAmsUhc2RWt73CY8zrMJPS9e1HnYeseYbh}}    As expected, this URL will not parse correctly:    [URL Encode|https://www.urlencoder.org/] each value:    Name Code: {{%2FpKsRLhn}}   Pass Code: {{%2FHAx3rBkdsQAmsUhc2RWt73CY8zrMJPS9e1HnYeseYbh}}    All of these requests authenticate properly:      While no authentication for the same URL will fail:         h4. Windows Pip     This workaround does not solve this issue for python/pip when running on Windows, see my comment below for details.",Improvement,Major,Closed,"2018-06-29 16:39:36","2018-06-29 15:39:36",1
"Sonatype Nexus","Document Docker use of content selectors","*Acceptance*    Amend the documentation so that users know how to subdivide Docker repositories based on tag names. Make sure they know it's leaky (since you can request content by hash, in theory.)",Story,Major,Done,"2018-06-28 16:05:48","2018-06-28 15:05:48",2
"Sonatype Nexus","Unable to install hosted gem which has multiple version requirements","h1. Bug description    If a ruby gem is hosted on Sonatype Nexus 3 Rubygems repository    and that ruby gem contains multiple version requirements for a dependency in its gemspec    and the project which uses the ruby gem does not have a Gemfile.lock    Then bundler will fail to install the project gems with the following message:    h1.      We noticed this bug on our production ruby gem repositories (hosted on Sonatype Nexus3 v3.6.2) then I reproduced with the latest version of SNRM : v3.12.1         This issue has been reported on bundler github (see [https://github.com/bundler/bundler/issues/6048] ). The original bug report mentions Sonatype Nexus but was closed without having been properly investigated.       h1. Reproducing the bug       h2. Nexus Setup         I installed an instance of Sonatype Nexus3 using docker like this:    Once the instance has booted, I open [http://localhost:8081|http://localhost:8081/] with browser, log to nexus using default credentials (admin/admin123), then I create a hosted rubygems repository which I name gems-test.    The URL of the gems-test repository on the local nexus is [http://localhost:8081/repository/gems-test/]       h2. Test ruby gem         I generated a sample ruby gem using the `bundle gem test-gem-requirement-bug` command on my workstation.         I edited the generate gem to supply the following gemspec:         Note the multiple version requirement on the activesupport dependency above.         Then I `gem build *gemspec` to produce the gem.         Then I upload the produced gem to Nexus using the upload interface at http://localhost:8081/#browse/upload:gems-test         If everything was successful the ruby gem should be listed in the browse view of the gems-test repository (URL [http://localhost:8081/#browse/browse:gems-test] )  h2. Test ruby project         I create a sample ruby project on my workstation, which uses the test-gem-requirement-bug gem.              Then, still in the testproject directory, I run:         To install the project dependencies.         The bundle install command fails with the trace at the top of project.                   Note that running bundle install --path .bundle --full-index succeeds to install the gem and its dependencies (even if it is inefficient).               ",Bug,Major,Closed,"2018-06-27 15:42:27","2018-06-27 14:42:27",3
"Sonatype Nexus","RemoteBlockedIOException WARN logged for every content request to manual or auto blocked repository should be TRACE","# In Nexus 3.12.1, create a proxy repository.   # Set block outbound connections on the repository to true.   # Fire a request to the repository.    You will see a warning like this in the log:  {quote}2018-06-26 14:30:18,863-0500 WARN [qtp335821775-220] admin org.sonatype.nexus.repository.maven.internal.proxy.MavenProxyFacet - Exception org.sonatype.nexus.repository.httpclient.RemoteBlockedIOException: Remote Manually Blocked checking remote for update, proxy repo maven-central failed to fetch foo/bar/maven-metadata.xml, content not in cache.  {quote}  This will be repeated for every single request received by the proxy, filling the logs with useless messages.    *Expected:*    -This should be logged at DEBUG, if at all.- Upon closer review moving the level to TRACE seems better since the blocked status of a repository can be easily determined from other INFO level log messages and the repository status is also visible when viewing the repositories list in the UI.",Bug,Major,Closed,"2018-06-26 20:34:05","2018-06-26 19:34:05",1
"Sonatype Nexus","Nexus 2 to 3 upgrade fails with concurrency error in NuGet","The exception below was observed in the migration logs of someone who was upgrading from Nexus 2 to Nexus 3. This looks like a concurrency bug to me:  ",Bug,Major,Closed,"2018-06-21 20:16:14","2018-06-21 19:16:14",3
"Sonatype Nexus","Last-Modified not returned in header for migrated RAW artifacts.","Nexus 3.x does not return a Last-Modified header for migrated artifacts (migrated from Nexus 2.x)  {quote}$ curl --head localhost:8081/repository/jenkins-tools/jdk/jdk1.8.0_171.tar.gz    HTTP/1.1 200 OK    Date: Thu, 21 Jun 2018 11:22:30 GMT    Server: Nexus/3.12.0-01 (PRO)    X-Content-Type-Options: nosniff    Content-Security-Policy: sandbox allow-forms allow-modals allow-popups allow-presentation allow-scripts allow-top-navigation    Content-Type: application/x-gzip    Content-Length: 190882219  {quote}  If you upload an artifact to that Nexus 3.x instance, then the Last-Modified is returned.  {quote}$ curl --head localhost:8081/repository/jenkins-tools-test/jdk/jdk1.8.0_171.tar.gz    HTTP/1.1 200 OK    Date: Thu, 21 Jun 2018 11:22:24 GMT    Server: Nexus/3.12.0-01 (PRO)    X-Content-Type-Options: nosniff    Content-Security-Policy: sandbox allow-forms allow-modals allow-popups allow-presentation allow-scripts allow-top-navigation    Last-Modified: Thu, 21 Jun 2018 11:17:29 GMT    Content-Type: application/x-gzip    Content-Length: 190882219  {quote}  Reproduced this with Raw repo. Works fine with Maven2",Bug,Major,Closed,"2018-06-21 14:07:15","2018-06-21 13:07:15",2
"Sonatype Nexus","Uncaught TypeError: Cannot read property 'length' of null trying to save a role which cannot be found","Configure LDAP server and LDAP realm.    Try to map an LDAP role that does not exist.    Click Save to save the role.    Saving the role will fail because Nexus tries to find the role in LDAP and can't. The UI should show a message that the role could could not be found.    The javascript console contains this error:    nexus-coreui-plugin-prod.js?_v=3.12.1-01:1 Uncaught TypeError: Cannot read property 'length' of null   at j.load (nexus-coreui-plugin-prod.js?_v=3.12.1-01:1)   at A.fire (baseapp-prod.js?_v=3.12.1-01:1)   at j.continueFireEvent (baseapp-prod.js?_v=3.12.1-01:1)   at j.fireEventArgs (baseapp-prod.js?_v=3.12.1-01:1)   at j.a.fireEventArgs (baseapp-prod.js?_v=3.12.1-01:1)   at j.fireEvent (baseapp-prod.js?_v=3.12.1-01:1)   at j.onProxyLoad (baseapp-prod.js?_v=3.12.1-01:1)   at A.processResponse (baseapp-prod.js?_v=3.12.1-01:1)   at A.<anonymous> (baseapp-prod.js?_v=3.12.1-01:1)   at baseapp-prod.js?_v=3.12.1-01:1         !image-2018-06-20-17-23-16-072.png!  h4. Expected    - there should be no javascript errors in this case.",Bug,Major,Closed,"2018-06-20 21:22:55","2018-06-20 20:22:55",2
"Sonatype Nexus","WARN Unable to look up Crowd user null due to java.lang.IllegalStateException/Crowd not configured even when Crowd realm is not active","h4. Reproduce #1    Do not add Crowd realm as active.  Do not configure a crowd server.  Have LDAP realm enabled.  Have one LDAP server configured.  If there is a problem authenticating the LDAP user, the Crowd realm is tried anyways despite all this:    2018-06-20 15:09:38,770-0300 WARN  [pool-21-thread-2] *UNKNOWN com.sonatype.nexus.crowd.internal.CrowdUserManager - Unable to look up Crowd user null due to java.lang.IllegalStateException/Crowd not configured    h4. Reproduce #2   Boot a vanilla Nexus 3.13.0 instance. Signin as the default admin user. Enable user Token and realm. View you user token a few times. Sign-out. The nexus.log shows WARN messages seemingly for every outreach related request made as the anonymous user.    {noformat:title=nexus.log}  2018-06-29 16:17:06,859-0300 INFO  [qtp1106547043-64] admin org.sonatype.nexus.rapture.internal.security.SessionServlet - Deleting session for user: admin  2018-06-29 16:17:07,667-0300 INFO  [pool-21-thread-14] *UNKNOWN org.ehcache.jsr107.ConfigurationMerger - Configuration of cache enterprise-ldap will be supplemented by template nexus-default  2018-06-29 16:17:07,669-0300 INFO  [pool-21-thread-14] *UNKNOWN org.ehcache.core.EhcacheManager - Cache 'enterprise-ldap' created in EhcacheManager.  2018-06-29 16:17:07,670-0300 INFO  [pool-21-thread-14] *UNKNOWN org.ehcache.jsr107.Eh107CacheManager - Registering Ehcache MBean javax.cache:type=CacheConfiguration,CacheManager=file./app/nexus-testing/3.13.0-01/nexus-installer-3.13.0-20180628.151433-87-mac-archive/nexus-3.13.0-SNAPSHOT/etc/fabric/ehcache.xml,Cache=enterprise-ldap  2018-06-29 16:17:07,670-0300 INFO  [pool-21-thread-14] *UNKNOWN org.ehcache.jsr107.Eh107CacheManager - Registering Ehcache MBean javax.cache:type=CacheStatistics,CacheManager=file./app/nexus-testing/3.13.0-01/nexus-installer-3.13.0-20180628.151433-87-mac-archive/nexus-3.13.0-SNAPSHOT/etc/fabric/ehcache.xml,Cache=enterprise-ldap  2018-06-29 16:17:07,689-0300 WARN  [pool-21-thread-14] *UNKNOWN com.sonatype.nexus.crowd.internal.CrowdUserManager - Unable to look up Crowd user null due to java.lang.IllegalStateException/Crowd not configured  2018-06-29 16:17:07,750-0300 WARN  [qtp1106547043-61] *UNKNOWN com.sonatype.nexus.crowd.internal.CrowdUserManager - Unable to look up Crowd user null due to java.lang.IllegalStateException/Crowd not configured  2018-06-29 16:17:07,802-0300 WARN  [qtp1106547043-64] *UNKNOWN com.sonatype.nexus.crowd.internal.CrowdUserManager - Unable to look up Crowd user null due to java.lang.IllegalStateException/Crowd not configured  2018-06-29 16:17:07,804-0300 WARN  [qtp1106547043-65] *UNKNOWN com.sonatype.nexus.crowd.internal.CrowdUserManager - Unable to look up Crowd user null due to java.lang.IllegalStateException/Crowd not configured  2018-06-29 16:17:07,806-0300 WARN  [qtp1106547043-190] *UNKNOWN com.sonatype.nexus.crowd.internal.CrowdUserManager - Unable to look up Crowd user null due to java.lang.IllegalStateException/Crowd not configured  2018-06-29 16:17:07,910-0300 WARN  [qtp1106547043-61] *UNKNOWN com.sonatype.nexus.crowd.internal.CrowdUserManager - Unable to look up Crowd user null due to java.lang.IllegalStateException/Crowd not configured      h4. Expected  - realms that are not enabled should not be tried  - do not add WARN logging for user not found in realm not enabled  - reconsider not WARN log level if simply a user cannot be found anyways - INFO better  - outreach resource should not perform user lookup for all realms, especially disabled realms - outreach in theory just needs to know if you are an administrator or anonymous user ti display appropriate content",Bug,Major,Open,"2018-06-20 19:32:15","2018-06-20 18:32:15",3
"Sonatype Nexus","log LDAP server configuration changes at default log levels","log at INFO to the application log the complete configuration of an ldap server entry when it is created or updated or deleted by a user in the UI or script ( excluding direct database manipulation ).    The log message can be formatted as standard object notation as you might see inside the support zip export _masking any credentials that may be included in the configuration objects_.",Improvement,Major,Open,"2018-06-20 19:14:30","2018-06-20 18:14:30",1
"Sonatype Nexus","IllegalStateException: Clustering is not enabled when refreshing nodes view in PRO when not clustered","Unpack a fresh PRO instance and start it without clustering.    Log in as admin and navigate to the nodes view: http://127.0.0.1:8081/#admin/system/nodes    Click the refresh symbol in the top-right of the UI and you'll get the following warning in the UI:        The issue appears to be that refreshing the nodes view using the refresh icon triggers reloading of the {{NX.coreui.store.Node}} store which then calls {{NX.direct.proui_Node.read}}. Note this store is not loaded when you navigate to the nodes view, only when you subsequently refresh the view using the refresh icon (and the warning only appears when not clustered).    One fix would be to avoid reloading the store when non-clustered, even when the refresh icon is clicked. The other option would be to make the PRO {{NodeComponent}} more robust and only use the {{hazelcastProvider}} when clustered - the other methods in that class have similar checks, it's only the read method that attempts to use the {{hazelcastProvider}} without checking if clustering is enabled or not. (We should pass back an empty result if clustering is not enabled.)",Bug,Minor,Closed,"2018-06-20 16:09:04","2018-06-20 15:09:04",1
"Sonatype Nexus","Repository Health Check reports can create orphaned blobs and log WARN Attempt to access non-existent blob","During recent testing [~<USER> saw the following output   {quote}org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access non-existent blob bg-score-critical.png (/Users/<USER>Documents/Work/nexus/NX3/nexus-internal/target/sonatype-work/nexus3/blobs/default/content/vol-20/chap-35/bg-score-critical-png.properties)  {quote}  Looking at the blob store we can see that the properties file exists but it includes the extension .png in the name    !screenshot-2.png|width=820,height=602!    Also notice that there are duplicates of the file, is it possible that we are leaving behind dead blobs because the naming is wrong?       h4. Reproduce    Load a repository with components. Enable Repository Health Check on that repository.    A script added in 3.13.0 can be run to detect and delete orphaned blobs and this will report blobs created by RHC as orphaned.    {noformat:title=OrphanedBlobFinder script only available as of 3.13.0}  import org.sonatype.nexus.repository.tools.OrphanedBlobFinder    def orphanedBlobFinder = container.lookup(OrphanedBlobFinder.class.name)    orphanedBlobFinder.delete()  {noformat}     h4. Diagnosis    The repository health check feature should not be creating orphaned blobs- this issue should be fixed. However presence of the WARN messages for the RHC generated blobs can be ignored by Nexus users until we ship a fix for that issue.          ",Bug,Major,Open,"2018-06-12 16:20:30","2018-06-12 15:20:30",2
"Sonatype Nexus","legacy URLs do not work with nexus.view.exhaustForAgents property","In 3.10.0, set these in etc/nexus.properties:        This request will be exhausted by the ExhaustRequestFilter filter:    {{curl -v -X PUT [http://localhost:8081/repository/maven-releases/foo] -H user-agent: maven-artifact -o /dev/null}}    This request will not and fail as per scenarios described in https://issues.sonatype.org/browse/NEXUS-10234 :    {{curl -v -X PUT [http://localhost:8081/content/repositories/maven-releases/foo] -H user-agent: maven-artifact -o /dev/null}}    Debugging shows that the filter still has the default agent pattern of *Apache-Maven.** for legacy URLs instead of the one set by the property.    h4. Expected    Legacy URLs should be perform identically to the regular URLs in the described case.          ",Bug,Major,Closed,"2018-06-06 19:17:10","2018-06-06 18:17:10",1
"Sonatype Nexus","Yum component properties update does not reflect in UI summary pane","As part of update test (so redeploy was on/allowed), I pushed the below item:    Then I realized I had the wrong package pushing so before metadata rebuild, I pushed again:    On review of the component/asset properties via the UI summary pane, it shows the fuse-sshfs property not the electricfence property. The rpm downloaded is electricfence however and the xml shows the right one as well (electricfence). Also not really surprisingly considering that, the blob updated attribute shows a different date than created.    If you do the reverse of this (eletricfence then fuse-sshfs) it does the reverse as well so it's not just something with electricfence.    I then tried waiting til after the metadata rebuild and seeing if that helped. It didn't.   It seems only the first package being pushed not the update is updating the properties in the UI even though the package is updated.   I tried clearing browser cache and restarting my browser in between as well, no dice.",Bug,Medium,Closed,"2018-06-05 19:42:35","2018-06-05 18:42:35",0.5
"Sonatype Nexus","LDAP Verify login validates for credentials before closing","I noticed that on LDAP config, if you click Verify login and then immediately cancel, it prompts for username validation before closing the window resulting in the need for an additional click to cancel.",Bug,Trivial,Closed,"2018-06-04 22:58:00","2018-06-04 21:58:00",0.5
"Sonatype Nexus","Yum Metadata Rebuild task says it's done and waiting but it's still working","I noticed when testing with a Yum DB with a million records that when I ran the Yum Metadata Rebuild task manually, it fired off a log message saying starting in waiting super quickly:    However, under the covers it's still running and the metadata isn't (re)generated til it's complete so it looks like it failed.  This seems to be pretty confusing for anyone who doesn't know this.  I certainly thought it failed when the log said waiting and the metadata didn't show.",Bug,Medium,Open,"2018-06-01 21:58:25","2018-06-01 20:58:25",5
"Sonatype Nexus","Removing repository does not remove tasks specific to the removed repository","Removing repository does not remove tasks specific to the removed repository. This cause the task to fail with a NullPointerException.    *Steps to Reproduce*   * Create a rebuild index task on existing repo.   * Remove that repository   * Run the rebuild index task    *Expected Behaviour*    Either remove the task linked to the removed repository or provide an error when task is run that explains the repository has been deleted (instead of the NullPointerException) .     ",Bug,Major,Closed,"2018-06-01 17:29:16","2018-06-01 16:29:16",1
"Sonatype Nexus","Spurious warnings logged when pushing docker images","Run the following commands:    {code}  docker pull hello-world  docker tag hello-world localhost:8444/hello-world  docker push localhost:8444/hellowworld  {code}    The upload succeeds, but 21 warnings are logged. They don't appear to hurt anything, the push succeeds.  But it is causing a lot of log noise.     ",Bug,Minor,Closed,"2018-05-31 20:06:48","2018-05-31 19:06:48",1
"Sonatype Nexus","Restarting while backup is in progress leaves NXRM as read-only","If you restart a node while it's taking a backup then the node will preserve the read-only state, despite the backup task having been aborted. The following log entry during restart is where it restores the frozen state:      The first thing to determine is whether this is acceptable behaviour - while it leaves NXRM in a degraded state (only returning previously cached content, disallowing write operations) it could be considered the safe option given NXRM was shutdown during backup. It is also not difficult to return NXRM to a writable state, using the UI or REST. If we decide this is working-as-designed then this ticket will verify that manual intervention can quickly return NXRM to normal service. We should also verify that the behaviour is the same whether NXRM is clustered or non-clustered.    However, if it's determined that this is not acceptable behaviour then this ticket will look at how to avoid leaving the freeze state if the backup task was aborted during shutdown. This may involve making sure we update the freeze state regardless of how the backup task ends. Note if the process is forcibly killed (eg. power-cut) then we won't get any chance to update it, but in that case it might be best to start as read-only as there may be data integrity issues. Another option would be to try and detect when backup was aborted and ignore restoring the freeze state - but that sounds more fragile. Other suggestions are welcome :)    While recreating these scenarios (restarting while non-clustered backup is in progress and restarting while clustered backup is in progress) also consider whether extra logging would be useful.    Summary:    * Confirm restarting while non-clustered backup is in progress leaves NXRM as read-only  * Confirm restarting while clustered backup is in progress leaves NXRM as read-only  * Get input from team / PO about desired behaviour  * Implement any change in behaviour (if necessary)  * Consider additional logging / recording reason for freeze",Bug,Major,Closed,"2018-05-29 10:08:17","2018-05-29 09:08:17",5
"Sonatype Nexus","user role mappings do not match user ids case insensitively","[User ids are intentionally matched case insensitively|https://issues.sonatype.org/browse/NEXUS-4115]. This issue demonstrates a case where they are not.    Setup Nexus to connect to an LDAP realm which contains a user record which has a userid of lowercase *testuser1*. Verify that you can authenticate as that user id.    Create a new role in nexus called *custom_role*.    Create a script to map roles to users like this and put in an Execute Script task:        Execute the script. The script creates a record in the Nexus security database similar to this:        One can authenticate the userid as testuser1 or TESTUSER1. However when the user record is found in the Users list in nexus, there will be no roles shown in the Active role list and after signin, the user will not have the permissions granted by the custom_role either.    Conversely if the user mapping is created using the Nexus UI, the userid is stored in Nexus with the lettercase matching that as stored in the LDAP server. In that case, when the custom_role is mapped to the user, there is no problem reading back its active roles.    h4. Expected    Since userids are to be authenticated case insensitively, a users roles should also be looked up by userid from the Nexus database case insensitively.  Since it is also possible that NXRM has allowed multiple user role mappings to the same userid ( but with different lettercase ), there should be a way for an admin to reconcile these duplicate userids either by way of running a script or from an upgrade step.    ",Bug,Critical,Closed,"2018-05-29 05:22:50","2018-05-29 04:22:50",2
"Sonatype Nexus","Nexus Repository 3.12.0 render error -- removeAll","After installation and login I receive the following error randomly when browsing.    Remove IP address.    ----------------    Unable to get property 'removeAll' of undefined or null reference (http://X.X.X.X:8081/static/rapture/nexus-rapture-prod.js?_v=3.12.0-01:1) ",Bug,Medium,Closed,"2018-05-27 00:59:40","2018-05-26 23:59:40",5
"Sonatype Nexus","rebuild maven metadata task may fail against permissive layout coordinates missing a base version","The following repository was defined in Nexus 3.6.0:        When the rebuild Maven metadata task processes this repository, the following exception can be triggered and the task will fail:        There are no seemingly no obvious log messages that can be enabled to identify the problem coordinates.    h4. Expected.    First priority is that the task should not fail. The repo policy was permissive and possibly could have been mixed or releases at some point. We allowed files to be stored in the repository that cause the task to fail. The task should proceed to fix the metadata as best as it can.    Second priority is to improve logging. The [next log line|https://github.com/sonatype/nexus-internal/blob/de1c5692c0ce54b20ea5c8eeab9c6b7a4a459320/plugins/nexus-repository-maven/src/main/java/org/sonatype/nexus/repository/maven/internal/hosted/metadata/MetadataBuilder.java#L263] below [where the exception is thrown|https://github.com/sonatype/nexus-internal/blob/de1c5692c0ce54b20ea5c8eeab9c6b7a4a459320/plugins/nexus-repository-maven/src/main/java/org/sonatype/nexus/repository/maven/internal/hosted/metadata/MetadataBuilder.java#L261]  is exactly what we could use to find the offending path and possibly delete the data from the repository to work around the problem.        Putting logging statements printing method arguments after method arguments are validated is an anti-pattern that should be avoided.",Bug,Major,Closed,"2018-05-25 14:20:58","2018-05-25 13:20:58",2
"Sonatype Nexus","Soft deleted blob in health check prevents viewing of component information","After upgrading from 3.10.0 to 3.12.0 a soft deleted blob prevented viewing of component information in an IQ integrated Nexus Repo instance.  The UI shows an NPE:  {quote}ERROR: (ID 4ceb7d0e-0bd4-49a1-9d71-1b72515fc38a) java.lang.NullPointerException  {quote}  The nexus.log shows:          ",Bug,Major,Closed,"2018-05-24 23:30:19","2018-05-24 22:30:19",1
"Sonatype Nexus","out of range error when installing some npm packages via proxy","I use nexus 2.14.8 as a npm proxy, when I run    npm install rc-select --registry=[http://nexus.example.com/content/repositories/npm-proxy/]    I get a lot of 500 error from the server.     nexus log:    ",Bug,Major,Closed,"2018-05-23 18:01:34","2018-05-23 17:01:34",0.5
"Sonatype Nexus","Apply content selector permissions to staging operations","*Acceptance*   * Allow staging operations on the basis of content selector permissions   * e.g. admins can allow staging operations to and from portions of repositories, rather than at the whole-repo level as specified in --NEXUS-15153--   * In situations where users don't have privileges to complete the operation*, the entire operation should return an error code.    e.g. components ABC are in Repo 1 (R1).   # A user can see ABC in R1   # User initiates move ABC to R2   # System checks permissions, finds user can't delete A from R1, and can't write C to R2.",Story,Major,Done,"2018-05-22 22:01:02","2018-05-22 21:01:02",5
"Sonatype Nexus","Staging REST endpoint returns 401 when a user is authenticated but lacks needed privileges","The new staging REST API returns a 401 response when a user has been successfully authenticated, but does not have the needed privileges to perform the operation.  This is incorrect, and very confusing.  It should return a 403 error when a user has been authenticated, but is not permitted.                    ",Bug,Major,Closed,"2018-05-21 20:37:48","2018-05-21 19:37:48",1
"Sonatype Nexus","PartialFetchHandler produces invalid HTTP responses","Any URL that has PartialFetchHandler involved produces invalid HTTP responses.    This was reported against the Nexus APT community plugin here: https://github.com/sonatype-nexus-community/nexus-repository-apt/issues/47    I looked into this, and it looks like {{PartialFetchHandler}} sends an invalid {{Content-Range}} header here: [https://github.com/sonatype/nexus-public/blob/82d58ec7e1464cf25efca423bbe5f8cbd6eb4f55/components/nexus-repository/src/main/java/org/sonatype/nexus/repository/http/PartialFetchHandler.java#L119]    According to the RFC ([https://tools.ietf.org/html/rfc7233#section-4.2]) the {{Content-Range}} header needs a unit specifier of bytes in it.    Also, it seems like the base code doesn't correctly handle the {{If-Range}} header. I have a PR that fixes both issues if you want to merge to the base code: [mpoindexter/nexus-public#1|https://github.com/mpoindexter/nexus-public/pull/1]",Bug,Major,Closed,"2018-05-17 01:55:52","2018-05-17 00:55:52",1
"Sonatype Nexus","Error communicating with IQ server persists indefinitely in repository manager if IQ server connection fails while displaying the repository list","*Historical:* This issue moved from https://issues.sonatype.org/browse/NEXUS-16977    Start a new NXRM 3.10.0-04.    Start a new IQ server 1.46 install.    Click Analyze button in NXRM repo list for maven-central, choose Yes to All to enable healthcheck for all repos. ( by default this means maven-central and nuget.org-proxy )    Click away from repo list. Click back to repo list.    Eventually the Healthcheck column states insufficient trend data for nuget.org-proxy and maven-central. The IQ Policy Violation column shows a circle with a line through it icon.    Configure IQ server connection to the running IQ server. Verify it is working.    Add a IQ: Audit and Quarantine capability for maven-central.    Click back to repositories list several times. Eventually the IQ Policy Violations column will show No Violations and a link to the report.    Make a request for an artifact in maven-central.  curl -v -u admin:admin123 http://localhost:8081/repository/maven-central/abbot/abbot/0.13.0/abbot-0.13.0.jar -o /dev/null    Click away and back to the repo list. IQ Policy Violations still shows No Violations.    Login to IQ server and verify that maven-central is registered correctly.    In NXRM click the maven-central report link. The report should show 1 component identified.    Stop IQ server    Request a different component from maven-central repo. This one takes 15 seconds to fail because Nexus can't reach IQ server.    Click away and then back to the repo list in NXRM. IQ Policy Violation column shows Error communicating with IQ Server Connection refused.    Start IQ Server.    Click away from then back into the repositories list. The IQ policy Violations column now shows No Violations + link again as it is able to detect that IQ server is available.    Stop IQ Server.    Click away and then back to the repo list in NXRM. IQ Policy Violation column shows Error communicating with IQ Server.    Start IQ Server.    Click away and then back to the repo list in NXRM. IQ Policy Violation column still shows Error communicating with IQ Server.    **{color:red}From this point on there is no non-destructive way to clear the Error Communicating with IQ server message except to restart NXRM{color}**    Other non-destructive things tried that do not work:    1) request a component through maven-central while IQ server is offline  2) signin and signout of NXRM UI  3) Click Verify Connection again successfully in NXRM IQ Server configuration screen    h4. Workaround    To reset the UI connection state:    First wait until or at least verify the IQ server has become available again - you can test this with the Verify Connection button in the IQ Server configuration screen. Even though the verification of connection succeeds, this will not make the UI error message go away.    Make a request for a jar artifact that exists at the remote but is not yet cached in the proxy repository local cache OR has never been requested while IQ server was disconnected. This should trigger a new evaluation for that artifact. If you do not know of an artifact that is at the remote that is not yet cached, use the Nexus UI to find jar asset, delete it, then make a request for it again through your proxy repository. This re-requesting of a non-cached asset that needs auditing will reset the audit task error state, if the IQ server can be reached.     Then click away from and click back to the repositories list view. The IQ Policy Evaluation column should then remove the error state.    h4. Expected    Brief interruptions to IQ server communication ( like restarts) should not persist indefinitely. If they do persist, there should be a well travelled trivial method to reset the connection state.    The stated workaround is not adequate:    - it is confusing and a manual process - it should be automatic  - it may be impossible to know the path of an artifact that exists at the remote that has never been requested through the proxy repository  - the manual process may need repeating for 10s to 100s of repos  - the log messages in the application log are not informative to solve or diagnose the problem  - Verify Connection on the IQ Server configuration verifies that the connection works, yet the UI state never resolves itself despite this    ",Bug,Major,Closed,"2018-05-16 17:34:53","2018-05-16 16:34:53",2
"Sonatype Nexus","Task Does Not Run (Again) if it Overruns into Next Run Time","If a scheduled task overruns into its 'Next Run' time, the 'Next Run' time is not updated and the task does not run again.    *To reproduce:*  1. Configure an 'Execute Script' task with the attached script. It is coded to run for ~5minutes.  2. Configure a cron expression for the task frequency so that it runs every 2 minutes i.e. 0 0/2 * 1/1 * ? *    As the task runs for 5 minutes, it goes past its next run time which does not get updated and the task does not run after its first run.",Bug,Major,Closed,"2018-05-09 18:48:15","2018-05-09 17:48:15",3
"Sonatype Nexus","NullPointerException when accessing the HTML view of a repository as anonymous user (when anonymous access is disabled)","I've received this error under these circumstances:   * Nexus OSS 3.11.0-01   * anonymous access disabled   * used browser to access: [https://nexus/service/rest/repository/browse/maven-group/]   ** result: ERROR: (ID e58724ee-f009-47f8-9c17-2be6ee10e8e7) java.lang.NullPointerException   * if I log in to Nexus, the browsing succeeds    I am happy an anonymous user cannot browse the repository (as intended), but they should probably just get an Unauthorized message rather than a NullPointerException.",Bug,Major,Closed,"2018-05-06 06:09:10","2018-05-06 05:09:10",1
"Sonatype Nexus","Task scheduling can give UI errors","Example repro steps:  Enable a Repository Health Check on a maven, nuget, or npm repo.    Attempt to edit the settings for the resulting task, e.g.    System - Repository Health Check: maven-central (Check for new report availability)    Change the 'Task frequency', from Hourly to Daily and save the changes.     The UI shows errors like the one below, and the page will need to be reloaded at the browser level to function:    !UIErrorRHCTaskSchdule.png!",Bug,Minor,Closed,"2018-05-04 15:56:16","2018-05-04 14:56:16",2
"Sonatype Nexus","not running Compact Blobstore may lead to noisy 'IOException An attempt was made to move the file pointer before the beginning of the file'","A customer had 9 custom blobstores, no Compact blobstore tasks scheduled and after upgrading to 3.10.0 started noticing 1GB sized application log files ( nexus.log) filled with these messages:        h4. Expected    Handling this better in the future - ie. continuing but with potentially reduced features (such as read-only mode) to avoid further corruption + clear logging so customer knows how to fix it. Be smarter about reclaiming disk with compact blobstore tasks especially when a system contains many blobstores.        ",Bug,Major,Open,"2018-05-04 15:01:11","2018-05-04 14:01:11",3
"Sonatype Nexus","Nexus 2 to 3 migration fails if there are staging build promotion repositories.","An upgrade from Nexus 2.x to 3.x will fail if Nexus 2.x has staging build promotion repositories.   The repositories migration list will not even load.  The logs show this error:       {quote}2018-05-02 14:11:03,506-0600 ERROR [pool-21-thread-3] admin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: migration_Repository.read, java-method: com.sonatype.nexus.migration.ui.RepositoryComponent.read   java.lang.NullPointerException: Cannot get property 'memberNames' on null object   at org.codehaus.groovy.runtime.NullObject.getProperty(NullObject.java:60)   at org.codehaus.groovy.runtime.InvokerHelper.getProperty(InvokerHelper.java:174)   at org.codehaus.groovy.runtime.DefaultGroovyMethods.getAt(DefaultGroovyMethods.java:257)   at org.codehaus.groovy.runtime.dgm$241.invoke(Unknown Source)   at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite$PogoMetaMethodSiteNoUnwrapNoCoerce.invoke(PogoMetaMethodSite.java:251)   at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite.call(PogoMetaMethodSite.java:71)   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48)   at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:35)   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48)   at org.codehaus.groovy.runtime.callsite.PojoMetaMethodSite.call(PojoMetaMethodSite.java:58)   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125)   at com.sonatype.nexus.migration.ui.RepositoryComponent$_closure3.doCall(RepositoryComponent.groovy:144)  {quote}  *Expected*    There isn't currently an upgrade path from Nexus 2.x staging to Nexus 3.x staging, so it is expected that the the build promotion repositories should show up in the migration repository list as disabled.",Bug,Major,Closed,"2018-05-02 22:40:42","2018-05-02 21:40:42",3
"Sonatype Nexus","I cant start nexus in Openshift using the Nexus Repository Manager","*2 Points*    *** When I try to use the Nexus Repository Manager Docker image available from Red Hat, I can't start the pod. I receive this error:  id: cannot find name for user ID 1001230000  2018-05-02 17:27:44,407+0000 WARN [FelixStartLevel] *SYSTEM uk.org.lidalia.sysoutslf4j.context.SysOutOverSLF4JInitialiser - Your logging framework class org.ops4j.pax.logging.slf4j.Slf4jLogger is not known - if it needs access to the standard println methods on the console you will need to register it by calling registerLoggingSystemPackage  2018-05-02 17:27:44,419+0000 INFO [FelixStartLevel] *SYSTEM uk.org.lidalia.sysoutslf4j.context.SysOutOverSLF4J - Package org.ops4j.pax.logging.slf4j registered; all classes within it or subpackages of it will be allowed to print to System.out and System.err  2018-05-02 17:27:44,427+0000 INFO [FelixStartLevel] *SYSTEM uk.org.lidalia.sysoutslf4j.context.SysOutOverSLF4J - Replaced standard System.out and System.err PrintStreams with SLF4JPrintStreams  2018-05-02 17:27:44,429+0000 INFO [FelixStartLevel] *SYSTEM uk.org.lidalia.sysoutslf4j.context.SysOutOverSLF4J - Redirected System.out and System.err to SLF4J for this context  2018-05-02 17:27:44,443+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - Properties:  2018-05-02 17:27:44,444+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - application-host='0.0.0.0'  2018-05-02 17:27:44,444+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - application-port='8081'  2018-05-02 17:27:44,444+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - fabric.etc='/opt/sonatype/nexus/etc/fabric'  2018-05-02 17:27:44,444+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - jetty.etc='/opt/sonatype/nexus/etc/jetty'  2018-05-02 17:27:44,444+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - karaf.base='/opt/sonatype/nexus'  2018-05-02 17:27:44,445+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - karaf.data='/nexus-data'  2018-05-02 17:27:44,445+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - karaf.etc='/opt/sonatype/nexus/etc/karaf'  2018-05-02 17:27:44,445+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - karaf.home='/opt/sonatype/nexus'  2018-05-02 17:27:44,445+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - karaf.instances='/nexus-data/instances'  2018-05-02 17:27:44,445+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - logback.etc='/opt/sonatype/nexus/etc/logback'  2018-05-02 17:27:44,446+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - nexus-args='/opt/sonatype/nexus/etc/jetty/jetty.xml,/opt/sonatype/nexus/etc/jetty/jetty-http.xml,/opt/sonatype/nexus/etc/jetty/jetty-requestlog.xml'  2018-05-02 17:27:44,446+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - nexus-context-path='/'  2018-05-02 17:27:44,446+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - nexus-edition='nexus-pro-edition'  2018-05-02 17:27:44,446+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - nexus-features='nexus-pro-feature'  2018-05-02 17:27:44,446+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - nexus.clustered='false'  2018-05-02 17:27:44,447+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.ConfigurationBuilder - ssl.etc='/opt/sonatype/nexus/etc/ssl'  2018-05-02 17:27:44,447+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.Launcher - Java: 1.8.0_162, Java HotSpot(TM) 64-Bit Server VM, Oracle Corporation, 25.162-b12  2018-05-02 17:27:44,487+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.Launcher - OS: Linux, 3.10.0-514.21.1.el7.x86_64, amd64  2018-05-02 17:27:44,489+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.Launcher - User: ?, en, ?  2018-05-02 17:27:44,489+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.Launcher - CWD: /opt/sonatype/nexus  2018-05-02 17:27:44,517+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.Launcher - TMP: /nexus-data/tmp  2018-05-02 17:27:44,523+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.jetty.JettyServer - Starting  2018-05-02 17:27:44,536+0000 INFO [FelixStartLevel] *SYSTEM org.eclipse.jetty.util.log - Logging initialized @16135ms to org.eclipse.jetty.util.log.Slf4jLog  2018-05-02 17:27:44,588+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.jetty.JettyServer - Applying configuration: file:/opt/sonatype/nexus/etc/jetty/jetty.xml  2018-05-02 17:27:45,110+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.jetty.JettyServer - Applying configuration: file:/opt/sonatype/nexus/etc/jetty/jetty-http.xml  2018-05-02 17:27:45,283+0000 INFO [FelixStartLevel] *SYSTEM org.sonatype.nexus.bootstrap.jetty.JettyServer - Applying configuration: file:/opt/sonatype/nexus/etc/jetty/jetty-requestlog.xml  2018-05-02 17:28:04,758+0000 INFO [jetty-main-1] *SYSTEM org.sonatype.nexus.bootstrap.jetty.JettyServer - Starting: org.eclipse.jetty.server.Server@204f7a7e[9.4.8.v20171121]  2018-05-02 17:28:13,270+0000 INFO [jetty-main-1] *SYSTEM org.eclipse.jetty.server.Server - jetty-9.4.8.v20171121, build timestamp: 2017-11-21T21:27:37Z, git hash: 82b8fb23f757335bb3329d540ce37a2a2615f0a8         It's look like the entrypoint never used...        * *The Dockerfile Red hat*    The docker file available to build the image for Openshift available at     [https://github.com/sonatype/docker-nexus3] does not respect the Openshift recommendation available at     You can see at this line     [https://github.com/sonatype/docker-nexus3/blob/5f926027a50742d1baacb7a8c2d0b6aceff23586/Dockerfile.rh.el#L79]     USER nexus.         The Openshift documentation recommend to use a uid.     [https://docs.openshift.org/latest/creating_images/guidelines.html#openshift-origin-specific-guidelines]         [https://github.com/sonatype/docker-nexus3/blob/5f926027a50742d1baacb7a8c2d0b6aceff23586/Dockerfile.rh.el#L83]         maybe it's me that didn't do something correctly...          Thanks for any help!",Bug,Critical,Open,"2018-05-02 18:51:45","2018-05-02 17:51:45",2
"Sonatype Nexus","org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.getRepositoriesMap permission bottleneck for large numbers of repositories in nested group repos","org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.getRepositoriesMap is a synchronized method allowing only one thread access at a time.    There are several triggers to get a repositories map per HTTP request into Nexus.    Example thread stacks which confluence around this method are:    {noformat:title=/service/local/data_index}  qtp162721995-13491 id=13491 state=BLOCKED      - waiting to lock <0x0e70f442> (a org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry)       owned by qtp162721995-5951 id=5951      at org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.getRepositoriesMap(DefaultRepositoryRegistry.java:207)      at org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.getRepository(DefaultRepositoryRegistry.java:118)      at org.sonatype.nexus.proxy.repository.AbstractGroupRepository.getMemberRepositories(AbstractGroupRepository.java:390)      at org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.getGroupsOfRepository(DefaultRepositoryRegistry.java:175)      at org.sonatype.nexus.proxy.access.DefaultNexusItemAuthorizer.authorizePathCascade(DefaultNexusItemAuthorizer.java:69)      at org.sonatype.nexus.proxy.access.DefaultNexusItemAuthorizer.authorizePath(DefaultNexusItemAuthorizer.java:63)      at org.sonatype.nexus.proxy.access.DefaultNexusItemAuthorizer.authorizePathCascade(DefaultNexusItemAuthorizer.java:71)      at org.sonatype.nexus.proxy.access.DefaultNexusItemAuthorizer.authorizePath(DefaultNexusItemAuthorizer.java:63)      at org.sonatype.nexus.index.DefaultIndexArtifactFilter.filterArtifactInfo(DefaultIndexArtifactFilter.java:85)      at org.sonatype.nexus.index.DefaultIndexerManager$18.accepts(DefaultIndexerManager.java:1854)      at org.apache.maven.index.AndMultiArtifactInfoFilter.accepts(AndMultiArtifactInfoFilter.java:46)      at org.apache.maven.index.AbstractMultiArtifactInfoFilter.accepts(AbstractMultiArtifactInfoFilter.java:80)      at org.apache.maven.index.DefaultIteratorResultSet.createNextAi(DefaultIteratorResultSet.java:245)      at org.apache.maven.index.DefaultIteratorResultSet.next(DefaultIteratorResultSet.java:153)      at org.apache.maven.index.DefaultIteratorResultSet.next(DefaultIteratorResultSet.java:51)      at org.sonatype.nexus.rest.index.AbstractIndexerNexusPlexusResource.ai2NaColl(AbstractIndexerNexusPlexusResource.java:67)      at org.sonatype.nexus.rest.index.AbstractIndexPlexusResource.get(AbstractIndexPlexusResource.java:165)      at org.sonatype.nexus.rest.index.DefaultIndexPlexusResource.get(DefaultIndexPlexusResource.java:86)      at org.sonatype.plexus.rest.resource.RestletResource.represent(RestletResource.java:233)      {noformat:title=NexusTargetMappingAuthorizationFilter}  qtp162721995-408 id=408 state=BLOCKED      - waiting to lock <0x0e70f442> (a org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry)       owned by qtp162721995-5951 id=5951      at org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.getRepositoriesMap(DefaultRepositoryRegistry.java:207)      at org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.getRepository(DefaultRepositoryRegistry.java:118)      at org.sonatype.nexus.proxy.repository.AbstractGroupRepository.getMemberRepositories(AbstractGroupRepository.java:390)      at org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.getGroupsOfRepository(DefaultRepositoryRegistry.java:175)      at org.sonatype.nexus.proxy.access.DefaultNexusItemAuthorizer.authorizePathCascade(DefaultNexusItemAuthorizer.java:69)      at org.sonatype.nexus.proxy.access.DefaultNexusItemAuthorizer.authorizePath(DefaultNexusItemAuthorizer.java:63)      at org.sonatype.nexus.proxy.access.DefaultNexusItemAuthorizer.authorizePathCascade(DefaultNexusItemAuthorizer.java:71)      at org.sonatype.nexus.proxy.access.DefaultNexusItemAuthorizer.authorizePath(DefaultNexusItemAuthorizer.java:63)      at org.sonatype.nexus.proxy.access.DefaultNexusItemAuthorizer.authorizePathCascade(DefaultNexusItemAuthorizer.java:71)      at org.sonatype.nexus.proxy.access.DefaultNexusItemAuthorizer.authorizePath(DefaultNexusItemAuthorizer.java:63)      at org.sonatype.nexus.proxy.access.DefaultNexusItemAuthorizer.authorizePathCascade(DefaultNexusItemAuthorizer.java:71)      at org.sonatype.nexus.proxy.access.DefaultNexusItemAuthorizer.authorizePath(DefaultNexusItemAuthorizer.java:63)      at org.sonatype.nexus.proxy.router.DefaultRepositoryRouter.authorizePath(DefaultRepositoryRouter.java:619)      at org.sonatype.nexus.security.filter.authz.NexusTargetMappingAuthorizationFilter.isAccessAllowed(NexusTargetMappingAuthorizationFilter.java:160)      at org.apache.shiro.web.filter.AccessControlFilter.onPreHandle(AccessControlFilter.java:162)      at org.apache.shiro.web.filter.PathMatchingFilter.isFilterChainContinued(PathMatchingFilter.java:203)      at org.apache.shiro.web.filter.PathMatchingFilter.preHandle(PathMatchingFilter.java:178)      at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:131)      at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)      at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)      at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)      at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)      at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)      at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)      at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)      at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)      at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)      at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)      at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)      at org.sonatype.nexus.web.internal.SecurityFilter.executeChain(SecurityFilter.java:90)      {noformat:title=Smart Proxy event publishing}  qtp162721995-1015 id=1015 state=BLOCKED      - waiting to lock <0x0e70f442> (a org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry)       owned by qtp162721995-5951 id=5951      at org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.getRepositoriesMap(DefaultRepositoryRegistry.java:207)      at org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.getRepository(DefaultRepositoryRegistry.java:118)      at org.sonatype.nexus.proxy.repository.AbstractGroupRepository.getMemberRepositories(AbstractGroupRepository.java:390)      at org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.getGroupsOfRepository(DefaultRepositoryRegistry.java:175)      at com.sonatype.nexus.plugins.smartproxy.event.internal.PublishEventInspector.includeRecipients(PublishEventInspector.java:268)      at com.sonatype.nexus.plugins.smartproxy.event.internal.PublishEventInspector.includeRecipients(PublishEventInspector.java:271)      at com.sonatype.nexus.plugins.smartproxy.event.internal.PublishEventInspector.includeRecipients(PublishEventInspector.java:271)      at com.sonatype.nexus.plugins.smartproxy.event.internal.PublishEventInspector.includeRecipients(PublishEventInspector.java:271)      at com.sonatype.nexus.plugins.smartproxy.event.internal.PublishEventInspector.recipients(PublishEventInspector.java:253)      at com.sonatype.nexus.plugins.smartproxy.event.internal.PublishEventInspector.maybeFireItemUpdated(PublishEventInspector.java:354)      at com.sonatype.nexus.plugins.smartproxy.event.internal.PublishEventInspector.on(PublishEventInspector.java:182)      at sun.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)      at java.lang.reflect.Method.invoke(Method.java:498)      at org.sonatype.sisu.goodies.eventbus.internal.guava.EventHandler.handleEvent(EventHandler.java:80)      at org.sonatype.sisu.goodies.eventbus.internal.guava.EventBus.dispatch(EventBus.java:329)      at org.sonatype.sisu.goodies.eventbus.internal.DefaultGuavaEventBus.dispatch(DefaultGuavaEventBus.java:34)      at org.sonatype.sisu.goodies.eventbus.internal.ReentrantGuavaEventBus.dispatchQueuedEvents(ReentrantGuavaEventBus.java:57)      at org.sonatype.sisu.goodies.eventbus.internal.guava.EventBus.post(EventBus.java:281)      at org.sonatype.sisu.goodies.eventbus.internal.DefaultEventBus.post(DefaultEventBus.java:78)      at org.sonatype.nexus.proxy.repository.AbstractRepository.storeItem(AbstractRepository.java:1032)      at org.sonatype.nexus.proxy.maven.AbstractMavenRepository.storeItem(AbstractMavenRepository.java:466)      at org.sonatype.nexus.proxy.repository.AbstractRepository.storeItem(AbstractRepository.java:661)      at org.sonatype.nexus.proxy.router.DefaultRepositoryRouter.storeItem(DefaultRepositoryRouter.java:179)      at org.sonatype.nexus.content.internal.ContentServlet.doPut(ContentServlet.java:602)      at org.sonatype.nexus.content.internal.ContentServlet.service(ContentServlet.java:357)  {noformat}    Since the method is synchronized and this method copies the entire list of repository members which may be large, in a heavily loaded system receiving combinations of the mentioned code paths, threads may backup to the point where Nexus may appear non-responsive due to a high number of blocked threads on the subject method.    This performance problem is most likely to surface under two primary conditions:    1) nested group repo hierarchy  2) group repos containing thousands of repositories  ",Bug,Major,Closed,"2018-04-25 20:09:26","2018-04-25 19:09:26",1
"Sonatype Nexus","Uncaught TypeError Cannot read property 'loading' of null editing task schedules","When editing a scheduled task with a schedule, and trying to change that schedule, users may notice the UI report the following message:    *Uncaught TypeError Cannot read property 'loading' of null*    This has been noticed on various task types when trying to change the schedule from hourly to daily or weekly to monthly and then clicking the Save button.     After the error occurs, the UI may not refresh the task settings correctly and the Discard button may not appear to function properly.    Another side effect is the dialog to confirm discarding changes may not render in the correct position or not be visible entirely.    Despite the UI errors, the original changes that were attempted to be saved appear to be persisted correctly.    h4. Workaround    There is no option to prevent the UI error. However recovery is relatively simple.    Use the browser refresh button to refresh the entire Nexus UI. After that the current state of the task settings should render correctly.      ",Bug,Major,Closed,"2018-04-24 19:40:42","2018-04-24 18:40:42",2
"Sonatype Nexus","upgrade to a newer version of Quartz scheduler","Heres the list of commits that went in between Quartz-scheduler 2.2.2 (our version) and latest as of this ticket (2.3.0):    https://github.com/quartz-scheduler/quartz/compare/7733bc97c7c8ca6cd927049d7d36ae25261a1a0c...quartz-scheduler:0bd9adeace3e5dc238e84397573c3e9c6be265a6    Looks like JobStore interface has a couple of new methods which our JobStoreImpl would need to implement...    https://github.com/quartz-scheduler/quartz/milestone/1?closed=1 shows the issues which went into 2.3.0",Improvement,Major,Closed,"2018-04-23 18:58:19","2018-04-23 17:58:19",5
"Sonatype Nexus","no reason logged at default levels why QuartzTaskFuture healthcheck task is canceled","Example log messages that might be visible when a task is Cancelled:        The healthcheck task has no task logs by design in this case, and no other log messages indicate why the healthcheck task was immediately cancelled.    h4. Expected    There should be a log message at INFO explaining the root cause of task cancellation ( server shutting down, user manually cancelled the task, specific programatic condition not met to proceed, etc.? ) every time any task is cancelled.",Bug,Major,Closed,"2018-04-23 17:28:05","2018-04-23 16:28:05",1
"Sonatype Nexus","QueryPhaseExecutionException: Result window is too large Thrown for Search API","When paginating through a large set of search results using the search API (/service/rest/<USER>search/ or /service/rest/<USER>search/assets) a HTTP 500 error can be returned for the following reason:  {quote} QueryPhaseExecutionException[Result window is too large, from + size must be less than or equal to: [10000] but was [10050]. See the scroll api for a more efficient way to request large data sets. This limit can be set by changing the [index.max_result_window] index level parameter.]; }   org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed   at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:206)   at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:152)   at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46)   at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:874)   at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:852)   at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:389)   at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)   at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)   at java.lang.Thread.run(Unknown Source)   Caused by: org.elasticsearch.search.query.QueryPhaseExecutionException: Result window is too large, from + size must be less than or equal to: [10000] but was [10050]. See the scroll api for a more efficient way to request large data sets. This limit can be set by changing the [index.max_result_window] index level parameter.   at org.elasticsearch.search.internal.DefaultSearchContext.preProcess(DefaultSearchContext.java:212)   at org.elasticsearch.search.query.QueryPhase.preProcess(QueryPhase.java:103)   at org.elasticsearch.search.SearchService.createContext(SearchService.java:689)   at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:633)   at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:377)   at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368)   at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365)   at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)   at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:77)   at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:378)   at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)  {quote}  This is happening due to the default result window value of 10,000 for Elasticsearch being exceeded.         *Expected:*   Either limit search results when using the API and make it explicit to users that results have been/will be limited to n results (similar to --------NEXUS-10284--------)  or enable all results to be returned for a given search when using the API.         *Workaround:*   Add the 'index.max_result_window' property in <nexus_install>/etc/fabric/elasticsearch.yml file and restart Nexus:    _Note: Increasing this value can result in an increase of heap usage._",Bug,Minor,New,"2018-04-20 11:20:57","2018-04-20 10:20:57",3
"Sonatype Nexus","certificate errors using LDAP over SSL in HA","In a cluster configuration, if you configure a connection to an LDAP server that utilizes LDAP over SSL (an ldaps: connection) and attempt to store the certificate in the Nexus Truststore, only the node where the connection is created will be able to connect to the LDAP server.     If you attempt to click the 'Verify connection' button in the user interface of any other node, you will receive an error in the user interface and an error similar to the following in the nexus.log file:        You may also see the following errors in the nexus.log when an authentication attempt is made:         ",Bug,Major,Closed,"2018-04-19 22:33:59","2018-04-19 21:33:59",3
"Sonatype Nexus","WARN QuartzSchedulerSPI Job missing listener omitting from results","While the exact cause is still undetermined, QuartzSchedulerSPI WARN level messages have been noticed inside Nexus 3 application logs. Examples  {noformat:title=Example WARN messages}  2018-03-06 15:57:05,962-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.2d62e436-d3e3-4628-9a90-fe31f4172c74  2018-03-06 15:57:05,962-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.d45283d9-fb96-42d5-9d51-551838befdcd  2018-03-06 15:57:05,962-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.280db4c4-9aab-43de-a0b8-065f9a7095ce  2018-03-06 15:57:05,962-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.6ad857f0-f5bf-41ba-ad90-d9a0ce090d3f  2018-03-06 15:57:05,962-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.e6043eee-7fc5-404f-b858-61c9a9d70d06  2018-03-06 15:57:05,962-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.249a2184-7779-4d78-8d7b-21d004f92ef2  2018-03-06 15:57:05,963-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.df3f95c0-9ace-48ea-8c70-fd07a6af628a  2018-03-06 15:57:05,963-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.9aba2886-7efa-4976-95a9-7e934446b439  2018-03-06 15:57:05,963-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.c2329509-c5bb-43e6-afc5-2d6014e2acec  2018-03-06 15:57:05,965-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.2d62e436-d3e3-4628-9a90-fe31f4172c74  2018-03-06 15:57:05,965-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.d45283d9-fb96-42d5-9d51-551838befdcd  2018-03-06 15:57:05,965-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.280db4c4-9aab-43de-a0b8-065f9a7095ce  2018-03-06 15:57:05,965-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.6ad857f0-f5bf-41ba-ad90-d9a0ce090d3f  2018-03-06 15:57:05,965-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.e6043eee-7fc5-404f-b858-61c9a9d70d06  2018-03-06 15:57:05,965-0500 WARN  [pool-23-thread-1] NODE3 anonymous org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI - Job missing listener; omitting from results: nexus.249a2184-7779-4d78-8d7b-21d004f92ef2  {noformat}  At the same time, other unexplained or broken behaviour is appearing in the same Nexus instances, which usually can be tied back to having some sort of requirement on scheduled task processing. Possibly related are the fact these messages have recently been detected in HA-C environments where the connectivity between nodes in a cluster was suspect.  h4. Diagnosis    Reliable steps to reproduce the runtime state where these messages start appearing is under review. What seems consistent is that when nodes in an HA cluster cannot successfully sync, particularly at abrupt shutdown of a node, tasks may lose proper state and hence their triggers. Most commonly the situation arises with Repository Health Check Scheduled tasks.  h4. Short Term Mitigation for Large Log Files: Reduce Noisy Log Messages    To prevent the verbose log messages related to this problem from filling disk, short term an administrator can set the logger level of *org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI* to *ERROR*.    While this step silences the logging, we recommend taking additional steps in *Repairing Broken Tasks to fix the problems suggested by the symptoms.    A proper adjustment is delivered via NEXUS-19224 made in 3.17.0 as well as a system status check that warns of the condition.    h4. Temporary Fix: Repairing Broken Tasks (Nexus version 3.10-3.15)    This step is repair broken tasks. Running this script may not prevent the problem from re-occuring.    Download the attached script source,  [^NEXUS-16912-repair_missing_triggers-3.10-to-3.15.groovy]  create an Admin - Execute Script scheduled task and paste the contents of the script into the task source. After saving the task, manually run the task. After the task completes, it will be safe to return the *org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI* logger back to *INFO* level.    h4. Temporary Fix: Repairing Broken Tasks ( NXRM version 3.16 and newer )    As outcome of NEXUS-20019, download the attached script source,  [^NEXUS-16912-repair_missing_triggers-3.16-and-newer.groovy]   create an Admin - Execute Script scheduled task and paste the contents of the script into the task source. After saving the task, manually run the task. After the task completes, it will be safe to return the *org.sonatype.nexus.quartz.internal.QuartzSchedulerSPI* logger back to *INFO* level.    h4. Expected    Tasks should not lose internal triggers - take steps to prevent this condition from being possible, or if not possible to prevent in all circumstances - the condition should be self healing.",Bug,Major,Open,"2018-04-19 19:21:44","2018-04-19 18:21:44",5
"Sonatype Nexus","include HTTP request Content-Length header value in request.log","Sometimes problem diagnosis in Nexus Repository Manager may benefit from knowing the inbound http request anticipated content size.     For a large majority of requests to add content into Nexus,  HTTP PUT is used. In those cases, the request content size information is usually available from the [HTTP request Content-Length header value.|https://tools.ietf.org/html/rfc7230#section-3.3.2]. ( there are some exceptions, in particular When a message does not have a Transfer-Encoding header field, a Content-Length header field can provide the anticipated size, as a decimal number of octets, for a potential payload body. )    h4. Expected    The default request.log log pattern for Nexus should be adjusted to include the value if any of the Content-Length header of the request.    Current pattern as of nexus 3.10.0        Proposed new format:        This change should be announced in release notes in case users have configured external request log parsers which may need adjustment or prefer to not have this value printed.  ",Bug,Medium,Closed,"2018-04-18 20:09:39","2018-04-18 19:09:39",1
"Sonatype Nexus","Disable OrientDB live query support","We don't use the https://orientdb.com/docs/2.2.x/Live-Query.html feature and disabling it completely (ie. removing it totally as a DB hook) will give a small performance boost.    It will also guarantee to remove future log-spam issues caused by {{OLiveQueryHook}}'s erroneous assumption that there will be a valid DB thread-local when it's called - which isn't always the case depending on the scenario.    This has led in the past to a number of log-spam reports, mostly on HA but also on a couple of non-HA systems under stress. The previous reports should have been fixed now by upstream changes, but disabling the live-query feature would protect us from similar issues in the future.",Improvement,Major,Closed,"2018-04-17 21:27:39","2018-04-17 20:27:39",1
"Sonatype Nexus","deletions.index file limited to max 1G filesize","Version: OSS Nexus 3.2.0.-01    Symptom: nexus.log spammed with the following:    Looking into it the file at issue here is the {{deletions.index}} file which in this case was currently 1gb in size.    Root cause of the exception is the QueueFile attempting to resize the index file to twice its size using integer math, resulting in integer overflow and attempting to set the new file size to -2gb, thus the IllegalArgumentException by setLength().    Suggestions:   * Update the version of squareup's tape library to a more recent version that computes the resized index using the java 'long' type.   * Create a threshold on the size of the deletions.index file such that when exceeded it will trigger blobstore compaction. (This would avoid the situation completely even if the squareup dependency is not updated.)   * Be aware of and catch any exception during index resize and log an appropriate warning/error message to make the situation clear.   * Allow for more ways to trigger a rebuild of the deletion index.  Currently it will only be auto-rebuilt if both 1) the {{deletions.index}} file is deleted and 2) the nexus process has just started.  This precludes a runtime rebuilding of the index and requires and administrator to be aware that they must delete that particular file before restarting the process in order for the index to be rebuilt.    Discussion:   * I encountered this in a Nexus instance that admittedly was not following best practices.  It had 10 repositories of various types using the same blobstore, it was running a Maven Repository Metadata rebuilt every hour and, most importantly, never ran a blobstore compaction task.   * This resulted in a massive backlog of soft-deleted blob references to the point where the {{deleteions.index}} had effectively filled up and no longer recorded the deletions.  As such, even after I manually ran the compaction job (and scheduled it run more frequently, of course), there were still a huge amount of blobs marked for deletion that were not recorded in the index but were still present on disk (the blobstore metrics report a count of 73,554,252 blobs taking up 1.581TB of space.   * Looking at the BlobStoreFile code it appears this is still an issue in the latest release.  Understandably, it is likely that it is not encountered frequently given the requirement of a massive backlog of soft-deleted blobs.",Bug,Medium,Open,"2018-04-17 17:35:27","2018-04-17 16:35:27",3
"Sonatype Nexus","Enhance content validation for maven-metadata.xml files","The current file content validation for maven-metadata.xml files does very little. Caching bad metadata.xml files from servers can lead to build failures.  Furthermore, it can often be difficult to clean up bad maven-metadata.xml files from a proxy's cache, and even if you do, they may just get downloaded again.    Content validation for maven-metadata.xml files can be improved by parsing the files and making sure that:   # The GAV coordinates metadata.xml file are present in the file   # The GAV coordinates match the path the file is stored in    Files which do not meet the above criteria should be rejected.",Improvement,Major,Closed,"2018-04-13 19:40:07","2018-04-13 18:40:07",3
"Sonatype Nexus","Regression:  UI allows creation of roles with spaces in their ID's.  These can't be seen in the roles list, and can't be deleted","Not sure what happened here, but at some point we lost the fix for NEXUS-2904.    It is now (once again) possible to create roles with spaces in their ID's.  As before, the resulting role cannot be deleted via the UI.",Bug,Major,Closed,"2018-04-11 15:30:29","2018-04-11 14:30:29",3
"Sonatype Nexus","upgrade from Nexus 2.x to Nexus 3.x is allowed when nexus.clustered=true","Apparently you can start the upgrade process of 2.x into 3.x when 3.x is in HA-C clustered mode.    This type of upgrade is not tested or intended to be supported, therefore we should prevent a user from migrating in this mode or at the very least document that this is not supported.",Bug,Major,Closed,"2018-04-11 15:27:54","2018-04-11 14:27:54",1
"Sonatype Nexus","Delete incomplete uploads DockerUploadPurgeTask task fails in 3.10.0","We have a task, that runs daily, to delete incomplete docker uploads (Docker - Delete incomplete uploads). This has been functioning normally, until our upgrade to 3.10.0-04 yesterday.     Task schedule details:   * Age in hours: 24   * Task frequency: Daily   * Start date: 02/07/2016   * Time to run this task: 00:00    Run Summary, after manually clicking Run:   * Status: Waiting   * Next Run: Wed Apr 11 2017 00:00:00 GMT-0500   * Last result: Error[0s]    It has been failing since then, with the following error in the logs:  ",Bug,Critical,Closed,"2018-04-10 14:16:46","2018-04-10 13:16:46",2
"Sonatype Nexus","Connection pool leak when docker hub proxy repository receives 401 responses from auth.docker.io","Configure a proxy repository against docker hub, and configure credentials under http/authentication section of the proxy's settings.  Use login credentials that _will not work_ on docker hub.    Now fire 21 requests for content to the proxy, as in:  {code:java}   curl [http://localhost:8081/repository/docker-proxy/v2/maprtech/pacc/manifests/6.0.0_4.0.0_centos7]  {code}  The first 20 will fail unauthorized JSON responses, as expected.  But the 21st will fail with a connection pool timeout as Nexus attempts to retrieve the bearer token.    It is necessary to restart Nexus to clear this connection pool leak.     ",Bug,Critical,Closed,"2018-04-09 18:03:14","2018-04-09 17:03:14",1
"Sonatype Nexus","FileBlobStore Attempt to access non-existent blob path$health-check WARN log spam","When healthcheck is first enabled for a repository, warning messages are written to the log for missing files:  {quote}2018-02-17 11:55:13,683-0600 WARN [quartz-5-thread-3] NexusHDQ-One *SYSTEM org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access non-existent blob path$health-check/Jcenter.bintray-proxy/details/jquery-ui-1.8.17.custom.css (/opt/NexusSharedStorage/default/content/directpath/health-check/Jcenter.bintray-proxy/details/jquery-ui-1.8.17.custom.css.properties)  {quote}  {quote}2018-02-17 11:55:13,731-0600 WARN [quartz-5-thread-3] NexusHDQ-One *SYSTEM org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access non-existent blob path$health-check/Jcenter.bintray-proxy/details/jquery.ui.selectmenu.min.js (/opt/NexusSharedStorage/default/content/directpath/health-check/Jcenter.bintray-proxy/details/jquery.ui.selectmenu.min.js.properties)  {quote}  {quote}2018-02-17 11:55:13,781-0600 WARN [quartz-5-thread-3] NexusHDQ-One *SYSTEM org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access non-existent blob path$health-check/Jcenter.bintray-proxy/details/ui-bg_flat_75_ffffff_40x100.png (/opt/NexusSharedStorage/default/content/directpath/health-check/Jcenter.bintray-proxy/details/ui-bg_flat_75_ffffff_40x100.png.properties)  {quote}  {quote}2018-02-17 11:55:13,831-0600 WARN [quartz-5-thread-3] NexusHDQ-One *SYSTEM org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access non-existent blob path$health-check/Jcenter.bintray-proxy/details/bg-selectmenu.png (/opt/NexusSharedStorage/default/content/directpath/health-check/Jcenter.bintray-proxy/details/bg-selectmenu.png.properties)  {quote}  {quote}2018-02-17 11:55:13,880-0600 WARN [quartz-5-thread-3] NexusHDQ-One *SYSTEM org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access non-existent blob path$health-check/Jcenter.bintray-proxy/details/ui-icons_888888_256x240.png (/opt/NexusSharedStorage/default/content/directpath/health-check/Jcenter.bintray-proxy/details/ui-icons_888888_256x240.png.properties)  {quote}  {quote}2018-02-17 11:55:13,929-0600 WARN [quartz-5-thread-3] NexusHDQ-One *SYSTEM org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access non-existent blob path$health-check/Jcenter.bintray-proxy/details/jquery.ui.selectmenu.css (/opt/NexusSharedStorage/default/content/directpath/health-check/Jcenter.bintray-proxy/details/jquery.ui.selectmenu.css.properties)  {quote}  {quote}2018-02-17 11:55:13,980-0600 WARN [quartz-5-thread-3] NexusHDQ-One *SYSTEM org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access non-existent blob path$health-check/Jcenter.bintray-proxy/details/licenses.json (/opt/NexusSharedStorage/default/content/directpath/health-check/Jcenter.bintray-proxy/details/licenses.json.properties)  {quote}  {quote}2018-02-17 11:55:14,034-0600 WARN [quartz-5-thread-3] NexusHDQ-One *SYSTEM org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access non-existent blob path$health-check/Jcenter.bintray-proxy/details/security.json (/opt/NexusSharedStorage/default/content/directpath/health-check/Jcenter.bintray-proxy/details/security.json.properties)  {quote}  {quote}2018-02-17 11:55:14,084-0600 WARN [quartz-5-thread-3] NexusHDQ-One *SYSTEM org.sonatype.nexus.blobstore.file.FileBlobStore - Attempt to access non-existent blob path$health-check/Jcenter.bintray-proxy/details/details.html (/opt/NexusSharedStorage/default/content/directpath/health-check/Jcenter.bintray-proxy/details/details.html.properties)  {quote}  These files appear to be created on the fly if missing and do not impact the healthcheck task itself, but the warnings can spam the log and suggest there is an issue.    *Expected:*    These warning should be suppressed in respect to health check files, in the situation when it first enabled on a repository (and files are created if missing).     ",Bug,Major,Closed,"2018-04-04 15:17:13","2018-04-04 14:17:13",1
"Sonatype Nexus","scope authentication errors when connecting to registry.connect.redhat.com","Steps to reproduce:   # Create Docker proxy repository   # Remote storage: [https://registry.connect.redhat.com|https://registry.connect.redhat.com/]   # HTTP Authentication: RH Credentials |0|   # Connect to registry via Docker client or via HTTPs \{registry}/v2/sonatype/nexus-repository-manager/manifests/latest    Error:    Logs show error due to Could not retrieve token due to missing parameter: scope  ",Bug,Major,Closed,"2018-04-02 22:04:54","2018-04-02 21:04:54",3
"Sonatype Nexus","uploading npm component where package.json bugs key is string fails","+*steps to reproduce:*+   * download the file [http://registry.npmjs.org/crc/-/crc-3.0.0.tgz]   * use the Components API - Upload file with npm ([https://help.sonatype.com/repomanager3/rest-and-integration-api/components-api#ComponentsAPI-NPM)]    The request will fail with a 500 Internal Server Error and the message _child 'bugs' not a Map_    this error is caused by the fact that in the original package.json file bugs property is a string not an object.    based on [http://json.schemastore.org/package] the bugs property could be an object or a plain string    [original package.json|https://github.com/alexgorbatchev/node-crc/blob/v3.0.0/package.json#L28]    [npm registry package.json|http://registry.npmjs.org/crc/3.0.0]    _uploading (using npm publish) the raw *tgz* file works but the shasum changes and breaks the package_",Bug,Medium,Closed,"2018-04-02 20:57:05","2018-04-02 19:57:05",2
"Sonatype Nexus","Content selectors based on negative regular expressions do not handle leading slashes in a consistent manner","     Trying to create a regular expression that disallows access to paths starting with /com/foo/bar/.    This doesn't work:    And this does:    However, for positive regular expressions...    This doesn't work:    But this does work:    So that's at least consistent, but doesn't line up with [our documentation|https://help.sonatype.com/repomanager3/configuration/repository-management#RepositoryManagement-ContentSelectors] at all, which states that:  {quote}When writing a content selector, remember that the asset’s path will always begin with a leading slash when the selector is evaluated. This is true even though the leading slash is not displayed when searching or browsing assets.  {quote}   The above is the way it was supposed to work based on fixes done in ---NEXUS-11632--- and ---NEXUS-15545---.    For positive regular expressions things are also quite odd, but in a slightly different way.    This works:    As does this:    This doesn't work:    But this does work:    h3. Expected    Content selectors that use regular expressions should require that paths start with /. And using a leading ^ should be optional. That is the way Nexus 2.x works, so this is required for compatibility when upgrading.  h4. Update 4/2/18    For upload this is needed:    So to make both upload and download work you need:     ",Bug,Major,Closed,"2018-03-30 00:02:28","2018-03-29 23:02:28",3
"Sonatype Nexus","Staging: NuGet move/delete","Support move/delete for components in nuget hosted repositories.",Story,Major,Done,"2018-03-26 21:52:45","2018-03-26 20:52:45",5
"Sonatype Nexus","Staging: YUM move/delete","Support move/delete for components in yum hosted repositories.",Story,Major,Done,"2018-03-26 21:51:45","2018-03-26 20:51:45",5
"Sonatype Nexus","hazelcast-network.xml is not included in support zip","As of changes since 3.7.0 per -NEXUS-14377-, Nexus uses [the following logic to load hazelcast config files|https://github.com/sonatype/nexus-internal/blob/f8d90379daff553edf6bcb8e8f983a794ccde6f6/private/plugins/nexus-hazelcast-plugin/src/main/java/com/sonatype/nexus/hazelcast/internal/HazelcastInstanceProvider.java#L128]:   - if {{$karaf.data/etc/fabric/hazelcast-network.xml}} does not exist, copy {{$karaf.base/etc/fabric/hazelcast-network-default.xml}} to {{$karaf.data/etc/fabric/hazelcast-network.xml}}   - if {{$karaf.base/etc/fabric/hazelcast.xml}} exists, load it   - if {{$karaf.base/etc/fabric/hazelcast.xml}} does not exist, log a WARN and load default values from internal configuration    The problem is the support zip generator does not include {{$karaf.data/etc/fabric/hazelcast-network.xml}} and therefore by default it is impossible to learn what the user has configured hazelcast to do.    [https://github.com/sonatype/nexus-internal/blob/f8d90379daff553edf6bcb8e8f983a794ccde6f6/private/plugins/nexus-hazelcast-plugin/src/main/java/com/sonatype/nexus/hazelcast/internal/HazelcastInstanceProvider.java#L128]    The other fabric install dir files [are included|https://github.com/sonatype/nexus-internal/blob/d36a15cb656e48a290256155cf701b0f3da3742d/components/nexus-core/src/main/java/org/sonatype/nexus/internal/atlas/customizers/InstallConfigurationCustomizer.groovy#L90] and [sanitized|https://github.com/sonatype/nexus-internal/blob/d36a15cb656e48a290256155cf701b0f3da3742d/components/nexus-core/src/main/java/org/sonatype/nexus/internal/atlas/customizers/InstallConfigurationCustomizer.groovy#L60].  h4. Expected   - bundle {{$karaf.data/etc/fabric/hazelcast-network.xml}} into the support zip at path {{work/etc/fabric/hazelcast-network.xml}}   - *obfuscate any potential passwords* that may be in that file",Bug,Major,Closed,"2018-03-22 20:07:47","2018-03-22 20:07:47",1
"Sonatype Nexus","Hazelcast XSD warning logged at startup.","When you start up Nexus 3 in clustered mode you'll see a Hazelcast log warning message:      This is occurring because the XSD we're shipping with in our default configuration files does not match the version of Hazelcast we're shipping with:        https://github.com/hazelcast/hazelcast/blob/v3.7.8/hazelcast/src/main/java/com/hazelcast/config/AbstractXmlConfigHelper.java#L158    We should update our XMLS references to use the correct XSD version.         ",Bug,Major,Closed,"2018-03-20 22:03:34","2018-03-20 22:03:34",1
"Sonatype Nexus","Raw repo url returns Error 404","When placing the repository url in a browser, you would normally see a message with the following:  {quote}This maven2 hosted repository is not directly browseable at this URL.    Please use the [browse|http://localhost:8081/#browse/browse:maven-releases] or [HTML index|http://localhost:8081/service/rest/repository/browse/maven-releases/] views to inspect the contents of this repository.  {quote}       With a Raw repository url [http://localhost:8081/repository/raw-host/]  you get the following, unlike other repository types.  {quote}Error 404 Not Found  {quote}        ",Bug,Minor,Closed,"2018-03-20 15:09:21","2018-03-20 15:09:21",2
"Sonatype Nexus","An npm package that is in NXRM2 storage but not in its database causes a NullPointerException on migration to NXRM3","If an npm package is in NXRM2 storage but not in the database on migration it will throw an NPE (see below) and skipover.  While this behavior doesn't cause the migration to fail it's desired if we can include this component in the migration.        The same behavior for NuGet has been repaired in earlier version of NXRM3: NEXUS-13554",Bug,Minor,New,"2018-03-19 21:33:00","2018-03-19 21:33:00",2
"Sonatype Nexus","Content validation still blocks some items even when permissive","I noticed if I had a yum hosted repository with a permissive deploy policy if I curled in a nuget package, then I still got blocked by invalid content type detection as shown below.  My understanding from the setting and documentation is that permissive means you can add anything.  I believe this is how it works for other formats with validation.    e.g.  ",Bug,Medium,Closed,"2018-03-19 19:48:23","2018-03-19 19:48:23",1
"Sonatype Nexus","IllegalStateException Insufficient configured threads from a docker repository connector configuration","h4. Summary    On saving a Docker repository configuration that has defined a port number, the nexus.log may contain a message such as this:        This indicates that the pool of threads that Eclipse Jetty draws from to preallocate threads for the new connector is too small to meet the required total. The default pool size is 200 threads.    When this error happens on saving Docker repository configuration, no other changes can be made to the Docker repository configuration.    This error can also happen on Nexus startup, where each Docker repository connector is started.    Nexus version 3.8.0+ is more likely to trigger this issue because in that version Eclipse Jetty was upgraded to 9.4.8 from 9.3.20, and the thread allocation strategy has changed slightly in that version.    [Nexus Repository Manager 3.8.0 Release Notes|https://help.sonatype.com/repomanager3/release-notes/2018-release-notes#id-2018ReleaseNotes-RepositoryManager3.8.0]  [Eclipse Jetty 9.4.8 thread allocation|https://support.sonatype.com/hc/en-us/articles/360000744687]    h4. Short Term Workaround    You may be able to avoid the error by increasing the Jetty thread pool. Edit the configuration file ({{<nexus-app-dir>/etc/jetty/jetty.xml}}) and add a new maxThreads setter:        Caution: We suggest being conservative increasing the thread pool maxThreads - each new thread in the pool has the potential to increase workload inside of Nexus for concurrent request threads.     Restart Nexus to pick up changes to the file. Startup will fail if this file contains invalid XML.    h4. Long Term Workaround    Consider using a strategy where a reverse proxy in front of Nexus dynamically maps docker requests to Nexus Docker repositories. In this scenario, you will not need to specify port numbers and therefore new connectors, on your docker repos. Increasing the Jetty thread pool should not be required in this case:    https://support.sonatype.com/hc/en-us/articles/360000761828  ",Bug,Major,Closed,"2018-03-16 21:42:58","2018-03-16 21:42:58",3
"Sonatype Nexus","PublishMavenIndexTask failures may leave bad blob refs in the component database causing MissingBlobException","Due to NEXUS-16303, The publish Maven indexes task may fail - and under certain circumstances can leave bad blob refs in the component database.        The bad blob ref gets left behind:        h4. Expected    The PublishMavenIndexTask should never leave bad blob refs in the component DB on any error.",Bug,Major,Closed,"2018-03-16 16:35:16","2018-03-16 16:35:16",0
"Sonatype Nexus","DeadBlobFinder does not find bad blob refs for Maven indexer files","Due to NEXUS-16303, The publish Maven indexes task may fail - and under certain circumstances can leave bad blob refs in the component database.        When the following script is run, the DeadBlobFinder does not find the bad blob refs:        Yet the bad blob ref exists:        h4. Expected    DeadBlobFinder should find ALL dead blobs.",Bug,Major,Closed,"2018-03-16 16:30:16","2018-03-16 16:30:16",2
"Sonatype Nexus","NXRM 3 Yum Metadata Generation takes forever","We recently migrated completely from nexus2 to nexus3, now that it has full yum support (hosted). Recently, we noticed that when we were doing our rpm builds/uploads, that when we would deploy new instances, we were not seeing the expected artifacts on the machines. I dug into this a bit and observed the following:        ==========    =========  In both of these cases, regenerating the metadata is taking 15 minutes.  That is a major detriment and will cause inefficiencies for developers, slowing down a company's ability to handle CI/CD",Bug,Major,Closed,"2018-03-14 22:54:31","2018-03-14 22:54:31",8
"Sonatype Nexus","Nexus 3 does not auto-block on 401 responses from https://maven.oracle.com","Nexus 3 does not auto-block on receiving 401 responses from the remote of a proxy repository.  Instead, it keeps checking the remote for every inbound request.     This is not consistent with Nexus 2.x, which does auto-block for 401 responses.  See NEXUS-6515.    Failure to auto-block on receiving 401 can cause major performance problems, and also has the disadvantage that a user is not alerted to the fact that a proxy repository is not working.  It is true that there are cases where you would not want to auto-block on 401, but those are rare, and can be handled by disabling auto-block in the repository's configuration.           Note: The reproduce case for the above is to create a proxy of https://maven.oracle.com and enter invalid credentials into the authentication settings for it.",Bug,Major,Closed,"2018-03-14 14:11:12","2018-03-14 14:11:12",2
"Sonatype Nexus","NotSerializableException com.orientechnologies.orient.core.sql.OSoftQueryResultList","In an 3.9.0 HA-C cluster the following log message was noticed:        h4. Cause    This is a problem in the OrientDB database version used by Nexus reported upstream as https://www.prjhub.com/#/issues/9975.    ",Bug,Major,Closed,"2018-03-13 15:33:28","2018-03-13 15:33:28",1
"Sonatype Nexus","yum proxy should be able to fetch non-yum files","We changed yum hosted to allow deployment of maven files and any other content (like raw). The yum proxy implementation should also be able to fetch these files. Although fetching the maven metadata files is less likely/useful it could be that uses want to fetch readme files or plugin metadata files that Yum can use.    h3. Acceptance Criteria   * Users should be able to fetch anything that can be stored in a yum hosted repo in permissive mode via a proxy repository.",Bug,Minor,Open,"2018-03-13 13:49:02","2018-03-13 13:49:02",2
"Sonatype Nexus","Remove Releases from Repository task may fail with IllegalArgumentException Comparison method violates its general contract!","Deploy into a hosted Maven releases repository ( id: releases ) versions of the same GA that have a mixture of versions such as:        See attached versions.txt for the complete list of versions used in the reproduce case.    Then run a Remove Releases from Repository scheduled task that tries to remove released versions against this repo.    When the task is run with these settings:    Repository: Releases  Number to Keep: 500  Repository Target: All (Maven 2)  *Use Index: True ( checked )*    It fails like this:        When the task is run with    *Use index: False ( unchecked )*    the task also fails with a slightly different stack:        h4. Explanation    The Maven repository format does not strictly enforce non-semantic type versions:    https://maven.apache.org/guides/mini/guide-naming-conventions.html    However, in order for the task to decide which 500 release versions to keep, it must sort them in order of highest to lowest. Since it is impossible to accurately determine if a hash style version number is sorted before or after a semantic style version, using the Remove Releases from Repository task against such a set of mixed versions is not reliable.    h4. Expected    The task should not fail since there is no explicit Maven repository format rule that does not allow mixing both types of version numbers. However since the task is trying to determine which versions to keep after sorting them, and it can't reliably do this in this case, the task should skip problem GAs with mixed versions it encounters and log all the found versions for the GA it found with the problem at WARN level in the log.    Cleaning up such mixed versions releases is left as an exercise to the Nexus Administrator.   ",Bug,Major,Closed,"2018-03-12 16:35:17","2018-03-12 16:35:17",2
"Sonatype Nexus","PyPi proxy repositories don't normalize artifact names.","Per [PEP 503|https://www.python.org/dev/peps/pep-0503/#normalized-names] PyPi repositories should normalize the names of artifacts stored in them.  This is being done for hosted repositories, but it is not currently done for proxy repositories.     Specifically, the normalization requires that:  {quote}only valid characters in a name are the ASCII alphabet, ASCII numbers, {{.}}, \{-}, and \{_}. The name should be lowercased with all runs of the characters {{.}}, \{_-_}, or \{_} replaced with a single {{-}} character.   {quote}  This means that duplication of stored packages can occur, since the name stored in the proxy repository will be the one it was requested with, not the normalized name.  It also will cause confusion, components retrieved through proxy repositories will not always have the same name as what is stored on the remote.",Bug,Major,Open,"2018-03-08 20:54:55","2018-03-08 20:54:55",1
"Sonatype Nexus","Content Selector preview filter is case sensitive","I just noticed that if I have a package SONATYPE.TEST.1.0.nupkg and am previewing content selectors if I filter test it won't show up.  If I filter TEST it does show up.  I think there'd be more value here if this was case insensitive.  To know the exact case when trying to pare things down seems less useful than not knowing and finding the things you want.  On the other hand, I can see it the other way too.  Am filing, maybe folks have opinions for or against.  It'd be good to hear this was intentional.",Bug,Minor,New,"2018-03-07 22:18:27","2018-03-07 22:18:27",3
"Sonatype Nexus","API key changes when the regular account password changes","NuGet API keys should be tied to identity ( username + realm identity), and identity should not include profile attributes such as regular password, user first name, last name, or email.    Nexus 3.x: Change the regular password of a repository manager user account. This will change the NuGet API key as well. This should not happen.    Nexus 2.x does not change the NuGet API key when password or any other account profile data changes.    Related mailing list exchange: https://groups.google.com/a/glists.sonatype.com/d/msgid/nexus-users/19330e21-3372-418f-9cd3-0b4c8fa89f69%40glists.sonatype.com?utm_medium=email&utm_source=footer  ",Bug,Major,Closed,"2018-03-07 14:46:39","2018-03-07 14:46:39",2
"Sonatype Nexus","DELETE asset REST endpoint for yum should not delete component","I noticed that when a delete by asset is done on a yum hosted repository that it also deletes the component, this in turn will delete the remaining assets of the component.     *To reproduce:*   # Upload two rpms for different architectures, I used bakefile from [http://mirror.centos.org/centos/6/extras/i386/Packages/bakefile-0.2.8-3.el6.centos.i686.rpm] and [http://mirror.centos.org/centos/6/extras/x86_64/Packages/bakefile-0.2.8-3.el6.centos.x86_64.rpm]   # Use the rest api to perform a search: [http://localhost:8081/service/rest/<USER>search?repository=yum-hosted&format=yum&name=bakefile&version=0.2.8-3.el6.centos] will return something similar to the response shown below, i.e. one component containing two assets.   # Use one of the assets id value to issue a delete [http://localhost:8081/service/rest/<USER>assets/eXVtLWhvc3RlZDoyZmZmNTA5YTdjMmE5ZWJlMjI1MmIxNTY5OWI3MzdjYg]     # Perform the same search as in step 1   # Observe that the component and all rpms have now been deleted.         *Acceptance Criteria*   # delete by asset should not delete the component when other assets are associated with the component.   # delete by component should delete itself and all associated assets.",Bug,Major,Closed,"2018-03-07 14:23:40","2018-03-07 14:23:40",3
"Sonatype Nexus","New ruby gems dependency files are cached in blob storage every time Nexus requests them from a proxy repository remote","After installing bundler using the gem command, I have these two files in my blobstore:    After this, I expired cache in my rubygems.org proxy repository, and then requested this (just once):    [http://localhost:8081/repository/rubygems-proxy/api/v1/dependencies?gems=bundle]    And now I have:    Those older blobs are not marked for deletion, running compact blobstore does not remove them.    Every time cache expires and the dependency request is made two more dependency files are cached. Over time, these will consume quite a lot of space.  h5. Expected:    # Older dependency files should be deleted as new ones are downloaded from the remote.    # Ideally, if the content of the file has not changed, no new file will be stored.   # We will need to publish a groovy script that can find the orphaned dependency blobs created by this bug and delete them.",Bug,Major,Closed,"2018-03-06 17:48:00","2018-03-06 17:48:00",1
"Sonatype Nexus","Help - Issue tracker link currently defunct","In the help menu, if you click on Issue Tracker the link currently goes to links.sonatype.com/products/nexus/issues which redirects to https://support.sonatype.com/hc/en-us/articles/213466158-Sonatype-Nexus-Issues which is a non-existant page.  I suspect the link broke and this affects all versions but I haven't checked back at this time.",Bug,Medium,Closed,"2018-03-05 22:47:16","2018-03-05 22:47:16",1
"Sonatype Nexus","Search field clearing for /#security-users","If I use the X next to the search button to clear the field, it disappears and I'm not able to clear the field again this way until I refresh my Nexus tab or re-login. Happens in https://oss.sonatype.org/#security-users and with All Authorized Users in the drop-down. Have not reproduced elsewhere.",Bug,Minor,Closed,"2018-03-05 20:10:11","2018-03-05 20:10:11",1
"Sonatype Nexus","Upgrade to OrientDB 2.2.34 to pick up HA sync and backup fixes","Changes since last release we picked up (2.2.31):    https://github.com/orientechnologies/orientdb/wiki/OrientDB-2.2-Release-Notes#2234---april-12-2018  https://github.com/orientechnologies/orientdb/wiki/OrientDB-2.2-Release-Notes#2233---march-5-2018  https://github.com/orientechnologies/orientdb/wiki/OrientDB-2.2-Release-Notes#2232---february-5-2018    Note: 2.2.33 introduced an HA regression around sync'ing of delta changes which was fixed in 2.2.34",Story,Major,Done,"2018-03-05 17:48:31","2018-03-05 17:48:31",1
"Sonatype Nexus","Role to privilege cache gets cleared out at inappropriate times due to use of weak references","     The default security realm in Nexus holds a cache of roles to privileges using a map that has weakly referenced values.     [https://github.com/sonatype/nexus-public/blob/release-2.14.4-03/components/nexus-security-realms/src/main/java/org/sonatype/security/realms/XmlRolePermissionResolver.java#L79]    This means that there is the potential for this map to lose all it's values every time Java runs garbage collection.  Rebuilding this map can be expensive on a heavily loaded instance, because the requests threads can experience considerable lock contention as they try to put new values into the map.    In Nexus 3.x we changed this map to use soft references. This prevents the values from being reclaimed unless heap memory is actually low.  We should make the same change in Nexus 2.",Bug,Major,Closed,"2018-03-05 17:06:39","2018-03-05 17:06:39",1
"Sonatype Nexus","Connection reset when uploading large file using Apache Ivy","Not entierly sure if this is bug or not.    We had a build job which uploaded a few fairly large (~200Mb) artifacts to artifacts to nexus 2 with apache ivy. After upgrade this build job will not work any more.    The reason is that Ivy cannot be set to authenticate preemptively to nexus. So what happens is that ivy immediately sends the request without authentication header to nexus and eventually nexus times out with a connection reset error. Nexus is trying to read the request to be able to reply back with a WWW-Authenticate response, but instead just resets the connection.    If however the same request is made with authentication header, then the nexus will not time out, and everything will work as expected.    It seems to me that there are two different timeouts being used here. And no apparent way to configure any of them.         Using Nexus 3.7.1",Bug,Minor,Closed,"2018-03-05 12:18:07","2018-03-05 12:18:07",1
"Sonatype Nexus","Download Endpoint Returns Checksum Files if Maven Classifier Param is Set","When calling /<USER>search/assets or /<USER>search/assets/download with both the maven classifier and maven extension parameters, the response returns the checksum files along with the asset specified in the extension.    For example calling:    [http://localhost:8081/service/rest/<USER>search/assets?repository=maven-releases&version=1.0.1&maven.groupId=org.foo&maven.artifactId=bar.project&maven.extension=jar&maven.classifier=blah|http://localhost:8081/service/rest/<USER>search/assets?repository=maven-releases&version=1.0.1&maven.groupId=org.foo&maven.artifactId=bar.project&maven.extension=zip&maven.classifier=blah]    Will result in the jar asset as well as its checksum files being returned. It is expected that only the jar will be returned.    Omitting the classifier parameter results in only the jar being returned as expected.          ",Bug,Major,Closed,"2018-03-02 17:47:06","2018-03-02 17:47:06",1
"Sonatype Nexus","Ability to DELETE from a yum hosted repository","When testing yum repositories it was realized that there is currently no implementation of http DELETE to allow deletion of rpms    While there is a way to delete via the REST API ( [see mailing list answer|https://groups.google.com/a/glists.sonatype.com/d/msg/nexus-users/bVLQHtkDYAU/dx4c4g3pDAAJ] ) - a standard HTTP DELETE to the path of the RPM file should be allowed as well, similar to RAW or Maven repos. Nexus 2.x supported this and there are no YUM repository format rules that disallow this.    *Acceptance*   # RPMs can be deleted by making a http DELETE request. Updating yum metadata asynchronously from this action  should be handled as well.( ie. do not block the delete waiting for metadata to update )   # Attempting a DELETE of metadata will return a http 405 (NOT_ALLOWED) as these files will be updated automatically.   # Maven files (e.g. pom.xml) and other file types in PERMISSIVE repositories can be deleted by making a http DELETE request.",Improvement,Major,Closed,"2018-03-01 11:34:04","2018-03-01 11:34:04",2
"Sonatype Nexus","save docker repository configuration may log WARN java.io.IOException Resource temporarily unavailable","In Nexus 3.8.0, try saving a docker repository configuration that is already successfully configured with a connector port. You may see a WARN in the logs on this normal operation:          This may be due to changes to using jetty 9.4.x in Nexus 3.8.0.    h4. Expected    Unless this is user actionable and indicates a normal problem, this WARN message should be programatically avoided to avoid needless concern.    The failure appears to be on closing the connector so we should verify that connectors are not being left behind on each save.    ",Bug,Trivial,Open,"2018-02-28 18:11:46","2018-02-28 18:11:46",0
"Sonatype Nexus","PyPi hosted repository packages can only be searched by pep-0503 normalized name","Use twine to upload a python package with a special character in its name, such as jyt.python    into a hosted pypi repository:    1. python setup.py sdist --formats=gztar    2. twine upload FILENAME.tar.gz --repository-url NEXUS_PYPI_URL    Then try to use the REST API or UI search to find this package by its name. Searching using jyt.python will not work, but jyt_python will work. This appears to be due to the normalization of names applied by Nexus as defined by [https://www.python.org/dev/peps/pep-0503/#normalized-names] .    Contrary, when using a PyPi proxy to a python package with . in its name, Nexus stores this name NOT normalized and searching without an underscore will work.  h4. Expected   - one should be able to find PyPi packages using REST or UI search in a consistent way regardless of name normalization or the repository type containing the package   - Updated: a discussion on the implications of this ticket was held on 11/08/18. To fully implement this ticket would require an upgrade step. This was felt unnecessary at the moment, therefore only new uploaded packages will be able to search on both normalized and non-normalized package names.",Bug,Major,Closed,"2018-02-28 14:27:13","2018-02-28 14:27:13",3
"Sonatype Nexus","NullPointerException when merging group GAV maven-metadata.xml for  non-timestamped snapshot","Nexus 3.8.0 gets an NPE when merging GAV level maven-metadata.xml files from non-timestamped snapshot deploys.     Example maven-metadata.xml file:  {code:java}  <?xml version=1.0 encoding=UTF-8?>  <metadata>    <groupId>org.sonatype</groupId>    <artifactId>project</artifactId>    <version>1.1.5-SNAPSHOT</version>    <versioning>      <snapshot>        <buildNumber>1</buildNumber>      </snapshot>      <lastUpdated>20180227155805</lastUpdated>    </versioning>  </metadata>  {code}  When this file is merged with another repository's maven-metadata.xml file at the group level you get an NPE, and a 500 response:         *Reproduce Case*:  Create two snapshot repositories, put them in a group repository.  Deploy a normal timestamped snapshot into the first one.  For the second one, put <uniqueVersion>false</uniqueVersion> in the distributionManagement section in the pom file, and deploy using 2.2.1.      Then attempt to retreive the GAV level maven-metadata.xml file through the group repository.         *Expected #1*: Nexus should be able to handle files like these, there are still commonly used tools  (Ivy) that can't deploy timestamped snapshots.    *Expected #2*: In the more general case, if Nexus encounters a maven-metadata.xml file it can't parse during merge it should log a warning, and ignore the bad file.     ",Bug,Major,Closed,"2018-02-27 16:11:18","2018-02-27 16:11:18",2
"Sonatype Nexus","Nexus does not interpret + signs at URLs correctly","See https://github.com/NuGet/Home/issues/3858 , I have the same issue. What I observe when calling NCR's Nexus installation:    ```  > http://***.com/nexus/service/local/nuget/repo-name/Nuget.Name/1.2.3+09d6b7c  404 Path /Nuget.Name/1.2.3 09d6b7c/Nuget.Name-1.2.3 09d6b7c.nupkg not found in local storage of repository Repository [id=repo-name]  ```    Note the `+` sign missing in the response. Now when I escape manually:    ```  > http://***.com/nexus/service/local/nuget/repo-name/Nuget.Name/1.2.3%2B09d6b7c  [download offered]  ```    According sources for simpletons like me like ( https://stackoverflow.com/a/2678602/577067 ), it seems to me that you should not replace + by space in the path component of URLs. You should present me with the NuGet package for the first query.    Until this is fixed, we can't use SemVer 2 with Nexus.",Bug,Major,Closed,"2018-02-27 15:24:54","2018-02-27 15:24:54",0
"Sonatype Nexus","Attempting to rebuild browse nodes for deleted repositories results in NullPointerException on startup","When a repository is deleted, it is marked as such by renaming it to an obscure name in the database. This renaming will allow an end user to avoid referential integrity issues should they wish to create a new repository with the same name.    When scheduled tasks run against All Repositories, the list may include these obscurely named deleted repos. An example where this was seen in practice is in the following logging in Nexus 3.7.1 at startup:        h4. Expected     Mainly the NullPointerException should not happen.    Since deleted repos are effectively gone - tasks should not be able to retrieve a list of repositories that includes deleted repositories by default. If there is a valid use case for processing deleted repos with a task, the task should explicitly handle asking for a list which may include them ( although I am unaware of such use case at this time ).      ",Bug,Major,Closed,"2018-02-26 22:20:36","2018-02-26 22:20:36",2
"Sonatype Nexus","Publishing maven indexes against large repository has poor performance, gets OrientDB profiler warning","Publishing maven indexes against a large repository can run very slowly.    The OrientDb profiler emits a warning when the task is run indicating that the query being run is returning a result set that is too large:     {quote}  2018-02-23 08:20:16,493-0700 INFO [Thread-41067] *SYSTEM com.orientechnologies.common.profiler.OProfilerStub - $ANSI\{green \{db=component}} [TIP] Query 'SELECT last_updated AS lastModified, component.group AS groupId, component.name AS artifactId, component.attributes.maven2.baseVersion AS version, component.attributes.maven2.packaging AS packaging, component.attributes.maven2.pom_name AS pom_name, component.attributes.maven2.pom_description AS pom_description, attributes.maven2.classifier AS classifier, name AS path, attributes.content.last_modified AS contentLastModified, size AS contentSize, attributes.checksum.sha1 AS sha1 FROM asset WHERE bucket = [#129|https://sonatype.zendesk.com/agent/tickets/129]:1 AND attributes.maven2.asset_kind = ARTIFACT AND component IS NOT NULL' returned a result set with more than 10000 records. Check if you really need all these records, or reduce the resultset by using a LIMIT to improve both performance and used RAM  {quote}    ",Bug,Major,Closed,"2018-02-23 17:13:25","2018-02-23 17:13:25",8
"Sonatype Nexus","NuGet group repository package requests may respond with URLs to member repositories","From: https://groups.google.com/a/glists.sonatype.com/d/msgid/nexus-users/f2f39b37-7d39-45b1-96c1-a9dd5677672f%40glists.sonatype.com?utm_medium=email&utm_source=footer    I have multiple repositories:  nuget-dotnet-firstparty  nuget-dotnet-thirdparty  nuget-dotnet-generated  etc  and a group repository called:  nuget-dotnet  which brings all of the above together.    This is all on the server DepServer.    When I try to do a nuget restore when the client has access to nuget-dotnet (the group repository) only I get the following:  WARNING: Error downloading 'MyPackage.1.2.3' from 'https://DepServer:8443/repository/nuget-dotnet-firstparty/MyPackage/1.2.3'.  The HTTP request to 'GET https://DepServer:8443/repository/nuget-dotnet-firstparty/MyPackage/1.2.3' has timed out after 100000ms    Now, the client has no references to nuget-dotnet-firstparty, and so no security access set up for it.  But it shouldn't need it, because it has access to the group.    I couldn't work out why it was that it was having this issue, so I went looking through the information on the server via the nuget protocol.  What I found was:    https://DepServer:8443/repository/nuget-dotnet/  points to  https://DepServer:8443/repository/nuget-dotnet/Packages  Each entry has a link with a title of V2FeedPackage an an href of Packages(Id='MyPackage',Version='1.2.3')  Following one of those URLs shows that a line with  - content type=application/zip and a src of  https://DepServer:8443/repository/nuget-dotnet-firstparty/MyPackage/1.2.3    However, as the client has no access to the nuget-dotnet-firstparty repository, only to the group repository, that's when the error occurs.      h4. Expected    Responses from group requests should only reference urls to the group repo, not group members.  ",Bug,Major,Closed,"2018-02-23 15:50:43","2018-02-23 15:50:43",3
"Sonatype Nexus","Metadata for NPM group considers pre-release version higher than actual version","[https://semver.org/#spec-item-11] it says:    Example: 1.0.0-alpha < 1.0.0-alpha.1 < 1.0.0-alpha.<USER>< 1.0.0-<USER>< 1.0.0-<USER>2 < 1.0.0-<USER>11 < 1.0.0-rc.1 < 1.0.0.    So, semantic versioning considers anything with “-” a prerelease so 1.0.0-SNAPSHOT is considered prerelease and 1.0.0 is bigger than 1.0.0-SNAPSHOT.    1) Upload a package to hosted npm repo npm-snapshot with version 1.0.0-SNAPSHOT    2) Upload a package to hosted npm repo npm-release with version 1.0.0.    For repo npm-snapshot 1.0.0-SNAPSHOT is latest    For repo npm-release 1.0.0 is latest    3) Look at the group metadata, you will notice that it sets 1.0.0-SNAPSHOT as the latest         npm install testdeploy  from group repo will return 1.0.0-SNAPSHOT, as 1.0.0-SNAPSHOT set as latest.    Even if look at the deploy times 1.0.0 is deployed later than 1.0.0-SNAPSHOT.    So there may be some issue with npm group logic on picking which version should be latest as there is a latest tag on each member npm repos.         A workaround is do a {{npm install package@*}} which will exclude prereleases.",Bug,Major,Closed,"2018-02-23 13:30:14","2018-02-23 13:30:14",3
"Sonatype Nexus","PublishMavenIndexTask fails to republish maven Index if hosted Maven repository has write policy of ALLOW_ONCE","On locally hosted repositories, Maven indexes are not published for the second running of the task for those repositories marked as Release.    I expected that if the repositories marked as release had not changed, then no update to the index would be attempted and the logs would indicate that. Instead a error occurred stating the following:    org.sonatype.nexus.repository.IllegalOperationException: Repository does not allow updating assets: releases    was present in the task log, and the task manager showed that the task had failed with an error.    ----    The releases repository has a writePolicy of ALLOW_ONCE. That policy is intended to prevent republishing/overwriting the same artifact into the repository.    It is not intended to prevent the publish indexes task from running repeatedly and updating.                 Also, when the task fails in some circumstances it can leave blob references in the database that are deleted from the blob store. Future runs of the task may throw MissingBlobException - see NEXUS-16560  ",Bug,Major,Closed,"2018-02-21 23:35:56","2018-02-21 23:35:56",1
"Sonatype Nexus","disable mime type validation by default for RAW proxy repos","Create a RAW proxy to     https://repo.saltstack.com/yum/redhat/7/x86_64/latest/    Then try to proxy http://localhost:8081/repository/raw-proxy/SALTSTACK-GPG-KEY.pub    Mime detection fails for this file with:    {quote}  Detected content type [text/plain], but expected [application/x-mspublisher]: SALTSTACK-GPG-KEY.pub  {quote}    The file contents are not x-mpublisher - pub is a common extension for public key files, like in this case - see attached for a copy of that file at time of reporting this issue.    h4. Expected    - RAW proxy repos by default should have mime detection disabled?  - fix this mime detection      ",Bug,Major,Open,"2018-02-21 15:00:47","2018-02-21 15:00:47",2
"Sonatype Nexus","Nexus welcome page announces Nexus Repository 2.14.8 is now available when it is not","Right after updating to 2.14.7, Nexus promotes a new Update on its landing page:      Nexus Repository 2.14.8 is now available with support for ...    But following the link only leads to the 2.14.7 version. 2.14.8 does not seem to be available.",Bug,Major,Closed,"2018-02-21 10:03:18","2018-02-21 10:03:18",0.5
"Sonatype Nexus","Assigned privileges are restored when repository is deleted and created again","Assigned privileges are restored when repository is deleted and created again with same repository id.    1) Have an existing proxy nuget-test.  2) Assign nx-repository-view-nuget-nuget-test-_ to a Role._  _3) Delete repo nuget-test._  _4) Check that nx-repository-view-nuget-nuget-test-_ is removed from the Role.  5) Create proxy nuget-test.  6) Check that nx-repository-view-nuget-nuget-test-* is added back to the Role.    Not sure if this is intentional, but does indicate that role privilege are not cleaned up on deletion on a repo",Bug,Medium,Closed,"2018-02-16 17:43:22","2018-02-16 17:43:22",2
"Sonatype Nexus","Swagger UI caching causing load problems on upgrade","URLs to load parts of the swagger-ui via the http://localhost:8081/#admin/system/api link do not include the typical cache busting mechanism employed by other URLS {{?_v=<productversion>}}. The URLs include a Cache-Control: max-age=2592000 header in the response which causes the generic URL content to be cached for 30 days in the browser.    We have had several reports of problems loading the in product swagger-ui because of this caching issue.      {noformat:title=Request}    GET /swagger-ui/ HTTP/1.1  Host: localhost:8081  Connection: keep-alive  Upgrade-Insecure-Requests: 1  User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.167 Safari/537.36  Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8  Referer: http://localhost:8081/  Accept-Encoding: gzip, deflate, br  Accept-Language: en-US,en;q=0.9  Cookie: NXSESSIONID=b1639abe-c8f8-4e43-b1dc-04828c8713f2      The broken interface leads to support tickets and users mailing list questions.    h4. Expected    Include cache buster query param in all UI URLs. UI users should not be forced to clear browser cache and restart their browsers on upgrading Nexus.    h4. Workaround    Clear browser cache and restart web browsers after upgrading Nexus. Some reports of force refreshing using CTRL-F5 have worked as well.  ",Bug,Major,Closed,"2018-02-16 14:08:42","2018-02-16 14:08:42",2
"Sonatype Nexus","Require user tokens for repository authentication now enforced properly","When User token is enabled and the Require user tokens for repository authentication is also enabled, docker requests are still allowed to use plain text credentials instead of being forced to use user token credentials.    The changes made by NEXUS-11231 seem to only affect Maven and Raw format repositories.    h4. Expected    When Require user tokens for repository authentication is enabled, all non user-token credentials should be blocked for all repository formats.",Bug,Major,Closed,"2018-02-15 14:19:17","2018-02-15 14:19:17",0
"Sonatype Nexus","indexof in an OData $filter throws an OQueryParsingException","Use of indexof in an OData $filter throws an OQueryParsingException:           ",Bug,Major,Open,"2018-02-15 09:08:29","2018-02-15 09:08:29",0
"Sonatype Nexus","Nexus Pro reverts to Nexus OSS if license is removed","If you remove the Nexus Repo Manager license from the Java preference store Nexus will revert to OSS mode.    This is of particular concern to Nexus Firewall users, when running in OSS mode quarantine is not enforced.    Also, there is a bug in recent Java 8 versions, a Java update can wipe out the user preference store. We've encountered this on multiple support tickets recently:    [https://support.sonatype.com/hc/en-us/articles/360000093547-Java-update-in-Windows-can-remove-Nexus-license]    Firewall users who encounter the above issue will find that quarantine is no longer enforced, and will not be until they re-install their license and restart Nexus.    h4. Symptom on Upgrading Nexus Repository Manager Where OSS Mode is Enabled Trying to Load formerly PRO database Model        *Expected*    Once an instance has had a Pro license, it should not downgrade to OSS, but should present the 'please supply a license' screen.",Bug,Major,Closed,"2018-02-12 19:49:11","2018-02-12 19:49:11",3
"Sonatype Nexus","pip search on group requires read privilege on member repositories","On my production installation, I only grant anonymous access to a set of specific repositories/groups. This is the situation for pypi:   * a 'pypi' proxy repository pointing to [https://pypi.python.org/|https://pypi.python.org/] which is not browsable/readable for anonymous   * a group repository 'pypi-public' containing the above proxy repository. This one is the default the anonymous user must use with browse/read permissions granted    Using the 'pypi-public' group to install packages from pip command line is behaving as expected (packages get downloaded and installed)    Using the pip command line to search packages against the group fires a login prompt. To enable anonymous search your have to specifically grant the read access on the 'pypi' member repository. This is annoying as the admin must remember to grant read access to new member repository. The read permission on the group should be enough to complete the search.",Bug,Medium,Closed,"2018-02-12 07:22:53","2018-02-12 07:22:53",2
"Sonatype Nexus","Add privilege that controls access to IQ component details","I've granted every privilege in Nexus 3 that there is to a user, and they still do not have permissions to view IQ component details.    It should be possible for a non-admin user to view the IQ component details when looking at a component.  Currently the only way I can get access is to give the user the nx-admin role.    This was tested in both Nexus 3.8.0.    A support zip with my test configuration is attached, the test user has credentials test:test.",Bug,Major,Closed,"2018-02-09 17:14:55","2018-02-09 17:14:55",3
"Sonatype Nexus","Yum Hosted implement Condition GET for remaining endpoints","When requesting from a Yum Hosted we should provided a proper response for a conditional get with the {{If-Modified-Since}} header.    *Acceptance Criteria*   * Add for the URI patterns in {{YumHostedRecipe}} to add a Conditional Request Handler, affected URL's should return a 304 http status if data was not modified before the date time given in the {{If-Modified-Since}} header.    ** /repomd.xml   ** /repodata/*   ** *.rpm   ** **.**    *Example call*     ",Improvement,Major,Closed,"2018-02-09 16:52:41","2018-02-09 16:52:41",1
"Sonatype Nexus","Add UI upload for Yum","*Acceptance criteria*   * A user can select an RPM and upload it to a yum hosted repository.   * An RPM can be uploaded to any path in the repository that is at or deeper than the configured repodata depth. ",Story,Major,Done,"2018-02-09 12:23:50","2018-02-09 12:23:50",3
"Sonatype Nexus","UI poll requests iterates over all privileges.","Every time the UI polls Nexus it iterates over all privileges:    [https://github.com/sonatype/nexus-internal/blob/release-3.8.0-02/components/nexus-rapture/src/main/java/org/sonatype/nexus/rapture/internal/security/SecurityComponent.java#L197]    This is similar to an issue we fixed in Nexus 2.x (NEXUS-5713).    The processing of these privileges looks very expensive:         h4. Mitigation    Reducing the frequency the UI makes poll requests will in turn reduce the total processing of these requests by UI users. By default, poll requests are sent every 5 seconds.    Go to system/capabilities in the administration UI, and click on the UI: Settings capability. In the settings tab, change the authenticated user status interval to something like 120 seconds. Make sure the standard request timeout value is higher than 120 seconds or whatever you sent the value to.    ",Bug,Major,Closed,"2018-02-07 19:17:20","2018-02-07 19:17:20",5
"Sonatype Nexus","Performance: Only load a single page for content selector preview","The content selector preview can have performance issues with large sets of data and broad queries. The current preview functionality appears to make a backend call to load the first 50 matches which includes a count of all matches, and then additionally loads 5 more pages.    Suggestion is to load a single page with a message that there are more matching results. The user can leverage the 'filter' field to satisfy the use case of does this CSEL match the asset I am looking for    *Acceptance*   * Instead of loading 5 pages, just load one page of 50 records   * If the count of the results is 50, display a message that there are more matching results and we are limiting to 50   * The user can leverage the existing filter text box to satisfy the use case of does this selector match the asset I am thinking of",Story,Major,"Ready for Development","2018-02-07 17:49:08","2018-02-07 17:49:08",3
"Sonatype Nexus","Provide a means to disable paged result sets in LDAP searches","Some LDAP servers have paged result sets disabled for performance reasons (1).    These LDAP servers no longer work with Nexus versions 3.6.0 and higher due to the fix for -NEXUS-10565-.    We should consider adding a way to to disable paged results sets in our LDAP searches to restore compatibility with these servers.    1) [https://www.ibm.com/support/knowledgecenter/en/SSLTBW_2.1.0/com.ibm.zos.v2r1.glpa200/glpa200_Paged_search_considerations.htm]",Improvement,Major,Closed,"2018-02-07 17:04:54","2018-02-07 17:04:54",2
"Sonatype Nexus","Yum Proxy implement Condition GET","When requesting from a Yum Proxy we should provided a proper response for a conditional get with the {{If-Modified-Since}} header.    *Acceptance Criteria*   * Add for the URI patterns in {{YumProxyRecipe}} to add a Conditional Request Handler, affected URL's should return a 304 http status if data was not modified before the date time given in the {{If-Modified-Since}} header.    ** /repomd.xml   ** /repodata/*   ** *.rpm   ** *.xml.asc    *Example call*     ",Improvement,Major,Closed,"2018-02-07 15:32:56","2018-02-07 15:32:56",1
"Sonatype Nexus","Yum Hosted Recipe should not add the negative cache handler","If the yum hosted metadata is fetched before it is generated then a 404 will be returned. Because the negative cache handler has been incorrectly implemented on hosted the 404 will still be returned after the metadata has been generate. This is true for RPMs as well (fetched before upload and fetched after upload). There is no way to clear the negative cache without waiting for it to expire or restarting the server.    The Yum hosted recipe is adding the NegativeCacheHandler (i.e. [https://github.com/sonatype/nexus-internal/blob/30c875f80f2406800b8ec37cc618bee0cfd47897/private/plugins/nexus-repository-yum/src/main/java/org/sonatype/nexus/repository/yum/internal/hosted/YumHostedRecipe.groovy#L90)]       ",Bug,Major,Closed,"2018-02-02 18:09:47","2018-02-02 18:09:47",1
"Sonatype Nexus","Users dropdown does not match table text","I noticed that the first option in the Users page Source dropdown is Local but the table shows the source to be Default.  See attached.    The dropdown used to be Default and this is a (somewhat) recent change but I didn't check back to older versions to find out when.    Screen on https://help.sonatype.com/display/NXRM3/Users is dated (thus documentation component), even in the event this is an intentional change/inconsistency.",Bug,Trivial,Open,"2018-02-01 23:33:55","2018-02-01 23:33:55",1
"Sonatype Nexus","Yum hosted should log more information when the metadata is being generated","A message is logged when createrepo starts but not during the generation or when it finishes, making it unclear whether the metadata has been updated.",Improvement,Major,Closed,"2018-02-01 12:54:57","2018-02-01 12:54:57",1
"Sonatype Nexus","Group members appear in seemingly random order","While testing bower, I added 2 proxy repos and a hosted repo (in that order) and went to put them in a group.  I noticed the order displayed on the Available list was: proxy, hosted, proxy2.  This was not in the creation order or alphabetical order.    I can imagine this might be a problem with more than 3 repos.  However, workaround SHOULD be filtering, assuming the names arn't too similar and long.    I doubt this is regression, tho I haven't checked at this time.  I also doubt this is bower specific, tho I also didn't check.",Bug,Minor,Closed,"2018-01-31 23:08:29","2018-01-31 23:08:29",2
"Sonatype Nexus","Repository HTTP configuration not available in Safari","In the edit screen for a proxy repository the http configuration sections are not displayed when viewed in Safari. Works fine in Firefox    !Screen Shot 2018-01-31 at 17.01.31.png|thumbnail!         This issue isn't just affecting the HTTP Configuration section, all the subheadings on the new Repository form page are now hidden. See screenshot below:    !Safari - Broken Proxy Repo Page.png|thumbnail!    It also affects other pages with similar elements. e.g.     !Safari - Broken HTTP Page.png|thumbnail!        What's more, after the ExtJS upgrade, the style of the subheadings on all browsers is off. They are supposed to be larger than the form fields as shown in the Chrome screenshot below:     !Chrome - Proxy Repo Subheading Styles Pre Upgrade.png|thumbnail!     But after the upgrade, the structure of the DOM nodes that ExtJS generates was modified and the custom CSS style rule for subheadings is no longer matching. Therefore the subheadings look like all the other text on that page as can be seen on Chrome below:     !Chrome - Proxy Repo Subheading Styles Off.png|thumbnail!   ",Bug,Major,Closed,"2018-01-31 21:03:05","2018-01-31 21:03:05",2
"Sonatype Nexus","The NPM search endpoint doesn't handle forward slashes in scoped package names correctly","Using the npm search endpoint ([http://myhost:8081/repository/my-npm-repo/-/v1/search?text=%22%40myscope%2Fmyproject%401.0.0%22&size=20),] with a forward slash in a scoped package name (normal for scoped packages) results in an error.    The issue is due to incorrect handling of the url I think, as it works fine when I add quotes:    [http://myhost:8081/repository/my-npm-repo/-/v1/search?text=%22%40myscope%2Fmyproject%401.0.0%22&size=20|http://myhost:8081/repository/my-npm-repo/-/v1/search?text=%22%40myscope%2Fmyproject%401.0.0%22&size=20),]    However, the NPM client does NOT add quotes, and therefore, this doesn't work with plain npm.",Bug,Medium,Open,"2018-01-31 07:49:31","2018-01-31 07:49:31",2
"Sonatype Nexus","repomd.xml file remains when yum hosted depth level is changed and metadata regenerated","# Create a yum hosted repository with depth 3  # Upload some RPMs  # Wait for the metadata to be generated  # Change the repository's depth to 4  # Regenerate the data manual using the Rebuild Yum Metadata task  # The repomd.xml from the original generation will remain and be visible in the tree view but all other metadata files will have been deleted.    See screenshot for example  !Screen Shot 2018-01-30 at 16.34.35.png|thumbnail! ",Bug,Minor,Open,"2018-01-30 20:34:55","2018-01-30 20:34:55",2
"Sonatype Nexus","Yum proxy is not able to remove absolute URLs for metadata files that aren't at the root of a repository.","When repomd.xml is fetched through a yum proxy then Nexus automatically fetches the primary.xml.gz file so that it can remove any absolute urls, and update the checksum and size attributes that are stored in repomd.xml.    This works fine when the metadata is at the root of the repository. (i.e. remote url of http://mirror.centos.org/centos/7/os/x86_64 and a request url of http://localhost:8081/repository/yum-proxy/repodata/repomd.xml).    It fails when metadata is not at the root because it uses the path directly from the repomd.xml.    # Create a yum proxy repository with remote url http://mirror.centos.org/centos  # Fetch repomd.xml via http://localhost:8081/repository/yum-proxy/7/os/x86_64/repodata/repomd.xml  # The following message will be logged    {quote}  2018-01-30 10:53:43,834-0400 WARN  [qtp732641399-75] admin org.sonatype.nexus.repository.yum.internal.proxy.YumProxyFacetImpl - Failed to fetch metadata file for path repodata/b686d3a0f337323e656d9387b9a76ce6808b26255fc3a138b1a87d3b1cb95ed5-primary.xml.gz and repository yum-proxy-97. Received status code 404  {quote}    To fix this we need to prepend the /7/os/x86_64 part of the request url onto the url that is extracted from repomd.xml",Bug,Major,Closed,"2018-01-30 15:37:49","2018-01-30 15:37:49",2
"Sonatype Nexus","Proxied yum packages can become undiscoverable","NXRM Proxy repos should continue to serve packages even if they go missing upstream. However, since we proxy the metadata listing from upstream we're vulnerable to effectively propagating upstream deletions.    # Create a yum *hosted* repo with two RPMs in it.  # Wait for the hosted repository to generate the metadata (this defaults to 60 seconds)  # Create a yum *proxy* of the hosted repo.  # Fetch the metadata through the *proxy*, specifically repomd.xml which will automatically fetch primary.xml.gz.  # Fetch both the RPMs through the *proxy* so that they are cached.  # Delete one of the RPMs from the hosted repo and wait for the metadata to be regenerated. The primary.xml.gz file in the hosted repository should now only list one RPM.  # Invalidate the cache on the proxy and then fetch the repomd.xml again.  # The primary.xml.gz file in the proxy will now only list one RPM but both RPMs will be available in the repository.    (Note another way to reproduce this would using a Centos 6 Docker image and a Centos 7 Docker image and then to point a proxy at a centos 6 remote http://mirror.centos.org/centos-6/6.9/os/x86_64/ install some packages, change the remote url to centos 7 install some packages http://mirror.centos.org/centos-7/7/os/x86_64/ the go back and try and install the 6 packages, which will fail)    This issue is the Yum version of the NPM-specific NEXUS-15714.",Bug,Major,Closed,"2018-01-29 14:37:59","2018-01-29 14:37:59",5
"Sonatype Nexus","Error when maintainers is shortened string","When a npm hosted package.json contains a maintainers attribute that is of a shortened type an exception is thrown:          To replicate the problem for npm-hosted on NX3 follow the same instructions as [here|https://issues.sonatype.org/browse/NEXUS-12347?focusedCommentId=451315&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-451315] but adding a maintainers attribute to the package.json. For example    The above example in my opinion does not match the specification but it has been noted that some packages are using this format (i.e. not an array of maintainers).",Bug,Major,Closed,"2018-01-26 10:46:59","2018-01-26 10:46:59",1
"Sonatype Nexus","Docker push can fail in HA Environment","Within a HA Environment, a Docker push of an image with several layers can fail due to the upload requests landing on different nodes within the cluster.    For example, Node A handles the initial POST and PATCH requests, but the PUT is handled by a different node (Node B) which doesn't appear to be aware of the upload and ends up throwing a java.lang.IllegalStateException: Missing upload with uuid: and returning a 404:  {quote}org.sonatype.nexus.repository.docker.internal.DockerHostedFacetImpl - Failed to complete upload   java.lang.IllegalStateException: Missing upload with uuid: f26e5743-c7c3-4300-ae69-00166e49b9c7   at org.sonatype.nexus.repository.docker.internal.UploadManagerImpl.ensureGetUpload(UploadManagerImpl.java:134)   at org.sonatype.nexus.repository.docker.internal.UploadManagerImpl.complete(UploadManagerImpl.java:94)   at org.sonatype.nexus.repository.docker.internal.DockerHostedFacetImpl.completeBlobUpload(DockerHostedFacetImpl.java:574)  {quote}",Bug,Critical,Closed,"2018-01-25 15:40:01","2018-01-25 15:40:01",3
"Sonatype Nexus","Continue to serve locally cached proxied npm packages that are unpublished on the remote","It is rare, but technically unpublishing npm packages is possible at a remote npm registry.    When Nexus is proxying a remote npm repository, a specific package version may get locally cached. Then the remote may unpublish that same package, thus altering the package metadata which lists the versions of the package at the remote site.    The next time Nexus gets the remote metadata for that package, the metadata is replaced, not merged, with its own local metadata. See https://issues.sonatype.org/browse/NEXUS-8624.    If metadata age is set as -1, then Nexus will never get new metadata, so will not know about new versions that get published.    If it is set to anything greater, then the new metadata from the remote may get downloaded and will not refer to the already locally cached package, it will replace the local metadata and Nexus will not serve the already cached unpublished package to inbound requests.    There is a use case for continuing to serve the already cached package, if we have a project depending on that package, we don't want our project to be affected if this module is unpublished at the remote.    Nexus should also provide an option to continue serving the cached packages, while at the same time have a method to reconcile packages/metadata which are explicitly deleted from the local cache or remote site.",Bug,Major,Closed,"2018-01-24 15:21:41","2018-01-24 15:21:41",5
"Sonatype Nexus","Invalid cookie header blocks accessing https://maven.oracle.com","Following the instruction [https://help.sonatype.com/display/NXRM3/Maven+Repositories#MavenRepositories-ProxyingtheOracleMavenRepository] we set up a local Maven 2 proxy to maven.oracle.com in our Nexus Repository ManagerOSS 3.6.0-02.    As a result, proxy stays empty, because it cannot authenticate in maven.oracle.com which returns the default redirect for not authenticated users. Analyzing the logs we see the following reported for each request the maven2 proxy sends to maven.oracle.com:    {{org.apache.http.client.protocol.ResponseProcessCookies - Invalid cookie header: Set-Cookie: IntradocAuth=Basic; path=/; Expires=Thu, 24 Jan 2019 06:36:16 GMT; HttpOnly. Invalid 'expires' attribute: Thu, 24 Jan 2019 06:36:16 GMT}}    -We understand that as an attempt of maven.oracle.com to establish a session for all following requests from the proxy, which fails. As a result, the requests are not authorized and the artifacts there are not accessible.-    h4. Expected    - suppress the following WARN logging for Oracle repos cookies    - add a log message and auto block the repository if we can reliably detect that the Oracle user agreement needs to be accepted    ",Bug,Minor,Open,"2018-01-24 09:14:00","2018-01-24 09:14:00",2
"Sonatype Nexus","Intermittent Nuget Illegal argument errors resulting in 400 response","Seeing Intermittent failures from Nuget calls which results in 400 response  {quote}2018-01-22 21:52:26,218+0100 INFO [qtp383736885-1059] anonymous com.sonatype.nexus.plugins.nuget.rest.NugetGalleryResource - Illegal argument: Problem preparing SQL: SELECT P.*,(P.VERSION=L.AV) AS ISABSOLUTELATESTVERSION,(P.VERSION=L.V) AS ISLATESTVERSION FROM (SELECT ID,MAX_VERSION(VERSION) AS AV,MAX_VERSION(CASEWHEN(ISPRERELEASE,'',VERSION)) AS V FROM PACKAGES WHERE LOCATE(CONCAT(CONCAT(':',REPOSITORYID),':'),?1) GROUP BY ID) AS L INNER JOIN PACKAGES AS P ON L.ID=P.ID WHERE LOCATE(CONCAT(CONCAT(':',REPOSITORYID),':'),?1) AND P.ID = 'Core.Tests.Common' AND (P.DOWNLOADCOUNT < 0 OR (P.DOWNLOADCOUNT = 0 AND (P.ID > 'Core.Tests.Common' OR P.ID = 'Core.Tests.Common' AND P.VERSION > '5.7.160-snapshot'))) ORDER BY P.DOWNLOADCOUNT DESC,P.ID,P.VERSION LIMIT 40  {quote}       Below is the call related to the above error. It returned a 400 response:  {quote}x.x.x.x - - [22/Jan/2018:21:52:26 +0100] GET /nexus/service/local/nuget/nuget-all/FindPackagesById?id=%27Core.Tests.Common%27&$orderby=DownloadCount+desc&$skiptoken=0%2C%27Core.Tests.Common%27%2C%275.7.160-snapshot%27 HTTP/1.1 400 238 34376  {quote}  We can also see it working two seconds before. This came from the same IP address. Not seeing any difference with the call above.  {quote}x.x.x.x - - [22/Jan/2018:21:52:24 +0100] GET /nexus/service/local/nuget/nuget-all/FindPackagesById?id=%27Core.Tests.Common%27&$orderby=DownloadCount+desc&$skiptoken=0%2C%27Core.Tests.Common%27%2C%275.7.160-snapshot%27 HTTP/1.1 200 101152 32692  {quote}  Majority of the call all work fine. These intermittent failures cause issues in automated builds.     ",Bug,Major,Open,"2018-01-23 13:32:46","2018-01-23 13:32:46",0
"Sonatype Nexus","docker proxy repository does not work for container-registry.oracle.com","I am trying to proxy the oracle container registry, which requires a username/password. It seems there is an error in the callback during auth as it has a space in it.    [https://blogs.oracle.com/weblogicserver/the-oracle-container-registry-has-gone-live]    i get the following error;        h4. Cause    In DockerProxyFacetImpl.retrieveBearerToken we do        The URL is not properly encoded.      h4. Reproduce    # Sign up at https://container-registry.oracle.com   # Create a Docker proxy against that (with authentication)  # pull something with docker against this repo. ie. {{docker pull localhost:12344/database/enterprise:12.2.0.1}}",Bug,Major,Closed,"2018-01-18 14:45:55","2018-01-18 14:45:55",1
"Sonatype Nexus","GET /-/v1/search java.lang.IllegalArgumentException Invalid query WARN message with no context","Customer logs contain verbose WARN messages such as this using 3.7.1:        The problem is the large stack trace for a WARN message for a query that at first glance does not appear to be invalid. There is also absolutely no log message information about WHY it is not valid. The log message and spam it creates it not helpful unless more context is added - hiding the context at DEBUG level is NOT helpful.    ",Bug,Major,Closed,"2018-01-16 16:39:21","2018-01-16 16:39:21",2
"Sonatype Nexus","Reduce the default frequency of updating asset last access time","*Background*    Currently the asset last access time is updated every 1 minute at the most frequent and this is not adjustable. See NEXUS-15469. This can cause excessive updates to the database triggered by asset downloads.    *Acceptance*   * Make the default 'last accessed time' update rate 12 hours (not 1 minute).   * Modify the UI so that it only displays the day (and leaves off hours/minutes/seconds) for this date.   * Download count will not be impacted.",Story,Critical,Done,"2018-01-12 15:01:48","2018-01-12 15:01:48",2
"Sonatype Nexus","Blob store type field is editable... it shouldn't be","The blobstore type field is editable.  If you put in a value that is not in the list and save you get an NPE (see screenshot).               ",Bug,Minor,Closed,"2018-01-11 22:46:03","2018-01-11 22:46:03",1
"Sonatype Nexus","ensure scheduled tasks are cancelable (part 2)","From execution of --NEXUS-13208-- there are additional scheduled tasks which, as of 3.7, do not support cancellation. For the same reasons as the aforementioned JIRA these tasks should be allowed to be canceled where possible.         * CompactBlobStoreTask   * DockerUploadPurgetask   * PurgeApiKeysTask   * -RebuildAssetUploadMetadataTask- (completed previously)   * -RebuildBrowseNodesTask- (completed previously)   * RebuildIndexTask   * -YumCreateRepoTask- (not addressing at this time)   * -RepairYumProxyComponentsTask- (class no longer exists)","Technical Debt",Major,Closed,"2018-01-11 01:23:07","2018-01-11 01:23:07",8
"Sonatype Nexus","Asset not updated when a npm package is republished","I have a npm hosted repository with a deployment policy = Allow redeploy in order to simulate snapshot versions.   After the second publish, I can't install the dependency anymore because there is a failure when checksums are compared (tested with npm 5.6.0 and yarn 1.3.2).       The problem appears in Nexus 3.7.0. I don't have this problem with Nexus 3.6.2.        Steps to reproduce the problem:   * Create a npm hosted repository with a deployment policy = Allow redeploy   * Create a directory with only this package.json:       * Publish to the npm hosted repository       * Create a file README.md   * Publish again to the npm hosted repository   * At this step, you can already see there is a problem in the Nexus UI (asset not updated)   * Create another directory with only this package.json:       * Get the dependencies       * It fails    ",Bug,Major,Closed,"2018-01-09 10:45:29","2018-01-09 10:45:29",2
"Sonatype Nexus","NuGet API Key generated by a user authenticated with RUT will get purged by Purge Orphaned API Keys task","h4. Setup    - Nexus 3.7.1  - NuGet API Key realm is active  - RUT Auth realm is active  - RUT Auth Capability is enabled    h4. Problem Reproduce    # Authenticate to Nexus 3 UI using RUT Auth ( your user account can be ldap, crowd or default realm user account )  # Go to your profile and generate a NuGet API Key by clicking Access Key. ( You will be prompted for authentication due to NEXUS-10692 ). When prompted for password, enter your password. Record the displayed API Key.  # Schedule and run a Purge Orphaned  API Key task. After the task completes, your Nuget API Key previously displayed will no longer be valid as the task considered it orphaned and removed it.    Debug logging while the task is run shows why the task considered it orphaned:        h4. Expected    When a RUT authed user creates an API key ( for NuGet or any other key realm ) the API key should be associated to the realm that actually stores the user's account for the purposes of authentication as determined by the order of realms in the active realms list ( default, ldap, crowd), instead of {{rutauth-realm}}. In this way, the key will not normally be considered orphaned and not be removed by the the purge task.    h4. Regression    Nexus 2.x is not known to have this same problem so this issue may affect upgraded configurations from Nexus 2x to 3x.",Bug,Critical,Closed,"2018-01-08 18:03:39","2018-01-08 18:03:39",2
"Sonatype Nexus","when a repository name contains uppercase letters, nx-repository-* privileges will not take effect in the UI","It seems that privileges nx-repository-*--**-*<repoName>-* are not applied when repoName contains uppercase characters. Our test case :   * Create a repository MyTest, Maven2 hosted (put some artefact in it for testing)   * Create a role Admin-MyTest containing privileges nx-repository-admin-maven2-MyTest-*** and nx-repository-view-maven2-MyTest-*   * Create a user and assign it the previously created role   * Login with this user, you should see you are only read-only when browsing content of repository MyTest (cannot add/edit/delete components or artifacts) and cannot change repository parameters (read-only too)      When trying to administer the settings of a repo with uppercase characters, the settings page is greyed out and at the bottom of the screen is the message You don't have permission to update repositories.     ",Bug,Major,Open,"2018-01-08 17:27:23","2018-01-08 17:27:23",2
"Sonatype Nexus","include edition and version in logged uptime message","When Nexus is shutdown, the Uptime is logged - example:        If the shutdown immediately precedes a Nexus upgrade, it is useful to understand what edition and version was shut down immediately preceding the upgrade.    h4. Expected    - include the last active edition and version that was shutdown, in the uptime message:    Example: {{Uptime: 22 hours, 21 minutes, 28 seconds and 576 milliseconds (nexus-pro-edition/3.7.1.02)}}    - make sure that if there is a license change during the last run of the server, the reported edition accurately reflects that last change    *Note:* The edition version string example suggested here is the same one seen during these messages on startup:        Another format of edition version could be acceptable as well, open to suggestions.  ",Bug,Major,Closed,"2018-01-08 16:11:57","2018-01-08 16:11:57",1
"Sonatype Nexus","RubyGems: Search by name is case sensitive","I found searching artifact-id in a RubyGems repository for aasm returned results but searching AASM did not.  It seems unhelpful to be able to need to know the case in order to find a result.    I did not check against NXRM2 or older NXRM3 at this time.",Bug,Minor,Open,"2018-01-02 23:16:31","2018-01-02 23:16:31",2
"Sonatype Nexus","Raw: Search by name is case sensitive","I found searching name in a raw repository for index.html returned results but searching INDEX.HTML did not.  It seems unhelpful to be able to need to know the case in order to find a result.",Bug,Minor,Open,"2018-01-02 23:15:02","2018-01-02 23:15:02",2
"Sonatype Nexus","Docker: Search (by image name) is case sensitive","I found searching artifact-id in a Docker repository for hello-world returned results but searching hello-WORLD did not.  It seems unhelpful to be able to need to know the case in order to find a result.",Bug,Minor,Open,"2018-01-02 23:13:15","2018-01-02 23:13:15",2
"Sonatype Nexus","Smart Proxy - Publish/Subscribe Configuration privileges don't work","The Smart Proxy - Publish/Subscribe Configuration privileges don't work, event after granting them to a user they will still receive a 403 response when trying to access the /service/local/smartproxy/pub-sub resource:    127.0.0.1 - deployment [02/Jan/2018:08:36:19 -0600] GET /nexus/service/local/smartproxy/pub-sub/amd-core-rm-Snapshots?_dc=1514903779880 HTTP/1.1 403 581 3     ",Bug,Major,Closed,"2018-01-02 14:49:39","2018-01-02 14:49:39",2
"Sonatype Nexus","logging from different task threads may log to the same task log if tasks are started within the same second","It was noticed that the log messages from two different distinct task threads processing different repositories may log to the same task specific log.  h4. Expected    Each scheduled task should log to its own uniquely named task log.     ",Bug,Major,Closed,"2017-12-29 19:38:13","2017-12-29 19:38:13",2
"Sonatype Nexus","Not Found Cache TTL timeout setting of -1 fails upgrade from Nexus 2x to 3x","In Nexus 2.x instance, if the Not Found Cache TTL timeout is set to -1, then this fails the migration.    You see the following warning in the logs.     Also caused the migration to hang on a group repo containing the above repo.",Bug,Medium,Closed,"2017-12-29 16:59:40","2017-12-29 16:59:40",2
"Sonatype Nexus","NPM allows redeploys despite Deploy Policy","We no longer get any type of HTTP error message when redeploying an NPM package to a hosted repo, with the Deploy Policy set to *Disable Redeploy.*    A HTTP 200 is returned..     ",Bug,Minor,Closed,"2017-12-21 20:29:48","2017-12-21 20:29:48",1
"Sonatype Nexus","repositories marked not online can prevent tree and html view from displaying all content","If a Nexus 2 or 3 instance is upgraded to 3.7.0, and that original instance contained any repository marked offline or out of service, then the background task which builds the Tree View / HTML view may fail to index existing cached items in ANY other repository. The result is there is no way to Browse those repositories that were not indexed by the background task. The exact repositories affected is indeterminate.    Offline means:   * Nexus 3.x: The Online checkbox is not selected.   * Nexus 2.x: The repository has been Put out of service    This bug does not fail builds which download components or prevent UI search from working, but will hide repository items from the tree view and HTML view for some repositories.    {noformat:title=Example nexus.log ERROR message that will be reported in this scenario}  2017-12-21 09:08:16,900-0600 ERROR [quartz-3-thread-5] *SYSTEM org.sonatype.nexus.repository.browse.internal.RebuildBrowseNodesTask - Could not re-create browse nodes for repository: RepositoryImpl$$EnhancerByGuice$$c53e9f01{type=hosted, format=nuget, name='nuget-hosted'}  org.sonatype.nexus.scheduling.TaskInterruptedException: Repository nuget-hosted is offline, rebuilding browse nodes was cancelled  at org.sonatype.nexus.repository.browse.internal.RebuildBrowseNodesTask.checkContinuation(RebuildBrowseNodesTask.java:144)  at org.sonatype.nexus.repository.browse.internal.RebuildBrowseNodesTask.execute(RebuildBrowseNodesTask.java:101)  at org.sonatype.nexus.repository.RepositoryTaskSupport.execute(RepositoryTaskSupport.java:69)  at org.sonatype.nexus.scheduling.TaskSupport.call(TaskSupport.java:93)  at org.sonatype.nexus.quartz.internal.task.QuartzTaskJob.doExecute(QuartzTaskJob.java:145)  at org.sonatype.nexus.quartz.internal.task.QuartzTaskJob.execute(QuartzTaskJob.java:108)  at org.quartz.core.JobRunShell.run(JobRunShell.java:202)  at org.sonatype.nexus.thread.internal.MDCAwareRunnable.run(MDCAwareRunnable.java:40)  at org.apache.shiro.subject.support.SubjectRunnable.doRun(SubjectRunnable.java:120)  at org.apache.shiro.subject.support.SubjectRunnable.run(SubjectRunnable.java:108)  at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)  at java.util.concurrent.FutureTask.run(Unknown Source)  at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)  at java.lang.Thread.run(Unknown Source)  {noformat}    h4. Workaround   * if you have repositories marked offline or out of service, do not upgrade to 3.7.0   * if you require access to another bug fix in 3.7.0 before this issue is fixed in a newer release, then contact [<EMAIL>|mailto:<EMAIL>] to learn about your options    h4. Expected    All cached repository content should be viewable in tree view, regardless whether a repository is offline or online. Also, a single offline repo should not fail fast the RebuildBrowseNodesTask at all.",Bug,Blocker,Closed,"2017-12-21 15:56:53","2017-12-21 15:56:53",2
"Sonatype Nexus","No way to download a jar through /rest/beta/search/assets/download if a jar with classifier for same GAV exists","I'm trying to use the /rest/<USER>search/assets/download to download a jar file:    org/foo/project/1.0.0/project-1.0.0.jar    To do this, I used:    [http://localhost:8081/nexus/service/siesta/rest/<USER>search/assets/downlload?repository=maven-releases&maven.groupId=org.foo&maven.artifactId=project&maven.baseVersion=1.0.0&maven.extension=jar]    But this always fails with a 400 response. The logs show that the reason for this is multiple files are found. Using  the/rest/<USER>search/assets endpoit I find that the reason is there is also a jar with a classifier:    I can find no way to create a search that does not match the classifier.  So I always get two results, and I cannot download this file directly by REST API.    This is either a bug in the API, or a bug in the documentation.  If the latter, the REST API documentation should show how to search for an empty classifier.     ",Bug,Major,Closed,"2017-12-13 20:42:06","2017-12-13 20:42:06",2
"Sonatype Nexus","Logging in from anonymous search causes exception","Steps to reproduce:    * Sign out of the UI  * Search for a component (e.g. aether)  * Click one of the results (e.g. aether-impl)  * Sign in    After a short delay, an exception pops up and the search feature grays out.",Bug,Major,Closed,"2017-12-13 15:24:42","2017-12-13 15:24:42",2
"Sonatype Nexus","Security -> Realms UI shows incorrect saved realm order for Active realms","Steps to reproduce:   # Add a new Realm to the Active list (LDAP in this example), and move the new realm below the existing Nexus Local realms. The screenshot below shows the order just before Saving:   !PreSaveOrder.png!   # Click the Save button, and the screen is refreshed and the Active realm order is changed and no longer matches what was saved. In the example below, the LDAP realm is shown first in the list.   !PostSaveOrderWrong.png!         Note:  - despite the different displayed order after clicking Save, the database will store the realm order that was displayed before clicking Save  - if you move the order around, the Save button disables itself when the order is changed to match the last order that was actually saved",Bug,Critical,Closed,"2017-12-11 19:29:43","2017-12-11 19:29:43",2
"Sonatype Nexus","Nexus 3 service will not start if /tmp is not writable","By default Nexus 3 sets the java.io.tmpdir to a location other than /tmp, but Install4J still attempts to write a file to /tmp and the startup fails if the nexus user cannot write to /tmp, either due to permissions or if a file of the same name it is trying to write, already exists - for example one left over from an unclean shutdown.    h4. Workaround     A workaround is documented here: https://help.sonatype.com/repomanager3/installation/run-as-a-service#RunasaService-PIDFile    h4. Expected    Perhaps this should be added to the default configuration?    h4. Reproduce    To test, set permissions on tmp to only allow the root user to write to it. Attempt to start nexus 3 not as root user. Startup should silently fail.",Bug,Minor,Closed,"2017-12-11 17:54:54","2017-12-11 17:54:54",1
"Sonatype Nexus","docker anonymous pull configuration confusing","Users find the docker anonymous pull option confusing.    Change:    Force basic authentication:  [ ] Disable to allow anonymous pull (Note: also requires Docker Bearer Token Realm to be activated)    to:    Anonymous docker pull:  [ ] - Allow anonymous docker pull ( Docker Bearer Token Realm required )    NOTE: This will be an inversion of the current flag in the UI.",Bug,Major,Closed,"2017-12-07 21:56:16","2017-12-07 21:56:16",2
"Sonatype Nexus","Multiple edits of user roles fails with: ConcurrentModificationException: User-role mapping","When adding multiple roles to an LDAP user in multiple steps, the second role will fail to save and the UI shows an error like: Warning: user-role mapping 'USERID' updated in the meantime     Steps to reproduce.   # Setup LDAP   # Search for (via Source: LDAP, and search box) and Select an LDAP user.    # Add a role from the Available list to the Granted list. Click Save.   # Add a second role from the Available list to the Granted list. Click Save. Boom! The warning above is shown, and the change is not saved, nor will retries save the change.    Example:    After saving first role:    !RoleAdd1.png!         Failed save of second role:    !RoleAdd2Error.png!    Support.zip from reproduce case:    [^support-20171207-145031-1.zip]    Stack trace:      h4. Short term workaround for affected versions    A short term workaround should allow you to make role assignment changes if you can't immediately upgrade:    # Make a note of all the currently assigned Roles for the user. Remove all assigned roles, click 'Save'. The user should have no roles at this point.  # Add all Roles you want for the user, click 'Save'. There should be no errors.  ",Bug,Major,Closed,"2017-12-07 20:10:31","2017-12-07 20:10:31",2
"Sonatype Nexus","Repository List REST endpoint","Create a new REST endpoint for Repository interaction; initial phase will only support a small number of operations    *Acceptance*   * User has the ability to retrieve the list of configured repositories in NXRM3   * Returned information should include, at a minimum, the unique repository name, format, and location (URL)   ** Consider including additional metadata during implementation as desired     * Visibility of repos through this endpoint should match the visibility of repos on the UI - it should abide by the same permission scheme    *Notes*   * 'Bucket' doesn't have format on it, so unlike the other REST endpoints this will probably be driven by the config db.",Story,Major,Done,"2017-12-06 20:44:43","2017-12-06 20:44:43",3
"Sonatype Nexus","Component naming for Yum Proxy does not match RPM header","Yum Proxy does not use the correct naming conventions for components. This is inconsistent and could cause problems in the future. Also, the versioning does not include the release number.    *Example*  For the package GeoIP-1.5.0-11.el7.x86_64.rpm    Component name for proxy = GeoIP-1.5.0-11.el7.x86_64  Expected component name = GeoIP  Version field for both = 1.5.0    *Acceptance Criteria*  * Yum proxy should use the name from the RPM header (i.e. GeoIP).  * Existing Yum Proxy repositories should be upgraded so those already fetched components use the new naming convention.  * Yum proxy should include the release number in the version (1.5.0-11.el7).  * Existing components in Yum Proxy repositories should be upgraded to use the new versioning.",Bug,Major,Closed,"2017-12-05 20:50:26","2017-12-05 20:50:26",3
"Sonatype Nexus","SSL certificates are added to truststore using truncated URLs instead of remote URL path parts and can cause PKIX trust error","h5. Prep    # Configure Charles Proxy at localhost:8888 and enable SSL Proxying for all hosts    # Install Nexus Repository Manager Pro 2.14.2  # Start it up, signin as admin user  # Delete all the default repos  # Configure the following loggers:  ## {{org.sonatype.sisu.goodies.ssl}} at TRACE  ## {{com.sonatype.nexus.ssl}} at TRACE  # Configure Server to use http proxy of localhost:8888 which points at Charles proxy  # Stop nexus  # add to {{bin/jsw/conf/wrapper.conf}} this line:    # Delete all logs: {{sonatype-work/nexus/logs/\*}} and {{nexus-professional-2.14.2-01/logs/\*}}    h5. Test    # Start Nexus and signin as admin  # Create a maven 2 proxy repo with remote url of https://maven.repository.redhat.com  ## disable Download Remote Indexes to prevent automatic download attempt on save  # Refresh browser list - should show PKIX error that remote is not trusted  # Go to SSL tab. Enable Nexus trust store and add cert to trust store using the features on that UI tab.  # refresh repo list. repo remains autoblocked with PKIX errors  # Note at least three additional problems:  ## The Common name for the cert added to the trust store is for access.redhat.com  ## The SubjectAlternateName entries for the remote cert are:    The only reference to access.redhat.com is {{DNSName: api.access.redhat.com}}  ## the fingerprint for the cert Nexus adds to the trust store does not match the SHA1 of either cert in the chain returned from this command:    Since the certificates are matched by alias, and the alias is the fingerprint, it makes sense there is no match and therefore the cert is not trusted.  # There is no way to clear the PKIX failures using the UI SSL Certificates feature.    h5. Diagnosis    This step:  - SSL Certificates -> Add -> Load from server -> enter https://maven.repository.redhat.com/ga/  Sends an HTTPS request to {{https://maven.repository.redhat.com/}} and not {{https://maven.repository.redhat.com/ga/}} - since https://maven.repository.redhat.com/ does a 301 redirect to https://access.redhat.com/site/maven-repository then 301 to https://access.redhat.com/maven-repository, Nexus adds the certificate from {{https://access.redhat.com/maven-repository}} which != the cert at {{https://maven.repository.redhat.com/ga/}}    This step:    - SSL Certificates -> Add -> Load from server -> enter maven.repository.redhat.com  Makes an SSL socket direct connection to maven.repository.redhat.com:443 and bypasses the configured HTTP proxy server. Since the HTTP Proxy server was bypassed, the certificate either can't be fetched ( firewall ) or the certificate stored will be the original one from the remote without the HTTP proxy server ROOT cert. So any outbound requests to https://maven.repository.redhat.com:443/ga/ will also not be trusted.    This step:     - Select redhat proxy repo -> SSL Tab -> Add to trust store  Performs same actions as SSL Certificates -> Add -> Load from server -> enter https://maven.repository.redhat.com/ga/ - which does not work for same reasons.    h5. Expected    When a cert is added for a repository, make the https request using the **full remote URL**, not a request to the remote host port without its full path part.    When the Load from server SSL certificates feature is used to load a cert, use the full https URL entered by the user, not just the host and port parts without the added path parts.    h5. Workaround    Import the HTTP proxy root cert into a copy of the JVM cacerts truststore file and reference that custom file from wrapper.conf via system properties as described at     https://help.sonatype.com/display/NXRM2M/Managing+Outbound+SSL+Certificates#ManagingOutboundSSLCertificates-TrustingSSLCertificatesUsingkeytool    h6. Possible Workaround    Import the last cert in the chain for the proxy remote url through the HTTP proxy server using these instructions:    https://support.sonatype.com/hc/en-us/articles/213464948-How-to-trust-the-SSL-certificate-issued-by-the-HTTP-proxy-server-in-Nexus  ",Bug,Major,Open,"2017-12-05 16:24:54","2017-12-05 16:24:54",1
"Sonatype Nexus","Yum search is case sensitive","While testing, I found that searching for component VirtualGL works but virtualgl and Virtualgl does not work.  We have this issue for several repos this is the ticket for yum.",Bug,Minor,Open,"2017-12-01 22:37:43","2017-12-01 22:37:43",2
"Sonatype Nexus","No Yum specific search fields defined in Documentation","I noticed that the yum specific search fields are not defined in the documentation (specifically https://help.sonatype.com/display/NXRM3/Searching+for+Components#SearchingforComponents-SearchCriteriaandComponentAttributes).  This seems an oversight.",Bug,Major,Closed,"2017-12-01 22:34:11","2017-12-01 22:34:11",1
"Sonatype Nexus","Package Name field does nothing distinct from Name field","While testing, I noticed that the Package Name field for Yum as far as I could tell did nothing different than the name field.  It is possible this is masked by another bug, like lack of wildcarding but after speaking to dev, I am skeptical of that.  Filing a ticket to resolve.    Initial thoughts seem to be to consolodate to one field, which I suspect would be Name as Package Name is only Yum specific.",Bug,Minor,Open,"2017-12-01 22:25:12","2017-12-01 22:25:12",1
"Sonatype Nexus","MissingBlobException can occur when publishing maven index","Hello    I configured   * a blobstore 'central' with   ** proxy-repo for maven-central   * a blobstore 'test-index' with   ** a hosted-repo 'test-index-hosted'   ** a group-repo 'test-index' which groups 'central' and 'test-index-hosted    The indices for 'maven-central' and 'test-index-hosted' are created and published    When i execute the task 'Publish Maven indexes of test-index', it finishes with an error and I get the following stacktrace         The attatched picture shows  that the missing file in the hosted repo is the '.index/nexus-maven-repository-index.properties' from the 'maven-central' proxy-repo which is stored inside the 'central'-blobstore.    When I browse the asset inside 'maven-central' then i can download it.    When I browse the asset inside 'test-index' then i get a http-404. All other maven artifacts are downloadable.         When I remove 'maven-central' from 'test-index' or store it inside the same blobstore then there are no issues and everything works fine          ",Bug,Major,Closed,"2017-12-01 11:51:36","2017-12-01 11:51:36",3
"Sonatype Nexus","Asset search does not treat short and long parameter names the same","Using the shortened parameter names produces the expected result:      But using the long name for extension does not:    These two searches should produce the same result, since {{maven.extension}} is mapped to {{assets.attributes.maven2.extension}}.",Bug,Major,Closed,"2017-11-29 23:38:18","2017-11-29 23:38:18",1
"Sonatype Nexus","Error response code 204 not listed in REST API codes for component and asset delete","While testing, I entered a ID into the REST API via the UI and submitted it and was returned (the expected) 204 response code. I noticed it was not listed in the status code list however.        Acceptance   * Add Swagger doc for 204 response for successful component or asset delete",Bug,Minor,Closed,"2017-11-29 23:30:36","2017-11-29 23:30:36",0.5
"Sonatype Nexus","Incorrect error response code 406 for bad ID in DELETE /component","If you take a real, but incorrect ID (such as an asset ID) and use it as a component ID in {{DELETE /component/\{id}}}, you get a 406 response.    Acceptance    * Should be considered a malformed ID and return a 422 response",Bug,Trivial,Closed,"2017-11-29 23:28:05","2017-11-29 23:28:05",0.5
"Sonatype Nexus","HA-C nodes do not rejoin their cluster after cluster shutdown","Given an HA-C cluster, when nodes that were previously members of the cluster have been shut down, the nodes will not always properly rejoin the cluster. The following errors have been encountered in the log files:    {code}  2017-11-21 07:18:04,448+0000 ERROR [FelixStartLevel] *SYSTEM com.sonatype.nexus.hazelcast.internal.orient.SharedHazelcastPlugin - [F7E2EC33-6D42028D-074D8BDF-2EED45CB-ABC97A45] No LSN found for delta sync for database 'accesslog'. Asking for full database sync...  {code}    Additionally, there may be error messages similar to the following:    {code}  Caused by: com.orientechnologies.orient.server.distributed.ODistributedException: Quorum (1) cannot be reached on server 'XXXXXXXX-XXXXXXXX-XXXXXXXX-XXXXXXXX-XXXXXXXX' database 'config' because it is major than the nodes in quorum (0)  {code}    h4. Reproduce    To reproduce, here is a brief description of what was done:    1) Start up Nexus1 in the 3-node cluster   2) Start up Nexus2 in the 3-node cluster   3) Start up Nexus3 in the 3-node cluster   4) Add some config to Nexus like new repositories, new users, etc.   5) Stop Nexus1   6) Stop Nexus2   7) Stop Nexus3   8) Try to start up Nexus1 or Nexus2 but an error will occur:    9) If you try to start Nexus3, then it starts up.    h4. Expected    There should not be a defined order to which nodes must rejoin the cluster after being shutdown.    h4. Workaround    The only workaround seems to be to abandon the two nodes that won't start, and add two new nodes to the one working node.    ",Bug,Critical,Closed,"2017-11-21 20:39:03","2017-11-21 20:39:03",3
"Sonatype Nexus","UI Notification of scheduled task completion","I have ran a couple of manually triggered tasks and after they have completed I am not able to re-run them without performing a refresh of the UI. The run button remains disabled.    The last log I see is:  ",Improvement,Minor,Open,"2017-11-17 12:03:28","2017-11-17 12:03:28",2
"Sonatype Nexus","deprecate /service/siesta part of REST API urls","*Background*    This is seemingly cosmetic issue for the REST API. I think it was discussed in the past, as we were planning development of long term public REST API for Nexus 3, but I don't see an issue to track it.    The REST APIs are being mounted under   - /service/siesta/rest/<USER>tasks   - /service/siesta/rest/v1/tasks    The /service/siesta part was not intended to be a long term mount point. To my knowledge it was only kept to make getting /service/siesta/rest/v1/script out the door quicker.    *Acceptance*   * Expose the NXRM 3 public REST api under /service/rest/v1   * This includes the existing scripting endpoint, so update the examples for the scripting API   * the previous /service/siesta/rest/v1/script endpoint has been moved to /service/rest/v1/script  - there is no shim - release notes will announce scripts depending on the old URL will need to be updated ",Story,Major,Done,"2017-11-16 02:52:18","2017-11-16 02:52:18",3
"Sonatype Nexus","Remove support for the non-gzipped specs 4.8 from Rubygems","Remove support for rubygems specs 4.8 file for performance reasons and deprecated repository format feature.    This file is an uncompressed repository-wide index and Rubygems.org no longer supports it since it has been replaced by other more efficient indexes.",Improvement,Major,Closed,"2017-11-15 15:08:03","2017-11-15 15:08:03",2
"Sonatype Nexus","Artifact with no maven group is redeployed when Disable redeploy is set on maven hosted repo","It is possible to redeploy artifacts when Deployment Policy is set to Disable redeploy. This only happens when the artifact has no maven group.    Steps to reproduce:    1) Create a maven hosted repo with the following setting:   Layout Policy : Permissive   Deployment Policy: Disable redeploy.    2) Upload a file to    [http://localhost:8081/repository/maven-hosted/TestZip/1.0.0/TestZip-1.0.0.zip]    3) Upload again to the same path. This should not be allowed.    [http://localhost:8081/repository/maven-hosted/TestZip/1.0.0/TestZip-1.0.0.zip]    If a maven group is present in the path then the redeploy is prevented         *Acceptance*    Attempts to redeploy should be prevented.",Bug,Trivial,Closed,"2017-11-13 13:36:30","2017-11-13 13:36:30",1
"Sonatype Nexus","nuget list against a www.nuget.org/api/v2/ proxy repository returns partial results","Tested with NuGet CLI 4.3.0    nuget list -Verbosity detailed jquery -Source http://localhost:8081/repository/nuget.org-proxy/     pages results 3 times    nuget list -Verbosity detailed jquery -Source https://www.nuget.org/api/v2/     pages results 40 times    Attached is a charles capture showing both commands for comparison against Nexus 3.6.0.    h4. Expected    There should be no difference in results paged through for identical queries.  ",Bug,Major,Closed,"2017-11-10 18:02:54","2017-11-10 18:02:54",3
"Sonatype Nexus","Rebuild maven repository metadata task bloats blobstore","h2. Description   # Start up Nexus with a clean blob store   # Deploy a Maven project into a hosted release repository   # Scan the blobstore with find . -name *.properties|xargs grep deleted=true, observe there are no deleted blobs   # Schedule and run a rebuild repository metadata task against the repository you deployed into   # Scan the blobstore again, observer there are now 3 deleted blobs for each maven-metadata.xml file   # Run the task again   # Scan the blobstore again, observe there are now an additional 3 deleted blobs for each maven-metadata.xml file    h2. Expected    Rebuilt maven-metadata.xml files should only be written out if they have changed from the previous version.  This means that it is expected that the first run of the task will delete all the existing maven-metadata.xml files and their checksums, since Nexus does not build the files in the same format as Maven.    The consequence of this behavior is that blob storage gets unnecessarily full of deleted files, consuming way more space than is needed, and running a compact blob store task can take a very long time to complete.    The hope is two things:   * avoid replacing the blob with an identical blob - if the hashes match, leave the original in place (and see if there's a way to purge the rejected candidate replacement)   * another thing to consider would be <USER>deleting maven-metadata files immediately instead of soft-deleting them (as long as that's not a weird special case down in generic asset code); this would stop blobstores getting bloated with soft-deleted derived content",Bug,Major,Closed,"2017-11-09 20:36:52","2017-11-09 20:36:52",3
"Sonatype Nexus"," Hosted nuget repository ignore the framework version, always returns the .NET Core Version","As per issue reported here:     [https://groups.google.com/a/glists.sonatype.com/forum/?utm_medium=email&utm_source=footer#!msg/nexus-users/f-CDUV-OqAQ/H2EdCL1pBgAJ]    the behavior when installing a package from a hosted repo is different to that from nuget.org, a nexus proxy to nuget.org, using klondike, or using nugetserver.org's implementation.    In all cases except the nexus hosted repo, the behavior is the same - the others all return the .NET Framework version and it's dependencies whereas the hosted nexus repo returns the .NETCore version and it's dependencies.    The referenced thread contains a project which will demonstrate the problem but as a minimal example of the problem, create a new empty nexus repo and put *only* System.Threading.Tasks 4.3.0 in it - you can get that from here: [https://www.nuget.org/packages/System.Threading.Tasks/]    You can see that the .Net framework version has no dependencies at all, whereas the .NET Core version has dependencies.    Now create an empty folder somewhere and in that folder, try to install System.Threading.Tasks and you will see the output as per the nuget-nexus.jpg image I attached.  The package failed to install because of the .NET Core dependencies which are not available in this repo.    Then try the same thing with a local klondike instance - or indeed with nuget.org, though of course this will have all the dependencies available so you aren't really comparing like with like (ie repositories containing only this single package).    The attached nuget-klondike.jpg image shows that using the klondike repo, the package was successfully installed.    I was using the latest nexus-3.6.0-02 from your website.    https://docs.microsoft.com/en-us/nuget/schema/target-frameworks     ",Bug,Blocker,Closed,"2017-11-08 06:28:02","2017-11-08 06:28:02",2
"Sonatype Nexus","Random version deleted if there are multiple versions with same digest","Issue: If multiple image version exist with same digest/sha value, nexus randomly picks and deletes any one version.    Usecase:    Developers build snapshots as part of CI/CD process during development phase.    Final snapshot is tagged as release version so digest stays the same.    Developer tries to delete the snapshot version using the API but nexus randomly deletes any version that has the same digest.    Command used to delete :   curl -v -X DELETE -u '<userid>:<passwd>' https://<host>:<port>/v2/<image name>/manifests/<digest>        Fix Suggestion:    Option1 :    Digest should be unique per version    Option2:    Expose delete API that accepts version in the input request so clients know which exact version will be deleted.",Bug,Major,Closed,"2017-11-07 20:31:27","2017-11-07 20:31:27",3
"Sonatype Nexus","Script to report blob and repository size and space reclaimable by Compact Blobstore task","Customers are trying to understand how NXRM is using their disk space; currently it's <USER>for them to ascribe the size of a blob store to particular repositories.    This is a simpler version of NEXUS-13056.  h4. Acceptance   * Admins can run a script to read the properties files of a blob store to summarize which repositories are using the blob store, and how much space each is consuming   * Tabulate both the total size, and the size that could be reclaimed by compacting (i.e. soft-deleted blobs)    h4. Solution    We have a script that iterates over all files in a single blobstore and reports the total size of all files per repository in that blobstore and the amount of disk that could be reclaimed by running a compact blobstore task on that blobstore.   # Visit this support page: [https://support.sonatype.com/hc/en-us/articles/115009519847]   # Follow the instructions for *Listing the Size of File-based Repositories and Blobstores*",Story,Major,Done,"2017-11-07 20:13:57","2017-11-07 20:13:57",2
"Sonatype Nexus","Regression: Nexus 3 returns 501, 400 and 204 responses for MKCOL requests","Nexus 3 returns 501, 400, and 204 responses for MKCOL requests:       {quote}127.0.0.1 - admin [01/Nov/2017:13:37:07 -0500] MKCOL /repository/ HTTP/1.1 400 0 1 Jakarta Commons-HttpClient/3.1    127.0.0.1 - admin [01/Nov/2017:13:37:07 -0500] MKCOL /repository/raw/site/ HTTP/1.1 204 0 1 Jakarta Commons-HttpClient/3.1    127.0.0.1 - admin [01/Nov/2017:13:37:07 -0500] MKCOL /repository/raw/ HTTP/1.1 400 0 1 Jakarta Commons-HttpClient/3.1    127.0.0.1 - admin [01/Nov/2017:13:37:07 -0500] MKCOL /repository/ HTTP/1.1 400 0 2 Jakarta Commons-HttpClient/3.1    127.0.0.1 - - [01/Nov/2017:13:37:07 -0500] MKCOL / HTTP/1.1 501 0 1 Jakarta Commons-HttpClient/3.1  {quote}       It should be returning 405. This is covered here for Nexus 2.x:    https://issues.sonatype.org/browse/NEXUS-6169    It is currently returning 400 for MKCOL within a repository, and 501 for MKCOL to the context root, and 204 for other directory creation requests.         This error response can break builds, and cause HTTP monitoring alarms to be raised when they should not be.    The 204 responses are causing the maven-site-plugin to make separate MKCOL requests to create each parent directory individually, rather than giving up after the first 405 is received.  This causes site deploys to Nexus Repo 3 to take much longer than they did for Nexus Repo 2, even though the time for processing the PUT requests is faster in Repo 3.    Here is a sample of requests for Nexus Repo 2:  {quote}123.123.123.123 - admin [13/Jun/2019:14:29:18 -0400] MKCOL /nexus/content/sites/site/org/foo/bar/fubar/tools/blah/project/0.0.1-SNAPSHOT/images/ HTTP/1.1 405 654 4   123.123.123.123 - admin [13/Jun/2019:14:29:18 -0400] PUT /nexus/content/sites/site/org/foo/bar/fubar/tools/blah/project/0.0.1-SNAPSHOT/./images/icon_warning.gif HTTP/1.1 201 0 7  {quote}  And Nexus Repo 3:  {quote}123.123.123.123 - admin [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/repository/site/org/foo/bar/fubar/tools/blah/project/0.0.1-SNAPSHOT/images/ HTTP/1.1 204 0 0 1   123.123.123.123 - admin [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/repository/site/org/foo/bar/fubar/tools/blah/project/0.0.1-SNAPSHOT/ HTTP/1.1 204 0 0 1   123.123.123.123 - admin [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/repository/site/org/foo/bar/fubar/tools/blah/project/ HTTP/1.1 204 0 0 1   123.123.123.123 - admin [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/repository/site/org/foo/bar/fubar/tools/blah/ HTTP/1.1 204 0 0 1   123.123.123.123 - admin [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/repository/site/org/foo/bar/fubar/tools/ HTTP/1.1 204 0 0 1   123.123.123.123 - admin [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/repository/site/org/foo/bar/fubar/ HTTP/1.1 204 0 0 2   123.123.123.123 - admin [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/repository/site/org/foo/bar/ HTTP/1.1 204 0 0 1   123.123.123.123 - admin [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/repository/site/org/foo/ HTTP/1.1 204 0 0 1   123.123.123.123 - admin [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/repository/site/org/ HTTP/1.1 204 0 0 2   123.123.123.123 - admin [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/repository/site/ HTTP/1.1 400 0 0 2   123.123.123.123 - admin [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/repository/ HTTP/1.1 400 0 0 1   123.123.123.123 - - [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/ HTTP/1.1 501 0 0 0   123.123.123.123 - - [13/Jun/2019:14:06:46 -0400] MKCOL /nxrm/ HTTP/1.1 501 0 0 1   123.123.123.123 - admin [13/Jun/2019:14:06:46 -0400] PUT /nexus/content/sites/site/org/foo/bar/fubar/tools/blah/project/0.0.1-SNAPSHOT/./images/icon_warning.gif HTTP/1.1 201 0 7  {quote}  As you can imagine, for a large site deploy all those extra MKCOL requests become very time consuming.    *Expected*: Nexus Repo 3 should return HTTP 405 (method not allowed) for all MKCOL requests, just as Nexus Repo 2 does.    ",Bug,Major,Closed,"2017-11-01 19:29:30","2017-11-01 19:29:30",2
"Sonatype Nexus","Missing repository recipe prevents startup","If a repository recipe cannot be found it prevents the startup Nexus.  This is a problem, because third party plugins often create new repository recipes, and it is very easy to forget to re-install a third party plugin during an upgrade.      Expected: An error should be logged if a repository recipe cannot be found, and the repository should either not be loaded, or should be disabled.  Nexus should still be able to start.  ",Bug,Major,Closed,"2017-10-24 16:03:05","2017-10-24 15:03:05",1
"Sonatype Nexus","UI session time out not respected","Admin user login.   Edits UI: Settings capability from default values.   Authenticated User polling interval was set to 2 minutes   Session timeout set to 3 minutes.   Save capability.   Logout.   Login as admin user and wait on welcome screen.    Stay on welcome screen.    After approx *5* minutes ( not the expected 3) , UI timed out and prompts user that session will timeout in 30 seconds and begins count down.    Allow the session to timeout. The UI sends an explicit request ( not user initiated ) to delete the session.    h4. Expected    The UI session timeout after inactivity should be respected for any new sessions while the regular polling the UI does should not be classified as 'activity'.  h4. Reference    https://groups.google.com/a/glists.sonatype.com/d/msgid/nexus-users/68d7050b-18bb-4793-b23b-f2efd8ec6306%40glists.sonatype.com?utm_medium=email&utm_source=footer     ",Bug,Major,Closed,"2017-10-19 19:43:22","2017-10-19 18:43:22",1
"Sonatype Nexus","Etag is missing in http response for an artifact download from a proxy repository nexus3","Etag is missing in the http response for an artifact download from a proxy repository, however it works with hosted repository    Nexus: 3.6.0-02    Repository type: proxy    Format: maven2    Proxy: [http://repo1.maven.org/maven2/]         The http response in nexus2x is returned with Etag ",Bug,Major,Closed,"2017-10-19 12:24:38","2017-10-19 11:24:38",0
"Sonatype Nexus","Add sha1 to asset resource on REST API","One outcome of NEXUS-14631, all agreed that sha1 (a universal attribute on all formats) should be part of the asset resource response in the API    Acceptance   * Add checksum to asset resource (AssetXO)   * Should apply to /components, /assets, and /search",Improvement,Major,Closed,"2017-10-18 20:44:27","2017-10-18 19:44:27",1
"Sonatype Nexus","consider parallelizing Maven metadata rebuild process","This is part of the effort to enhance performance in the Maven metadata rebuild    Acceptance   * Investigate the loops in {{MetadataRebuilder.rebuildMetadata}} and {{MetadataRebuilder.rebuildMetadataInner}} to see if they can benefit from parallel execution",Improvement,Major,New,"2017-10-18 18:41:54","2017-10-18 17:41:54",2
"Sonatype Nexus","allow customizing maven metadata rebuild db query buffer size and timeout values to mitigate IllegalStateException Timed out reading result from queue","Customers with large databases can have issues with the maven metadata rebuild with timeouts. Maven metadata can be rebuilt with the explicit task or as a side effect of snapshot removal tasks.    Currently this implementation uses an asynchronous Orient query where Orient is feeding results into the backing queue faster than the metadata code can process them. Ultimately once the limits of the backing queue are hit (defaults are size 128, timeout 1 minute) then an error is thrown:    One of the approaches to alleviate this issue without looking at larger re-writes is that we want to make these values configurable    *Acceptance*:   * The {{MetadataRebuilder.browseGAVs}} query needs to ultimately use {{OrientAsyncHelper.asyncIterable}} with the {{bufferSize}} and {{timeoutSeconds}} options. This will require adding a {{StorageTx.browse}} that exposes these two params.   * Configuration option for the buffer size in {{browseGAVs}} query. Default should be 1000   * Configuration option for the timeout in the {{browseGAVs}} query. Default should be 60 seconds",Improvement,Major,Closed,"2017-10-18 18:13:08","2017-10-18 17:13:08",1
"Sonatype Nexus","Yum proxy repository with relative paths in location cannot be proxied","This yum repository:    [https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64]    has relative paths in it's location tags in the primary.xml.gz file:    It is not possible to create a proxy repository of this location in Nexus 3, because the location tags are not rewritten.  The yum client attempts to make a request to the ../../pool location against nexus, and this is not valid.",Bug,Major,Closed,"2017-10-12 20:27:08","2017-10-12 19:27:08",2
"Sonatype Nexus","REST Asset Search JSON API","*Acceptance*   * This sub-resource accepts the same inputs as NEXUS-11745 (search REST endpoint), except it replies with an ordered JSON list of assets   * Until NEXUS-11744 (order by 'latest') is implemented, it's fine if the ordering is unspecified (e.g. it emerges from Elastic Search scoring)    *Non-Requirements*    (Just for clarity)   * We're trying to avoid format-specific logic   ** For maven, if people want the 'jar' (which was a default in NXRM2), then they specify that as a search parameter. maven.extension-jar   ** Primary maven artifacts, as designated in POMs, aren't considered. Users have to ask for what they want.   ** Similarly for PyPI, it's users' responsibility to know if they want an egg, a wheel, if they care, etc. and to specify the search accordingly",Story,Major,Done,"2017-10-12 20:15:01","2017-10-12 19:15:01",5
"Sonatype Nexus","Setting require user tokens for repository authentication prevents npm bearer tokens from working","If you enable  require user tokens for repository authentication under security/user tokens in the UI then publishing npm packages using npm bearer tokens no longer works.    Expected:  Npm bearer tokens should continue to work regardless of the user token required setting. Bearer tokens are just as secure as user tokens.    Also note that you cannot execute npm login using a user token, npm won't allow it due to the charachters in the username. So that doesn't provide a workaround:     ",Bug,Major,Closed,"2017-10-12 18:13:41","2017-10-12 17:13:41",3
"Sonatype Nexus","Errors reported when accessing NXRM3 via index.html","Intermittant errors have been reported when accessing NXRM3 via index.html (aka localhost:8081/index.html). See attached.   No errors have been reported when using the site without index.html.   Reportedly, this was carryover from NXRM2 (and was a result of old bookmarking).    *Steps to Reproduce*   * Edit _nexus.properties_ and set _nexus-context-path=/nexus/_   * Start nxrm and go to [http://localhost:8081/nexus/index.html]",Bug,Minor,Closed,"2017-10-11 21:20:37","2017-10-11 20:20:37",1
"Sonatype Nexus","If an npm metadata request to a proxy repository's remote times out you get a 500 response through nexus.","     If a proxy repository's request to it's remote server times out you will get a 500 response from Nexus.  The 500 response will be sent not only if you directly access the proxy repository, but also if you make the request through a group repository that contains the proxy:         This should not be the case, when a proxy repository's remote cannot be reached this should be logged, but this should not result in a 500 response from Nexus.       ",Bug,Major,Open,"2017-10-11 17:17:48","2017-10-11 16:17:48",0
"Sonatype Nexus","INFO log message is missing when a repository is deleted/created/changed","- -creating a repository-   - -deleting a repository-   - changing settings of a repository    Are system changes and all system level changes need to be logged visibly at default log levels.    For group repositories, the group members added or removed need to be logged explicitly. A concern is that logging the entire active group member list ( even the first level ) would create a very verbose log statement in some circumstances - this is why only first level additions and removals are requested. Yes - when the repo is first created, listing all the first level member ids is expected.",Bug,Major,Closed,"2017-10-10 17:33:32","2017-10-10 16:33:32",1
"Sonatype Nexus","Pypi proxying is broken between 2 NXRM instances","We have several nexuses. The two in question are set up such that:   * `A` nexus has a pypi group `pypi`, with several constituent repositories   * `B` nexus has a pypi proxy repository pypi-upstream, configured with an upstream url of `https://A.example.com/repository/pypi/`    We're seeing it fail to proxy artifacts correctly.         If we view `https://B.example.com/repository/pypi-upstream/simple/python-dateutil/` it shows no links. Invalidating the cache or rebuilding the index doesn't help.    A tcpdump on nexus A shows that it is indeed sending a request, however the request it sends has an If-Modified-Since header, which consequently returns no results.         Nexus B accepts this, fills it's cache with a blank result (which is nonsense), and proxying is thus failing.         (Querying nexus A using curl presents many links for `https://A.example.com/repository/pypi/simple/python-dateutil/`, the packages are definitely there)     ",Bug,Major,Closed,"2017-10-09 18:38:34","2017-10-09 17:38:34",3
"Sonatype Nexus","Nexus unresponsive due to healthcheck asset download count","Nexus becomes unresponsive and CPU is high.    Following threads are seen in the thread dump.      See the following errors in the log:        Workaround is to disable asset download count.    [How do I disable recording download asset counts?|https://support.sonatype.com/hc/en-us/articles/115006490287-How-do-I-disable-recording-download-asset-counts-]",Bug,Major,Closed,"2017-10-09 16:08:56","2017-10-09 15:08:56",1
"Sonatype Nexus","add anonymous search for docker repositories","As an extension to providing anonymous docker pull access we would also like to provide search capability.",Improvement,Major,Closed,"2017-10-06 19:58:15","2017-10-06 18:58:15",1
"Sonatype Nexus","ERROR failed to release FreezeRequest from DatabaseBackupTask","Database backup task may indicate successful completion, but also report fail to release FreezeRequest.        The message implies the database may be left frozen.    h4. Expected    The ERROR message consequences need to be better understood and prevented if possible.  If there is a marker file stored someplace and its presence changes behavior, then we need to capture that fact in a support zip in some place other than a log file ( ie. sysinfo.json? ) - -I suggest sysinfo.json because we cannot infinitely grow the support zip with included files- sounds like the actual contents of frozen.marker may be relevant, therefore will be relevant to include the actual file if present, in the support zip.",Bug,Major,Closed,"2017-10-06 19:04:09","2017-10-06 18:04:09",1
"Sonatype Nexus","directory to restore backups from should not be named backup","The Database backup scheduled task asks for a directory to store database backups within.    Naturally some users would want to store this some place under their existing karaf.data directory in a directory named 'backup.    Unfortunately Nexus allows this, which means next time they try to start nexus, an automatic restore will be attempted.    Worse, if there are more than two backups there, Nexus will not even start.  h4. Expected   * explicitly do not allow the task which performs backup to accept a target location which is the same location from which a restore will automatically take place   * change the default restore location from $\{karaf.data}/backup to something much more obvious, like $\{karaf.data}/restore-from-backup    * do not worry about backwards restore compatibility to the old restore location - it was just a bad idea",Bug,Critical,Closed,"2017-10-06 18:25:02","2017-10-06 17:25:02",2
"Sonatype Nexus","Cannot perform docker pull against some Docker-Hub proxy","Hi,   I have Nexus OSS 3.6.0-02 installed running on the context path [http://10.105.139.17:8082/nexus]   I have:   - created a docker proxy repository to docker hub listening on 10.105.139.17:18001   - configured the docker client to allow insecure calls to the docker repository 10.105.139.17:18001    I can perform a search for jenkins docker images and get a resultset via:           but cannot perform a docker login or docker pull           My docker client details are:       Could you please confirm if this is a bug related to running Nexus OSS 3.6 on a context path /nexus or if this is a mis-configuration error.    Many Thanks        <USER>",Bug,Major,Closed,"2017-10-06 12:50:54","2017-10-06 11:50:54",1
"Sonatype Nexus","Add support for proxying yum repositories that have sha1 checksums","If you proxy a yum repository in Nexus 3 whose remote has sha style checksums it will fail.         An example of this style can be seen here:    [http://yum.spacewalkproject.org/2.5-client/RHEL/7/x86_64/repodata/]         As noted in the createrepo documentation:         We should consider adding support for this style of checksum, since an and user is often not in control of the checksum format that is used on the remote of a proxy repository.",Story,Major,Done,"2017-10-05 22:13:27","2017-10-05 21:13:27",0.5
"Sonatype Nexus","Bower proxy repository does not follow 301/302/308 HTTP redirect","We noticed that proxying bower at http://bower.herokuapp.com was no longer working and it was determined that this was because they had moved their source to https://registry.bower.io and were now redirecting with a 308.    It was noted we should generally follow these redirects (301/302/308) to avoid outages.    h4. Workaround     Change the remote url of the proxy repository to the new location.",Bug,Minor,Open,"2017-10-05 20:16:06","2017-10-05 19:16:06",2
"Sonatype Nexus","Anonymous docker pull generates incorrect error message when image is not found","Hello awesome Sonatypers!    Just installed Nexus 3.6.0-02 for long-waited anonymous Docker pulls (finally!) - it's very awesome, thanks a lot for this improvement - we can now finally get rid of our latest Registry!    I just noticed one thing: if the pull is anonymous AND the image requested does not exist, Nexus reports Authentication Required error instead of Image not found as you can see below:         Pulling image that exists in the registry works as expected:         Correct error message image not found displayed after authenticating with docker login:  ",Bug,Minor,Open,"2017-10-03 06:48:11","2017-10-03 05:48:11",2
"Sonatype Nexus","PyPI hosted repository does not send etag header","Seems like the response from Nexus when downloading a hosted PyPI artifact doesn't include an etag or expires header.  This prevents pip from caching the artifact.  I see Maven handles this better by synthesizing an etag on upload if none is set:  [MavenFacetUtils.jav|https://github.com/sonatype/nexus-public/blob/1c8eff7e75a95cd96f4152e3f649245f21a76c66/plugins/nexus-repository-maven/src/main/java/org/sonatype/nexus/repository/maven/internal/MavenFacetUtils.java#L149]a    You can see [here|https://github.com/pypa/pip/blob/a9d56c7734fd465d01437d61f632749a293e7805/src/pip/_vendor/cachecontrol/controller.py#L273-L279] for how pip handles the caching, and why an etag or expires header is desirable.     The response looks like:     HTTP/1.1 200 OK    Date: Mon, 02 Oct 2017 16:49:10 GMT    Server: Nexus/3.5.0-02 (OSS)    X-Frame-Options: SAMEORIGIN    X-Content-Type-Options: nosniff    Last-Modified: Mon, 25 Sep 2017 22:13:17 GMT    Content-Type: application/zip    Content-Length: 51711",Bug,Major,Closed,"2017-10-03 00:40:38","2017-10-02 23:40:38",1
"Sonatype Nexus","NPM: Search results on lower case only","Searches using the Search UI and /v1/search and /v1/search/assets REST APIs always performs searches _against_ the lowercased version of the npm metadata values. For example, package scope, and license names (MIT, ISC). The UI and the originally uploaded/downloaded package metadata may contain uppercased letters.    UI may show a  package scope/group value of SONATYPE.    A search like this will NOT find that package:    http://localhost:8081/service/rest/v1/search/assets?repository=npm-hosted&name=simple-npm-package&version=1.0.1&npm.scope=SONATYPE    However a search like this will find it:    http://localhost:8081/service/rest/v1/search/assets?repository=npm-hosted&name=simple-npm-package&version=1.0.1&npm.scope=sonatype    h4. Notes    NPM maintainers recommend that new package names ( and likewise scopes ) should preferably be lowercased to begin with, before they are published.    See notes here:     https://docs.npmjs.com/files/package.json  https://docs.npmjs.com/misc/scope    {quote}  Some rules:  * New packages must not have uppercase letters in the name.  {quote}    h4. Expected    Searches against terms with case differences should be intuitive. Performing searches using exact case matches should find the exact case matched terms in the UI and REST API and any other search.    ",Bug,Major,New,"2017-10-02 21:52:43","2017-10-02 20:52:43",1
"Sonatype Nexus","npm logout throws a 403 error","the npm login command works with no permissions, but to do a logout you get a 403 error.  Once the -delete permission is added to the user/role you are allowed to.     Nexus 3.5.2        ",Bug,Major,Closed,"2017-09-29 20:50:00","2017-09-29 19:50:00",3
"Sonatype Nexus","Analyze Application does not use the nexus truststore ","If you are behind a corporate http proxy server that uses a private SSL certificate it is not possible to use the Analyze Application feature in Nexus 3.x.  The reason for this is that feature does not use the Nexus truststore.",Bug,Major,Open,"2017-09-27 23:33:17","2017-09-27 22:33:17",3
"Sonatype Nexus","Race condition can cause component upload to fail.","If a large file is uploaded while a snapshot removal task is running it can fail with a file not found error.  This is a rare race condition, but it can happen.    This is because the directories needed in the target repository are made here:    https://github.com/sonatype/nexus-public/blob/release-2.14.5-02/components/nexus-core/src/main/java/org/sonatype/nexus/proxy/storage/local/fs/DefaultFSPeer.java#L159    Only after this is the file actually stored, and then after it is stored Nexus attempts to rename it to it's final destination:    https://github.com/sonatype/nexus-public/blob/release-2.14.5-02/components/nexus-core/src/main/java/org/sonatype/nexus/proxy/storage/local/fs/DefaultFSPeer.java#L190    But at that point a snapshot removal task may have deleted it's destination directory.    This was actually observed in a user's log files. They had an upload that finished at 26/Sep/2017:07:39:42 -0700, and ran for 790 seconds.    A snapshot removal task finished at 07:35:32:        And then a few minutes later the upload failed because the destination directory didn't exist anymore.      ",Bug,Major,Closed,"2017-09-26 22:08:00","2017-09-26 21:08:00",3
"Sonatype Nexus","/service/siesta/rest/beta/search IllegalStateException current database instance is not active on the current thread while under stress","Under stress ( 700-900 requests per second of various types ) the /service/siesta/rest/<USER>search resource may trigger the following message in the nexus.log:        **Note**: When this exception happens, the request.log will not show any 4xx or 5xx status codes for this request, only 200 - this seems wrong as it sounds like a pretty severe error and may suggest the REST resource needs better error handling. Unclear what the response payload did contain ( and error payload with message and status code 200???? )",Bug,Major,Closed,"2017-09-26 19:58:02","2017-09-26 18:58:02",3
"Sonatype Nexus","Access log output not sorted as expected","Came up with static analysis of the codebase that the Comparable impl here was never implemented correctly.",Bug,Trivial,Closed,"2017-09-21 20:42:35","2017-09-21 19:42:35",0.5
"Sonatype Nexus","Privileges warn they're read only twice","On our default uneditable privilieges I noticed that the message that they cannot be edited appears twice.    See attached (by the discard button).    I suspect this is regression but haven't back checked at this time.",Bug,Trivial,Closed,"2017-09-20 22:39:58","2017-09-20 21:39:58",1
"Sonatype Nexus","REST Search & Download by 'Latest'","*Acceptance*   * Extend the search & download service so that users can sort the search results by 'latest version' (see below)   ** In the case of more than one, return the first-ordered result (since the 'best' result is unambiguous).   * There multiple standard latest orderings   ** format-specific ordering   *** maven2 ordering of component.version (as implemented by [Apache Maven Artifact Resolver|https://maven.apache.org/resolver/] ( formerly [Eclipse Aether|https://projects.eclipse.org/projects/technology.aether] which is being [migrated to maven-resolver|http://maven.apache.org/aether.html] )   *** semver ordering of component.version     ",Story,Major,Done,"2017-09-20 15:51:02","2017-09-20 14:51:02",8
"Sonatype Nexus","Content selector with ' in path errors","One of the comments on https://docs.sonatype.com/display/Nexus/Content+Selector+Testing is  String literals containing  or ' will be rejected.  I attempted _path =^ /jtt/jtza'pp/_ and got back the below error both in the UI and in the nexus.log:    Full here: https://gist.github.com/joedragons/6c052e86c4c19a45a4c569b41b845a15    So it is rejected but filing in case we want to handle the error (I suspect we normally do, tho this may be an exception).    I checked 3.5.2 and this is not new to CSEL and not regression.",Bug,Minor,Closed,"2017-09-19 21:22:21","2017-09-19 20:22:21",0.5
"Sonatype Nexus","Content Selector Name sort does nothing","I added 2 items to a raw hosted repo, ticketlist.txt and warn.txt.  On preview, sorting them by name ascending and descending didn't seem to do anything.  I tested this on CSEL but this does not seem to be regression.",Bug,Medium,Open,"2017-09-18 22:50:36","2017-09-18 21:50:36",3
"Sonatype Nexus","Repository creation fails often with Javascript errors in Edge Browser","*To reproduce*   # On a Windows 10 machine (can be a vm) start up NXRM, preferably the latest 3.* version   # Login with Admin credentials   # Navigate to Repositories   # Click create Repository   # Select for example yum-proxy    *Expected*   * Create Yum Proxy repository page    *Actual*   * Empty page stuck at Repositories / Select Recipe, showing a red danger popup saying :      *Side affect*   * After above error, click on the left hand side Repository -> Repositories link will show the same error with strange screen layout (see attached screen capture)    Note appears to be similar as NEXUS-14048",Bug,Major,Closed,"2017-09-18 22:39:49","2017-09-18 21:39:49",3
"Sonatype Nexus","Possible regression, publishing npm package fails on 3.5.2, same package works on 3.1.0","Paypal is getting an error when publishing the attached npm package into Nexus 3.5.2.The same package can be published into Nexus 3.1.0 without any problem.           This is caused by the scope: null line here:        The _args is added by the npm installer when it locally installs a package in a node_modules directory:    https://github.com/npm/npm/issues/10393    And it seems like it was only put in when using npm versions prior to 5, although I'm not completely certain about that.    I'm not sure about whether publishing the package.json produced by a local install is a good idea or not, but we should at least be able to handle these uploads, especially because we used to do that in version 3.1.0. (We may want to be ignoring these fields being put in by the npm install altogether, but this particular issue is related to a parsing regression.)",Bug,Major,Closed,"2017-09-18 19:49:43","2017-09-18 18:49:43",1
"Sonatype Nexus","No INFO log message when repositories are created and deleted","When a user creates or deletes a repository in Nexus 3 nothing is logged at all to record these actions in the nexus.log file.    This is very important information, without it we will get reports of repositories disappearing, and no way to investigate them.  There should be an INFO level log message for both of these events.",Bug,Major,Closed,"2017-09-18 17:18:58","2017-09-18 16:18:58",0.5
"Sonatype Nexus","Schedule task compact blob store failed with BlobId: null","Hi,    since we upgraded in 3.5.2 the scheduled task compact blob store failed.    2017-09-18 07:19:21,342+0000 WARN [quartz-1-thread-19] *SYSTEM org.sonatype.nexus.quartz.internal.task.QuartzTaskJob - Task 8d20bb2e-f599-4977-97f0-3970fc912118 : 'maven' [blobstore.compact] execution failure   org.sonatype.nexus.blobstore.api.BlobStoreException: BlobId: null, java.lang.NullPointerException   at org.sonatype.nexus.blobstore.file.FileBlobStore.compact(FileBlobStore.java:575)   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39)   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:270)   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53)   at org.sonatype.nexus.blobstore.compact.internal.CompactBlobStoreTask.execute(CompactBlobStoreTask.java:79)   at org.sonatype.nexus.scheduling.TaskSupport.call(TaskSupport.java:92)   at org.sonatype.nexus.quartz.internal.task.QuartzTaskJob.doExecute(QuartzTaskJob.java:145)   at org.sonatype.nexus.quartz.internal.task.QuartzTaskJob.execute(QuartzTaskJob.java:108)   at org.quartz.core.JobRunShell.run(JobRunShell.java:202)   at org.sonatype.nexus.thread.internal.MDCAwareRunnable.run(MDCAwareRunnable.java:40)   at org.apache.shiro.subject.support.SubjectRunnable.doRun(SubjectRunnable.java:120)   at org.apache.shiro.subject.support.SubjectRunnable.run(SubjectRunnable.java:108)   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   at java.util.concurrent.FutureTask.run(FutureTask.java:266)   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   at java.lang.Thread.run(Thread.java:745)   Caused by: java.lang.NullPointerException: null   at org.sonatype.nexus.blobstore.file.FileBlobStore.maybeCompactBlob(FileBlobStore.java:583)   at org.sonatype.nexus.blobstore.file.FileBlobStore.compact(FileBlobStore.java:563)   ... 16 common frames omitted         Thx",Bug,Major,Closed,"2017-09-18 09:01:29","2017-09-18 08:01:29",1
"Sonatype Nexus","S3 Blobstore - provide a blobstore 'prefix' option","As a nexus administrator    I want to have multiple blobstores in one S3 bucket    so that I can use 1 S3 buckets for all my blobstores    *Assumptions*    At time of writing, the S3 Blobstore assumes that the bucket is exclusive to the blobstore (the content is stored at the root of the bucket).    If we provide administrators the ability to supply a prefix for all content in the S3 blobstore, this will allow them to have multiple blobstores sitting in one S3 bucket.    *Acceptance Criteria*    * The UI presents an option, empty by default, for a content prefix to use. When set, all content for the blobstore is stored under the prefix.    * Using the prefix allows multiple separate blobstores to co-exist in the same S3 bucket.",Story,Major,Done,"2017-09-13 15:12:53","2017-09-13 14:12:53",2
"Sonatype Nexus","Yum proxy of mirrors.centos.org fails with encoding error ","Reproduce steps...    # Create a yum proxy repository in Nexus with remote set to http://mirror.centos.org/centos/7/os/x86_64  # Configure yum in CentOS 7.3 to use it    This fails with an error complaining that the encoding has not been set in the primary.xml file.    Sure enough, if you check the file from RedHat it has:        Our generated XML is missing the encoding:        Full error log is below:    ",Bug,Major,Closed,"2017-09-12 20:57:10","2017-09-12 19:57:10",0.5
"Sonatype Nexus","Possible to create a repository with an empty name via API","It is possible to create a repository via the API which has an empty name.  Once created, this cannot be deleted via the UI. The UI won't let you save because it fails form validation.  The only way to delete it is by executing a direct OrientDB query.    Expected: The API should block creation of an repository with an empty name, just as the UI currently does.",Bug,Major,Open,"2017-09-11 21:34:01","2017-09-11 20:34:01",1
"Sonatype Nexus","Thread count increases linearly with scheduled task execution","Starting with 3.5.0, a new thread appears to be created each time a scheduled task executes, but is left in the WAITING state at the conclusion of the task. The overall thread count for the Nexus process increases indefinitely until the max user processes limit is reached (ulimit -u). Once this occurs, Nexus becomes mostly unresponsive.    The behavior was first observed in a regular installation of 3.5.0 on RHEL 6, where the default ulimit -u was set to 1024. Increasing the max user processes limit extends the time before restarting the Nexus process is required.    The issue of threads linearly increasing was reproduced using the sonatype/nexus3 Docker image on a macOS host using the following steps:   # Create and run Nexus in new Docker container with defaults:  {code:none}  docker run -d -p 8081:8081 --name nexus sonatype/nexus3:3.5.1  {code}     # Login as admin, navigate to Metrics, download Thread dump (result attached: 01-threads-start.txt)   # Create scheduled task, select Advanced for Task frequency, and provide * * * * * ? for cron expression to run every second.   # Wait 30 minutes (approx. 1800 tasks run, 1800+ threads).   # Navigate to Metrics, download Thread dump (result attached: 02-threads-1800-tasks-run.txt)    Thread count never exceeds 120 when following the same steps on released versions 3.3.0 - 3.4.1. ",Bug,Critical,Closed,"2017-09-06 20:01:58","2017-09-06 19:01:58",2
"Sonatype Nexus","Certain OData requests can cause pathological regex behavior in Nuget implementation","Certain Nuget OData requests do not play well with the regex-based query rewriting introduced in 3.5.0 causing poor performance.     This can be confirmed by trying the following request:    I have also been able to confirm that this issue does not occur if the regexes are not in play.",Bug,Blocker,Closed,"2017-09-05 06:45:34","2017-09-05 05:45:34",2
"Sonatype Nexus","outbound proxy repository requests for identical files which take more than 10 minutes duplicate work and disk space","Configure a Proxy repository which points to a remote server hosting a large file that will take over 10 minutes to download.    Send 2 or more identical requests into the proxy repository for that large file.    One request will begin downloading the remote file. The other requests will be put into a queue waiting for it to complete.    The first request starts writing the remote file into the blobstore as a temporary file. It may look like this:        After 10 minutes, the initial request is not done. The second thread that was in the queue will get tired of waiting and begin downloading the same file. Now two threads are actively downloading the same file from the remote and writing the content to the blobstore to a temporary file.        This pattern continues for as long as there are identical inbound requests for the same file in a queue - every 10 minutes, a new outbound request for the same file begins. The disk holding the repository blobstore location becomes more full.    In the case of    - the remote file is large ( less common multi-GB )   - the network is comparatively slow and/or bandwidth starved ( common )  - requests for identical files at the same time come into Nexus concurrently ( common ie. chef )  - the blobstore does not have considerable free space larger than (concurrent requests \* file size)     there becomes a high probability that the blobstore may fill with these temporary files, overflowing the disk. Running out of disk is a critical event.    h4. Expected    - the common cases described should be better mitigated against to prevent high disk usage and otherwise useless outbound requests and negative side effects of this behaviour    h4. Workaround    A Nexus administrator needs to guestimate the longest time the largest file should take to be downloaded from a proxy repository remote. Knowing this value, they can change the default 10 minute wait period to this new value.    For example, if the longest remote request can take up to 8 hrs, then:    Edit {{sonatype-work/nexus3/etc/nexus.properties}}    Add a new line like this to the file:        or        or          ",Bug,Major,Closed,"2017-08-31 22:46:48","2017-08-31 21:46:48",1
"Sonatype Nexus","Nexus 3 docker image should allow tweaking the -XX:MaxDirectMemorySize","Our [installation requirements|https://help.sonatype.com/display/NXRM3/System+Requirements#SystemRequirements-GeneralMemoryGuidelines] indicate that -XX:MaxDirectMemorySize should be increased on systems that have sufficient RAM to support doing so.  But our Nexus 3 docker image currently provides no way to change this value.    We should change our Docker image to allow customization of that falue.",Improvement,Major,Closed,"2017-08-31 19:19:38","2017-08-31 18:19:38",1
"Sonatype Nexus","Component Database got corrupted after OOM exception.","After an OutOfMemoryError, the component database was corrupted. A {{repair database --fix-links and rebuild index *}} was required to fix the database.      There have been many timeout errors throughout the day:  ",Bug,Major,Closed,"2017-08-29 17:28:16","2017-08-29 16:28:16",5
"Sonatype Nexus","potential OutOfMemory or poor performance retrieving specs.4.8.gz from a rubygems repository","Make a RubyGems group. ( gem-group )  Put a RubyGems proxy to https://rubygems.org in the group as the only member.    Make a HEAD request for http://localhost:8081/repository/gem-group/specs.4.8.gz - HEAD with return no content as expected, status 200.  Make a GET request for http://localhost:8081/repository/gem-group/specs.4.8.gz - GET will return content and status 200.    A local test on Nexus with no load showed consistent 6-7 second response times infinitely for both types of requests with a single user making the request.    The time required for Nexus to begin a HTTP response is identical for both HTTP methods and much slower than sending the same request to rubygems.org.    Repeating the requests over and over even though no content has changed, does not improve the response time.    A thread dump while a HEAD request is active shows the following work being performed:        As load increases ( increase concurrent threads requesting these files ), the time to respond increases exponentially.    Further it is very easy to trigger OutOfMemory when multiple threads request this file at the same time using either method type.      ",Bug,Critical,Closed,"2017-08-25 20:39:25","2017-08-25 19:39:25",5
"Sonatype Nexus","Migrated proxy does not migrate analyzed","I migrated over my Central proxy and noticed that while the contents migrated and the Health Check task migrated, the health check column in the repository list still had the analyze button (the NXRM2 one had report results).  I tried running the task and still nothing.  I may be missing some subtlty (or maybe itetentional) but it seems like this aspect is not migrated to me.  Workaround is click the analyze button and enable as usual (NOTE: Doing this results in Insufficient Trend Data but still it's enabled).  I left major as I have no clue if the trend data is gathering while not analyzing.  If it is, then this seems minor.",Bug,Major,Closed,"2017-08-21 19:06:33","2017-08-21 18:06:33",3
"Sonatype Nexus","ERROR OConcurrentModificationException Cannot UPDATE the record because the version is not the latest during upgrade of npm repositories ","During upgrade from Nexus 2.x to Nexus 3.x, Nexus 3 logs may report the following type of ERROR:        This looks like a problem where multiple ProcessChangesStep threads in Nexus 3 could be attempting to update the same npm package metadata for different tarballs. The concern is that some npm package metadata tarballs _may_ be lost on upgrade to Nexus 3 when encountering this type of ERROR.    In the case of a proxy repository, does not appear to be serious. In the case of this happening with a hosted repository, this is considerably more serious.      h4. Workaround    In Nexus 3, edit ./bin/nexus.vmoptions  Add this new line at the end of that file and save:        This attempts to reduce the migration concurrency to avoid the problem of different threads trying to update the same record.    Restart the Nexus 3 migration using a completely empty karaf.data directory",Bug,Major,Closed,"2017-08-18 19:39:18","2017-08-18 18:39:18",5
"Sonatype Nexus","configurable repodata depth for yum proxy repos","*Background*    The yum client commands and yum configuration files [support dynamic variables|https://www.centos.org/docs/5/html/5.2/Deployment_Guide/s1-yum-useful-variables.html]:    $releasever   This is replaced with the package's version, as listed in distroverpkg. This defaults to the version of the redhat-release package.    $arch   This is replaced with your system's architecture, as listed by os.uname() in Python.    $basearch   This is replaced with your base architecture. For example, if $arch=i686 then $basearch=i386.    The yum client can use these variables to dynamically construct the final URL of the repository from which to download yum metadata - for example in yum.conf:    The advantage from a client perspective is a more flexible configuration.    Using Nexus 2.x Yum support or Nexus 3.5.0 Yum Proxy support, a Nexus administrator needs to create a single Yum repository for every combination of dynamic variable. This is because Nexus will only expect repodata at the root of the remote URL value of a proxy repo or at the base of a hosted repo.    This is not ideal since repositories are heavyweight and the management of these many repositories is not scalable if a repository is made for every unique variable combination.    Instead it should be possible to create a single Nexus repository that supports any unique combination of URL form used by the client *at a specific depth*. The base URL from the Nexus administrator perspective would be simply [http://nexus:8081/repository/yum-proxy/] and the administrator would configure a depth at which they expect the metadata about what is in the repository will be stored/calculated.    Example:   Client configures baseurl=[http://nexus:8081/repository/yum-proxy/$releasever/os/$basearch/]   Nexus has single yum proxy repo at [http://nexus:8081/repository/yum-proxy/] with a repodata metadata depth of '3' ( 3 path parts ). So metadata will be accessible under [http://nexus:8081/repository/yum-proxy/$releasever/os/$basearch/repodata/*]    Example:   Client configures baseurl=[http://nexus:8081/repository/yum-proxy/$basearch/$releasever]   Nexus has single yum proxy repo at [http://nexus:8081/repository/yum-proxy/] with a repodata metadata depth of '2'. ( 2 path parts ). So metadata will be accessible under [http://nexus:8081/repository/yum-proxy/$basearch/$releasever/repodata/*]    Note: this scheme does not mean repodata within a single Nexus repository can be at multiple depths - you would still need to create more than one repository per depth    *Acceptance*   * Support repos at a configurable depth inside a single aggregating repo   ** When we generate metadata, it's at the correct depth   ** Ensure we're only invalidating the appropriate metadata when content changes ",Story,Critical,Done,"2017-08-18 14:26:56","2017-08-18 13:26:56",5
"Sonatype Nexus","Component/Asset browsing UI gets JavaScript errors in Edge browser","Reproduce steps:   # Load the Nexus 3.5 UI in the Edge browser on Windows 10   # Click on the asset browser   # Click on the component browser    You'll get a JavaScript error (see screenshot).    I reproduced this using an Edge browser which had a completely clear cache.",Bug,Major,Closed,"2017-08-16 18:51:20","2017-08-16 17:51:20",2
"Sonatype Nexus","NPE in RubygemsContentFacetImpl while handling asset download count","While doing upgrade testing in NEXUS-13735 I saw this NPE while running a Ruby {{bundle install}} command.    Saw in 3.4, but also reproduced in 3.5. I was just following the instructions at [https://docs.sonatype.com/display/Nexus/RubyGems+Testing+-+NX3.] The final test is to download a custom asset from a hosted repository.",Bug,Major,Closed,"2017-08-01 18:50:52","2017-08-01 17:50:52",0.5
"Sonatype Nexus","Group repositories created through the Provisioning API do not preserve member order","Two problems introduced by the fix for NEXUS-13064:  - Jackson serializes LinkedHashSet to a HashSet when transmitting to the client, losing the ordering  - Orientdb serializes LinkedHashSet to OTrackedSet when converting the mapped attributes on a Repository configuration, so even though the member order is initially correct with the in-memory representation, restarting the server will reload from the db and therefore lose the order    NOTE:  - for the small number of Repositories that are likely affected by this, the manual remediation after this fix is to load the Group repo in the UI, reorder the members as desired and save; from this point forward the order should be consistent  ",Bug,Major,Closed,"2017-08-15 23:47:19","2017-08-15 22:47:19",1
"Sonatype Nexus","NuGet filter=(tolower(Id)) queries don't use a database index in Nexus 2.x, causing severe performance issues in large instances","Nexus 2.14.4 has experienced some severe performance problems with certain NuGet builds. Queries issued sporadically slow down, and they frequently get complete failures due to the h2 connection pool being exhausted.    They have builds that are making large numbers of queries like this:    Investigation has shown the cause was queries with a e.g. ((LOWER(ID) = 'nunit') in them. It turns out these will not use the index, and will result in a full table scan being done.     *Acceptance*   * Queries with a LOWER will use the index",Bug,Blocker,Closed,"2017-08-15 20:13:43","2017-08-15 19:13:43",2
"Sonatype Nexus","Support Nuget NormalizedVersion queries","Newer versions of NuGet make queries with a NormalizedVersion field.    [https://github.com/NuGet/NuGetGallery/issues/2944]    Example:         When Nexus 2.x receives one of these queries it results in an error:         The query is then re-issued by NuGet.exe with just version, so this isn't visible to the end user.  But it creates a *ton* of log noise, and no doubt slows builds down.",Bug,Major,Closed,"2017-08-15 16:02:35","2017-08-15 15:02:35",2
"Sonatype Nexus","Remove snapshots from Maven repository remove if released option may progress slowly","The maven snapshot removal task is doing more work than expected. Expected that it would look at the snapshots in the snapshot repo and then check whether those exist in release repos. Instead it seems to be looking in other repos and checking whether those components exist in the snapshot repo.    Steps to reproduce:    Create a new maven snapshot repo and add one 0.0.1-SNAPSHOT version of a component.    Configure the snapshot removal task with minimum snapshot count 1 and remove if released enabled with a grace period 1 day.    Run the task with debug logging enabled.    Expected:    The snapshot would not be removed since it was just added, and there would be very little activity recorded in the log since there is just one snapshot in the repo and nothing to clean up.    Actual:    A whole bunch of debug log messages were recorded looking for components that do not exist in the snapshot repository. From the logs it looks like the task is iterating over other repositories, such as the central proxy, and checking whether those components exist in the snapshot repo.    Example log entry:    Searching for nexus-buildsupport only exists in Central proxy repo.     ",Bug,Critical,Closed,"2017-08-09 20:36:29","2017-08-09 19:36:29",5
"Sonatype Nexus","/swagger-ui prompts to save a useless file instead of redirecting to something useful","Load this in a browser:    http://localhost:8081/swagger-ui    You are prompted to save a file. Saving this file on a local machine takes about 15 seconds. When it is done, all this file contains is this text:        h4. Expected    redirect to proper swagger-ui url of http://localhost:8081/swagger-ui/#/ and load that instead.    Users are not going to anticipate /swagger-ui/#/ and are going to frequently type /swagger-ui and expect something more useful to happen. When it doesn't, they will file support questions.",Bug,Minor,Closed,"2017-08-09 13:46:18","2017-08-09 12:46:18",1
"Sonatype Nexus","Expand Snapshot Remover task log messages with context","Per --NEXUS-13580-- - Tasks that can support additional task log progress information need to be updated to provide  {quote} # At the start and end of each major area of work performed by the task, add a contextual INFO log message to the nexus.log and task specific log indicating what work is being/been performed   # At regular intervals during work, log progress with contextual data about the actual progress of that specific work{quote}  AC for the Snapshot Remover task:   # Major areas of work: Effectively each major method in {{RemoveSnapshotsFacetImpl}} can have a log.info. A number already do (e.g. {{processSnapshots}}), but some do not (e.g. {{processRepository}} and {{findReleasedSnapshots}}). There are many possible places of 'major work' in this task (compared to all others) so this may require some iteration with feedback from support.   # Contextual data: depends on the major stage we are in, but there are a number of iterators in the task that can be leveraged.    _Note: the exact items logged may get clearer as the work is done. Above AC is from a quick analysis of the code_    Original description (above description added to be inline with [the other task log context updates|https://issues.sonatype.org/issues/?jql=issue%20in%20linkedIssues(NEXUS-13580)%20AND%20summary%20~%20%22with%20context%22%20ORDER%20BY%20key%20ASC]:  ----  In contrast to NEXUS-13939 which deals with <USER>messages only across all tasks, this is a more specific issue about snapshot removal task.  h4. Expected   - At the start and end of each major area of work performed by the task, add a contextual INFO log message to the nexus.log and task specific log indicating what work is being/been performed   - at regular intervals during work, log progress with contextual data about the actual progress of that specific work   - looking at a thread dump should not be the only way to tell what the task is doing at any given moment.    Attached Example task log output which is not adequate.    When the log was captured, a thread dump shows the task is busy trying to find released snapshots, but there is no indication in the log that this is what it is actually doing or what progress it has made so that one can have a better sense of when it might complete or move on to the next piece of work.  ",Bug,Major,Closed,"2017-08-09 13:22:03","2017-08-09 12:22:03",2
"Sonatype Nexus","When certificate has no name, there is no breadcrumb","I noticed when I upload a certificate with no common name, the breadcrumb in the UI does not work.  You can get back to the SSL Certificates list via the left nav but IMO this is a workaround.  I did not check older NX3 (or NX2) at this time but doubt this is regression.",Bug,Trivial,Open,"2017-08-08 21:35:11","2017-08-08 20:35:11",2
"Sonatype Nexus","default task log progress ---- Mark ---- messages are missing helpful context and therefore should be removed","Starting in 3.5.0, the task specific logs ( not nexus.log ) may print messages such as this ( specific concern is about these ---- <USER>---- messages ):        These <USER>messages are not helpful because:    - they lack context  - they fill the logs without telling us what the task is doing  - the thread id is different from the task thread doing the actual work  - a thread dump can tell use where in the code the task thread is doing work specificly  - a leading informative log message ahead of beginning any major work is a better way to summarize what work a task is about to begin  - an end user can view task state ( ie. Running,waiting, etc) for end user visible tasks in the tasks UI    Some tasks take days to run, and could leave 1440 of these in the log per day for no discernable value.    h4. Expected    For now the simplest thing is to remove the default progress logging which prints ---- <USER>---- as a log message. In other words, there should be no periodic progress logging unless explicitly coded into a task and that log message includes task specific progress data. Any work to add more explicit progress logging should be done via another ticket.",Bug,Major,Closed,"2017-08-08 20:31:06","2017-08-08 19:31:06",1
"Sonatype Nexus","help link printed in log file for open file descriptor limit minimums does not match the link used in the UI","The link in the log file is different than the UI warning link at the top of the UI:    http://links.sonatype.com/products/nexus/system-reqs#filehandles    h4. Expected    Make the link in the log use the links.sonatype.com link instead of the support.sonatype.com link     ",Bug,Minor,Closed,"2017-08-07 22:08:35","2017-08-07 21:08:35",1
"Sonatype Nexus","yum proxy xml re-encoded and truncated",".xml and .xml.gz files proxied and cached by the nexus Yum Proxy are being re-encoded. Additionally .xml.gz files are being truncated.              whereas downloading from the remote repository source directly:         Using sha256sum on the two downloaded urls give me different checksums as well. Interestingly, the sha256sum of the file I download from the nexus3.5.0 container matches the asset checksum sha245 attribute of the file (via the browser). This leads me to believe that as the yum proxy attempts to fetch the file, it is saving it with an incorrect length.         You can see more evidence of the munging if you expand and diff the two xml files:         to reproduce, setup a yum proxy repository with a name of frYum6 and a source of [http://centos.mirror.iweb.ca/6.9/os/x86_64/]         Then compare the checksum of the downloaded file:    $ curl -o nexus.primary.xml.gz [http://your.nexus3.test.server/repository/frYum6/repodata/ed2b2d4ac98d774d4cd3e91467e1532f7e8b0275cfc91a0d214b532dcaf1e979-primary.xml.gz]         with the source:    $ curl -o mirror.primary.xml.gz  http://centos.mirror.iweb.ca/6/os/x86_64/repodata/ed2b2d4ac98d774d4cd3e91467e1532f7e8b0275cfc91a0d214b532dcaf1e979-primary.xml.gz    $ sha256sum *gz  ed2b2d4ac98d774d4cd3e91467e1532f7e8b0275cfc91a0d214b532dcaf1e979 mirror.primary.xml.gz  c24f8d887a2a374469ad5276d9c14f72b93abc7c3b6bd1437482aa832dd1d330 nexus.primary.xml.gz     ",Bug,Major,Closed,"2017-08-05 09:34:23","2017-08-05 08:34:23",1
"Sonatype Nexus","RHC fails with certificate errors even though RHC has been configured to use nexus truststore","In some cases repository health check will fail with certificate errors even when it has been configured to use the Nexus certificate truststore,  and the needed certificate is in the truststore.    In many cases when this happens it can be fixed by going to the health check capability, disabling use nexus truststore and saving, and then enabling it and saving again.  But this does not always work.    A complete reproduce case is available on the linked issue (NEXUS-13855).  ",Bug,Major,Open,"2017-08-04 21:23:56","2017-08-04 20:23:56",5
"Sonatype Nexus","Generation of maven-metadata.xml representing a group of plugins adds an extra groupId tag, which to be used for artifacts","When using “Rebuild Maven repository metadata” task, maven-metadata.xml that represents plugin groups, has and extra “groupId” tag. As maven documentation states here ([http://maven.apache.org/ref/3.5.0/maven-repository-metadata/repository-metadata.html]) there are two types of matadata content: artifacts /artifact versions (groupId, artifactId, version, versioning) and group of plugins (plugins).    Metadata generated by Nexus 3    Metadata in Maven Central ([http://repo1.maven.org/maven2/org/codehaus/mojo/maven-metadata.xml])     When using the maven repository directly that is not really an issue but when that repository participates in maven repository group is one.    Current Nexus 3 matadata merge (RepositoryMetadataMerger.merge) has a validation bug so when merging metadata for plugins from different repositories may result in a incomplete result.",Bug,Major,Closed,"2017-08-04 19:09:58","2017-08-04 18:09:58",3
"Sonatype Nexus","conditional GET to npm group repository returns status 404 instead of 304 or 200","When a Nexus 3 instance proxy's a repository it sends conditional GET requests for npm metadata to the remote.  These fail if the remote is a group repository in another Nexus 3 instance.    Reproduce case:   # Configure an npm proxy repository to https:registry.npmjs.org in Nexus 3.5.0   # Create an npm group repository, add the proxy repo into it as a member   # Request npm metadata through the group, such as [http://localhost:8081/repository/npm-group/ansi-regex]   # Now request it again with a conditional GET - That will return a 404 response:      h4. Expected    Nexus should return 304 (not modified) IF   the combined/merged metadata for all group repository members is no different ( not updated ) as compared to the conditional get conditions as applied by general standards.    -[https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.25]- OBSOLETE   [https://tools.ietf.org/html/rfc7232] - CURRENT conditional gets   [https://tools.ietf.org/html/rfc7230#section-3.2] - message headers general    Note: Sending the same conditional GET directly to the remote proxy returns 304.    h4. Outcome    Group repo requests will return 200 status + the most recent package metadata content instead of 404 now.  Proper 304 response to conditional gets is a desired future improvement.",Bug,Blocker,Closed,"2017-08-04 18:24:18","2017-08-04 17:24:18",2
"Sonatype Nexus","Docker image should set java preference store location","Our Docker images should override the Java preferences store location to be somewhere under the work directory.  This way an installed license will not be lost when a new Docker image is deployed.          ",Improvement,Major,Closed,"2017-08-03 20:02:52","2017-08-03 19:02:52",1
"Sonatype Nexus","add YUM proxy repository support","As a systems developer, so that I can minimize downtime, I want to be able to access remote yum packages if the remote yum repository goes down    Acceptance Criteria:    * Access to metadata in SQLLite database format should be blocked   * If proxied metadata is changed, the metadata in the proxy repository will be updated when a package is requested   * Proxy repository must function if the remote repository goes down  ** The proxy will serve what cached components are currently available   * A user with sufficient privilege will be able to run the following commands:   ** yum install _<package name/s>_  ** yum update _<package name/s>_  ** yum check-update  ** yum remove _<package name/s>_  ** yum search _<keyword>_  ** yum list   * Deleting a yum component should function the same as yum remove, removing the dependencies as well     ",Story,Major,Done,"2017-08-03 09:15:45","2017-08-03 08:15:45",8
"Sonatype Nexus","outreach content makes requests to external hosts and should only reference NXRM urls instead","It is common for organizations to block requests to external sites from an end users web browser. This is the primary reason outreach content is loaded from Nexus itself, instead of having the iframe reach out to the internet by way of the end users web browser.    The outreach content is dynamic, but as of the original filing date of this ticket I noticed it sends requests to     https://use.fontawesome.com    Whether there is a fallback for fonts in case this external request does not work is irrelevant. Include any fonts directly in the content instead.    In Aug 2020, requests to googleads.g.doubleclick.net were also detected.    h4. Expected    Outreach content should not reference external content that does not reside or is accessible through urls on the Nexus server itself.    ",Bug,Minor,Open,"2017-08-03 06:12:32","2017-08-03 05:12:32",1
"Sonatype Nexus","static css files are not using a cache buster which may cause unexpected UI rendering","When you load the Nexus UI, requests are made to URLs like this:    [http://localhost:8081/static/rapture/resources/baseapp-prod_01.css]   [http://localhost:8081/static/rapture/resources/baseapp-prod_02.css]   [http://localhost:8081/static/rapture/resources/baseapp-prod_03.css]    It seems that the browser will cache these and then during upgrade of Nexus to a new version with the same files, may read the file from the browser cache instead of asking for a new version from Nexus.    This could lead to artifacts like this:    !image-2017-08-03-02-02-03-687.png!    Instead of the expected:    !image-2017-08-03-02-02-28-285.png!  h4. Expected    The static resource urls should be handled in such a way that makes them unique per Nexus release and so that a user does not need to clear their browser cache to load new UI elements as intended.    h4. Workaround    Manually clear your browser cache and restart the browser, then load the new version of Nexus.   ",Bug,Major,Closed,"2017-08-03 06:04:49","2017-08-03 05:04:49",1
"Sonatype Nexus","invalid POST search requests to PyPI repository returns status code 500 instead of 400","When a PyPi repository parsing the POSTed search request and the content is not valid, Nexus returns a 500 response.    Expected    - 400 is a more appropriate status code to return if the input is invalid for a post request, return that instead, unless 500 was chosen because of specific client handling requiring 500    ",Bug,Major,Open,"2017-08-03 04:39:20","2017-08-03 03:39:20",1
"Sonatype Nexus","Docker unauthenticated access shows unknown: unknown console output","*Description*    When having configured a docker proxy without or with invalid HTTP Authentication we expect a similar or at least close to output message as docker hub would give us.    *To reproduce*   # Setup a private repo on Docker Hub (see [here|https://issues.sonatype.org/browse/NEXUS-11300?focusedCommentId=425137&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-425137] for some instructions on a setup)   # Setup a docker proxy, do not give it any HTTP Authentication   # On the command do a pull   ## docker pull <ip:port>/<username>/<reponame>    *Actual*    *Expected*  ",Bug,Major,Closed,"2017-08-02 21:36:12","2017-08-02 20:36:12",1
"Sonatype Nexus","If an old indexing context is found when creating a new repository it should be deleted","When a repository is deleted in Nexus the search index context is not always deleted properly.      If you later try to recreate the repository the old search index context will be found, and this will result in an error.  The only way to recover from this is to shut the server down. manually remove the old index context from disk.  Then restart and rebuild the index for the affected repository.    Expected: If an old (stale) indexing context is present on disk when a repository is being created we should delete it, and create a new one.    ",Bug,Major,Closed,"2017-07-31 16:28:24","2017-07-31 15:28:24",2
"Sonatype Nexus","IE11: Outreach wraps despite there being space","Noticed in IE11, that Outreach will wrap around despite there being space for both columns.  I made the left navigation as small as possible and still doesn't not wrap.  I don't have this issue in Chrome or FF.",Bug,Trivial,Closed,"2017-07-26 18:21:53","2017-07-26 17:21:53",1
"Sonatype Nexus","Leading/trailing whitespace not trimmed from role ID's","When creating a new role ID in Nexus 3 leading and trailing spaces are not trimmed.  So you can create roles that have whitespace preceding and trailing the role ID.         *To Reproduce*   # Navigate to <your:server>/#admin/security/roles   # {color:#ff0000}!https://issues.sonatype.org/images/icons/emoticons/add.png|width=16,height=16!  {color}Create Role > Nexus Role   # Add an ID with leading or trailing spaces    *Expected*    Field to show an validation message when a Role ID has leading or trailing spaces    *Actual*    Role is able to be saved without out any challenge or failure",Bug,Major,Closed,"2017-07-26 14:13:08","2017-07-26 13:13:08",2
"Sonatype Nexus","NPM search against a group returns a 400 rather than 404","While investigating https://issues.sonatype.org/browse/NEXUS-13840 we found that NPM search against an NPM group containing a proxy returns a 400 whereas NPM search against a proxy returns a 404.    *Note:* the NPM search endpoint has been deprecated because of the change to / - /v1/search : https://issues.sonatype.org/browse/NEXUS-13151 and therefore we expect a 404 response.    We should be careful in our impl here and discuss how we can support both old+new clients whatever we change.",Bug,Major,Open,"2017-07-24 16:10:38","2017-07-24 15:10:38",1
"Sonatype Nexus","Publish Maven Indexes task SimpleDateFormat NullPointerException","A PublishMavenIndexes task may fail with a NullPointerException processing the last published date:        h4. Expected    - runtime exceptions like NullPointerException should be avoided - it is a programming error - log a more specific message as to what expectations were not met and possibly why or bypass the problem entirely  - in a rolled up suppressed exception displayed at end of task, when a task runs over multiple repositories ( All Repositories or a group repository with members ), the specific repository name where the exception was encountered would be minimum information to include, not just including the stack trace ( may need to be separate issue if something to be handled globally for all suppressed exceptions per repo ). In other words, *we need to have it logged which hosted or proxy repository had the actual problem index.*",Bug,Major,Open,"2017-07-20 15:47:20","2017-07-20 14:47:20",2
"Sonatype Nexus","Danger Uncaught TypeError Cannot read property 'load' of undefined when reloading UI after server disconnect","See attached video for reproduce case.    Basically  1. Login as admin and load a restricted config page ( example security/realms )  2. Stop nexus  3. Wait for UI to report server is disconnected  4. Start nexus  5. Retry UI loading with the dialog  6. Login again  7. See Danger message after login and also you apparently don't have access to the UI that admin should have access to.  8. refresh the browser page - realms are visible.    This was verified using Chrome.",Bug,Minor,Closed,"2017-07-19 18:01:07","2017-07-19 17:01:07",2
"Sonatype Nexus","JVM optimizations may log exceptions without stack traces by default due to OmitStackTraceInFastThrow ","We have seen at least two instances where a java.lang.NullPointerException is thrown unintentionally due to programming error and yet no stack trace is logged to help us determine and fix the root cause of the bug.    This seems to be due to a JVM optimization according to: http://www.oracle.com/technetwork/java/javase/relnotes-139183.html    bq. The compiler in the server VM now provides correct stack backtraces for all cold built-in exceptions. For performance purposes, when such an exception is thrown a few times, the method may be recompiled. After recompilation, the compiler may choose a faster tactic using preallocated exceptions that do not provide a stack trace. To disable completely the use of preallocated exceptions, use this new flag: -XX:-OmitStackTraceInFastThrow     h4. Expected    - prevent critical exceptions to be logged without without a stack trace, by turning off the JVM optimization and setting {{-XX:-OmitStackTraceInFastThrow}} by default    Additional Reference: https://stackoverflow.com/a/27214402/235000    h4. Workaround    A user may wish to disable this JVM optimization themselves until it is made the default option. They can edit bin/nexus.vmoptions and add the following line and restart Nexus:    ",Bug,Major,Closed,"2017-07-19 15:29:29","2017-07-19 14:29:29",1
"Sonatype Nexus","possible to have more than one Repository Audit task for the same repository","We have seen it possible to have Nexus Repository Manager create more than one Repository Audit tasks for the same repository. The intent is that you should never have more than one per repository.    ",Bug,Major,Open,"2017-07-18 14:33:14","2017-07-18 13:33:14",3
"Sonatype Nexus","NuGet metadata shows as latest falsely","I noticed that if I downloaded https://www.nuget.org/packages/NuGet.Core/2.8.5 into my NXRM3 that the is_latest_version field in the metadata shows as true. However, on nuget.org it shows 2.14.0 is the latest.  I verified this as a non-regression from what I was testing so am filing seperately.  While reproducable I noticed the same behavior with Microsoft.Owin.Host.SystemWeb/2.0.1 in case you need a second source.",Bug,Major,Open,"2017-07-14 22:05:38","2017-07-14 21:05:38",3
"Sonatype Nexus","NuGet metadata can incorrectly display pre-release as blank","I noticed that if I downloaded https://www.nuget.org/packages/bootstrap/4.0.0-alpha6 into my NXRM3 that the is_prerelease field in the metadata shows as blank.  However, on nuget.org it's clearly marked is a pre-release.  I verified this as a non-regression from what I was testing so am filing seperately.  While reproducable I noticed the same behavior with HtmlAgilityPack/1.5.2-beta2 in case you need a second source.",Bug,Major,Closed,"2017-07-14 22:00:21","2017-07-14 21:00:21",2
"Sonatype Nexus","Prevent the user from creating 'script' tasks with missing language engines","It is possible to 'Create Execute script Task' using a user defined 'Script Language' in the input box.   * This box could be read only since groovy is required as the language or a only allow selection from a list.",Bug,Minor,Open,"2017-07-12 14:07:47","2017-07-12 13:07:47",1
"Sonatype Nexus","User tokens not migrated if LDAP user ID case does not match login case","User token lookups in Nexus 3 from user ID to token are done using a case sensitive match.  This causes a problem after upgrading from Nexus 2.x to 3.x because Nexus 2.x uses the case a user logs in with when creating a token, and Nexus 3 uses the case of the ID stored in the LDAP server.    Reproduce steps:   # Create an upper case LDAP user ID in an LDAP system.   # Map this user into roles in Nexus 2.x that allow access to user tokens   # Enable user token access in Nexus 2.x   # Log in as the LDAP user using a lower case login ID, and access the user token   # Upgrade to Nexus 3.4.0   # Log in as the LDAP user using a lower case login ID, and access the user token         You will see that the token in Nexus 3 does not match the one in Nexus 2.    *Notes*   * LDAP user IDs are not case sensitive. This should be preserved in NXRM 3's behavior.   * This will likely require an upgrade step that cleans up duplicate user tokens that only differ by case.     * This problem may also affect default realm user ids.",Bug,Major,Closed,"2017-07-11 23:13:56","2017-07-11 22:13:56",3
"Sonatype Nexus","scheduleTask does not validate required fields","Tested schedule backup task creation via groovy script. The script runs successfully regardless if required items are missing. In this case location and node id were omitted.    Code snippet:  {code:java}  // build and schedule task  TaskConfiguration config = scheduler.createTaskConfigurationInstance(typeId)  config.enabled = jobEnabled  config.name = jobName  //config.alertEmail = task.email  //config.setString(location, task.location)  //config.setString(limitnode, currentNodeId)  TaskInfo taskInfo = scheduler.scheduleTask(config, scheduler.scheduleFactory.hourly(currentDate))  {code}   Returns 200/OK :  ",Bug,Major,Open,"2017-07-10 22:18:08","2017-07-10 21:18:08",2
"Sonatype Nexus","Privilege name does not fit in list of Privileges box","When assigning privileges to roles the list containing Available and Given does not have room horizontally for a lot of the privileges especially when the scrollbar is visible. It makes it ever so <USER>to get an overview of what privileges are given.    Could you please either increase the width or make them resizeable?",Improvement,Major,Closed,"2017-07-10 11:50:38","2017-07-10 10:50:38",1
"Sonatype Nexus","Ingest product license file on server startup via a system property","*Acceptance*   * We want a clean system with no blob stores or repositories, starting up a Nexus Pro with clustered=true from a fresh install   * The ability for NXRM to ingest a license file on startup (e.g. by specifying where the license file is)   * Use the {{nexus.licenseFile}} nexus property to point to the license file   * Fails startup if {{nexus.licenseFile}} is set but that license file is invalid",Story,Major,Done,"2017-07-05 18:29:56","2017-07-05 17:29:56",3
"Sonatype Nexus","non-standard date format in NuGet ODATA feed causes IllegalArgumentException Invalid format","After an export/import operation is performed to repair a Nexus Repository Manager 3 database, (c.f. NEXUS-12064), NXRM can generate NuGet feeds with a non-standard date format, causing client exceptions and 500 responses from Nexus while retrieving those packages.     Date format before:  {code:java}  <d:Published m:type=Edm.DateTime>2017-04-02T13:37:50.910Z</d:Published>  {code}  Date format now (triggering error):  {code:java}  <d:Published m:type=Edm.DateTime>1480511591411</d:Published>{code}    Example Log message:          h4. Cause    We believe this is caused by an export / import of the database. The date-times in question are stored in a part of the database that is schema-less and therefore loses the information that a timestamp was actually a date object.    h4. Mitigation    The linked ticket also suggests that this only affects older versions of the client and is fixed in Visual Studio 2015 and later (see https://issues.sonatype.org/browse/NEXUS-12064?focusedCommentId=412345&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-412345). If you are using an older version of Visual Studio and are affected by this bug then we suggest upgrading NXRM to the fix version listed in this ticket or upgrading to 3.12.1 and applying the patch attached to this ticket for that specific version.      ",Bug,Major,Closed,"2017-07-05 17:11:56","2017-07-05 16:11:56",2
"Sonatype Nexus","OOM may lead to blobstore/database inconsistencies","We had a user here who had thousands of blobs that were referenced in their database, but are not in blob storage.    The cause seems to be that they ran out of heap space, and this caused CPU starvation of threads writing to the blob store. These threads reached their timeout, and the blobs were not written.  An example of this is below.  ",Bug,Critical,Closed,"2017-06-30 18:37:13","2017-06-30 17:37:13",5
"Sonatype Nexus","A NuGet package that is in Nexus 2.x storage but not in its database causes a NullPointerException on migration to Nexus 3","If a NuGet package is in repository storage but not in the Nexus 2.x database you will get an NPE in Nexus 3 when it migrates it.    To reproduce this, just place a NuGet package into directly into storage in the right spot in Nexus 2, and run an upgrade to Nexus 3.         *This may also affect npm*.",Bug,Major,Closed,"2017-06-28 21:24:18","2017-06-28 20:24:18",2
"Sonatype Nexus","prevent restoring database backups with mismatched versions","*Background*    As discovered in the field, some users have occasionally restored some databases, but not all of them. In other cases, restores were carried out using a set of export files taken from different exports. This can lead to unusable NXRM instances with an incoherent state.    *Acceptance*   * Modify the filenames of database exports so it's clear whether they were generated   * Disallow restores from incomplete sets, or sets with mismatched export times",Story,Major,Done,"2017-06-26 20:24:22","2017-06-26 19:24:22",5
"Sonatype Nexus","warn in UI when ulimit < 65536 on Linux or OSX","As per -NEXUS-12041-, Nexus 3.x process user should have a minimum max ulimit of 65536 file handles. Having less could potentially lead to a critical failure.  h4.      *Acceptance*   * When NXRM detects that it has insufficient file handles   ** a prominent user interface warning is shown to administrators (indicating NXRM failed a health check, pls check the logs)   ** an ERROR appears in the log",Improvement,Major,Closed,"2017-06-26 19:27:44","2017-06-26 18:27:44",1
"Sonatype Nexus","Re-introduce LDAP user caching","{{EnterpriseLdapManager}} in NX2 used to provide user-level caching to avoid repeated requests for the same information from going upstream to the LDAP server. This was necessary to avoid a flood of upstream LDAP requests from token-based realms such as NuGet or Usertoken.    When the LDAP codebase was ported to NX3 this caching appears to have been removed from {{EnterpriseLdapManager}}. This story will look at re-introducing user-level caching to the NX3 LDAP codebase, so all token-based realms (and other users of LDAP-based information) can take advantage of this cache and don't have to implement their own caching.    See https://issues.sonatype.org/browse/NEXUS-13467?focusedCommentId=415462&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-415462 for more background.",Improvement,Major,Closed,"2017-06-26 17:45:26","2017-06-26 16:45:26",5
"Sonatype Nexus","Accesslog database cleanup fails with BufferUnderflowException","We should add some limits to this deletion to ensure that it doesn't suffer from what are presumably issues deleting large amounts of data at once.   ",Bug,Major,Closed,"2017-06-21 17:19:43","2017-06-21 16:19:43",2
"Sonatype Nexus","Extend proxy cooperation across HA nodes","NEXUS-13378 introduced proxy cooperation between threads in the same node, to avoid the same content being downloaded multiple times.    This story will look at supporting proxy cooperation across HA nodes, potentially using Hazelcast to perform the cooperation. Since hazelcast is only available in HA this will likely involve different implementations for the local and HA case, sharing the same common interface.",Improvement,Critical,Closed,"2017-06-21 15:57:46","2017-06-21 14:57:46",5
"Sonatype Nexus","Upgrading (NXRM2 to NXRM3) a group without selecting any members as well hangs","I noticed that if I selected the (default) public group from my NXRM2 to Upgrade without selecting any members (central, etc) then it goes completely through the process but on syncronization just sits and does not finish.    Workaround is to abort and restart and actually select some content however I think this could be cleaner.    I did not check older NXRM3 at this time however on investigation of the ticket I was testing, the dev believes this was not new behavior so likely was around for a while.  Note: I waited between 5-10 minutes twice.",Bug,Minor,Open,"2017-06-20 23:08:16","2017-06-20 22:08:16",2
"Sonatype Nexus","RemoveSnapshotsTask has threading issues and incorrectly processes npm repositories","Nexus 3.3.1 was configured with two Snapshot removal tasks that started at the same time:    See attached text file for play-by-play.    h4. Problems  - quartz-1-thread-11 task is only configured to process agfa-snapshots but logs it is also processing orbis-snapshots:  2017-06-17 03:00:00,141+0200 INFO  [quartz-1-thread-11] *SYSTEM org.sonatype.nexus.repository.maven.internal.RemoveSnapshotsFacetImpl - Removing snapshots on repository orbis-snapshots with configuration: org.sonatype.nexus.repository.maven.tasks.RemoveSnapshotsConfig(2, 7, true, 365)  - the ending task thread is clearly processing **npm** assets when it should only be processing Maven repositories  - one of tasks times out and fails performing a query - the other one takes an extremely long time with very little progress logging.",Bug,Major,Closed,"2017-06-20 16:24:04","2017-06-20 15:24:04",3
"Sonatype Nexus","rapid deployment of RPM files into Yum enabled Maven 2 hosted repo may cause some to be excluded from yum specific metadata files","Finding intermittent issue with RPMs missing from Yum metadata files,  but is present in Nexus. There is no failure in the createrepo task, but the issue is that in the package list file that createrepo uses to regenerate the metadata, some RPM entries are missing.       {quote}nexus-professional-2.14.2-01/tmp/nexus-yum-repository-plugin/.cache-<repo-id>/.packageFiles/<repo-id>.txt  {quote}    Example task execution that references a --pkglist file so that createrepo does not have to completely scan the entire repository storage for rpm files.:    2017-06-19 16:57:32,918+0300 DEBUG [pxpool-1-thread-14] deployment org.sonatype.nexus.yum.internal.task.CommandLineExecutor - Execute command : createrepo --update --verbose --no-database --outputdir /pciuser/tools/nexus/nexus1/Nexus_Pro/sonatype-work/nexus/storage/amd-core-rm-fnd-Releases --pkglist /pciuser/tools/nexus/nexus1/Nexus_Pro/nexus-professional-2.14.2-01/tmp/nexus-yum-repository-plugin/.cache-amd-core-rm-fnd-Releases/.packageFiles/amd-core-rm-fnd-Releases.txt --cachedir /pciuser/tools/nexus/nexus1/Nexus_Pro/nexus-professional-2.14.2-01/tmp/nexus-yum-repository-plugin/.cache-amd-core-rm-fnd-Releases/amd-core-rm-fnd-Releases /pciuser/tools/nexus/nexus1/Nexus_Pro/sonatype-work/nexus/storage/amd-core-rm-fnd-Releases     There must some race condition on updating the nexus-yum-repository-plugin/.cache-<repo-id>/.packageFiles/<repo-id>.txt when there are large number of rpm uploads at the time.    h4. Workaround    # Create a new Scheduled Task of type Yum: Generated Metadata.   #- Select the repository for createrepo to be the repository with the missing rpm.  #- Make sure the Full Rebuild check box is selected.  #- Recurrence should be manual if this is a one time fix.  # Save the task.  # Run the task.    Generating a Yum Metadata using the Full Rebuild option resolves the issue as that packlist file is regenerated from scanning the repository storage for all the deployed rpm files. ",Bug,Medium,Open,"2017-06-20 16:18:48","2017-06-20 15:18:48",5
"Sonatype Nexus","Infinite loop when using $filter (the $skip-Parameter is ignored)","Please see the comment from <USER>",Bug,Major,Closed,"2017-06-18 11:42:44","2017-06-18 10:42:44",3
"Sonatype Nexus","HEAD WARN when pushing docker images","I noticed if I push an image to docker hosted, I am getting back messages like this:  {quote}  2017-06-16 15:01:34,297-0400 WARN [qtp31792032-299] admin org.sonatype.nexus.repository.docker.internal.V2Handlers - Error: HEAD /v2/mongo/blobs/sha256:4a3c5460d81c6322019bdbe40d0921c4c97f425506306d8b6708b4a614665863: 404 - org.sonatype.nexus.repository.docker.internal.V2Exception$BlobNotFound: blob unknown to registry  {quote}    As far as I can tell everything is functioning correctly, so does not seem WARN worthy at least.  This reminds me of NEXUS-10517 but is definitely pushing not pulling from group.",Bug,Minor,Closed,"2017-06-16 20:54:36","2017-06-16 19:54:36",2
"Sonatype Nexus","Sorting repository list according status column not working","I am logged in as administrator in our *Nexus OSS 3.3.1-01* instance. Sorting list of all repositories according status column is obviously not working.",Bug,Medium,Open,"2017-06-14 08:57:03","2017-06-14 07:57:03",2
"Sonatype Nexus","Docker V2 API returns incorrect list of tags for a repository","I use {{GET /v2/_catalog}} Docker API call to get a list of repositories, then request a list of tags as {{GET /v2/<name>/tags/list}} and the response differs from Nexus WebUI, see below:    There are *45+* tags returned from Docker API call, but Nexus WebUI knows only about *16*.    I used Docker API to remove all these extra/obsolete layers/images by issuing {{DELETE /v2/<name>/manifests/<reference>}} calls before.    Seems like Nexus is aware these objects are no longer valid, but Nexus Docker Registry API still announces them.    I expect Registry API and Nexus WebUI show the same objects.",Bug,Major,Closed,"2017-06-13 14:00:44","2017-06-13 13:00:44",3
"Sonatype Nexus","non-migration of admin credentials isn't documented","The Admin user credentials from NXRM 2 are not migrated to NXRM 3. Although this may not be a bug and is intentional, it should be mentioned in the following section of documentation.       [20.5.3. What Is Not Upgraded|http://books.sonatype.com/nexus-book/reference3/upgrading.html#not-upgraded]",Bug,Major,Closed,"2017-06-13 10:53:19","2017-06-13 09:53:19",1
"Sonatype Nexus","inbound validly escaped URLs are unescaped before they are sent outbound for proxy repositories instead of sent as is","If you send a request like this to a proxy repository:    Nexus 2  {{[http://localhost:8081/nexus/content/repositories/amazon-main/201703c0ffee/x86_64/gcc-c%2B%2B-4.8.3-3.20.amzn1.noarch.rpm]}}    Nexus 3:  {{[http://localhost:8081/repository/amazon-main/201703c0ffee/x86_64/gcc-c%2B%2B-4.8.3-3.20.amzn1.noarch.rpm]}}    The outbound request from Nexus to the remote URL will not have the + character escaped.  This will result in a failure to retrieve the requested file.    h4. *Expected:*     If the inbound URL is a valid escaped URL, then send that exact same request path outbound escaping unchanged because this will mean if something different is wanted, then it will be up to the client making the original request to send something different.       ",Bug,Major,Open,"2017-06-12 23:44:14","2017-06-12 22:44:14",2
"Sonatype Nexus","java.util.ConcurrentModificationException possible with Docker UploadManager during POST to blobs/uploads","A POST request to a Docker repository at endpoint /v2/*/blobs/uploads/ may result in a ConcurrentModificationException and 500 HTTP status code response.    request.log    {code:java}   172.20.9.5 - user [12/Jun/2017:07:15:59 -0700] POST /repository/docker-internal/v2/twistlock/blobs/uploads/ HTTP/1.1 500 65 31 docker/17.06.0-ce-rc2 go/go1.8.3 git-commit/402dd4a kernel/4.9.30-moby os/linux arch/amd64 UpstreamClient(Docker-Client/17.06.0-ce-rc2 (darwin))  {code}    nexus.log:        h4. Diagnosis    Failure to follow the fully advertised Collections.synchronizedList() contract, leading to potential for ConcurrentModificationException.  ",Bug,Major,Closed,"2017-06-12 17:35:06","2017-06-12 16:35:06",0.5
"Sonatype Nexus","Limit multiple outbound upstream requests for the same proxied asset","NX3 currently allows multiple requests for the same proxied asset to go upstream, one of which will be the winner when the storage transaction is committed. This avoids any upfront locking, improving scalability - especially in a distributed setup. The downside is the potential for duplicated work, which will end up being thrown away for any losing threads.    This story will attempt to limit the amount duplicated proxy work, while maintaining scalability.",Improvement,Major,Closed,"2017-06-10 01:30:55","2017-06-10 00:30:55",5
"Sonatype Nexus","BlobAttributes deletedReason is logged as reason: null instead of the actual reason","BlobAttributes deletedReason is persisted, but is not restored on load    This leads to the following non-helpful messages:      Instead of:    ",Bug,Major,Closed,"2017-06-09 14:47:55","2017-06-09 13:47:55",1
"Sonatype Nexus","Conditional GET requests for Docker image layers always download the layer when proxying another Nexus","Tested this with 3.2.1, although the problem has also been reported against 3.3.1 as well.   # (Optional) Keep things simple and use --insecure-registry and plain http ports for the docker repos In this example I will use plain http ports.   # (Optional) use https ports and have your docker daemon trust the Nexus certificate.   # Configure Nexus A with a docker hosted repo. ( 192.168.2.97:14440 )     # Configure Nexus B with a docker proxy repo which proxies Nexus A hosted repo. ( 192.168.2.97:13350 )     # Configure the following loggers in Nexus B so that you can monitor the outbound HTTP headers and requests:   ## org.apache.http at DEBUG   # Docker Login to both proxy and hosted repos so that docker v2 API works and Nexus does not fall back automatically to using /v1 API ( which would otherwise void this test).   ## docker login 192.168.2.97:14440   ## docker login 192.168.2.97:13350   # Find and remove all images with the same name to remove all the layers attached to those images - in this example I will re-use the sonatype/nexus 3 image:   ## docker images ( list ALL images based on sonatype/nexus3 )   ## docker rmi <fill sonatype/nexus3 image name as reported under REPOSITORY column of previous command> - there may be more than one image, delete them all to make sure subsequent pulls actually download layers not already cached   # tag and push an image to Nexus A docker hosted.   ## docker pull sonatype/nexus3 ( download from official docker registry )   ## docker tag sonatype/nexus3 192.168.2.97:14440/sonatype/nexus3 ( tag the nexus 3 image against the hosted repo )   ## docker push 192.168.2.97:14440/sonatype/nexus3 ( push the image and layers to hosted repo )   # remove the local image you just tagged from the docker client cache. This should also remove dependent layers forcing them to re-download on the next pull.   ## docker rmi 192.168.2.97:14440/sonatype/nexus3   # request the image through the proxy repository which will in turn download from the hosted repo   ## docker pull 192.168.2.97:13350/sonatype/nexus3   # Examine the nexus.log of Nexus B. There you will find outbound requests to the hosted repo, downloading the layers as expected.   # Delete the cached image and layers from the proxy now and then pull again   ## docker rmi 192.168.2.97:13350/sonatype/nexus3   ## docker pull 192.168.2.97:13350/sonatype/nexus3   # Examine the nexus.log of Nexus B. There you will find identical outbound requests to the hosted repo again. The manifest request will return 304 indicating it is not changed. {color:#ff0000}*However all the conditional GET requests for the layers will return 200 and the full content of the image.*{color}    h4. Problem    The images are always re-downloaded from the remote Nexus, even if the hash/content was unchanged. The conditional GET does not work as expected - 304 status code and no content was expected.    For comparison, proxying the official docker registry at [https://registry-1.docker.io|https://registry-1.docker.io/] from Nexus 3.2.1 does work correctly in that the official registry returns 304 for unchanged layers.    h4. Workaround    Set Component Max Age to {{-1}} as image layers never change hash identity anyways. This prevents already cached image layers from being requested from the remote.",Bug,Major,Closed,"2017-06-08 18:42:56","2017-06-08 17:42:56",3
"Sonatype Nexus","Regenerate CMA from Blobs - Docker","*Acceptance*    Augment the self-repair/consistency task so that it will re-create component metadata entries for this format.   * Every operation should be logged to the new long-running task log.   ** Creating a new component db record   ** Conflicts (e.g. there's an unreferenced blob, but there's already an asset record that exist at the implied coordinate, but it refers to a different blob)   * Conflicts never overwrite existing Orient metadata; they're only logged.   * All operations should have a 'do no work' mode as per ---NEXUS-12390---   * -Restore should work if only components are dropped- (while true we have a ticket for this elsewhere)   * Restore should work if only assets are dropped   * Restore should work if both component and asset are dropped",Story,Major,Done,"2017-06-08 16:42:06","2017-06-08 15:42:06",8
"Sonatype Nexus","add per task log files for easier task auditing","*Background*    There are a number of long-running tasks whose specifics we need to audit (self-repair tasks being a good example, but also purging releases, snapshots, etc.), but we don't want to a) fill the nexus log with a million line items, or b) lose information at the whim of a customer's log levels. Support frequently gets requests from users asking to understand what happened to specific artifacts.    *Acceptance*   * Create a service that can accept all these detailed actions, in large volumes   * One log file per run of a given scheduled task   * Output files should be dated, clearly indicate which task was run   * Emit the log file location into the log at the start and end of the scheduled task   * Include task logs in the support tools zip ",Story,Major,Done,"2017-06-08 16:04:02","2017-06-08 15:04:02",3
"Sonatype Nexus","400 bad request when deploying a release versioned Maven artifact with an artifactId containing the word SNAPSHOT","My artifact name is A_INITIAL_SNAPSHOT_DWSCHEMA_TABLES_00 (I know this is ugly but it is my company's naming convention)    When I try to release my artifact I get the following error. What I am uploading is a release (version 0.1) so it should not be refused. If I just change the name of my artifact removing SNAPSHOT everything works fine so I guess instead of just checking the version number, Nexus is wrongly checking if the String SNAPSHOT is present anywhere in the artifact description.    Here is the exception:  ",Bug,Minor,Closed,"2017-06-07 07:14:42","2017-06-07 06:14:42",2
"Sonatype Nexus","Maven artifact whose case does not match the version folder they reside in are not migrated","If you have a Maven artifacts in Nexus 2 whose artifact ID does not match the ID of the artifact folder they reside in these artifacts will not be migrated to Nexus 3 on upgrade.    See attached screenshots for an example of this.    This is a critical bug, it is unfortunately not at all uncommon for users who are running Nexus 2.x on Windows to have artifacts whose case changes over time.  These will be lost on upgrade.    I've attached the work directory from Nexus 2.x to make this easy to reproduce.          ",Bug,Critical,Closed,"2017-06-06 17:57:50","2017-06-06 16:57:50",3
"Sonatype Nexus","Better explain that you can't publish to proxies/groups for formats","Scenario:   # A user sets up required tooling to use a proxy or group (more than likely a group)   # User attempts to publish/deploy/etc... to URL   ## Nexus Repo rightfully denies this   # User spends next few minutes or hours Googling to try and figure out what they've messed up with their config, rather than realizing this is by design    Some thing I stumble upon in the community role is that our users try and publish to proxies and groups more often than they should. I think that we could be a bit more explicit about this being impossible, at least until we did something for groups where you can publish and it picks the first hosted repo (I remember a ticket like this).    Example of confusion: [https://stackoverflow.com/questions/37856845/405-error-on-maven-build-to-nexus-3/40618154#40618154]    Acceptance Criteria:   * Maybe we run the documentation changes by the previously confused users and see if it is more clear to them that you cannot publish to a proxy/group",Story,Minor,"Ready for Development","2017-06-05 23:36:14","2017-06-05 22:36:14",1
"Sonatype Nexus","500 responses from Nexus after enabling quarantine on NuGet proxy repository","Reproduce steps:   # Configure Nexus 3.3.1 to use an IQ server   # Set up audit/quarantine capability for a proxy of https://www.nuget.org/api/v2/.  Enable quarantine for this capability   # Request a NuGet package through the server, such ashttp://localhost:8081/repository/nuget.org-proxy/Newtonsoft.Json/10.0.2          You'll get a 500 response from the server.   Note that this affects all new component requests, not just the first one.    Not all repository formats are affected by this bug.  I was not able to reproduce this using Maven, for example.     When the failure occurs the log shows:              When we confirm the fix, we need to make sure that we haven't left a whole bunch of artifacts in pending status.",Bug,Blocker,Closed,"2017-06-01 17:11:36","2017-06-01 16:11:36",3
"Sonatype Nexus","email non-ssl fails when 'use Nexus truststore is selected'","When none of the SSL options are selected for email server, but Use the Nexus Trust Store is then email connection fails with the following error.        Although the Use the Nexus Trust Store does not make sense when connecting to non-ssl email server, it should not fail a and use plain text connect.    A valid use case would be to have Enable STARTTLS support for insecure connections selected, so if SSL is available it would use it, otherwise use plain text. But with  Use the Nexus Trust Store select it will for it to use SSL.",Bug,Major,Closed,"2017-06-01 12:02:48","2017-06-01 11:02:48",2
"Sonatype Nexus","race condition writing to request.log under high load may cause dead lock, thread pool exhaustion and CPU spike","Nexus 2.x uses version 1.1.2 of logback-access,logback-core,logback-classic. As such it may be affected by a race condition that has been reported and described in https://jira.qos.ch/browse/LOGBACK-1270.    Nexus uses a custom PatternLayoutEncoder defined inside the logback-access.xml file so that the request log can print the user name for each authenticated request log line.    Recently the LogBack developers released a backported fix for version 1.1.x line of releases. Nexus 2.14.x uses version 1.1.2 of logback.    h4. Symptoms    The main symptom is a single thread was blocking many others from writing to the request.log.    {noformat:title=Example Blocking Thread}  qtp2074628523-9375 #9375 prio=5 os_prio=0 tid=0x00007f8cb0404800 nid=0x2014 waiting for monitor entry [0x00007f8d4466b000]     java.lang.Thread.State: BLOCKED (on object monitor)      at ch.qos.logback.core.pattern.PatternLayoutBase.writeLoopOnConverters(PatternLayoutBase.java:116)      at ch.qos.logback.access.PatternLayout.doLayout(PatternLayout.java:196)      at ch.qos.logback.access.PatternLayout.doLayout(PatternLayout.java:65)      at ch.qos.logback.core.encoder.LayoutWrappingEncoder.doEncode(LayoutWrappingEncoder.java:134)      at ch.qos.logback.core.OutputStreamAppender.writeOut(OutputStreamAppender.java:194)      at ch.qos.logback.core.FileAppender.writeOut(FileAppender.java:209)      at ch.qos.logback.core.OutputStreamAppender.subAppend(OutputStreamAppender.java:219)      at ch.qos.logback.core.rolling.RollingFileAppender.subAppend(RollingFileAppender.java:182)      at ch.qos.logback.core.OutputStreamAppender.append(OutputStreamAppender.java:103)      at ch.qos.logback.core.UnsynchronizedAppenderBase.doAppend(UnsynchronizedAppenderBase.java:88)      at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:48)      at ch.qos.logback.access.jetty.RequestLogImpl.log(RequestLogImpl.java:142)      at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:92)      at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:154)      at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)      at org.eclipse.jetty.server.Server.handle(Server.java:370)      at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)      at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)      at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)      at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)      at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)      at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)      at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:696)      at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:53)      at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)      at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)      at java.lang.Thread.run(Unknown Source)       Locked ownable synchronizers:      - <0x00000006c8e2e578> (a java.util.concurrent.locks.ReentrantLock$FairSync)          h4. Workaround    A restart will be required to escape the dead lock.    ",Bug,Major,Closed,"2017-05-29 22:22:11","2017-05-29 21:22:11",2
"Sonatype Nexus","Deleting last asset from search leaves component until refresh","While testing, I found if I deleted the last asset of a component that I had searched, I was returned to the search list however the component was still there.  If you manually enter the component, it has no assets.  If you refresh the search again, the component disappears.  While I was looking to see if this was filed (seemed familiar), I noticed browse does NOT act the same way.  Thus I am filing a bug, as I had suspsected it might be intentional, but cannot rationalize why Search would work this way and Browse not (Browse works as I expected).  Marking minor since the workaround is to refresh.",Bug,Minor,Closed,"2017-05-29 20:44:47","2017-05-29 19:44:47",2
"Sonatype Nexus","NPM group search document is not invalidated when member search documents change","While testing NPM (mostly group search) I noticed this exception a few times.  I could not find a reproducable case nor am I sure any adverse behavior but am filing after discussion with the team and also after seeing in 3.3.1, knowing it's not (recent) regression.    ",Bug,Major,Closed,"2017-05-24 20:05:43","2017-05-24 19:05:43",2
"Sonatype Nexus","Deleting docker image leaves dangling image of same ID","When I have 2 images with different tags but delete one using curl, it removes the sha file and the latest image but leaves the other image there.  This was intentional after NEXUS-12711 but further work could be done so delete both images.  The workaround is run the delete again and it will remove the second image.    Steps to repro:  1) docker pull hello-world  2) docker tag hello-world <hosted:port>/hello-world  3) docker push <hosted:port>/hello-world  4) docker tag hello-world <hosted:port>/hello-world:second  5) docker push <hosted:port>/hello-world:second  6) curl -v -u 'admin:admin123' -H 'Accept:application/vnd.docker.distribution.manifest.v2+json' https://<hosted:port>/v2/hello-world/manifests/latest -k  7) curl -v -X DELETE -u 'admin:admin123' https://<hosted:port>/v2/hello-world/manifests/sha256:<Docker-Content-Digest> -k  8) curl -u 'admin:admin123' https://<hosted:port>/v2/hello-world/tags/list -k  shows second. UI also shows image and manifest for second.  WEIRD9) curl -v -u 'admin:admin123' -H 'Accept:application/vnd.docker.distribution.manifest.v2+json' https://<hosted:port>/v2/hello-world/manifests/second -k  shows the <Docker-Content-Digest> same as latest. So seems an associated file is now missing (on push, both the manifest and sha file are created).",Improvement,Minor,Closed,"2017-05-23 21:13:49","2017-05-23 20:13:49",2
"Sonatype Nexus","Impossible to know which user roles are from external realms","Search for an LDAP user that has both directly assigned Nexus roles, and roles assigned through external LDAP group mapping.         In the roles list for the user there is no distinction between the two types of roles.  It's important to have this distinction, because they behave differently.  For instance, you can't remove an external role mapping from a user (see screenshot).         As an example of how this could be done, in Nexus 2 these external roles would show as grayed out in the list.",Bug,Major,Open,"2017-05-19 16:06:54","2017-05-19 15:06:54",3
"Sonatype Nexus","gem development dependencies are treated as runtime dependencies","1. publish a gem with dev dependencies to nx3 hosted repo  2. when you install the gem from the hosted repo, nx3 reports the dev dependencies as main dependencies (downloads them when it should not ) - this is different than how rubygems.org and nexus 2 works    Ruby gems dependency metadata returned from /api/v1/dependencies incorrectly identifies development dependencies as runtime dependencies - this can cause builds to fail due to conflicts resolving dependency versions.    Expected  - make Nexus 3 treat dev dependencies like rubygems.org and nexus 2 do",Bug,Major,Closed,"2017-05-18 15:46:15","2017-05-18 14:46:15",3
"Sonatype Nexus","Search UI does not show up when using RUT authentication","When a user with nx-admin role is authenticated using RUT authorization the repository search UI does not show up.         To reproduce this set up remote user authorization:    [https://books.sonatype.com/nexus-book/3.3/reference/security.html#remote-user-token]    [https://support.sonatype.com/hc/en-us/articles/214942368-How-to-Configure-Request-Header-Authentication-in-Nexus-with-Apache]         Then simply authenticate through Apache using a user that has nx-admin role.  You will see that the search UI is missing on the landing page.",Bug,Critical,Closed,"2017-05-17 21:40:49","2017-05-17 20:40:49",1
"Sonatype Nexus","Administration UI cog does not show up when using RUT authentication","When a user with nx-admin role is authenticated using RUT authorization the cog icon which lets you into the user administration UI for Nexus does not show up.         To reproduce this set up remote user authorization:    [https://books.sonatype.com/nexus-book/3.3/reference/security.html#remote-user-token]    [https://support.sonatype.com/hc/en-us/articles/214942368-How-to-Configure-Request-Header-Authentication-in-Nexus-with-Apache]         Then simply authenticate through Apache using a user that has nx-admin role.  You will see that the administration cog is not visible.         Direct access to the administration UI through URL's like [http://localhost:8081/#admin/security/users] does work.     ",Bug,Major,Closed,"2017-05-17 20:22:01","2017-05-17 19:22:01",2
"Sonatype Nexus","NullPointerException on npm search when invalidating cache","While investigating https://issues.sonatype.org/browse/NEXUS-12716 I found another NPE when running npm search.    When npm search is run against a group containing a proxy the following stack is outputted but the search runs successfully:    This has something to do with the fact that the proxy fires the search index invalidation event while the group is in the middle of building its search index, although it is not immediately obvious how the repository field could ever be null.",Bug,Major,Closed,"2017-05-17 17:11:30","2017-05-17 16:11:30",2
"Sonatype Nexus","Use bulk API for incremental Elasticsearch updates","Incremental Elasticsearch index updates, such as those triggered by component and asset entity events, currently use the standard put and delete API. When a massive insert of assets occurs this could cause index updates to fail for the same reason as NEXUS-12520    To get the same benefits as NEXUS-12520 (automatic retries, etc.) we should also use the bulk API for incremental updates.",Improvement,Major,Closed,"2017-05-17 03:48:46","2017-05-17 02:48:46",2
"Sonatype Nexus","Query timeout when running Publish Maven Indexes task.","The Publish Maven Indexes task fails with query timeouts when run against large data sets.    The machine has plenty of RAM (32Gb).  14Gb of space was allocated for OrientDB cache, 4Gb for heap.        The hosted repo orbis-dev is using a custom blobstore that no other repo uses.    orbis-dev-2016 blob store:   Blob count: 2922750   Total size: 562.1 GB",Bug,Major,Closed,"2017-05-15 15:35:56","2017-05-15 14:35:56",5
"Sonatype Nexus","Rejecting requests including an Authorization header for unrestricted resoruces","This is a bug that bit me <USER>while trying to install scoped packages ([#6857|https://issues.sonatype.org/browse/NEXUS-6857]) with [yarn|https://yarnpkg.com/en/]. It is a new popular client for npm.    When requesting scoped packages, yarn always includes an Authorization header, if the user previously logged in to the npm registry.    This request is a standard non-scoped package and Nexus responds correctly.        This request is for a scoped package and includes the Authorization header.        Nexus responds with a 401.        Versus a yarn request without having logged in:            Expected behavior: Ignore the Authorization header for unrestricted packages instead of issuing a 401.",Bug,Major,Closed,"2017-05-15 08:08:37","2017-05-15 07:08:37",2
"Sonatype Nexus","when merging maven-metadata.xml for a group request fails the repository ID containing the bad metadata is not logged","If a maven-metadata.xml file merge fails in Nexus 3 the repository ID with bad metadata is not logged, even at ROOT DEBUG.  This makes it extremely difficult to find where the problematic file is.               ",Bug,Major,Closed,"2017-05-12 20:31:22","2017-05-12 19:31:22",0.5
"Sonatype Nexus","when browsing assets in a group repository the asset summary UI should display the containing member repository name ","If you use browse assets on a group repository you can find the files in the group.  But there is no way to know what repository these files actually live in.       This is a critical diagnostic tool needed by support.  As an example, a customer here had bad metadata files in their group repository which was causing merges to fail.    There was no way to find out what repository actually had the bad files.  Note that ?describe diagnostics are not user friendly and would not work in this case since it would end up running a merge, which would fail.    h4. Expected    - The asset details screen should show what proxy or hosted group member containing repository the asset resides in",Improvement,Major,Closed,"2017-05-12 20:26:12","2017-05-12 19:26:12",2
"Sonatype Nexus","Purge unused components and assets task should support PyPi and Bower proxy repositories","Currently the task Purge unused components and assets task is not configurable against and no-op for PyPi and Bower format proxy repositories.    h4. Expected    - PyPi and Bower proxy repositories should be selectable in the repository list shown on the task configiuration  - when the task is configured for All Repositories, PyPi and Bower proxy repositories should not be a no-op, but instead be processed     ",Improvement,Major,Closed,"2017-05-12 15:03:05","2017-05-12 14:03:05",0.5
"Sonatype Nexus","NullPointerException is thrown when user-agent header value is not present","Discovered as part of NEXUS-13048 where a user was doing an upload to a raw repository and seeing an NPE in the logs. The user was using a Groovy library to perform the upload which was not sending the user-agent header which caused the NPE.    Acceptance criteria: No NPE",Bug,Major,Closed,"2017-05-12 00:18:28","2017-05-11 23:18:28",1
"Sonatype Nexus","Timed out reading query result from queue when running purge unused snapshots task","     The purge unused snapshots task fails with query timeouts when run against large data sets.           The blob store this was running against is used only for the snapshot repository the task is running against.  It has:    blob count: 3752052   total size: 828.9 GB         The machine has plenty of RAM (32Gb).  14Gb of space was allocated for OrientDB cache, 4Gb for heap.            ",Bug,Critical,Closed,"2017-05-11 14:44:42","2017-05-11 13:44:42",5
"Sonatype Nexus","proxy repositories with Amazon S3 remotes can be automatically blocked if the Server header value is overridden","Create a Maven 2 proxy repository to a remote URL of https://artifacts.elastic.co/maven with automatic blocking enabled = True.    The remote is an Amazon S3 storage fronted by an nginx instance. The Server response header is:        But some response headers are also returned that indicate that in truth, that the remote comes from Amazon S3 web services:        As per NEXUS-3338, Nexus 2.x tries to detect the remote is an S3 server by looking at the Server header value - if it contains the string {{amazons3}}, then even if the auto-blocking remote checks return 404, the remote is not auto-blocked.    Since the remote is fronted by an nginx server which replaces the Server header values, then Nexus S3 detection fails and the remote is permanently Automatically Blocked from servicing any outbound requests.    h4. Workaround:    To have a proxy repository to such a remote, one needs to edit the configuration of the proxy repository and turn the Auto Blocking Enabled feature to False.    h4. Expected    Nexus should also look at other response headers to detect if the remote is S3 based, for example {{x-amz-request-id}} would be a good one as this would be unlikely stripped out by a reverse proxy server such as nginx.      ",Bug,Major,Open,"2017-05-11 14:11:09","2017-05-11 13:11:09",2
"Sonatype Nexus","Anonymous access to repositories does not work when Require user tokens for repository authentication is set","Configure user token access in the server, and enable Require user tokens for repository authentication.  Then run a Maven build against the server against a repository that allows anonymous read access.         The build will fail, a 401 response is sent.         The Require user tokens for repository authentication feature should not block anonymous requests.  It should only block requests that are sent with credentials that are not user tokens.",Bug,Blocker,Closed,"2017-05-10 18:59:25","2017-05-10 17:59:25",2
"Sonatype Nexus","When Require user tokens for repository authentication is set nexus does not send an authorization header","Configure user token access in the server, and enable Require user tokens for repository authentication.  Then run a Maven build against the server.  Artifact downloads will fail with 401 even if a valid token is used.    The reason for this is that Maven by default sends requests with non-preemptive authentication, and will only send credentials in response to a 401 response with a challenge header.  The challenge header is missing in the response.  Nexus should be setting something like:       ",Bug,Blocker,Closed,"2017-05-10 18:57:07","2017-05-10 17:57:07",1
"Sonatype Nexus","Remove Releases scheduled task aborts due to Comparison method violates its general contract!","Hi,    I created a scheduled task to remove all but 20 releases in my Releases repository and getting a java error every time I run it.    I've tried targeting all repositories or specificaly maven2, and get 2 different errors each time depending if Use Index is checked or not.    *Use Index enabled:*         *Use Index disabled:*  ",Bug,Major,Open,"2017-05-09 23:43:38","2017-05-09 22:43:38",2
"Sonatype Nexus","tasks may appear as Starting or Cancelling indefinitely and cannot be stopped cancelled or deleted","After restarting Nexus repository manager that has a large number of tasks, one or more tasks may   - transition to Starting state before Nexus boots  - never leaves Starting state to Started state  - the task has the Stop button enabled  - after clicking the Stop button the task is indefinitely in Cancelling state  - after the clicking the task Delete button, the task is indefinitely in Cancelling state    The nexus.log may show the task transitions from WAITING to RUNNING before Nexus reports it has fully booted - example: Rebuild Indexes:        A thread dump from the server may show the task thread stuck as follows:        h4. Workaround    A user may want to know how to delete the stuck task. The only way is to explicitly delete the task from the configuration database using a special OrientDB console command. Please contact support if you need the additional information to delete a similarly stuck task.",Bug,Critical,Closed,"2017-05-09 16:44:38","2017-05-09 15:44:38",3
"Sonatype Nexus","outreach capability Base URL is editable","Nexus 2 allowed setting an override URL for outreach for testing purposes.    The Base URL is for display purposes only and should not be editable. We display it so that in case you do override it, you can easily revert to the default value.    Nexus 3 incorrectly allows editing and saving the BaseURL field    Since Base URL is named the same as the Base URL field they are used to seeing in Nexus 2 and the Nexus 3 Base URL Capability is hidden by default, we have had at least one customer set the Base URL of outreach to the base URL of their Nexus instance expecting that to work.    *Expected*   - make Base URL for outreach capability not editable   - -if on upgrade it is changed from it's default value, reset it in the database-   - document this change in release notes in case the user used the Base URL field to perform an override instead of the override field   - Change of Labels and Help text (came out of PR review)   ** Change the field label {{Base URL *to* Default Outreach Content URL:}}.   ** Change the help text for that field from {{URL *to* use for querying page bundles.}} to {{Default external URL for downloading new Outreach content.}}   ** Change the field label {{Override URL:}} *to* read {{Override Outreach Content URL:}}   ** Change the help text for that field from {{Retrieve the page bundle from a specific URL.}} *to* {{Override external URL for downloading new Outreach content.}}",Bug,Minor,Closed,"2017-05-04 17:12:49","2017-05-04 16:12:49",1
"Sonatype Nexus","log and prevent startup when the started Nexus version is using a data directory from a newer Nexus version","Nexus 2 detected and failed startup in most cases where configuration file compatibility versions were conflicting.    Some Nexus 3 users accidentally or intentionally startup old versions of Nexus 3 against newer upgraded versions of Nexus 3 data directories. This may lead to potential problems and is certainly a state which is considered unknown. This complicates trying to solve any other reported problem with a running instance.    h4. Expected  - Nexus 3 should detect startup against incompatible data directories/files (ie. those with later schema versions compared to the installation attempting to run), fail, and log a SEVERE message indicating the problem into the nexus.log",Improvement,Major,Closed,"2017-05-04 15:34:06","2017-05-04 14:34:06",1
"Sonatype Nexus","com.orientechnologies.common.profiler.OAbstractProfiler$MemoryChecker log spam every 2 minutes","Some nexus.log files are filling with thousands of these log messages ( counted over 5000 in one 13 hr period, printed every 2 minutes ):        h4. Expected    - document what this means and what actions might or might not be taken  - provide a different message that does not refer to files/settings that are not applicable to the orient database being embedded inside nexus  - do not spam logs constantly if this INFO message is not important or not actionable",Bug,Major,Closed,"2017-05-04 13:53:16","2017-05-04 12:53:16",2
"Sonatype Nexus","Browse components of large repositories fails with IllegalStateException Timed out reading query result from queue","We are seeing the warning message *Operation failed as server could not be contacted* when browsing components of large repository as non-admin/admin users . This only happens when browsing components of huge repositories. Browsing assets of these repositories are fine. Browsing components of other smaller repositories are fine as well.     Can confirm that the same is also happening for browsing groups with huge repos in assets page for both admin/non admin users.        With Debug switched on, we see this error:       ",Bug,Critical,Closed,"2017-05-04 10:52:53","2017-05-04 09:52:53",5
"Sonatype Nexus","slow performance and metadata rebuild failures when running Remove snapshots from Maven repository against large datasets","Looking at the logs we can see that the task Deleted 576 components from 522 distinct GAVs, 13 minutes after task 'Remove2 old snapshot from Amundi Snapshots' has started.      Then there is a 4+ hours gap before a next log entry on 42 GAVs found that have already been released.      Rebuild of metadata has now started.      After 9 hours of rebuilding metadata you get the following failure.     ",Bug,Critical,Closed,"2017-05-03 17:25:17","2017-05-03 16:25:17",5
"Sonatype Nexus","IllegalArgumentException Version mismatch may be logged when GA maven-metadata.xml versions are merged in a group repository request ","Download for artifact appears to be working, but getting error in log and causing some concern over conflict or if something has been inproperly loaded.    [^nexus-logviewer-VersionMismatch.txt]        Maven central has npanday custom-lifecycle-maven-plugin  latest release 1.4.0-Incubating    We have the npanday custom-lifecycle-maven-plugin  built locally to have a 'pre release' release of 1.5.0-NSL  which was captured to host on a Nexus 2.11  3rd Party repo    Central and 3rd party proxies are included within a maven2 group  type where it is downloaded from.    when looking at pom.xml in various locations all appears well that I thought to check so far.     ",Bug,Minor,Closed,"2017-05-03 02:17:38","2017-05-03 01:17:38",2
"Sonatype Nexus","Pull on a non-existant image requests auth","If you do a pull of a non-existant image, you will be prompted for authentication even if you're already logged in.  I see no reason for this so filing; I'll let someone else tell me this isn't a bug=)",Bug,Medium,Open,"2017-05-01 21:48:30","2017-05-01 20:48:30",1
"Sonatype Nexus","Unfiltered LDAP user search will retrieve all users from an LDAP server, which can result in an OOM","Reproduce steps:   # Go to security/users in the UI   # Change the source to LDAP   # Hit enter in the filter by user ID box without inputting any data         Observe that _all_ user ID's from the LDAP server are retrieved, and for each one the full user record is retrieved.    This will result in a UI timeout if the LDAP server has a large number of users, or possibly even an OOM.           Expected:  The UI should limit the number of users retrieved in some way.   This could be a paged result set.  Or it could be as simple as only retrieving at most some arbitrary number o users, such as 1000.               ",Bug,Major,Closed,"2017-05-01 19:48:42","2017-05-01 18:48:42",2
"Sonatype Nexus","Uncaught TypeError UI errors","While pre-testing 3.3.1, I unpackaged the pro bundle and set it up to perform Migration.  I then ran migration from 2.14.4.  After doing such, I accessed Repositories to see if everything came across and noticed the attached errors.  [~<USER> had reported this in the support room several days prior.    Workaround appears to be loading in incognito window or clearing browser cache.    Before this, I had cleared my browser cache testing the 3.3.1 OSS bundle so this seems either related to cache differences between OSS and PRO or something related to Migration.",Bug,Minor,Closed,"2017-04-28 16:41:57","2017-04-28 15:41:57",2
"Sonatype Nexus","eliminate soft-deleted blobs and reduce transaction retries for identical proxy repository asset requests","*Background*    In highly concurrent situations, multiple clients may request the same content from an NXRM proxy repository. In these cases, the parallel requests significant churn on the Asset record, with unnecessarily large numbers of blobs created as a result of transaction retries fighting over which blob to attach to it. This could occur in multiple HA nodes using the same blobstore, or on a single node (multiple threads). Because the soft-deleted blobs from the unsuccessful tries linger until the blob store is compacted, this can also waste storage space.    *Acceptance*    Detect when a transaction is attempting to attach a blob to an Asset when an identical blob already exists on that Asset. In those cases, ignore the attach request, and retain the existing blob.     ",Improvement,Major,Closed,"2017-04-26 13:58:05","2017-04-26 12:58:05",5
"Sonatype Nexus","automatically retry blob creation when a UUID collision is detected","BlobIds are based on randomly generated UUIDs. While the chance of a collision is extremely rare (https://en.wikipedia.org/wiki/Universally_unique_identifier#Collisions) if it does ever happen then we should automatically retry the create blob operation with a fresh randomly generated id.",Improvement,Major,Closed,"2017-04-26 13:42:50","2017-04-26 12:42:50",2
"Sonatype Nexus","URL provided by UI Search by maven coordinates doesn't work","Hi,    When i do an UI Search, it's great browser url is updated to reflect choosen criteria. I could use it as browser bookmark. Unfortunatly, this url doesn't work with search for components by maven coordinates.         See attachments:     - SearchByAttribute : when i do a search by attribute     - SearchByURL: when i use URL provided by my my last search as bookmark => OK     - mavenSearch : when i do a maven search     - mavenSearchByURL: when i use URL provided by my last maven search as bookmark=> KO     ",Bug,Minor,Closed,"2017-04-26 09:26:45","2017-04-26 08:26:45",3
"Sonatype Nexus","NuGet FindPackagesById queries may perform slowly possibly leading to general non-responsiveness","Below example shows that the NuGet query is taking nearly 5 minutes to respond.     request.log      nexus.log      With many of theses type of request, causes Nexus hang and requires restart to recover. This issue is related to NEXUS-12337 where a fix is included in Nexus 3.3. Unfortunately it has not resolved this issue.    h4. Cause    The internal database queries backing the NuGet queries are being slowed down by the lowercasing of the Nuget package name, bypassing some important database indexes.",Bug,Critical,Closed,"2017-04-20 16:53:30","2017-04-20 15:53:30",3
"Sonatype Nexus","Warning in log seen when using content selector with coordinate.extension","Define a JEXL expression for a content selector like this:       {code:java}  format == maven2 and coordinate.extension == war  {code}       Hit the preview button in the content select or editor.  Observe that this works, only war files are shown in the preview.         But the nexus.log is filled with warnings:       ",Bug,Minor,Closed,"2017-04-19 19:18:50","2017-04-19 18:18:50",1
"Sonatype Nexus","Uninformative log message in ProxyFacetSupport - Content not present for throwing exception","Nexus 3.3 may log messages such as these:         Where did it throw the exception? What was the exception? Content not present for means nothing. What content where? On disk? In an http response from the proxy? Headers?    These log levels MAY have been overridden at the time in logback-overrides.xml, but these loggers should not prevent seeing a more useful log message:          ",Bug,Major,Closed,"2017-04-19 18:47:16","2017-04-19 17:47:16",2
"Sonatype Nexus","Exception while executing Purge unused docker manifests and images task","I have created a task of the type Purge unused docker manifests and images and when I execute it I always get this exception:      Before launching the task i have deleted some image from components UI",Bug,Major,Closed,"2017-04-19 16:57:43","2017-04-19 15:57:43",3
"Sonatype Nexus","possible to create a repository without a valid blobstore reference","# In browser window A, create a blobstore named test   # In browser window B start creating a repository that refers to blobstore test, but do not save it yet   # In browser window A, delete the blobstore test   # In browser window B, save the repository. It will save successfully, referring to non-existent blobstore test   # Try to delete the repository, you cannot - the delete will fail because the blobstore does not exist    The same thing can be done with a groovy script when calling RepositoryManager.create(config) API directly. There is not validation on save of a repo that a blobstore exists by that name.    Example groovy script that can also put Nexus in this state:       h3. Workaround    In order to fix the invalid state:   * create blobstore name that matches the name referenced by the repo   * *restart Nexus* ( without restart, repo delete still fails with)            * delete repository   * delete blobstore",Bug,Minor,Open,"2017-04-19 15:09:10","2017-04-19 14:09:10",2
"Sonatype Nexus","Upgrade from 2.x to 3.x Hangs on Group Repos containing only Staging Repos","My Nexus 2.14.4 has 2 group repositories containing only Staging repositories. Going through the upgrade steps in Nexus 3.3.0, I can select those groups, but the Staging Repos are not able to be selected. Also, I have an empty group, which is not able to be selected. See Screenshot. !image-2017-04-13-10-29-26-293.png!         During the Synchronizing step, it processes 19 of the 21 repositories, and the Process Changes completes and waits for changes on the Nexus 2 side, but the last 2 Repositories never complete Scanning. The message in the log is shown below as well as screenshot.    Rerunning the upgrade without selecting these two groups is successful.    !image-2017-04-13-10-31-52-430.png!",Bug,Minor,Closed,"2017-04-13 15:32:41","2017-04-13 14:32:41",3
"Sonatype Nexus","Active Directory dynamic nested groups","To support nested groups, Active Directory provides a [filter|https://msdn.microsoft.com/en-us/library/windows/desktop/aa746475(v=vs.85).aspx] which is added to the group member of attribute to provide a method to look up the ancestry of an object.    Nexus works with this successfully for static groups but not for dynamic groups.    Group member of attribute:  memberOf:1.2.840.113556.1.4.1941:    With the filter added to the dynamic group member of attribute, Nexus could not create an external role mapping.",Bug,Major,Open,"2017-04-12 23:32:53","2017-04-12 22:32:53",3
"Sonatype Nexus","npm publish a large package may cause java.lang.OutOfMemoryError: Java heap space when parsing the JSON payload","If one uploads a large npm package using npm publish, this could cause Nexus to run out of memory as it parses the POSTed JSON payload.         Reproduce with the following:    Artificially reduce the Nexus 3 max heap size to 256mb    Artificially create a large npm package to publish:   # Create a 25mb file ([http://unix.stackexchange.com/q/33629])   head -c 25M </dev/urandom > big.file   # Include big file in package.json   $ cat package.json | grep files   files : [ big.file ]         Attempt to npm publish while the Nexus 3.3 and below has the logger     at DEBUG.         You will see:            h3. Expected   - large npm package uploads should not cause Nexus to run out of memory - stream the JSON instead of loading it entirely into memory",Bug,Major,Closed,"2017-04-12 17:56:01","2017-04-12 16:56:01",3
"Sonatype Nexus","Docker-nexus3 - readme incorrectly describes how data volumes are used","readme contains:  {quote}Since data volumes are persistent until no containers use them,  {quote}  This statement appears wrong.    Data volumes are not deleted when no container uses them. In fact data volumes are never removed by docker when containers are deleted.    From [https://docs.docker.com/engine/tutorials/dockervolumes/#data-volumes] :  {quote}Data volumes persist even if the container itself is deleted.  Data volumes are designed to persist data, independent of the container’s lifecycle. Docker therefore never automatically deletes volumes when you remove a container, nor will it “garbage collect” volumes that are no longer referenced by a container.  {quote}",Bug,Minor,Closed,"2017-04-11 18:54:54","2017-04-11 17:54:54",0.5
"Sonatype Nexus","Only one capability of type 'Webhook: Repository' can be created","Users are prevented from creating more than one Repository webhook by the Capability rules, but need to be allowed to create for multiple Repositories.",Bug,Major,Closed,"2017-04-11 16:54:17","2017-04-11 15:54:17",0.5
"Sonatype Nexus","When a REST API request is made for assets or components in a repository that a user cannot access, the appropriate response code should be returned","Currently if a user makes a REST API request for components or assets in a repository they cannot access, they get an empty set. They should probably receive an error code. This occurs with the following resources:   * GET {{/service/siesta/rest/v1/assets}}   * GET {{/service/siesta/rest/v1/components}}    Technical note: What error code do we want to return? 403 vs 404.",Story,Major,Done,"2017-04-10 22:01:59","2017-04-10 21:01:59",2
"Sonatype Nexus","Upgrade Apache Tika dependency to 1.14","As part of investigating 10087 I found there was a slight improvement in the behaviour of Tika:         1.14 still wrongly identifies as text/html if the xml contains any tag starting with {{<html..}}, however if you have a comment at the start of your xml file, like the pom in question (Note: works even if it's empty {{<!-- -->}}) then it correctly identifies as text/xml.         To test:   # Create a proxy repo called RSO and point it to [https://repository.sonatype.org/service/local/repositories/sonatype-internal/content/]   # Request [http://localhost:8081/repository/RSO/com/sonatype/insight/ci/insight-ci-parent/2.14.4/insight-ci-parent-2.14.4.pom]    # You should be presented with a POM rather than a 404.     ",Improvement,Minor,Closed,"2017-04-07 17:25:14","2017-04-07 16:25:14",1
"Sonatype Nexus","submitting more than 20 tasks at once causes ERROR QuartzSchedulerThread - ThreadPool.runInThread() return false! for some tasks","Submitting considerably more than 20 tasks at once causes a rejection error for some tasks. These tasks do not run, instead they hang in a Waiting state. You can see an error in the logs reported from quartz:    To reproduce, you can run the test here: [https://github.com/sonatype/nexus-internal/pull/1671/files#diff-f47ab1796bb11e077d08f418a8fcf42e]    Changing the maximum tasks to 50 instead of 21.    Also, you can use this groovy script to schedule a large number of tasks to run at once:     ",Bug,Critical,Closed,"2017-04-05 00:36:16","2017-04-04 23:36:16",3
"Sonatype Nexus","Repository Health Check RHC only detects HTTP proxy server settings changes on server restart","1. Start up Nexus 3.2.1/3.4.0  2. Run repository health check against one repository  3. Configure an HTTP proxy server in Nexus  4. Run repository health check against another repository ( manually running the Health Check task is equivalent )  5. Problem: The second health check request will not be routed through the HTTP proxy server.  It is necessary to restart the server in order to fix this.    1. Remove an HTTP proxy server from Nexus  2. manually run a Health Check task  3. Problem: Requests to rhc-pro.sonatype.com or rhc.sonatype.com continue to try an go through the previously configured HTTP proxy server that was deleted.    h4. Expected    The repository health check feature should detect all relevant HTTP proxy server changes and use them immediately, it should not be necessary to restart the server or make other configuration changes.    h4. Workaround    After changing HTTP proxy server settings, a Nexus restart is required in order for Repository Health Check to detect and use the correct HTTP proxy server settings.  ",Bug,Major,Closed,"2017-03-29 18:56:05","2017-03-29 17:56:05",1
"Sonatype Nexus","if java.lang.Error is thrown during request processing it may not be logged at default log levels","A report was made recently where an NPM package deployment was failing with a 500 response.    Analysis was performed on the Nexus 3 logs    {noformat:title=request.log}  172.17.25.121 - admin [22/Mar/2017:23:11:27 +0000] PUT /repository/uwp/@itg%2fwebstack HTTP/1.1 500 0 4624 npm/4.4.1 node/v6.9.5 win32 x64      After changing the ROOT logger level to DEBUG the problem was reproduced and it was determined an OutOfMemoryError was being thrown:        h3. Expected    - Nexus should ALWAYS attempt to log java.lang.Error derivatives at ERROR log levels at the shallowest stack depth  - logging java.lang.Error should not depend on some higher level log statement  - one should not have to enable DEBUG log levels to notice an OutOfMemoryError  ",Bug,Critical,Closed,"2017-03-29 16:01:15","2017-03-29 15:01:15",1
"Sonatype Nexus","task scheduler threads may deadlock at QuartzTaskJob.mayBlock() when more than 20 blocking tasks are encountered","During some stress testing earlier, I added 100 Maven2 proxy repos and enabled IQ: Audit and Quarantine on them. Upon restarting Nexus, I was presented with 100 Repository Audit tasks that wouldn't move forward.    From the thread dump:    Per default configuration, 20 threads are allocated for Quartz, all of them are stuck like that in {{QuartzTaskJob.mayBlock()}}.",Bug,Critical,Closed,"2017-03-28 22:36:05","2017-03-28 21:36:05",3
"Sonatype Nexus","NullPointerException when running npm search","When trying npm search it fails with a NullPointerException.    I have reproduced this issue on 3.2.1. It seems to be related to searching across multiple blob stores. The npm search is run using the npm-group    npm-group using npm-group-blobstore  npm-host using npm-host-blobstore  npm-proxy using npm-proxy-blobstore    When all three are on the same blobstore, I am unable reproduce.    ",Bug,Major,Closed,"2017-03-24 16:01:03","2017-03-24 16:01:03",3
"Sonatype Nexus","Nexus docker registry delete REST api partially deletes an image","Deleted a docker image through docker registry REST api. The image was deleted successfully from Nexus UI, but still lists in the GET /v2/<name>/tags/list API.   No workaround exists.    Steps:  *Get image digest:*        From response header:  Docker-Content-Digest: sha256:0c2e8350966123c27427152c66024d280e8d60a01ca37b3bac84b61882b6f832    *Delete image*      get response: HTTP/1.1 202 Accepted    At this point image has been deleted from Nexus UI. But below list tags call still return the version        ",Bug,Major,Closed,"2017-03-23 17:59:50","2017-03-23 17:59:50",3
"Sonatype Nexus","Empty trash task does not traverse into group repositories.","Create an empty trash task, and set it to run against a group repository in Nexus 2  and Purge items older than (days) set to 0.    After running it, you will find that it has not removed any trash from any of the group's member repositories.    Expected:  The task should traverse the group's member repositories, the same way other tasks do when they are run against a group repository.  ",Bug,Major,Open,"2017-03-22 22:20:49","2017-03-22 22:20:49",2
"Sonatype Nexus","Create wildcard privilege form does not redirect to list view on success","Observed on master (d5e04b386).    1. Log in as admin.  2. Navigate to Security -> Privileges  3. Click Create privilege  4. Pick wildcard.  5. Enter valid name and pattern.  6. Submit ('create privilege').    Expect: to be taken back to the privileges list.  Observe: remain on Create wildcard privilege form. Form submit button still enabled.    There are 2 SecurityIT tests affected by this bug:    * Can add, edit, and delete wildcard privileges  * Can add, edit, and delete content selector privileges        ",Bug,Major,Closed,"2017-03-21 15:00:10","2017-03-21 15:00:10",2
"Sonatype Nexus","nx-licensing-uninstall serves no purpose","Early on in NXRM3 (or never ported, can't remember) we removed the ability to uninstall a license.  However, I just noticed there's still a nx-licensing-uninstall privilege.  As far as I know/can see, this does nothing but adds to the already confusing privilege list.  Note you can still remove a license via the console, however, this doesn't require a privilege so this wouldn't impact that as far as I know.    I could be convinced this is an improvement but I made a bug as I feel it's residual from the story work already done on removal of ability to remove a license itself.",Bug,Minor,Open,"2017-03-21 14:17:46","2017-03-21 14:17:46",1
"Sonatype Nexus","group privileges insufficient to search for member content","Logging in as a registered user which has BROWSE and READ privileges to the GROUP containing several private repos (and also nx-search-read).     The user DOES NOT have BROWSE or READ privileges to the individual group repository member repos in the GROUP, only the GROUP repository  (which works fine as maven2 repos).     Doing a search through the GUI does not yield any result at all, which is not what I expected.    The user can browse to the component and download, but is unable to search this component    Acceptance criteria:    * If the user has BROWSE permissions to the group, they should be able to search for components in the member repositories of that group (even if they don't have explicit permissions for those repositories). They should also be able to view the component/asset details,  though not download the assets (that requires the READ permission).  * Make sure that component-level permissions are still applied.",Bug,Minor,Closed,"2017-03-21 13:57:18","2017-03-21 13:57:18",5
"Sonatype Nexus","HEAD request to /v2/<name>/manifests/<reference> results in 404 error","When you specify a HEAD request to /v2/<name>/manifests/<reference> for an existing docker image in a Nexus docker repository, a 404 error will occur.    For example, I have tried to send a HEAD request to something like [http://host:8081/respository/dockerRepo/v2/test/alpine/manifests/latest] and I get back a 404.    However, if I try a GET request to [http://host:8081/respository/dockerRepo/v2/test/alpine/manifests/latest], I get back a response with the details that I am looking for.    In contrast, in a Docker registry, a HEAD request to [http://host:8081/v2/test/alpine/manifests/latest] works properly.    For more details about the API call, you can go to https://docs.docker.com/registry/spec/api/#pulling-an-image and look for Existing Manifests    The HEAD request should be supported in Nexus docker repositories and not be a 404 error.",Bug,Major,Closed,"2017-03-20 04:48:33","2017-03-20 04:48:33",3
"Sonatype Nexus","nexus-staging-maven-plugin does not work with SNI","The nexus-staging-maven-plugin does not work with SSL enabled servers that use SNI.    This can be easily reproduced by setting the nexusUrl parameter in the plugin configuration as follows:    {code:XML}                     <nexusUrl>https://nexus.opendaylight.org/</nexusUrl>  {code}    This results in:    {quote}  \[ERROR\] Failed to execute goal org.sonatype.plugins:nexus-staging-maven-plugin:1.6.8:deploy (injected-nexus-deploy) on project parent: Execution injected-nexus-deploy of goal org.sonatype.plugins:nexus-staging-maven-plugin:1.6.8:deploy failed: Nexus connection problem to URL [https://nexus.opendaylight.org/ ]: com.sun.jersey.api.client.ClientHandlerException: javax.net.ssl.SSLException: hostname in certificate didn't match: <nexus.opendaylight.org> != <logs.opendaylight.org> OR <logs.opendaylight.org> -> \[Help 1\]  {quote}      ",Bug,Major,Closed,"2017-03-17 15:59:54","2017-03-17 15:59:54",2
"Sonatype Nexus","proxy repository default negative cache size is too low to be effective","Nexus 2 had a global not found cache of 100000 entries shared across all repositories.    When we suspected large customers were overflowing this 100000 max entry limit, we would ask them to up this to 1 million and this resulted in noticeable performance improvements ( throughput)    Nexus 3 has a per repository not found cache of 1000 entries.    In the majority of cases the Nexus 3 default cache size is  too low and forces Nexus to go remote more often than desired.      ",Bug,Blocker,Closed,"2017-03-17 15:08:03","2017-03-17 15:08:03",2
"Sonatype Nexus","display given roles in alphabetical order by name instead of arbitrary order","The role definition screen appears to display the contained roles in an arbitrary order (maybe db insertion order). This makes them <USER>to grok, and is a usability regression from NX2.    Acceptance  * Order the roles in the role list alphabetically ",Story,Major,Done,"2017-03-17 02:25:27","2017-03-17 02:25:27",1
"Sonatype Nexus","HTTP requests which attempt modification should receive 503 when server is read-only mode","(This should probably get broken into a couple of issues.)    *Acceptance*    During read-only mode, NXRM won't accept writes. In this situation, it would be ideal if:   * Rejected requests return 503 specifically (rather than other 500-level responses).   * The reason code should specify that the cluster is in read-only mode   * This covers REST endpoints, and repository write access",Story,Major,Done,"2017-03-14 17:11:32","2017-03-14 17:11:32",3
"Sonatype Nexus","Some Nuget targetFramework metadata does not have the same makeup as others","While testing NEXUS-12484, I loaded https://www.nuget.org/packages/Elasticsearch.Net/ (5.2.0) into the default nuget.org-proxy.  I noticed the targetFramework metadata displayed link this:    {quote}  ::net45|::net46|NETStandard.Library:1.6.0:netstandard1.3|System.Collections.Specialized:4.0.1:netstandard1.3|System.Runtime.Serialization.Primitives:4.1.1:netstandard1.3|Microsoft.CSharp:4.0.1:netstandard1.3|System.Dynamic.Runtime:4.0.11:netstandard1.3|System.Reflection.TypeExtensions:4.1.0:netstandard1.3|System.ComponentModel.TypeConverter:4.1.0:netstandard1.3  {quote}    However, this seems to be missing the >= markup present in other packages.  For example, NETStandard.Library (>= 1.6.0) is listed and we show NETStandard.Library:1.6.0:netstandard1.3 but I feel that should be NETStandard.Library:[1.6.0, ):netstandard1.3.    Compare with https://www.nuget.org/packages/AutoMapper/4.2.0  {quote}  ::portable45-net45+win8+wpa81|::net45|Microsoft.CSharp:[4.0.0, ):dotnet5.1|System.Collections:[4.0.10, ):dotnet5.1|System.Collections.Concurrent:[4.0.10, ):dotnet5.1|System.Collections.Specialized:[4.0.0, ):dotnet5.1|System.ComponentModel.TypeConverter:[4.0.0, ):dotnet5.1|System.Diagnostics.Debug:[4.0.10, ):dotnet5.1|System.Dynamic.Runtime:[4.0.10, ):dotnet5.1|System.Globalization:[4.0.10, ):dotnet5.1|System.Linq:[4.0.0, ):dotnet5.1|System.Linq.Expressions:[4.0.10, ):dotnet5.1|System.Linq.Queryable:[4.0.0, ):dotnet5.1|System.ObjectModel:[4.0.10, ):dotnet5.1|System.Reflection:[4.0.10, ):dotnet5.1|System.Reflection.Emit:[4.0.0, ):dotnet5.1|System.Reflection.Emit.ILGeneration:[4.0.0, ):dotnet5.1|System.Reflection.Extensions:[4.0.0, ):dotnet5.1|System.Reflection.Primitives:[4.0.0, ):dotnet5.1|System.Reflection.TypeExtensions:[4.0.0, ):dotnet5.1|System.Runtime:[4.0.20, ):dotnet5.1|System.Runtime.Extensions:[4.0.10, ):dotnet5.1|System.Text.RegularExpressions:[4.0.10, ):dotnet5.1|System.Threading:[4.0.10, ):dotnet5.1|System.Threading.Tasks:[4.0.10, ):dotnet5.1  {quote}    I did not check older NX3 at this time because of NEXUS-12484, I do not believe I could (would show as Unsupported).",Bug,Major,Closed,"2017-03-14 14:27:44","2017-03-14 14:27:44",3
"Sonatype Nexus","Unable to Start Nexus-public","I am following directions at [https://www.github.com/sonatype/nexus-public]. I am running on OS X with:            Nexus is unable to start with the following stacktrace:      Has anyone encountered this? Is there a way through?",Bug,Major,Closed,"2017-03-12 09:31:29","2017-03-12 09:31:29",2
"Sonatype Nexus","Manage Privileges search dialog loses cursor focus","The search dialog in the Manage Privileges view loses cursor focus on the search text box while completing the auto-filter action after a user has begun to type search criteria.    It is likely the user will need to continue entering their search criteria to further narrow the results, causing the user to have to go through a process of selecting the search text box and typing, possibly several times.    This behavior is inconsistent within other UI search dialogs and results in a frustrating user experience.",Bug,Minor,Closed,"2017-03-10 13:44:27","2017-03-10 13:44:27",1
"Sonatype Nexus","Allow browse of repository storage via HTML index directory listing","Since the release of Nexus 3, some people still have expressed an interest in having a Browse Storage feature that works using basic HTML navigation.    Users of Nexus 2.x who just want to download a particular file for direct consumption often browse into the /content URL to locate what they want, click on it, and download it. This is a simple, very intuitive UI which can be used by end users who aren't very technical.    In Nexus 3 it is no longer possible to do this.    There are cases where you can download a file by requesting e.g.:   http://<nexus-hostname>/repository/<raw-repo-name/<filename>     This makes it intuitive if the directory listing would be given if you remove the filename from that url (However, currently that url returns 404)    Where it makes sense, consider allowing browsing of repositories via HTML directory listings.     A few repository formats where this likely does make sense are:    * Raw Repositories  * Maven  * Yum (future)     Additionally, the fact that Nexus 3 does not implement an HTML directory list, means implicitly **the Browse Remote feature of Nexus 2 will not work when a proxy is added against a Nexus 3 remote**.",Improvement,Major,Closed,"2016-07-12 13:34:44","2016-07-12 12:34:44",8
"Sonatype Nexus","add support for more secure and salted LDAP PasswordEncoders such as SHA-256 SHA-384 SHA-512","Failed to connect to LDAP Server: Password encoding: SSHA512 has no associated PasswordEncoder.    2017-03-22 16:49:37,575+0100 INFO UNKNOWN org.sonatype.nexus.ldap.internal.connector.dao.password.DefaultPasswordEncoderManager - Verifying password with encoding: SSHA512 (encoder: null).",Improvement,Major,Closed,"2017-03-08 13:47:07","2017-03-08 13:47:07",2
"Sonatype Nexus","assets visible by browsing are not available when searching due to non-optimized elasticsearch configuration rebuilding indexes","Hi,  Nexus OSS 3.1.0-04, Linux    Some maven releases  artefacts are missing when performing a search but I can see them when browsing.    Steps to reproduce :  - In the top global search textfield, I type the name of the artefact : nxxxx, then I press Enter  <2 secs>  - I see 2 releases (1.0.3 and 1.0.4) and 3 snapshots  release 1.0.1 is missing (but I'm sure it exists as a mvn deploy complain it already exist and the repository is configured in no redeploy)    Notes:  - adding quotes around the searched keywork produces the same results  - Being logged-in or not has no effect on the issue    Then, I browse:  - I click on Components  - I select the (Release) repository of the artefact  - I insert nxxxx in the right-side filter  [very long search : 20 secs+]  - I can see all the three releases : 1.0.1, 1.0.3 and 1.0.4    Reading the doc, I pretty sure than I don't need to run the Nexus rebuild index task (as all artefacts are deployed through Nexus with mvn deploy) but in case off, I run it : sometimes missing artefacts in the search reappear, sometimes others disappear again, so I disabled it again.    What do you think ?    Thanks",Bug,Critical,Closed,"2017-03-08 08:46:36","2017-03-08 08:46:36",3
"Sonatype Nexus","invalid nexus 2.x npm packages will fail the upgrade to nexus 3.x with 500 internal server error","An invalid npm package causes the migration to Nexus 3 fail with a 500 error.        The cause of issue is shown in the Nexus 2 logs      Cause of the issue is the following file:    sonatype-work/nexus/storage/npm-internal/somecompany-stilguide/-rev/undefined    This should really not cause a failure. The migration should just log a warning and skip this invalid component.  ",Bug,Major,Closed,"2017-03-07 15:08:09","2017-03-07 15:08:09",1
"Sonatype Nexus","Support of /v1/repositories/(namespace)/(repository)/tags in Nexus docker repositories","Is there support for an API endpoint of /v1/repositories/(namespace)/(repository)/tags in Nexus Docker repositories?    I have tried something like http://host:8081/respository/dockerRepo/v1/repositories/test/alpine/tags and this gets back a list of tags but the image ids have a value of null. Is there a way to get this information?    Example of output: {v1:null,v2:null,latest:null}    Note, if I try http://host:8081/v1/repositories/test/alpine/tags with a Nexus docker repository, I get back a 404.    In contrast, when I try http://host:8081/v1/repositories/test/alpine/tags on a Docker Registry, I get back the desired result:  {1.0: c18611c4d8b6fc5274af110637d10a815c07cbe6c32a31183bcfe9be2c56577c, 2.0: c18623c3c8b6ec5274bf110637d11e815c17cbe6c32a41183bcfe9bd8d56877d, 2.0.1: 8dbf8fb45d7b8fead97e13dc523eec9fa064dde3c2aeb9eedd6e6d31786c48b9, latest: 8dbf8fb45d7b8fead97e13dc523eec9fa064dde3c2aeb9eedd6e6d31786c48b9}    Thus, is there a way to accomplish this?",Bug,Major,Open,"2017-03-07 01:04:33","2017-03-07 01:04:33",2
"Sonatype Nexus","raw proxy repository negative not found cache does not cache correctly","While testing caching, I checked NFC in the raw repository by performing the below steps.  I was unable to get it working.  npm did work in 3.2.1 using the same procedure so raw, at least more recently, just doesn't seem to be working.    Steps I took:  1) Create raw hosted repo  2) Create raw proxy repo (of #1). Have NFC timeout as 5 min (from default 1440 min).  3) Hit the url for package on proxy (e.g. http://localhost:8081/repository/rawproxy1/ticketlist.txt). Should return not found.  4) Push the file (I used curl; curl -v --user 'admin:admin123' --upload-file ./ticketlist.txt http://localhost:8081/repository/rawhosted1/ticketlist.txt).  5) Before 5 minutes hit the url for package on proxy (e.g. http://localhost:8081/repository/rawproxy1/ticketlist.txt). EXPECTED not found but BUG/Test Concern #1: It loads.",Bug,Major,Closed,"2017-03-06 19:38:47","2017-03-06 19:38:47",2
"Sonatype Nexus","FileBlobStore error handling makes it impossible to see what blob causes a runtime exception","A user has a snapshot removal task failing due to a problem with a file in the blobstore:        There is a problem with the creation timestamp:    https://github.com/sonatype/nexus-internal/blob/release-3.2.1-01/components/nexus-blobstore-file/src/main/java/org/sonatype/nexus/blobstore/file/internal/BlobAttributes.java#L117    But we only catch IOException, so it is now impossible to see what blob caused this:    https://github.com/sonatype/nexus-internal/blob/release-3.2.1-01/components/nexus-blobstore-file/src/main/java/org/sonatype/nexus/blobstore/file/internal/FileBlobStore.java#L378    Is there a reason not to catch Exception there, and then wrap it up in BlobStoreException?  We need see what blob caused the issue whenever any exception is thrown.    ",Bug,Major,Closed,"2017-03-03 15:30:56","2017-03-03 15:30:56",1
"Sonatype Nexus","remote https repository with TLS client certificate loaded in NXRM JVM keystore not trusted","When a remote repository requires SSL client certificate authentication, Nexus 3 (3.2.0-01) does not match the client certificate present in the keyStore. With SSL debugging enabled, it logs:  {{2017-03-01 16:38:02,934+0100 INFO  [qtp1053574947-168] adm_lop sun.security.ssl.ClientHandshaker - Warning: no suitable certificate found - continuing without client authentication}}  As a result, we can't see the client certificate being sent to the remote repository in a tcpdump.  In the end Nexus throws an exception:  {{java.io.IOException: Received fatal alert: handshake_failure}}    The keyStore and trustStore's are the same as the previous old version 2 (nexus-2.14.2-01) where it was working well. A test with SSLPoke with the same setting and stores works fine. I attached log files for the working SSLPoke and the non-working Nexus.",Bug,Major,Closed,"2017-03-02 12:56:27","2017-03-02 12:56:27",3
"Sonatype Nexus","Book example fails to download required dependencies","Looks like between 3.2.0 and 3.2.1 something in the dependency chain here has changed substantially enough to make this example fail. Looks suspiciously like one of the libraries we use was upgraded and somehow we no longer have concrete versions for several dependencies, therefore attempting to download 'working' versions of these libs. See attached output for more(captured with these params while running the script: -Dgroovy.grape.report.downloads=true -Divy.message.logger.level=4 ).  Likely will require updating the dependency info in the script, but not necessarily in a trivial way if the problem really is dependency poms missing concrete version info.    https://github.com/sonatype/nexus-book-examples/blob/055bfa74f6c2761e234834537c3d4e89bc06afb9/scripting/complex-script/addUpdateScript.groovy    ",Bug,Major,Closed,"2017-03-01 21:01:34","2017-03-01 21:01:34",0.5
"Sonatype Nexus","add privilege that controls access to health check summary report","I've granted every healthcheck and iq privilege there is to a user, and they still do not have permissions to view the healthcheck summary report.    It should be possible for a non-admin user to view both the summary and the detail health check report in Nexus 3.    This was tested in both Nexus 3.2.1 and 3.3.0-SNAPSHOT.    A support zip with my test configuration is attached, the test user has credentials test:test.    ",Bug,Major,Closed,"2017-03-01 16:51:46","2017-03-01 16:51:46",2
"Sonatype Nexus","targetFramework attribute in NuGet nuspec file is rendered as Unsupported","Nexus does not correctly parse the targetFramework attribute from the nuspec file when we push an artifact to the nuget feed hosted on Nexus. When we check the dependency attribute on the uploaded artifact, it shows Unsupported. E.g. the following values are shown in the dependency attribute:     NETStandard.Library:1.6.0:Unsupported|System.Collections.Specialized:4.0.1:Unsupported|System.Runtime.Serialization.Primitives:4.1.1:Unsupported|Microsoft.CSharp:4.0.1:Unsupported|System.Dynamic.Runtime:4.0.11:Unsupported|System.Reflection.TypeExtensions:4.1.0:Unsupported|System.ComponentModel.TypeConverter:4.1.0:Unsupported    When downloading the artifact with Nexus as a proxy, it works fine what means that there are no Unsupported values but the real version mentioned there.    For me, it looks like the functionality that was built in NEXUS-6158 is broken as it doesn't just take the information that is provided from the nuspec file but is replacing that by Unsupported in the feed. Or is this expected behavior? It's not about having this information searchable via the API or so, it's about that it's just not there.",Bug,Major,Closed,"2017-03-01 16:07:58","2017-03-01 16:07:58",1
"Sonatype Nexus","invalid nexus 2.x NuGet repository files will cause nexus 3.x upgrade to fail with NullPointerException","Migration to Nexus 3 failed with following NullPointerException in the Nexus 2 instance.  From the stack trace we can see that the migration of Nuget repo is involved, but unsure of which nuget repo or exact cause of issue:    ",Bug,Blocker,Closed,"2017-03-01 14:19:27","2017-03-01 14:19:27",2
"Sonatype Nexus","Inconsistent behaviour with upload to snapshot repository","The following two snapshot paths are invalid and should really be rejected with 400 response.    com/sonatype/test/testapp/0.0-dev-SNAPSHOT/testapp-0.0-dev-1487857435-ecfcead.tgz   com/sonatype/test/testapp/0.0-dev-SNAPSHOT/testapp-0.0-dev-1488295749-d11e956.tgz    I am seeing inconsistent behaviour in both Nexus 2 and Nexus 3 when using a direct deploy method like below.    com/sonatype/test/testapp/0.0-dev-SNAPSHOT/testapp-0.0-dev-1487857435-ecfcead.tgz   * Nexus 2 uploads with 201 response   * Nexus 3 fails with 400 response    com/sonatype/test/testapp/0.0-dev-SNAPSHOT/testapp-0.0-dev-1488295749-d11e956.tgz   * Nexus 2 fails with 400 response   * Nexus 3 works with 201 response    h4. Expected    Nexus 2.x: We will not be making a change to Nexus 2.x codebase due to the potential regression risks related to users deploying or retrieving non-timestamped SNAPSHOT versions, which Apache Maven 2.x and Maven 1.x did allow.    Nexus 3.x: Nexus 3.x has dropped Maven 1.x support.    Nexus 3.x must allow deployments and retrieval of two types of SNAPSHOT versioning schemes:   - example-1.0-SNAPSHOT.jar ( deprecated and not recommended in industry )   - example-1.0-20171208.202054-1.jar ( preferred and modern )    All other invalid paths should be rejected for STRICT policy. Keep in mind there is a very strict layout for Maven 2 format repos.    The literal {{example-1.0-SNAPSHOT.jar}} form of file name is possible in Maven 2.x or versions of Apache IVY. Sonatype does not recommend using non-timestamped snapshot versioning schemes, and we do not optimize for that use case, however if you do it should work.",Bug,Major,Closed,"2017-03-01 13:35:57","2017-03-01 13:35:57",2
"Sonatype Nexus","NullPointerException while rebuilding maven metadata if database operations timeout",,Bug,Major,Closed,"2017-03-01 12:13:26","2017-03-01 12:13:26",1
"Sonatype Nexus","Repository health check fails for angular/core npm package.","Trying to run repository health check on npm package @angular/core/-/core-2.4.8.tgz results in a failure:    {quote}  Unable to identify component: Malformed npm component with path '/@angular/core/-/core-2.4.8.tgz'. If this is packageRoot, try selecting the tarball instead  {quote}    The log shows:    ",Bug,Major,Closed,"2017-02-28 20:30:11","2017-02-28 20:30:11",2
"Sonatype Nexus","Last downloaded date is updated on upload","We renamed the last_accessed field to last_downloaded as part of the work on NEXUS-12360, but the existing semantics don't entirely match what one would expect given the rename. In particular, there are a few situations where the Last Downloaded timestamp is updated when content is uploaded, and this doesn't match the expectations for it not to be.    Overall there are a couple of obvious solutions:    # We can rename the field (again) to something more neutral.  # We can stop updating this field for upload operations.    Given the expectations in NEXUS-12360 and conversations since then, I'm assuming we'll want to stop updating the field for upload operations and the like.",Bug,Major,Closed,"2017-02-28 18:11:29","2017-02-28 18:11:29",8
"Sonatype Nexus","allow HTTP POST for uploading scripts to scripting API","https://books.sonatype.com/nexus-book/reference3/scripting.html#scripting-configuration    In order to add a script into Nexus, you need to wrap the script in JSON first, then upload JSON using PUT.    This involves two steps:    1) package script as JSON  2) use a client like curl or wget to upload it    Wrapping a large script in json is cumbersome. You need to be familiar with JSON escaping rules.    It would be user friendly to allow POST *of* the groovy script as a file param as well as the other json payload attributes as POST parameters.    Idea from multiple customer feedback they would find it handy to avoid needing step 1.  ",Improvement,Major,Closed,"2017-02-23 18:51:11","2017-02-23 18:51:11",1
"Sonatype Nexus","npm proxy receiving connection reset responds to client with status 500 instead of 404","If an npm proxy repository receives a connection reset when connecting to it's remote a 500 response is returned by Nexus.  This is true even if the inbound request is made through a group repository.   Also, the proxy is not auto-blocked when this happens.      Moving the affected proxy to the bottom of an npm group repository does not provide a workaround, inbound metadata queries result in outbound queries to all members of the group.    Expected:    1. The proxy should not return a 500 response when the remote can't be reached, it should return 404, and log the connection problem.  2. The proxy should auto-block when it's remote can't be reached.    Testing note... I used cynic to set this up, so I could quickly get the connection reset error happening.  Note that cynic does not run on Mac OSX, so it's necessary to use Linux if you want to use this method.    https://pypi.python.org/pypi/cynic/1.0",Bug,Major,Closed,"2017-02-23 18:42:04","2017-02-23 18:42:04",2
"Sonatype Nexus","add support for npm login bearer token authentication to proxied upstream NPM private repositories","When configuring an NPM proxy repository HTTP Authentication allows for Authentication type of Username (I guess that means HTTP Basic Auth) and Windows NTLM.   It would be useful to also support the NPM specific npm login AKA npm Bearer Token authentication method.    *Acceptance*   * NXRM administrators can configure npm proxy repos to use _npm bearer token_ the authentication method with the upstream repository",Story,Major,Done,"2017-02-23 09:03:45","2017-02-23 09:03:45",3
"Sonatype Nexus","bower install fails when user has only group level privileges","If a user has read privileges to a bower group, but not the underlying bower proxy, then the bower install <package> will fail for any package that is not locally cached.    Steps to reproduce:  # Setup a bower group {{bower-group}} that has a bower proxy {{bower-proxy}} as a member  # Setup a user ({{boweruser}}) that only has view access to {{bower-group}} (i.e. {{nx-repository-view-bower-bower-group-*}})  # Try to install a bower package that is not locally cached in proxy {{bower-proxy}}  # Configure {{.bowerrc}} to use the {{boweruser}} user:      The bower install command will fail like the following:  ",Bug,Major,Closed,"2017-02-22 21:50:57","2017-02-22 21:50:57",1
"Sonatype Nexus","The https.protocols system property does not work for Nexus transport","See here:    https://issues.apache.org/jira/browse/HTTPCLIENT-1595    The https.protocols java system property does not work with httpclient 4.3.6, which is used by Nexus 2.14.3 as it's outbound transport.    This also affects clients built on the nexus-client-core, including (in particular) the nexus-staging-maven-plugin.  This means that if you've got builds running that require Java 7, and they are talking to a Nexus that uses newer TLS protocols the builds will not work.    We will need to bump up our httpclient version to fix this problem.",Bug,Major,Closed,"2017-02-22 15:40:40","2017-02-22 15:40:40",2
"Sonatype Nexus","GET request to Nexus  Pro raw format group repository trigger 500 MissingFacetException No facet of type AttributesFacet","in Nexus pro 3.2.1 with *a license installed that activates the IQ Quarantine support*:  1. Create a RAW proxy repository to https://services.gradle.org/ with default options.  2. Configure a RAW group repository with the RAW proxy as the lone member  3. Do not have IQ Server configured ( if configured may not matter, but it can happen if not configured).  4. send a GET request to the RAW group like this:    5. The request responds with:    6. The nexus log contains a stack trace such as this:        h2. Expected    - the zip file is downloaded and cached as expected through the proxy repo  - given the response reason phrase includes the exception message, might be worth verifying that response reason phrase text is parsed to confirm to the spec, which is _recommended_ up to 8000 octets long and a _required_ certain subset of characters.  https://tools.ietf.org/html/rfc7230#section-3.1 reason-phrase  = \*( HTAB / SP / VCHAR / obs-text ) - *Note: the reason phrase in this case appears to comply just fine.*    h2. Workaround    - request the file directly through the proxy repository instead, by passing the group repo, works fine.  - Nexus OSS does not have this problem          ",Bug,Major,Closed,"2017-02-21 13:13:26","2017-02-21 13:13:26",1
"Sonatype Nexus","NEXUS-10154 is not fixed in our official docker images","The fix for NEXUS-10154 was to add this system property to $INSTALL_DIR/conf/nexus.properties:        But the Nexus 2 docker images don't use our bootstrapper, so this file isn't processed.  Therefore these docker images are susceptible to NEXUS-10154.    We should modify our docker images to set this system property.",Bug,Major,Closed,"2017-02-17 20:56:40","2017-02-17 20:56:40",1
"Sonatype Nexus","Crowd realm is missing 'Clear Cache' option like the LDAP realm has","It appears the caching used in Shiro could allow for a 'Clear Cache' button for Crowd Realms, just as 'Clear Cache' is available for LDAP Realms.     The inability to manually clear credentials cached from Crowd is a problem when trying to workaround and caching problems.    This also relates to the configuration of realm specific cache timeout settings in: https://issues.sonatype.org/browse/NEXUS-9754, as if it is determined we are caching Crowd credentials via Shiro, then we should also allow configuration of the Crowd cache timeout.",Bug,Major,Closed,"2017-02-14 23:03:21","2017-02-14 23:03:21",2
"Sonatype Nexus","Crowd cache entries do not expire properly","1. Create a Crowd Realm in Nexus 3. Add a user in crowd and verify you can login to Nexus with that user.    2. Change the Crowd users password via the Crowd admin pages.    3. Close the browser used to login to Nexus, restart the browser and attempt to login to Nexus. The old password will still work, and the new (current) password does not work win Nexus for the crowd user.    * Note that if you do log out of the UI the cache entry is cleared, and the new password will work the next time.      It appears this is related to how we use Shiro caching realms.",Bug,Major,Closed,"2017-02-14 22:53:10","2017-02-14 22:53:10",0.5
"Sonatype Nexus","nexus-public base template binary fails to start due to DependencyResolver$UnresolvedDependencyException","While testing 3.2.1, I ran ./run.sh and forgot to designate pro or oss.  This ends up running base.  However, I noticed that my run did not succeed, it errored and shut down with the below.    On repro attempt, I did notice that if you run oss/pro first, it failed with different errors (I didn't write them down).  However, if you do a fresh build then run ./run.sh this seems reproducable.      Attaching full log as well in case I missed something.    As far as I know this is not intentional.  I am pretty sure I've run base in the past without modifications, however, it stopped being useful to me so haven't done so in a while.  If intentional, it'd be good to know what to do to get it working (as well as to know that).    Acceptance criteria:  the base template distribution will start without error",Bug,Major,Closed,"2017-02-14 16:37:09","2017-02-14 16:37:09",3
"Sonatype Nexus","add a dry run mode to the Restore Asset/Component metadata from Blob Store task","*Background*   The repair/rebuild task first introduced in NEXUS-11213 has the potential to make quite a few changes to data and/or blobs, especially in a post-restore situation.    *Acceptance*   * Add a mode to the rebuild/repair task that causes it to log the changes it would make, but not actually make any changes to blobs and/or metadata.   * Line items should still be made in a long-running task log for the run.   * Each task log entry should clearly indicate it was possible but not actually performed. (Some clear prefix?)",Story,Major,Done,"2017-02-13 20:59:42","2017-02-13 20:59:42",3
"Sonatype Nexus","if the component database references a soft-deleted blob then prevent blob store compaction task from hard deleting the blob","*Background*   An unwise sequence of backup and restore actions can produce a database that refers to missing blobs. (Example, drop a repository, restore the component database to an earlier state, start the system.)    *Acceptance*   * Blob store compaction does not delete blobs that are still referenced by component metadata.   * Mass deletions/compactions (e.g. dropping a repo) should still be performant.   * Make an entry in the long-running task log to record:   ** Every blob deletion that happens in compact   ** Every blob we choose NOT to delete due to a reference from component metadata",Story,Major,Done,"2017-02-13 20:49:39","2017-02-13 20:49:39",3
"Sonatype Nexus","attempt to refetch proxy repository content from remote when a referenced local blob is missing","*Background*   In the case of a damaged/ill-timed blobstore backup/restore, it's possible there are some missing blobs.    *Acceptance*   * If a blob in a proxy repo is missing, rather than immediately returning a 500 error, Repo attempts to refetch it.   * If the content is available in the remote, it is downloaded.    *Notes*   We should ensure we're only trying this for 'missing blob' situations that correspond to proxied artifacts. If it's a missing blob for cached metadata, there will be nothing to refetch.",Story,Major,Done,"2017-02-13 20:37:36","2017-02-13 20:37:36",3
"Sonatype Nexus","parsing dates in some gemspec files could fail with IllegalArgumentException: Invalid format","Nexus 3.2 is not able to serve the gem `barcode v2.0` via a rubygems proxy repo. It looks like it is having issue parsing a date.            actual barcode-0.2 gemspec:       This same request works in Nexus 2.14.2.    ",Bug,Major,Closed,"2017-02-10 13:43:52","2017-02-10 13:43:52",1
"Sonatype Nexus","UI Danger error message when enabling RHC on a Maven Snapshot Repo.","When clicking on Enable Health Check on a Maven snapshot repository, the following Danger error is displayed.    !Enable RHC on snapshot repo .png!    Although a RHC is not supported for Maven snapshot repositories, either a more informative message should be given or the Enable Health Check button should be disabled.",Bug,Major,Closed,"2017-02-09 17:04:05","2017-02-09 17:04:05",1
"Sonatype Nexus","Task to populate blobCreated dates and asset owner fields","*Background*  Once we've built NEXUS-12360, we need a way to backfill data from the (hidden) blob creation dates and [asset owner fields|https://issues.sonatype.org/browse/PE-165] in the blob store.    *Acceptance*  * There is a way for an admin user to populate Asset.blobCreated from the blob created dates in the blob store.  * {{blobUpdated}} should be set to the same date (since we don't know if it's been updated since then).  * Since one-off, user-visible, version-specific upgrade tasks aren't good, consider rolling this behavior into a general metadata/blob store reconciliation task (e.g. the same task from NEXUS-11213).  * Update documentation to describe the new scheduled task/behavior of the scheduled task.",Story,Major,Done,"2017-02-08 22:50:05","2017-02-08 22:50:05",3
"Sonatype Nexus","expose blob created and updated dates to avoid confusion with last updated date","*Background*  The 'last updated' field of Asset is confusing users, who think it shows when the content arrived. It doesn't, it indicates when the record itself was last updated (just like the same field on Component).    The information they care about isn't actually available - NXRM has it, but it's buried in blob store metadata.    *Acceptance*  * Remove the 'lastUpdated' field from the Asset metadata summary. This is an internal field that tracks when the metadata record has changed, and users don't care about it.  * Add two new Date fields to asset:  ** {{blobCreated}} - touched when a blob is first attached to the asset  ** {{blobUpdated}} - touched on creation, and when a new blob (i.e. different hash) is attached to the asset  ** Rename {{lastAccessed}} to {{lastDownloaded}} for clarity (e.g. it refers to when the content was downloaded, not when someone last had a look at the asset metadata through search/browse)  * Add the two new fields to the Asset summary.  * Update the book documentation to explain the fields.  ** Currently the [field descriptions|https://books.sonatype.com/nexus-book/reference3/using.html#_search_results] don't add value.    *Notes*  * Looking ahead to fabric, these fields still are 1:1 with the Asset - multiple blob_refs don't require us to have multiple created/updated fields, because the expectation is that the blobs will all be identical (barring corruption). These dates represent when they arrived in NXRM, rather than in a particular blob store. (The blob stores will continue to record that.)    *Technical Notes*  * blobCreated and blobUpdated will need to be nullable for situations like NuGet assets that don't have blobs.  ",Story,Major,Done,"2017-02-08 22:43:32","2017-02-08 22:43:32",3
"Sonatype Nexus","MavenModels throws an IOException when attempting to parse an empty InputStream","The Maven facet attempts to fill in information about a pom using the {{MavenModels.readModel}} function. If the supplied input stream is empty, this throws an exception and causes issues upstream when we (for example) attempt to migrate a zero-length pom or deploy one to a hosted repository (see stack trace of resulting HTTP 500 error below).    The javadoc for the method in question says that it should return \{@code null\} if input not parsable. It seems more consistent to return null when the input stream is empty instead of throwing an EOFException, but what would that cause unintended side-effects?    For reference, NX2 does not reject deployments of empty POMs.    ",Bug,Major,Closed,"2017-02-08 18:57:12","2017-02-08 18:57:12",1
"Sonatype Nexus","Faulty result ordering for NuGet searches","As found in NEXUS-12028, NuGet searches translate to db queries like    Note that the {{ORDER BY}} clause refers to the non-existing asset properties {{id}} and {{version}} instead of {{attributes.nuget.id|version}}.    At first glance, the cause might be https://github.com/sonatype/nexus-internal/blob/84a2d0537cb61ea16318e2748019f197bfb6b800/private/plugins/nexus-repository-nuget/src/main/java/com/sonatype/nexus/repository/nuget/odata/ODataUtils.java#L182 which doesn't consider the {{COLUMN_ALIASES}}.",Bug,Major,Closed,"2017-02-07 21:59:56","2017-02-07 21:59:56",2
"Sonatype Nexus","query parameter names for NuGet search requests are not case-insensitive","Fallout from NEXUS-12028: The request log from that ticket suggests that NuGet searches employ case-insensitive query parameters, i.e. {{/FindPackagesById()?Id=foo}} vs {{/FindPackagesById()?id=foo}}. Our current code however expects case-sensitive query parameters (cf. https://github.com/sonatype/nexus-internal/blob/84a2d0537cb61ea16318e2748019f197bfb6b800/private/plugins/nexus-repository-nuget/src/main/java/com/sonatype/nexus/repository/nuget/odata/ODataUtils.java#L127). This leads to wrong database queries if the parameter case in the request doesn't match the code's expectations, e.g.  - {{select from asset where (LOWER(attributes.nuget.id) = :p0) and (bucket=#25:0) ORDER BY attributes.nuget.download_count DESC, id asc, version asc, parameters: \[p0=foo\]}} vs  - {{select from asset where (bucket=#25:0) ORDER BY attributes.nuget.download_count DESC, id asc, version asc, parameters: \[\]}} (missing id criteria)  ",Bug,Major,Closed,"2017-02-07 21:49:04","2017-02-07 21:49:04",1
"Sonatype Nexus","NuGet queries against asset attributes can be slow due to non-optimized indexes","Certain NuGet query/download/update requests from visual studio 2015 are reported to be slow in Nexus 3.1    Nexus 2.14 does not exhibit the slowness.    The following NuGet related log message from a customer indicates slow query performance:        asset.attributes is a distinct data structure from other properties like asset.name, asset.format etc. [ code reference|https://github.com/sonatype/nexus-internal/blob/e28b4254688e26ea6daae74b67ad85c3936db85e/components/nexus-repository/src/main/java/org/sonatype/nexus/repository/storage/MetadataNodeEntityAdapter.java#L53] - therefore this excludes this issue being a duplicate of NEXUS-12310 where a missing index on component name was the problem.     'attributes.nuget.id' is not handled with an index    Also there are no indices around attributes.nuget.id in AssetEntityAdapter, so these kind of queries are non-performant because they do table scans.    For NuGet, users can essentially write their own queries where they can do pretty much anything non-performant, but we should ensure the sunny day uses cases by common clients are supported in a performant manner.",Bug,Major,Closed,"2017-02-07 21:40:15","2017-02-07 21:40:15",8
"Sonatype Nexus","Log spam when a user's session expires while viewing the repositories UI","When you're looking at the repository list in the nexus UI it polls the repository status using this call:    {quote}  127.0.0.1 - - \[07/Feb/2017:12:38:36 -0500\] GET /service/extdirect/poll/coreui_Repository_readStatus?_dc=1486489116483 HTTP/1.1 200 189 8  {quote}    When a user's session expires, the poll request fails. This is logged at ERROR level with a  stack trace.      This should not be logged at ERROR, this is a normal occurrence. -The message should be logged at INFO, and the stack trace logged at DEBUG.- The message should be logged at DEBUG with no stack trace (and should _definitely_ not be at ERROR level).     ",Bug,Major,Closed,"2017-02-07 19:14:09","2017-02-07 19:14:09",1
"Sonatype Nexus","Storage consideration when upgrading from 2.x to 3.x","The upgrade documentation should mention that you need double the storage as the data is duplicated when using file copy or downloading method to migrate.    [20.5.7. Data Transfer Methods|https://books.sonatype.com/nexus-book/reference3/upgrading.html#upgrade-methods]",Bug,Minor,Closed,"2017-02-06 14:36:39","2017-02-06 14:36:39",0.5
"Sonatype Nexus","scripting should support mapping roles from non-default sources","org.sonatype.nexus.security.SecurityApi has an addRole method:        This method does not allow specifying the role source, the implementation uses the default source (Default Authorization realm)    While it can work that you can create a role in the default source, and still have that picked up by LDAP or crowd, this seems to be by accident only, is not intuitive and a compatibility byproduct from Nexus 2.    This implicit byproduct is not a good long term approach.    Users want to map roles explicitly to LDAP and CROWD, not the default realm and providing a way to specify the role source would allow that.",Improvement,Major,Open,"2017-02-03 21:31:51","2017-02-03 21:31:51",2
"Sonatype Nexus","`npm publish` on an already published package version does not update all changed package metadata","I use the Nexus Repository for private NPM repository with allow-redeploy enabled. And the problem is that the system is not deleting dependencies in package.json at same module version number republished.    For example:   I have published package at version 0.0.2-SNAPSHOT  http://localhost:8081/nexus/content/repositories/npm-private/fooPackage/    I will get the metadata descriptor:       Then i will change dependencies for version 0.0.2-SNAPSHOT to this      after npm publish I will get from http://localhost:8081/nexus/content/repositories/npm-private/fooPackage/        I replicated this bug at latest docker images sonatype/nexus:oss and sonatype/nexus3.    I know that republishing in NPM is considered as an anti-pattern. But you are allowing this option in private repo and it is very usefull, because we using the snapshot versions in development cycle at it is a bit pain to change the version everytime if there is any update in snapshot.    I'm using this as a workaround now : https://support.sonatype.com/hc/en-us/articles/221433608-Deleting-a-specific-npm-package-version-in-Nexus-Repository-Manager-2-x    Thanks",Bug,Major,Closed,"2017-02-01 07:42:29","2017-02-01 07:42:29",2
"Sonatype Nexus","Remote Storage URL should be a required for proxy repository configuration","Just noticed that you can freely create a proxy repository without entering a Remote Storage url.  Seeing as this is a rather important part of a proxy repository, feels like this should be a required field.    Note: JoeT also validated that was an issue in 3.2.0, so this is NOT a regression",Bug,Minor,Closed,"2017-01-30 14:25:38","2017-01-30 14:25:38",0.5
"Sonatype Nexus","reduce JVM heap memory consumed by group repository 404 not found responses","AbstractGroupRepository collects any throwables thrown from its member repositories when requesting content and stores them in a map (memberThrowables) which it then propagates upstream inside a GroupItemNotFoundException. The stored throwables are only used when handling 'describe' requests.    For complex setups with lots of nested groups and many concurrent requests these throwables can end up taking a significant amount of heap, only never to be used because the requests are almost exclusively non-describe requests.    By skipping collection of these throwables for non-describe requests we should reduce pressure on the heap for all users (those with complex setups should see the most benefit).",Improvement,Major,Closed,"2017-01-27 18:03:47","2017-01-27 18:03:47",2
"Sonatype Nexus","book mentions upgrade options that are not available","https://books.sonatype.com/nexus-book/reference3/upgrading.html#upgrade-content    This section of the book implies that detailed parts of configuration, content and security can be selectively migrated to Nexus 3.    In fact that is not true anymore, due to the complexity that can entail. During initial upgrade testing and design, it was determined this level of flexibility was too error prone and potentially confusing for end users.    Now there are only two options:    - upgrade repositories and content ( and user accounts and associated security )  - Server configuration    The whole section of the book should be revised to match the current implementation.  ",Bug,Major,Closed,"2017-01-25 14:40:09","2017-01-25 14:40:09",1
"Sonatype Nexus","clarify that migrating repositories and content also migrates user accounts","A user was recently surprised that Nexus 2 user accounts are also migrated to Nexus 3, even if the  Server Configuration option was not checked during upgrade.    In fact migrating user accounts like this was deliberate, due to complex interactions that can occur between user accounts and custom roles and privileges possible in Nexus 2.    The book should clarify that migrating user accounts will happen, even if the Server configuration option is not checked.    ",Improvement,Major,Closed,"2017-01-25 13:59:48","2017-01-25 13:59:48",0.5
"Sonatype Nexus","Order by version incorrect","Ordering components on a repository does not use numerical order but instead does string comparison.    Therefore when sorting I see:  packagename-1.2  packagename-1.10  packagename-1.0    instead of  packagename-1.10  packagename-1.2  packagename-1.0    This is such a simple change and yet has such a large impact on usability that it should just be done. Especially since it's been dragging along for quite a long time.",Bug,Major,Closed,"2017-01-25 11:12:34","2017-01-25 11:12:34",5
"Sonatype Nexus","Generic LDAP Server UI configuration template should not have password attribute set by default","The Generic LDAP Server template has a value in the password attribute field.    Setting the password attribute is almost never needed, and in fact, it usually causes login failures.  We should remove this value from our Generic LDAP Server template.      When the password attribute is not set an LDAP bind will be done, which is what you want 99.9% of the time.    ",Bug,Minor,Closed,"2017-01-24 18:02:37","2017-01-24 18:02:37",0.5
"Sonatype Nexus","nxrm3 exposes maven snapshot version numbers in project metadata in release-only proxy repos","as a simple example, create a proxy repo in nx2 that points to the jboss repo (http://repository.jboss.org/nexus/content/groups/public/), but set the repository policy to Release. Next, create a group that includes maven-central and the jboss repo. Since the jboss repo hosts both snapshots and releases, you can see snapshot versions in the metadata for this project here:        However, when you do the same request against the group repository, those snapshot versions are not in the project metadata:        In nx3, the behavior is not preserved. As an experiment, I created a hosted repo that has a release policy of mixed, allowing both snapshots and releases. I called it snapsandrels. Next, I created a proxy repo with a release policy of Release and pointed it to snapsandrels. Last, I created a group repository that included the release-only proxy to snapsandrels and maven central (so that I could build a project against it). After deploying a snapshot directly to snapsandrels, you can grab the project metadata from the group repository:         However, nx3 doesn't let you retrieve that snapshot artifact because of the release policy. ",Bug,Major,Open,"2017-01-24 16:55:59","2017-01-24 16:55:59",5
"Sonatype Nexus","repository requests to paths containing certain characters may fail with status 500 Illegal character in path at index","*Acceptance*  Repository path parsing needs to be made more robust as currently it can fail for paths containing spaces. Secondly when a path cannot be parsed it should send back a 400 response (bad request) instead of letting the parse exception propagate all the way back to the view servlet.    *Example*  ",Bug,Minor,Closed,"2017-01-24 13:57:00","2017-01-24 13:57:00",1
"Sonatype Nexus","Partial coordinates for maven metadata","*Background*  1. A user creates a hosted repository, and a content selector permission based on a groupId, e.g. {{format == maven2 and coordinate.groupId =^ my.test}}  2. The user attempt to upload a .jar, via    3. Deployment fails:      The reason for this is that maven-metadata.xml files don't have any coordinates associated with them for the purposes of content selector evaluation. The workaround is that users can create a more complicated content selector that ORs the groupId with a path, but that's unnecessarily fiddly.    *Acceptance*  * maven-metadata.xml files have partial component coordinates assigned to them (just {{groupId}} and {{artifactId}}, I guess?) so that the scenario, above, works correctly and the client can update metadata.",Story,Major,Done,"2017-01-23 20:31:19","2017-01-23 20:31:19",3
"Sonatype Nexus","User token is deleted if external server cannot be reached","An error occurred when trying to contact a Crowd server to look up the user ID associated with a user token:    {quote}  2017-01-17 17:59:19,293-0600 WARN \[qtp1976642001-174945] *UNKNOWN com.atlassian.crowd.integration.rest.service.RestExecutor - The following URL does not specify a valid Crowd User Management REST service: https://com.server.com/crowd/rest/usermanagement/1/user?username=USERNAME  2017-01-17 17:59:19,355-0600 WARN \[qtp1976642001-174945] *UNKNOWN com.sonatype.nexus.crowd.internal.CrowdUserManager - Unable to look up Crowd user USERNAME due to javax.xml.bind.DataBindingException/javax.xml.bind.UnmarshalException  - with linked exception:  \[org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 1; Premature end of file.]  2017-01-17 17:59:19,355-0600 DEBUG \[qtp1976642001-174945] *UNKNOWN com.sonatype.nexus.usertoken.plugin.realm.UserTokenRealm - Removing stale user-token, target principals are no longer valid  2017-01-17 17:59:19,355-0600 DEBUG \[qtp1976642001-174945] *UNKNOWN com.sonatype.nexus.usertoken.plugin.internal.UserTokenServiceImpl - Removing record for: USERNAME  2017-01-17 17:59:19,371-0600 TRACE \[qtp1976642001-174945] *UNKNOWN org.sonatype.security.internal.UserIdMdcHelper - Set: USERNAME  {quote}    In response to this Nexus removed the user token.      Expected:    1. Nexus should not remove the token unless the server can be reached, and the user can't be found  2. Nexus should return a 401 if the server can't be reached.    ",Bug,Major,Closed,"2017-01-20 16:58:50","2017-01-20 16:58:50",2
"Sonatype Nexus","NXRM2 repository view privileges are not migrated to NXRM3 browse privileges during upgrade","A role in Nexus 2 may be assigned a repository view privilege - an example entry would take the form:    {{<repoid> - (view)}}    Where repoid is replaced with the actual repository identifier. Example:    {{company_repo-repo - (view)}}    When such a role is migrated to Nexus 3 by the upgrade process, this view privilege is omitted, resulting in users assigned that role to not be able to browse the contents of the affected repositories.  ----  In attached screenshots the somegroup role has view and read privileges to the somegroup group repository.    After upgrade, the somegroup role only has a read privilege. It should also have a nx-repository-view-<format>-somegroup-browse privilege for this group.  h4. Workaround    If you have a small number of affected roles, then assign the missing privilege manually to the affected Nexus 3 roles.    The missing privilege takes the form of this naming pattern:    {{nx-repository-view-<repo-format>-<repoid>-browse}}    Example:    {{nx-repository-view-maven2-company_repo-browse}}    Or you can assign view privileges to all repositories by using:    {{nx-repository-view-\*-\*-browse}}    If you have a large number of affected roles, then we advise waiting until we fix this issue before upgrading.               ",Bug,Critical,Closed,"2017-01-19 20:05:29","2017-01-19 20:05:29",2
"Sonatype Nexus","Support pushing Docker Windows Container images and loosen manifest validation to allow for 'foreign-layers'","I followed the instructions for setting up a Hosted Docker repository in Nexus. I'm using Windows containers on my Windows 10 machine. I created an image based off microsoft/nanoserver, which I try to push to the Hosted Docker repo in Nexus, but I am met with the following error: blob unknown: blob unknown to registry.     I switch Docker on my machine to use Linux containers, create an image, upload that image to the Hosted Docker repo in Nexus, and it succeeds.     My conclusion is that the Hosted Docker repo in Nexus is unable to store Windows Container images and there is no obvious place to configure the Nexus repo to host Windows Container images.    *Solution*  Minimally NXRM should be able to validate the pushed Manifest, taking into account that the 'foreign-layers' will never be in NXRM directly.",Improvement,Major,Closed,"2017-01-19 15:26:46","2017-01-19 15:26:46",2
"Sonatype Nexus","npm@4: searching a hosted repo a second time causes npm error","While reviewing npm@4, I noticed that I could search hosted repos and find results via the CLI (ie npm search --registry=http://localhost:8081/repository/npm-hosted/ whatever) however, after the first time I was getting an npm error not in the nexus.log but from npm.        Of note:  1) Resultant searches do show results (see above) before the error.  However, searches with no results JUST show the error which is confusing.  Marked minor because of this.  2) If you clear the cache (ie sudo rm -R ~/.npm) first this error does not occur.    This occurs in npm 4.0.0, 4.1.1 and 4.1.2.  It does not occur in 3.10.3.  I actually misanalyzed it as not occurring in 4.0.0 because I went from 3.10.3 to 4.0.0 without clearing cache (see #2 above).  This may be why this has not been seen much in the field.    I did not check older NX3 or NX2 at this time, however, because it's an npm CLI command, I doubt it'd make much difference.  I can check if desired.",Bug,Minor,Closed,"2017-01-18 19:41:08","2017-01-18 19:41:08",5
"Sonatype Nexus","gradually slowing upgrade of Nexus 2 site repositories to Nexus 3 raw repositories","Migration of large Nexus 2 site repositories containing many small files synonymous of typical published Maven 2 html/css/js sites, may gradually slow to a crawl when migrating into Nexus 3 raw repositories.    The slowness was seen with a Nexus 2 site repository of 485000 files ( double that if you include the related ./nexus/attributes files ).  The slowness is expected to be present during future publishing to the Nexus 3 RAW repo, even if the upgrade is eventually completed successfully.    Here are sample threads taken from a thread dump where the slowness was detected to eventually reach approx 1 <USER>linked item migrated per second. No disk issues were noticed to slow the <USER>linking, so the assumption is there is slowness in the code doing the migration.    {noformat:title=WAITING threads}  plan-executor-8-thread-1 id=270 state=WAITING      - waiting on <0x21e1bb52> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)      - locked <0x21e1bb52> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)      at sun.misc.Unsafe.park(Native Method)      at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)      at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)      at com.google.common.util.concurrent.Monitor.await(Monitor.java:1082)      at com.google.common.util.concurrent.Monitor.waitFor(Monitor.java:738)      at com.google.common.util.concurrent.Monitor$waitFor$0.call(Unknown Source)      at com.sonatype.nexus.migration.plan.StepExecutor.run(StepExecutor.groovy:111)      at com.sonatype.nexus.migration.plan.StepExecutor$run.call(Unknown Source)      at com.sonatype.nexus.migration.plan.Plan.runSteps(Plan.groovy:253)      at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)      at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)      at java.lang.reflect.Method.invoke(Method.java:498)      at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93)      at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325)      at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:384)      at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1024)      at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:69)      at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:166)      at com.sonatype.nexus.migration.plan.Plan$_doBegin_closure6.doCall(Plan.groovy:238)      at com.sonatype.nexus.migration.plan.Plan$_doBegin_closure6.doCall(Plan.groovy)      at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)      at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)      at java.lang.reflect.Method.invoke(Method.java:498)      at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93)      at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325)      at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294)      at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1024)      at groovy.lang.Closure.call(Closure.java:414)      at groovy.lang.Closure.call(Closure.java:408)      at groovy.lang.Closure.run(Closure.java:495)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)      at java.util.concurrent.FutureTask.run(FutureTask.java:266)      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)      at java.lang.Thread.run(Thread.java:745)        Locked synchronizers: count = 1        - java.util.concurrent.ThreadPoolExecutor$Worker@2a92b49    plan-executor-8-thread-2 id=271 state=WAITING      - waiting on <0x43ca5a69> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)      - locked <0x43ca5a69> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)      at sun.misc.Unsafe.park(Native Method)      at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)      at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)      at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)      at java_util_concurrent_BlockingQueue$take.call(Unknown Source)      at com.sonatype.nexus.migration.repository.ProcessChangesStep.sync(ProcessChangesStep.groovy:260)      at com.sonatype.nexus.migration.repository.ProcessChangesStep$sync.callCurrent(Unknown Source)      at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:52)      at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:154)      at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:158)      at com.sonatype.nexus.migration.repository.ProcessChangesStep.doRun(ProcessChangesStep.groovy:147)      at com.sonatype.nexus.migration.plan.Step.run(Step.groovy:271)      at com.sonatype.nexus.migration.plan.Step$run$1.call(Unknown Source)      at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48)      at com.sonatype.nexus.migration.plan.Step$run$1.call(Unknown Source)      at com.sonatype.nexus.migration.plan.StepExecutor.runSync(StepExecutor.groovy:168)      at sun.reflect.GeneratedMethodAccessor351.invoke(Unknown Source)      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)      at java.lang.reflect.Method.invoke(Method.java:498)      at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93)      at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325)      at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:384)      at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1024)      at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:69)      at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:166)      at com.sonatype.nexus.migration.plan.StepExecutor$_runAsync_closure1.doCall(StepExecutor.groovy:197)      at com.sonatype.nexus.migration.plan.StepExecutor$_runAsync_closure1.doCall(StepExecutor.groovy)      at sun.reflect.GeneratedMethodAccessor395.invoke(Unknown Source)      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)      at java.lang.reflect.Method.invoke(Method.java:498)      at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93)      at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325)      at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294)      at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1024)      at groovy.lang.Closure.call(Closure.java:414)      at groovy.lang.Closure.call(Closure.java:408)      at groovy.lang.Closure.run(Closure.java:495)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)      at java.util.concurrent.FutureTask.run(FutureTask.java:266)      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)      at java.lang.Thread.run(Thread.java:745)        Locked synchronizers: count = 1        - java.util.concurrent.ThreadPoolExecutor$Worker@3f5912e2    change-processing-9-thread-1 id=274 state=WAITING      - waiting on <0x7a65c73d> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)      - locked <0x7a65c73d> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)      at sun.misc.Unsafe.park(Native Method)      at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199)      at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:209)      at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285)      at com.orientechnologies.common.collection.closabledictionary.OClosableEntry.acquireStateLock(OClosableEntry.java:84)      at com.orientechnologies.common.collection.closabledictionary.OClosableLinkedContainer.acquire(OClosableLinkedContainer.java:267)      at com.orientechnologies.orient.core.storage.cache.local.OWOWCache.getFilledUpTo(OWOWCache.java:731)      at com.orientechnologies.orient.core.storage.impl.local.paginated.base.ODurableComponent.getFilledUpTo(ODurableComponent.java:135)      at com.orientechnologies.orient.core.storage.impl.local.paginated.OPaginatedCluster.readRecord(OPaginatedCluster.java:649)      at com.orientechnologies.orient.core.storage.impl.local.paginated.OPaginatedCluster.readRecord(OPaginatedCluster.java:628)      at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.doReadRecord(OAbstractPaginatedStorage.java:3234)      at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.readRecord(OAbstractPaginatedStorage.java:2864)      at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.readRecord(OAbstractPaginatedStorage.java:1091)      at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx$SimpleRecordReader.readRecord(ODatabaseDocumentTx.java:3227)      at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.executeReadRecord(ODatabaseDocumentTx.java:1921)      at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.load(ODatabaseDocumentTx.java:649)      at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.load(ODatabaseDocumentTx.java:102)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.executeSearchRecord(OCommandExecutorSQLSelect.java:588)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.serialIterator(OCommandExecutorSQLSelect.java:1619)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.fetchFromTarget(OCommandExecutorSQLSelect.java:1566)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.fetchValuesFromIndexCursor(OCommandExecutorSQLSelect.java:2450)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.searchForIndexes(OCommandExecutorSQLSelect.java:2265)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.searchInClasses(OCommandExecutorSQLSelect.java:1001)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLResultsetAbstract.assignTarget(OCommandExecutorSQLResultsetAbstract.java:209)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.assignTarget(OCommandExecutorSQLSelect.java:530)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.executeSearch(OCommandExecutorSQLSelect.java:512)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLSelect.execute(OCommandExecutorSQLSelect.java:488)      at com.orientechnologies.orient.core.sql.OCommandExecutorSQLDelegate.execute(OCommandExecutorSQLDelegate.java:74)      at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.executeCommand(OAbstractPaginatedStorage.java:2577)      at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.command(OAbstractPaginatedStorage.java:2523)      at com.orientechnologies.orient.core.command.OCommandRequestTextAbstract.execute(OCommandRequestTextAbstract.java:69)      at org.sonatype.nexus.repository.storage.MetadataNodeEntityAdapter.findByProperty(MetadataNodeEntityAdapter.java:147)      at org.sonatype.nexus.repository.storage.StorageTxImpl.findComponentWithProperty(StorageTxImpl.java:367)      at sun.reflect.GeneratedMethodAccessor463.invoke(Unknown Source)      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)      at java.lang.reflect.Method.invoke(Method.java:498)      at org.sonatype.nexus.common.stateguard.SimpleMethodInvocation.proceed(SimpleMethodInvocation.java:53)      at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39)      at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:270)      at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53)      at org.sonatype.nexus.common.stateguard.StateGuardAspect$1.invoke(StateGuardAspect.java:63)      at com.sun.proxy.$Proxy206.findComponentWithProperty(Unknown Source)      at org.sonatype.nexus.repository.raw.internal.RawContentFacetImpl.getOrCreateAsset(RawContentFacetImpl.java:131)      at org.sonatype.nexus.repository.raw.internal.RawContentFacetImpl$$EnhancerByGuice$$3286c0b4.CGLIB$getOrCreateAsset$2(<generated>)      at org.sonatype.nexus.repository.raw.internal.RawContentFacetImpl$$EnhancerByGuice$$3286c0b4$$FastClassByGuice$$af5c3f69.invoke(<generated>)      at com.google.inject.internal.cglib.proxy.$MethodProxy.invokeSuper(MethodProxy.java:228)      at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:76)      at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:45)      at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:77)      at com.google.inject.internal.InterceptorStackCallback.intercept(InterceptorStackCallback.java:55)      at org.sonatype.nexus.repository.raw.internal.RawContentFacetImpl$$EnhancerByGuice$$3286c0b4.getOrCreateAsset(<generated>)      at com.sonatype.nexus.migration.repository.migrators.RawHostedRepositoryMigrator.lambda$0(RawHostedRepositoryMigrator.java:47)      at com.sonatype.nexus.migration.repository.migrators.RawHostedRepositoryMigrator$$Lambda$149/1969362139.call(Unknown Source)      at org.sonatype.nexus.transaction.OperationPoint.proceed(OperationPoint.java:64)      at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:56)      at org.sonatype.nexus.transaction.Operations.transactional(Operations.java:200)      at org.sonatype.nexus.transaction.Operations.call(Operations.java:146)      at com.sonatype.nexus.migration.repository.migrators.RepositoryMigratorSupport.inStorageTx(RepositoryMigratorSupport.java:199)      at com.sonatype.nexus.migration.repository.migrators.RawHostedRepositoryMigrator.recordMetadata(RawHostedRepositoryMigrator.java:44)      at com.sonatype.nexus.migration.repository.migrators.RepositoryMigratorSupport.processChange(RepositoryMigratorSupport.java:135)      at com.sonatype.nexus.migration.repository.RepositoryMigrator$processChange$2.call(Unknown Source)      at com.sonatype.nexus.migration.repository.ProcessChangesStep$_submit_closure2.doCall(ProcessChangesStep.groovy:317)      at com.sonatype.nexus.migration.repository.ProcessChangesStep$_submit_closure2.doCall(ProcessChangesStep.groovy)      at sun.reflect.GeneratedMethodAccessor460.invoke(Unknown Source)      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)      at java.lang.reflect.Method.invoke(Method.java:498)      at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93)      at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325)      at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294)      at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1024)      at groovy.lang.Closure.call(Closure.java:414)      at groovy.lang.Closure.call(Closure.java:408)      at groovy.lang.Closure.run(Closure.java:495)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)      at java.util.concurrent.FutureTask.run(FutureTask.java:266)      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)      at java.lang.Thread.run(Thread.java:745)        Locked synchronizers: count = 1        - java.util.concurrent.ThreadPoolExecutor$Worker@2a8387f1    ",Bug,Major,Closed,"2017-01-18 13:45:48","2017-01-18 13:45:48",3
"Sonatype Nexus","HTTP Proxy host name setting accepts invalid characters such as space which can prevent server start","The host name filed of Nexus 3 http proxy settings accepts spaces. It should not.    Worse, once you've set a host name with spaces in it it prevents startup of the server.    ",Bug,Major,Closed,"2017-01-17 18:10:50","2017-01-17 18:10:50",2
"Sonatype Nexus","Upgrade never completes if source repository has zero length files in it","If a source repository has zero length files in it upgrade never completes, the continue button at the end of migration is never enabled.    Zero length files can be created in a Nexus 2 repository if the disk fills up, or the process runs out of file handles.      On the Nexus 3 side we see:        On Nexus 2 the request log shows it is asking for the zero length file over and over again:        Deleting the zero length files from repository storage in Nexus 2 allows the upgrade to continue.    h3. Expected    In most cases, a zero length file is not valid ( created due to out of disk for example, or some other error )    However we cannot guess why a zero length file exists. Maybe it is a marker file of some sort.    The consensus seems to be that zero length files should be migrated and Nexus 3 should handle them.    Add a single INFO log message per migrated component/asset on the nexus 3 side stating the full path and repo being processed, and that that path was zero-length.    Do not confuse a zero length file in nexus 2 with a failure to download all bytes from Nexus 2.  ",Bug,Major,Closed,"2017-01-13 19:33:25","2017-01-13 19:33:25",1
"Sonatype Nexus","Auto-blocked proxy repository logs gigantic stack trace, doesn't say what was blocked, or why","When a repository is auto-blocked in Nexus 3 a very large stack trace is logged.  The log message does not indicate why it was auto-blocked, nor does it indicate what repository was blocked.  So it's pretty useless.  Furthermore, this WARN with the stack is logged every single time a request comes into the proxy repository, which fills up the log.    The log message should indicate which repository was auto-blocked.  It should only be logged when the repository is first auto-blocked.   The stack trace should be logged at DEBUG.    ",Bug,Major,Closed,"2017-01-13 15:34:53","2017-01-13 15:34:53",1
"Sonatype Nexus","Upgrade wizard checks for hard link capability even though a different ingest method is chosen","If you choose the Download ingest method during migration, Nexus 3 still seems to perform filesystem checks for hardlinking. If the hardlinking is not possible, this fills the Nexus 3 log with stack traces for potentially every repo being migrated ( if the storage is not <USER>link capable).    h3. Expected    - do not perform <USER>link checking if a different ingest method is chosen    h3. Symptoms:    Stack traces in the nexus 3 log look something like this for every repo:    ",Bug,Major,Closed,"2017-01-13 15:12:26","2017-01-13 15:12:26",1
"Sonatype Nexus","PyPi packages are case sensitive and not correctly redirected","Having uploaded all the Flask package to my PyPi repository and its dependencies I am unable to use easy_install to install Flask.    The following  {code:}  > easy_install Flask  Searching for Flask  Reading http://hostname/repository/my-pypi/simple/Flask/  Authenticating as admin for  http://hostname/repository/my-pypi/simple/Flask/ (from .pypirc)  Couldn't find index page for 'Flask' (maybe misspelled?)  Scanning index of all packages (this may take a while)  Reading http://hostname/repository/my-pypi/simple/  Authenticating as admin for http://hostname/repository/my-pypi/simple/ (from .pypirc)  No local packages or working download links found for Flask  error: Could not find suitable distribution for Requirement.parse('Flask')      will start to work as it can find the module as the search url has the lowercase f. This will however eventually fail when it tries to install the dependency of Jinja2 due to the same reason as above. i.e it is looking for Jinja2 with a capital 'J', as Jinja2 is supplied as a dependency it is not easy to change it to ask for the lowercase j.     Easy Install works when pointing to pypi.python.org.    Pip works ok and can deal with the case issues, but the requirement to use easy_install is due to the integration with setuptools which relies on easy_install.    This is using nexus 3.2.0-01.  ",Bug,Critical,Closed,"2017-01-13 13:22:00","2017-01-13 13:22:00",2
"Sonatype Nexus","Pulling from Docker group generates error unless read access assigned directly to member","Create a docker group repository, and put a docker hub proxy repository in this group.    Disable anonymous access in Nexus 3.  Then create a test user, and grant them read access to the docker group repository, but not to the docker hub proxy repository.    They will not be able to pull any docker images through the group, they'll get a 404 response every time. If you grant them direct read access to the docker hub proxy then requests through the docker group repository will start working.    I also tested this scenario with Maven repositories, and for those transitive privileges worked.    I've attached a support zip file with my setup.        ",Bug,Major,Closed,"2017-01-12 21:53:25","2017-01-12 21:53:25",2
"Sonatype Nexus","JPQLGenerator.toJpqlLiteral NullPointerException for NuGet /Packages() resource as submitted by OctopusDeploy","An end user has reported that OctopusDeploy submitted the following query to their NuGet repository in Nexus 3:        This results in an NPE (see below).  I'm not sure if something is wrong with this query or not, but even if something is wrong  Nexus should not get an NPE.    This problem can be reproduced by sending the above query to any NuGet repository in Nexus 3.2.    ",Bug,Minor,Closed,"2017-01-11 14:30:48","2017-01-11 14:30:48",1
"Sonatype Nexus","If-Modified-Since header fails with NPM proxy repository","The Nexus Repository OSS 3 (in Version 3.0.1-01) fails with the common HTTP header 'If-Modified-Since' for NPM repositories.    The official NPM registry does support this header, thus Nexus should also support it. (see example requests in the attachment)    Even when Nexus does not support a '304 Not Modified' response for this case, the normal '200 OK' response should be returned instead of a '404 Not Found'.    This header appears when for example a HTTP proxy is used between the NPM client and Nexus repository, that tries to do HTTP caching.    (I did not see any mentions of this in the Release Notes for the newer 3.x releases, thus I did not yet try the newer versions.)",Bug,Major,Closed,"2017-01-11 11:58:15","2017-01-11 11:58:15",2
"Sonatype Nexus","Poor performance from Nexus 3 purge unused snapshots task","The purge unused snapshot task runs very slowly against large numbers of components.    This has caused database query timeouts, and triggered a secondary bug in the handling of those timeouts:  NEXUS-12040    This may be similar to NEXUS-11614, so it's possible the fixes for that issue may be relevant to fixing this one.      ",Bug,Major,Closed,"2017-01-10 19:04:46","2017-01-10 19:04:46",3
"Sonatype Nexus","Faulty handling of query timeouts in OrientAsyncHelper.QueueConsumingIterable","https://github.com/sonatype/nexus-internal/blob/c341bcc9311c122cc17d51df0abb30920b2fe33f/components/nexus-repository/src/main/java/org/sonatype/nexus/repository/storage/OrientAsyncHelper.java#L184    The {{queue.poll()}} invocation there yields no exception but {{null}} when the timeout elapses. This causes the following issues:  # {{hasNext()}} returning {{true}} when in reality no element is available  # {{next()}} returning a non-deterministic number of {{null}} elements tripping up processing of the query results, e.g.    # {{next()}} failing with {{NoSuchElementException}} although the caller previously checked {{hasNext() == true}} ({{next()}} calls {{hasNext()}} again and can observe a different value than the caller, like the end-of-query sentinel), e.g.  ",Bug,Major,Closed,"2017-01-10 14:31:37","2017-01-10 14:31:37",2
"Sonatype Nexus","NXRM3 does not use its SSL truststore for redirects","Configure Nexus to go through an http proxy server that rewrites remote site certificates using a private certificate.    Trust the remote certificate in Nexus ( add to SSL certificates UI as a trusted cert ).    When a request reaches the remote, the response may ask for a 302 redirect to a different host.    Nexus trusts the SSL certificate of the first host. When Nexus follows the 302 redirect, and gets a response, it will not trust the response and fail with PKIX errors as expected.    Go to the SSL UI, and add the certificate being returned from the second host manually using load from server and the host name of the redirect (in my case this was dseasb33srnrn.cloudfront.net).    The outbound requests will still fail with SSL handshake errors because the truststore is not used for the 302 redirect.    Example remote hosts that perform 302 redirects as normal course are as [https://registry-1.docker.io|https://registry-1.docker.io/] or [https://www.nuget.org|https://www.nuget.org/] - so at least docker and nuget proxy repositories are affected.  h4. Diagnosis    Set the logger     org.sonatype.nexus.httpclient.outbound    to level    DEBUG    Repeat the build requests into nexus that cause this problem. The logger will show you the different hosts that outbound requests are being 3xx redirected to.     Compare the serial number of certificates already added in your SSL Certificates truststore to the certificates of all the redirected hostnames related to the PKIX error. If there are differences then you have verified this is the problem. A command to do this is:    h4. Expected    If the Use Nexus Truststore option is enabled for a repository, then all TLS based hosts that might be encountered for 302/301/307 redirects fetching content from a proxy repository remote URL should consult the Nexus truststore for certificate verification, even if the hostname and port is different from the initial request.  h4. Workaround    It seems you can avoid the problem by importing the HTTP proxy server root certificate or redirect host certificate into a custom truststore. Then Nexus will implicitly trust any remote signed by that certificate, including redirected hosts.    Follow the directions here: https://help.sonatype.com/repomanager3/security/configuring-ssl#ConfiguringSSL-OutboundSSL-TrustingSSLCertificatesUsingKeytool    1. Make a copy of JRE cacerts file   2. Import the certificates from the redirect hosts into it as trusted cert entries. Determine the redirect hosts by examining the DEBUG log statements from the org.sonatype.nexus.httpclient.outbound logger when the PKIX errors are reproduced inside of nexus.log   3. Specify to use the modified cacerts file as the JVM truststore for Nexus by specifying system properties inside bin/nexus.vmoptions.  h4. Known SSL Certificates That May Require Explicit Import Into A Custom JVM Truststore  h5. Nuget.org   - [https://az320820.vo.msecnd.net|https://az320820.vo.msecnd.net/] or [https://api.nuget.org|https://api.nuget.org/]    h5. Pypi   - [https://files.pythonhosted.org|https://files.pythonhosted.org/]    h5. Docker  - https://production.cloudflare.docker.com/  - cloudflare.net  - auth.docker.io",Bug,Major,Closed,"2017-01-09 16:05:46","2017-01-09 16:05:46",3
"Sonatype Nexus","Schedule task prompts for discarding changes after change of day","I noticed that if I have a weekly scheduled task saved if I go in to edit the day it runs, when I save, the changes save however, the discard button is still enabled and when I try and navigate away I get prompted to discard.  If I do or click the discard button, it reverts the change, however, when I reload the task the change is saved.  Since the save works, am marking minor, however, it is pretty confusing.    Repro steps:  1) Create scheduled task (any afaik) filling in required fields.  For frequency select weekly, any start time and pick a day (any afaik).  Save.  2) Reselect the task (it goes to the list).  3) Edit the day from whatever you picked to another day.  Save.  BUG: Discard button is still enabled.  4) Click away, for example to Nodes.  BUG: Prompt occurs for discard or go back.    I didn't check older NX3 or NX2 at this time.",Bug,Minor,Closed,"2017-01-06 19:33:31","2017-01-06 19:33:31",1
"Sonatype Nexus","LDAP cache entries do not expire properly","Map an LDAP user into Nexus 3, and log in as this user.    Change the user's LDAP password.  Don't log out of Nexus, instead restart the web browser.  Then wait 5 minutes for the cache entry to expire, and try the login again.    It won't work with the new password, you still need to use the old password.  Users have reported waiting over 24 hours, and still the old password works. It is necessary to manually clear out the LDAP cache in Nexus 3 to fix this.     Note that if you do log out of the UI the cache entry is cleared, and the new password will work the next time.",Bug,Critical,Closed,"2017-01-05 19:08:15","2017-01-05 19:08:15",3
"Sonatype Nexus","Upgrade fails with NPE if user has a group repository that contains only staging repositories","A user has a group repository that contains only staging repositories:    {code:XML}      <repository>        <id>Test_Profile</id>        <name>Test Profile</name>        <providerRole>org.sonatype.nexus.proxy.repository.GroupRepository</providerRole>        <providerHint>maven2</providerHint>        <localStatus>IN_SERVICE</localStatus>        <notFoundCacheTTL>15</notFoundCacheTTL>        <userManaged>true</userManaged>        <exposed>true</exposed>        <browseable>true</browseable>        <writePolicy>READ_ONLY</writePolicy>        <indexable>true</indexable>        <localStorage>          <provider>file</provider>        </localStorage>        <externalConfiguration>          <memberRepositories>            <memberRepository>test-1001</memberRepository>          </memberRepositories>        </externalConfiguration>      </repository>    {code}    The upgrade wizard allows this group repository to be selected (see screenshot).    And then the upgrade subsequently fails with an NPE because the group repository cannot be found.     Note: I had to patch the server to add extra logging to find out what repository caused this problem, because the repository ID was not printed in the log.    ",Bug,Minor,Closed,"2017-01-05 15:47:19","2017-01-05 15:47:19",2
"Sonatype Nexus","Moving repositories between blob stores","Based on a Stackoverflow answer (http://stackoverflow.com/a/41449375/296959) it's currently not possible to move existing repositories between blob stores. Specifically I'm looking for moving a Maven repository to an another blob store, but i guess it's the same for each repository format.",Improvement,Major,Closed,"2017-01-05 14:55:26","2017-01-05 14:55:26",8
"Sonatype Nexus","Logging in from top level search errors and hides admin menu button","While on search either the top level Search or one of the children (eg. Custom) if you login you get an error.  Login happens but subsequently (on post-login refresh), the admin menu button does not appear.  The error seems to be different depending on browser (I tried), but errors regardless.  See below.    This may seem familiar because of NEXUS-9087 but the result is different.  Since that issue was also noted in 3.2, I am filing distinctly for triage.  If they are found to be the same, we can merge them.  In my quick attempt, this prevents me from seeing NEXUS-9087 so I believe if not the same, this should be addressed first.    Workaround is to not login from search (from welcome or component browse).    JS Error from Chrome:      JS Errors from FF:  ",Bug,Minor,Closed,"2017-01-04 19:26:48","2017-01-04 19:26:48",2
"Sonatype Nexus","Maven publish indexes task fails to run if repository's layout policy is strict","Create a maven proxy repository in Nexus with the layout policy of strict (the default).    Then try and run a publish indexes task agains it.  No outbound connections to the remote server will be seen.    Change the layout policy to permissive.  Then run publish indexes again.  This time it will work.",Bug,Major,Closed,"2017-01-03 16:42:08","2017-01-03 16:42:08",2
"Sonatype Nexus","provide guidance on using Amazon EFS with Nexus 3","*Background*  Customers want to use Amazon EFS with Nexus 3. Our performance testing has associated significant slowdowns with EFS, and ElasticSearch documentation recommends against it. (See below.)    *Acceptance*  * Update documentation and/or KB articles to make it clear EFS is potentially troublesome.  * Consider putting this on the Sonatype system requirements.        ",Story,Major,Done,"2016-12-30 15:27:24","2016-12-30 15:27:24",1
"Sonatype Nexus","Repository migration fails with com.fasterxml.jackson.databind.JsonMappingException: Invalid type marker byte 0xfa for expected field name (or END_OBJECT marker)","Upgrade fails with com.fasterxml.jackson.databind.JsonMappingException: Invalid type marker byte 0xfa for expected field name (or END_OBJECT marker).    Initial investigation is showing that this may have something to do with migrating a proxy of the npm registry.    ",Bug,Major,Closed,"2016-12-29 21:08:24","2016-12-29 21:08:24",2
"Sonatype Nexus","SNAPSHOT requests are processed by Maven 2 repositories with policy Release","h4. Nexus 2.x    1. Configure a Maven 2 proxy repo with policy RELEASE.  2. Add the Maven 2 proxy repo as a member to the public group.  3. Send the following request to a Nexus 2 public group containing a proxy repository member with policy RELEASE. Processing of the request is not handled by the RELEASE proxy repository as the path is detected as a SNAPSHOT request. Setting the logger {{remote.storage.outbound}} to DEBUG or processing the request with {{?describe}} proves this:    http://localhost:8081/nexus/content/groups/public/gov/utah/dws/erep/arch/base-pom/2.16-SNAPSHOT/maven-metadata.xml    h4. Nexus 3.2    1. Send the same request to a maven-public group with Release policy proxy repository ( ie. maven-central) as a group member and Nexus 3.2 sends the request outbound to the remote.  Setting the logger {{org.sonatype.nexus.httpclient.outbound}} to DEBUG proves this.    http://localhost:8081/repository/maven-public/gov/utah/dws/erep/arch/base-pom/2.16-SNAPSHOT/maven-metadata.xml      h3. Expected     For consistency - request paths that are detected as SNAPSHOT related in Nexus 2 should also be treated as SNAPSHOT related in Nexus 3 - unless Nexus 3 has an improvement to make over Nexus 2.     SNAPSHOT requests should not be processed AT ALL by RELEASE policy repository group members in Nexus 3.x, whether they are hosted or proxy repositories.    ",Bug,Critical,Closed,"2016-12-29 19:52:05","2016-12-29 19:52:05",2
"Sonatype Nexus","npm hosted repository package metadata tarball URLs incorrectly contain generated-on-request placeholder after upgrade","NEXUS-11874 fixed an error which prevented some npm hosted packages from being migrated from 2.x to 3.x if the Rebuild npm hosted metadata task had been run on the source repository.    Now an upgrade with Nexus Repository Manager 2.14.2 to 3.2.0, will migrate those hosted packages instead of failing the repository migration. However there is a new problem. When the package metadata for hosted npm packages are requested from Nexus 3, the tarball URLs may not be rewritten correctly and will contain invalid URLs which contain the internal placeholder term: generated-on-request.    1. Deploy an npm package to a Nexus Repository Manager 2.x npm hosted repository.  2. Schedule and run at least one Rebuild npm hosted metadata task against the Nexus Repository Manager 2.x npm hosted repository.  3. Migrate the npm hosted repository to Nexus 3.2.0.  4. Request the root level package metadata of a migrated package. The tarball URLs will contain the term generated-on-request instead of the expected tarball file name.    {noformat:title=Example bad metadata}  {maintainers:[{name:admin,email:<EMAIL>}],x-nx-rebuilt:2016-12-27T17:48:01.866-0400,keywords:[test1],dist-tags:{latest:0.0.1},versions:{0.0.1:{name:testproject1,version:0.0.1,description:Test Project 1,main:index.js,scripts:{test:echo \Error: no test specified\ && exit 0},dependencies:{commonjs:0.0.1},publishConfig:{registry:http://localhost:8081/nexus/content/repositories/npm-hosted/},keywords:[test1],author:{name:<USER>},license:ISC,readme:ERROR: No README data found!,_id:testproject1@0.0.1,_shasum:8bec15747a094d7720fc8a4d8e785b6ea5e23b85,_from:.,_npmVersion:4.0.5,_nodeVersion:0.12.2,_npmUser:{name:admin,email:<EMAIL>},maintainers:[{name:admin,email:<EMAIL>}],dist:{shasum:8bec15747a094d7720fc8a4d8e785b6ea5e23b85,tarball:http://localhost:8091/repository/npm-hosted/testproject1/-/generated-on-request}}},name:testproject1,_rev:1,description:Test Project 1,_id:testproject1,readme:ERROR: No README data found!,time:{created:2016-12-27T21:34:40.348Z,modified:2016-12-27T21:48:01.870Z,0.0.1:2016-12-27T21:34:40.348Z}}  {noformat}    The invalid URLs will of course return 404 and therefore builds which previously worked using Nexus 2 will fail when used with Nexus 3.    h4. Expected    Package metadata migrated from Nexus 2 should render with proper tarball urls.    ",Bug,Critical,Closed,"2016-12-27 22:07:51","2016-12-27 22:07:51",3
"Sonatype Nexus","JobStoreImpl should skip over malformed records to allow nexus to start","In the case where jobs end up malformed in the config database, as such:    3 item(s) found. Query executed in 0.003 sec(s).}}    and/or        The empty records (#28:3 and #42:3) caused an NPE which stopped nexus from starting:  ",Bug,Major,Closed,"2016-12-21 16:40:55","2016-12-21 16:40:55",3
"Sonatype Nexus","npm install fails with 500 error when user has Group level privileges","If a user has read privileges to a npm group, but not the underlying npm proxy, then the npm install <package> will get a 500 response for any package that is not locally cached in the npm proxy.      Steps to reproduce:  1) Setup a npm group _npm-all_ that has npm proxy _npmjs_ as a member  2) Setup a user that has access to group repo _npm-all_ (privilege nx-repository-view-npm-npm-all).  3) Try to install a npm package that is not locally cached in  proxy _npmjs_     The npm install command will fail with something like the following:        Nexus logs will show the following:      *Workaround* If you give that user a read privilege to the proxy _npmjs_ (nx-repository-view-npm-npmjs-read) then the user should be able to install the package that is not already cached.    Group level permissions should be transitive, therefore use has the same privileges for all member repositories.",Bug,Major,Closed,"2016-12-21 11:58:34","2016-12-21 11:58:34",0.5
"Sonatype Nexus","Deploying docker manifest which has unknown properties causes an entire docker package to become unusable.","An end user uploaded some docker images using docker 1.13.0 RC which had manifests containing unsupported tags.    Now they can't seem to get out of the bad state, seems that deleting the bad manifests doesn't fix it, and they can't deploy new versions of this image using Docker 1.12.    {quote}  2016-12-15 14:51:06,613-0600 INFO \[qtp252865835-11141] snikifor org.sonatype.nexus.repository.storage.SingleAssetComponentMaintenance - Deleting component: Component\{metadata=AttachedEntityMetadata\{document=component#10:33165\{bucket:#9:9,format:docker,last_updated:Thu Dec 15 14:49:20 CST 2016,attributes:\[1],group:null,name:dock2box/centos7.2.1511,version:fb8c651} v1}, name=dock2box/centos7.2.1511, version=fb8c651, group=null}    2016-12-15 15:08:52,271-0600 WARN \[qtp252865835-11186] registry_svc org.sonatype.nexus.repository.docker.internal.V2Handlers - Error: HEAD /v2/stampede/centos7.2.1511/blobs/sha256:00e4abfa9a21665df632d0eaa741ba6dced8e8a3cf79722f85115d9d761125a9: 404 - org.sonatype.nexus.repository.docker.internal.V2Exception$BlobNotFound: blob unknown to registry  2016-12-15 15:09:05,293-0600 WARN \[qtp252865835-11201] snikifor org.sonatype.nexus.repository.docker.internal.V2Handlers - Error: GET /v2/stampede/centos7.2.1511/manifests/fb8c651  com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field comment (class org.sonatype.nexus.repository.docker.internal.V2ManifestConfig), not marked as ignorable (11 known properties: container_config, container, config, architecture, os, created, docker_version, author, rootfs, metaClass, history])  at \[Source: java.io.BufferedInputStream@12f67dcc; line: 1, column: 36] (through reference chain: org.sonatype.nexus.repository.docker.internal.V2ManifestConfig\[comment])  at com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException.from(UnrecognizedPropertyException.java:62) \[com.fasterxml.jackson.core.jackson-databind:2.7.1]  at com.fasterxml.jackson.databind.DeserializationContext.reportUnknownProperty(DeserializationContext.java:855) \[com.fasterxml.jackson.core.jackson-databind:2.7.1]  at com.fasterxml.jackson.databind.deser.std.StdDeserializer.handleUnknownProperty(StdDeserializer.java:1083) \[com.fasterxml.jackson.core.jackson-databind:2.7.1]  at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperty(BeanDeserializerBase.java:1389) \[com.fasterxml.jackson.core.jackson-databind:2.7.1]  at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownVanilla(BeanDeserializerBase.java:1367) \[com.fasterxml.jackson.core.jackson-databind:2.7.1]  at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:266) \[com.fasterxml.jackson.core.jackson-databind:2.7.1]  at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:125) \[com.fasterxml.jackson.core.jackson-databind:2.7.1]  at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3788) \[com.fasterxml.jackson.core.jackson-databind:2.7.1]  at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2849) \[com.fasterxml.jackson.core.jackson-databind:2.7.1]  at com.fasterxml.jackson.databind.ObjectMapper$readValue$1.call(Unknown Source) \[na:na]  at org.sonatype.nexus.repository.docker.internal.V2ManifestUtilImpl.loadConfigurationFile(V2ManifestUtilImpl.groovy:209) \[na:na]  at org.sonatype.nexus.repository.docker.internal.V2ManifestUtilImpl$loadConfigurationFile$16.callStatic(Unknown Source) \[na:na]  at org.sonatype.nexus.repository.docker.internal.V2ManifestUtilImpl.mayDowngrade(V2ManifestUtilImpl.groovy:127) \[na:na]  at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:44) \[org.sonatype.nexus.transaction:3.0.2.02]  at org.sonatype.nexus.repository.docker.internal.DockerHostedFacetImpl.getManifestByTag(DockerHostedFacetImpl.java:728) \[na:na]  at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:54) \[org.sonatype.nexus.transaction:3.0.2.02]  at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:53) \[org.sonatype.nexus.transaction:3.0.2.02]  at org.sonatype.nexus.repository.docker.internal.DockerHostedFacet$getManifestByTag.call(Unknown Source) \[na:na]  at org.sonatype.nexus.repository.docker.internal.V2Handlers$_closure14.doCall(V2Handlers.groovy:240) \[na:na]  at sun.reflect.GeneratedMethodAccessor296.invoke(Unknown Source) \[na:na]    {quote}  ",Bug,Major,Closed,"2016-12-19 16:45:17","2016-12-19 16:45:17",0.5
"Sonatype Nexus","privileges which allow reading repository content also expose all repository names when browsing assets / components ","Anonymous user is assigned one role with only the following:  nexus:repository-view:maven2:maven-central:browse  nexus:repository-view:maven2:maven-central:read    There is a difference in behaviour between Nexus 3.0.2 and 3.1.0.    In Nexus 3.0.2 you only see maven-central in Browse Assets/Components.  !Browse 3.0.2.png!    In Nexus 3.1.0 you see all the repos in Browse Assets/Components. You do not see artifacts under repositories that you do not permissions for, but the issue is that the repository should not displayed   !Browse 3.1.0.png!    NOTE: This does not allow users to see the repository content, just the repository names.",Bug,Major,Closed,"2016-12-16 17:44:35","2016-12-16 17:44:35",3
"Sonatype Nexus","REST-Controlled Scheduled Tasks","*Background*   Currently, there's a gap in terms of how NX3 backups can be orchestrated. We want admins to export the database (i.e. via the scheduled task), and keep the export files safe, and synchronize this with a blob store/rest of Nexus backup. This is tricky because the scheduled task is controlled inside Nexus, while blob stores are often backed up using an externally controlled rsync.    *Acceptance*   * There is a mechanism to list configured scheduled tasks, query their run status and invoke them (as if they were being manually invoked).    *Technical Notes*   * Perhaps the right way to do this is as part of beefing up the Provisioning API to cover scheduled tasks (including finding and triggering them).   * We'll defer configuration-specific endpoints (and this can currently be done with the provisioning API).   * Consider that some tasks may not come from our own plugins.",Story,Major,Done,"2016-12-16 16:26:26","2016-12-16 16:26:26",3
"Sonatype Nexus","Nexus 2 to Nexus 3 upgrade may fail with NullPointerException Cannot invoke method extract while processing RepositoryChangelogResource","I try to upgrade from 2.14.1-01 to 3.1.0-04. I selected single proxy repository and got the following:  !upgrade.JPG|thumbnail!    Nexus 2 log contains the following:        ",Bug,Major,Closed,"2016-12-15 18:32:13","2016-12-15 18:32:13",2
"Sonatype Nexus","Book inaccurately states Group search criteria supports asterisk for pattern matching","Description:   In Section 3.3.1 the book states Each criteria can be used with a search term and supports the * character (star, asterisk) for pattern matching. E.g., you could search with the *Group* search criteria and search for org.sonatype.nexus.*. This would return components with the group of org.sonatype.nexus, but also org.sonatype.nexus.plugins and many others.    But, applying the asterisk for the Keyword field seems to work.    Acceptance:  Update the example to Keyword search, instead of Group search.  ",Bug,Major,Closed,"2016-12-15 17:57:44","2016-12-15 17:57:44",0.5
"Sonatype Nexus","Stopping Nexus while a Drop Inactive Staging Repositories is running can lead to configuration inconsistencies","Saw this in a customer log.  A drop inactive staging repositories task was started:    {quote}  2016-12-09 18:00:02 INFO \[pxpool-1-thread-14\] *TASK com.sonatype.nexus.staging.internal.task.DropInactiveRepositoriesTask - Inactive repositories selected to drop: [build-50727, build-50728, build-50729, build-50730, build-50731, build-50732, build-50733, build-50734, build-50735, build-50736, build-50737, build-50738, build-50739, build-50740, build-50741, build-50742, build-50743, build-50744, build-50745, build-50746, build-50747, build-50748, build-50749, build-50750, build-50751, build-50752, build-50753, build-50754, build-50755, build-50756, build-50757, build-50758, build-50759, build-50760, build-50761, build-50762, build-50763, build-50764, build-50765, build-50766, build-50767, build-50768, build-50769, build-50770, build-50771, build-50772, build-50773, build-50774, build-50775, build-50776, build-50777, build-50778, build-50779, build-50780, build-50781, build-50782, build-50783, build-50784, build-50785, build-50786, build-50787, build-50788, build-50789, build-50790, build-50791, build-50792, build-50793, build-50794, build-50795, build-50796, build-50797, build-50798, build-50799, build-50800, build-50801, build-50802, build-50803, build-50804, build-50805, build-50806, build-50807, build-50808, build-50809, build-50810, build-50811, build-50812, build-50813, build-50814, build-50815, build-50816, build-50817, build-50818, build-50819, build-50820, build-50821, build-50822, build-50823, build-50824, build-50825, build-50826, build-50827, build-50828, build-50829, build-50830, build-50831, build-50832, build-50833, build-50834, build-50835, build-50836, build-50837, build-50838, build-50839, build-50840, build-50841, build-50842, build-50843, build-50844, build-50845, build-50846, build-50847, build-50848, build-50849, build-50850, build-50851, build-50852, build-50853, build-50854, build-50855, build-50856, build-50857, build-50858, build-50859, build-50860, build-50861, build-50862, build-50863, build-50864, build-50865, build-50866, build-50867, build-50868, build-50869, build-50870, build-50871, build-50872, build-50873, build-50874, build-50875, build-50876, build-50877, build-50878, build-50879, build-50880, build-50881, build-50882, build-50883, build-50884, build-50885, build-50886, build-50887, build-50888\]  {quote}    About a minute later Nexus was shut down:    {quote}  2016-12-09 18:01:07 INFO  \[WrapperListener_stop_runner] *SYSTEM org.sonatype.nexus.bootstrap.jsw.JswLauncher - Stopping with code: 0  2016-12-09 18:01:07 INFO  \[WrapperListener_stop_runner] *SYSTEM org.sonatype.nexus.bootstrap.jetty.JettyServer - Stopping  2016-12-09 18:01:07 INFO  \[WrapperListener_stop_runner] *SYSTEM org.sonatype.nexus.bootstrap.jetty.JettyServer - Stopping: org.eclipse.jetty.server.Server@695d7d60  2016-12-09 18:01:07 INFO  \[WrapperListener_stop_runner] *SYSTEM org.eclipse.jetty.server.Server - Graceful shutdown InstrumentedSelectChannelConnector@0.0.0.0:8080  2016-12-09 18:01:08 INFO  \[WrapperListener_stop_runner] *SYSTEM org.eclipse.jetty.server.Server - Graceful shutdown o.e.j.w.WebAppContext\{/nexus,file\:/usr/local/nexus-professional-2.12.0-01/nexus/},/usr/local/nexus-professional-2.12.0-01/nexus  {quote}    During shut down there are quite a few exceptions from the thread running the drop task.    And in the end the thread dropping the repositories is the last thing running, this is the end of the log:    {quote}  2016-12-09 18:01:17 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:17 WARN \[pxpool-1-thread-19] *TASK com.sonatype.nexus.staging.internal.task.RepositoryDropTask - One or more operations failed; aborting: com.sonatype.nexus.staging.StagingConfigurationException: org.sonatype.nexus.proxy.NoSuchRepositoryException: Repository with ID=build-50745 not found  2016-12-09 18:01:17 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:18 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:18 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:18 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:18 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:18 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:18 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:18 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:18 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:19 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:19 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:19 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:19 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:19 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:19 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:19 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:19 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:19 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  2016-12-09 18:01:20 INFO \[pxpool-1-thread-19] *TASK org.sonatype.nexus.configuration.ModelUtils - Saving model /usr/local/sonatype-work/nexus/conf/staging.xml  {quote}    After restart there are numerous inconsistencies between repositories in the nexus.xml and staging.xml files.  This resulted in the log getting enormous (20Gb), due to warnings, and also left a large number of staging repositories in a state where they couldn't be dropped.    ",Bug,Major,Closed,"2016-12-13 19:50:26","2016-12-13 19:50:26",5
"Sonatype Nexus","npm search against group repository fails with HTTP 500 due to not properly supporting /-/all resource","Steps to reproduce:     * Create {{npm-internal}} (hosted) repository with *its own blob store*.   * Create {{registry.npmjs.org-proxy}} (proxy for https://registry.npmjs.org/) repository with *its own blob store*.   * Create {{npm-group}} repository containing the first two repos with *its own blobstore*.   * Update your {{.npmrc}} to set {{registry=http://<nexus host>/repository/npm-group}}   * Open a terminal and run {{npm search <some package> --verbose}}    The HTTP {{500}} response should be printed on the terminal and the following is observed in the Nexus logs:        It appears that the {{npm-group}} repository is attempting to find the {{npm-hosted/-/all}} asset *in its blobstore*.    I've confirmed something like this is happening by performing the steps outlined above but used _the same blobstore for all repositories_ and no error is observed.",Bug,Major,Closed,"2016-12-13 18:15:29","2016-12-13 18:15:29",2
"Sonatype Nexus","content requests to Nexus 2 by migration agent should avoid HTTP 404 Not Found caused by URL encoding","*Background*  A number of customer bug reports have been traced to the fact that the NX2->NX3 migration REST API is using encoded slashes in requests. This causes problems with reverse proxies, and so far our recommendation is to fine tune the reverse proxy settings. This will continue to be problematic in the future, so let's adjust to eliminate the encoding.    The problem manifests itself when the HTTP download option is used during upgrade to Nexus 3, and Nexus 3 is sending requests for artifacts to Nexus 2. Nexus 3 sends requests to Nexus 2 with encoded slashes like   {{<base url>/service/siesta/migrationagent/repository-content/npmproxy/which%2F-%2Fwhich-1.0.9.tgz}}, those decoded slashes need to arrive at the Nexus 2 instance unaltered/undecoded in order for migration to work.    *Symptoms*    Requests by the Nexus migration agent to Nexus 2 will fail with 404 not found. Example stack trace from your nexus.log:        This can happen with any repository type.    *Acceptance*  * Remove slash encoding from the NX2 migration REST API so that we don't have problems with reverse proxies.  * Revert note added by https://github.com/sonatype/nexus-book-internal/pull/55 which will become obsolete    *Workaround*    - configure Nexus 3 to send requests to Nexus 2 directly instead of going through an intermediary reverse proxy  - configure the httpd in front of Nexus 2 with the directive {{AllowEncodedSlashes NoDecode}} and the option {{nocanon}} for your ProxyPass directive - do a similar change for nginx if using that server  - upgrade to 2.14.3/3.2.1 once released  ",Story,Major,Done,"2016-12-13 16:23:32","2016-12-13 16:23:32",3
"Sonatype Nexus","REST Asset Search & Download Resource","*Background*   This feature serves as a handy bridge between searching for things and downloading them. Having a download sub-resource means that clients can make simple HTTP calls for artifacts that may or may not exist, and download them without parsing any JSON.    *Acceptance*   * This sub-resource builds on NEXUS-14603 (asset search json api), but returns:   ** A 302 redirect to download the asset bytes   *** Rationale: This has the benefit of leaving a trail in build tools' logs that explains what specific artifact was suggested as the thing to download (e.g. in the case of a latest search), rather than simply returning bytes.   *** It's fine to reuse existing format-specific content-serving endpoints, if that's expedient (as with the asset download sub-resource)   ** If there are no search results, HTTP 404   ** If the search isn't sufficiently precise to pick a winning asset (i.e. there's no sort order and there's more than one search result), then we should return HTTP 400 (client error)   ** Request logs should make it easy to tell whether users were searching for content vs. trying to download content (e.g. because downloading is a sub-endpoint or uses a 'download' param or whatever)    *Questions/Notes*   * Partial fetch/HEAD support is of course desirable, but that will be handled by the format-specific content bytes endpoint  ",Story,Major,Done,"2016-12-12 21:45:56","2016-12-12 21:45:56",3
"Sonatype Nexus","http request header values should be checked for validity before allowing a request to proceed","Certain HTTP request headers have well established value formats. Nexus should check the format of these header values and reject the request with a 400 response in such a case. Log a message in nexus.log in such a case at INFO level.",Bug,Major,Closed,"2016-12-12 17:32:26","2016-12-12 17:32:26",3
"Sonatype Nexus","Ingestion of components from Nexus 2 during upgrade is not atomic","{{RepositoryMigratorSupport.processChange()}} first calls {{recordMetadata()}} then {{ingestContent()}}. Those two calls are separate transactions. NEXUS-11517 demonstrated a case where the metadata of a component could be successfully recorded but its content could not be retrieved, leaving behind an invalid asset (i.e. an asset lacking its blob).    Ideally, the processing of each change log entry for upgrade should be all-or-nothing to avoid inconsistent data and the false impression upgrade succeeded by having NX3 show components that are actually inaccessible:  ",Bug,Major,Open,"2016-12-12 14:26:10","2016-12-12 14:26:10",2
"Sonatype Nexus","npm packages cannot be migrated due to IllegalStateException PackageVersion expected when contained in a rebuilt hosted repository","Trying to migrate a npm repo from 2.14.1 to 3.1.    Error at Nexus 3.1 is      Error at Nexus 2.14.1 is  ",Bug,Major,Closed,"2016-12-09 11:29:18","2016-12-09 11:29:18",1
"Sonatype Nexus","Deleting a repository with an item in it errors in nexus.log","I deployed the attached pom to the default maven-snapshots repo and subsequently deleted it and later noticed the below error in the nexus.log.  I was able to repro this.  This does not occur when the snapshot repo is empty.    I did not check older NX3 or NX2 at this time however this reminded me of NEXUS-10759 where this doesn't occur (or at least the error is different) so there's either some subtly here or it's recent regression.  As with NEXUS-10759 the repo as far as I can tell does delete properly (definitely disappears from the UI and is able to be recreated), so marking minor for now despite the scary error.  Nothing bad shows on the UI side either.    ",Bug,Minor,Closed,"2016-12-08 23:08:35","2016-12-08 23:08:35",1
"Sonatype Nexus","Repository Administration shows errors with limited privileges","I made myself a role with nx-repository-admin-* and assigned to a user and when I logged in and navigated to repository admin, I got the attached error as well as the below from nexus.log.  I am suspect this is because I didn't have healthcheck privileges (as it says) and I know we want people to use healthcheck but I am skeptical we want them to use it so bad we throw errors down their throats.    This seemed familiar but I only saw one issue with this error and it was regarding anonymous access.    I didn't check NX2 at this time.  I checked also against NX3.1 and this is not recent regression.    Nexus.log snip:  ",Bug,Minor,Closed,"2016-12-07 21:09:34","2016-12-07 21:09:34",2
"Sonatype Nexus","Filtered items remain filtered after leaving the page but filter itself clears","I noticed that when I filtered some privileges, moved to Roles and moved back to Privileges that the filter remained in effect but the filter field itself cleared.  This was momentarily confusing, I thought I might have erased something or been on the wrong page.  You can click the clear x or refresh the browser as a workaround to restore the non-filtered list.  See attached vid.  I did not check vs NX2 at this time.  I did check 3.1.0 and this is not recent regression.",Bug,Minor,Closed,"2016-12-07 20:34:15","2016-12-07 20:34:15",1
"Sonatype Nexus","Upgrade fails if Nexus 2 override local storage is not using a file URL","If you have a repository in Nexus 2 which overrides local storage using a simple file path upgrade to Nexus 3 will fail.    {code:XML}    <localStorage>      <provider>file</provider>      <url>Z:\repositories\snapshots</url>    </localStorage>  {code}    The above is valid, the field takes either a file URL or a simple file path, see [here|https://github.com/sonatype/nexus-public/blob/477164f49c386e25a86c3866e4ac3a58c422b562/components/nexus-core/src/main/java/org/sonatype/nexus/proxy/storage/local/AbstractLocalRepositoryStorage.java#L137-L137].    But the upgrade fails with this:    ",Bug,Minor,Closed,"2016-12-06 20:02:05","2016-12-06 20:02:05",1
"Sonatype Nexus","Clearing (analytics) Events on Page 2+ hides Events until browser refresh","I noticed that if I have 2(+) pages of analytics events and I am on a page other than the first and clear, the pagination resets to 0 of 0 and I cannot see further events until a browser refresh.  Changing navigation or header refresh do not work.  This same behavior does not occur if you have 1 page or are on page 1.  See attached video.    I found if you were to wait until there was a page of events you were on it display (at page 1).    I didn't check older NX3 or NX2 at this time.",Bug,Trivial,Closed,"2016-12-01 21:47:58","2016-12-01 21:47:58",2
"Sonatype Nexus","editing nexus-default.properties is not discouraged","When you extract the nexus download archive, you notice a file at <install_dir>/etc/nexus-default.properties with uncommented property values.    Because this file is similar enough in name to nexus.properties ( from nexus 2 ) and the properties file we intend for them to customize is only created on startup at sonatype-work/nexus3/etc/nexus.properties , people are starting to edit the nexus-default.properties file instead of the nexus.properties file.    We keep seeing installations that have edited nexus-default.properties and not nexus.properties.  We want to discourage editing nexus-default.properties because the location of that file means that the custom values put there are not moved during upgrade, defeating the purpose of supporting a nexus.properties file in the work directory in the first place.    Acceptance criteria:     - keep nexus-default.properties  + add comments in the file explaining this file should not be edited   - ensure that comments about 'not editing' are not copied to nexus.properties    ",Bug,Major,Closed,"2016-12-01 16:55:20","2016-12-01 16:55:20",0.5
"Sonatype Nexus","prevent ClassCastException when handling StorageLinkItem during upgrade to Nexus 3","Migration does not seem to handle finding a org.sonatype.nexus.proxy.item.DefaultStorageLinkItem in a maven2 hosted repo well. It throws a ClassCastException trying to cast it to StorageFileItem.        h3. Expected:    - migrate that item  - if an exception is thrown like this related to storage items migration, ALWAYS log the file name trying to be processed ( not sure if scouring code to ensure this does warrant a separate issue )",Bug,Major,Closed,"2016-12-01 14:15:19","2016-12-01 14:15:19",3
"Sonatype Nexus","archived log file names should be named consistently","By default the request.log and nexus.log files are archived every 24 hours.     nexus-yyyy-mmdd.log.gz  request-yyyy-mm-dd.log.gz    The file name formats are defined in logback.xml and logback-access.xml respectively.    Example from nexus-3.1.0-02:        There is a needless inconsistency. This also appears to be a regression - this was once fixed in : https://github.com/sonatype/nexus-oss/pull/1550/files     h3. Expected:    Change the name format of the nexus log to match the request log:        What happened to archiving the karaf.log? Any other log archives should be named similar to above pattern.",Bug,Minor,Closed,"2016-11-30 13:05:31","2016-11-30 13:05:31",0.5
"Sonatype Nexus","RAR uploading fails - Detected content type x-zip-compressed but expected /x-rar","I tryed to upload a JCA RAR, but Nexus (OSS 3.0.2-02) throws the following error:    {quote}Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.4:deploy (default-deploy) on project jca.adapter: Failed to deploy artifacts: Could not transfer artifact de.jca:jca.adapter:rar:1.0.0 from/t  o nexus-deploy (http://x.x.x.x:8081/repository/releases/): Failed to transfer file: http://x.x.x.x:8081/repository/releases/jca/jca.adapter/1.0.0/jca.adapter-1.0.0.rar. Return code is: 400, Reason  Phrase: Detected content type [application/zip, application/x-zip-compressed], but expected [application/java-archive, application/x-rar-compressed, application/x-rar]: jca/jca.adapter/1.0.0/jca.adapter-1.0.0.rar.{quote}    This is how my pom file looks:  <project ...>   <modelVersion>4.0.0</modelVersion>   <artifactId>jca.adapter</artifactId>   <packaging>rar</packaging>     <dependencies ...>  </project>",Bug,Major,Closed,"2016-11-28 10:41:52","2016-11-28 10:41:52",3
"Sonatype Nexus","browsing hosted docker repo may trigger UnrecognizedPropertyException Unrecognized field","When browsing to attributes of the assets of a component in our hosted docker repo we get large stack traces like this as log spam. The UI and everything seems to work fine but there is a LOT of this filling up the log.    *********************  * Testing exception *  *********************  2016-11-23 18:00:09,578+0000 WARN  [qtp1616493320-1434] t841815 org.sonatype.nexus.repository.httpbridge.internal.ViewServlet - Service failure  com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field should_filter (class org.sonatype.nexus.repository.docker.internal.V1SearchResult), not marked as ignorable (7 known properties: is_official, star_count, metaClass, name, description, is_trusted, is_automated])   at [Source: org.apache.http.conn.EofSensorInputStream@67527483; line: 1, column: 262] (through reference chain: org.sonatype.nexus.repository.docker.internal.V1SearchResults[results]->java.util.ArrayList[0]->org.sonatype.nexus.repository.docker.internal.V1SearchResult[should_filter])   at com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException.from(UnrecognizedPropertyException.java:62) [na:na]   at com.fasterxml.jackson.databind.DeserializationContext.reportUnknownProperty(DeserializationContext.java:855) [na:na]   at com.fasterxml.jackson.databind.deser.std.StdDeserializer.handleUnknownProperty(StdDeserializer.java:1083) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperty(BeanDeserializerBase.java:1389) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownVanilla(BeanDeserializerBase.java:1367) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:266) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:125) [na:na]   at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:277) [na:na]   at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:249) [na:na]   at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:26) [na:na]   at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:490) [na:na]   at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:95) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:260) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:125) [na:na]   at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3788) [na:na]   at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2849) [na:na]   at com.fasterxml.jackson.databind.ObjectMapper$readValue$5.call(Unknown Source) [na:na]   at org.sonatype.nexus.repository.docker.internal.V1GroupSearchHandler$_doGet_closure2.doCall(V1GroupSearchHandler.groovy:73) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_101]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_101]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_101]   at java.lang.reflect.Method.invoke(Method.java:498) [na:1.8.0_101]   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [na:na]   at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [na:na]   at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [na:na]   at groovy.lang.Closure.call(Closure.java:426) [na:na]   at org.codehaus.groovy.runtime.DefaultGroovyMethods.callClosureForMapEntry(DefaultGroovyMethods.java:5226) [na:na]   at org.codehaus.groovy.runtime.DefaultGroovyMethods.collect(DefaultGroovyMethods.java:3446) [na:na]   at org.codehaus.groovy.runtime.DefaultGroovyMethods.collect(DefaultGroovyMethods.java:3463) [na:na]   at org.codehaus.groovy.runtime.dgm$67.invoke(Unknown Source) [na:na]   at org.codehaus.groovy.runtime.callsite.PojoMetaMethodSite$PojoMetaMethodSiteNoUnwrapNoCoerce.invoke(PojoMetaMethodSite.java:274) [na:na]   at org.codehaus.groovy.runtime.callsite.PojoMetaMethodSite.call(PojoMetaMethodSite.java:56) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125) [na:na]   at org.sonatype.nexus.repository.docker.internal.V1GroupSearchHandler.doGet(V1GroupSearchHandler.groovy:72) [na:na]   at org.sonatype.nexus.repository.group.GroupHandler.handle(GroupHandler.java:79) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80) [na:na]   at org.sonatype.nexus.repository.security.SecurityHandler.handle(SecurityHandler.java:52) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80) [na:na]   at org.sonatype.nexus.repository.view.Context$proceed.call(Unknown Source) [na:na]   at org.sonatype.nexus.repository.docker.internal.V1Handlers$_closure17.doCall(V1Handlers.groovy:245) [na:na]   at sun.reflect.GeneratedMethodAccessor432.invoke(Unknown Source) [na:na]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_101]   at java.lang.reflect.Method.invoke(Method.java:498) [na:1.8.0_101]   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [na:na]   at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [na:na]   at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1084) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [na:na]   at groovy.lang.Closure.call(Closure.java:426) [na:na]   at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [na:na]   at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [na:na]   at com.sun.proxy.$Proxy115.handle(Unknown Source) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80) [na:na]   at org.sonatype.nexus.repository.view.handlers.TimingHandler.handle(TimingHandler.java:46) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:80) [na:na]   at org.sonatype.nexus.repository.view.Context.start(Context.java:114) [na:na]   at org.sonatype.nexus.repository.view.Router.dispatch(Router.java:60) [na:na]   at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:52) [na:na]   at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:43) [na:na]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.dispatchAndSend(ViewServlet.java:198) [na:na]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.doService(ViewServlet.java:160) [na:na]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.service(ViewServlet.java:117) [na:na]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:71) [com.google.inject:4.0.0]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.3.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.3.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.3.2]   at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.1.0.04]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.3.2]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.3.2]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.3.2]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.3.2]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.3.2]   at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.1.0.04]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.3.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:112) [com.sonatype.nexus.plugins.nexus-licensing-plugin:3.1.0.04]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.base:3.1.0.04]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:97) [org.sonatype.nexus.base:3.1.0.04]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.1.0.04]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1668) [org.eclipse.jetty.servlet:9.3.7.v20160115]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581) [org.eclipse.jetty.servlet:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548) [org.eclipse.jetty.security:9.3.7.v20160115]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1158) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511) [org.eclipse.jetty.servlet:9.3.7.v20160115]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1090) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.7.v20160115]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:109) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.Server.handle(Server.java:517) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:308) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:242) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:75) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:213) [org.eclipse.jetty.util:9.3.7.v20160115]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:147) [org.eclipse.jetty.util:9.3.7.v20160115]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654) [org.eclipse.jetty.util:9.3.7.v20160115]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572) [org.eclipse.jetty.util:9.3.7.v20160115]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_101]",Bug,Minor,Closed,"2016-11-23 18:03:06","2016-11-23 18:03:06",0.5
"Sonatype Nexus","show ldap server name instead of id in Audit context column","While writing the audit documentation, I noticed that on the initial row in context, LDAP adjustments show ID not name.  ID isn't shown anywhere else in the UI, so this seems unhelpful for correlation.  You can see the name in the expanded row information so marking minor.    I didn't check older versions of NX3 however very little work has been done on this so I strongly suspect it's the same since implementation. NX2 doesn't have audit but has system feeds instead. I did not cross check against that either.    See attached, let me know if unclear.",Improvement,Minor,Closed,"2016-11-21 23:22:18","2016-11-21 23:22:18",0.5
"Sonatype Nexus","HA - add nodeId to analytics events","The current analytics event data definition (which I believe is shared with some analytics tools hosted by OPS) doesn't include the nodeId where the UI event occurred. This story will look at adding nodeId to analytics events. Whoever works on this task should check with OPS to find out whether adding this new field will cause any issues with their downstream analytics tools.    Open questions:   * should we also look at versioning the analytics data definition?   * does the local sequence counter provide much value in HA?   * existing records should leave the nodeId unspecified",Story,Major,Done,"2016-11-21 15:48:29","2016-11-21 15:48:29",2
"Sonatype Nexus","Log spam...  HEAD requests for docker blobs that return 404 logged with warning","Nexus 3.1.0 logs HEAD requests which are not found with WARN level, and Error in the message:    {quote}  2016-11-16 21:26:55,574+0000 WARN \[qtp1729674283-259] someuser org.sonatype.nexus.repository.docker.internal.V2Handlers - Error: HEAD /v2/1114/sample-project/blobs/sha256:aa02b7a32ac3cc52451474c7b78f6aea3d2c20c92aff40dcc0c5244aea5ff3ad: 404 - org.sonatype.nexus.repository.docker.internal.V2Exception$BlobNotFound: blob unknown to registry  {quote}    It should not do this, this is not indicative of a problem.  For example, Docker will do a HEAD request before it does a put to see if a layer already exists:    {quote}  22.115.159.20 - someuser \[16/Nov/2016:21:26:55 +0000] HEAD /repository/1114/v2/1114/sample-project/blobs/sha256:aa02b7a32ac3cc52451474c7b78f6aea3d2c20c92aff40dcc0c5244aea5ff3ad HTTP/1.1 404 0 19  22.115.159.20 - someuser \[16/Nov/2016:21:26:56 +0000] PUT /repository/1114/v2/1114/sample-project/blobs/uploads/0552bc82-77c6-4ee8-aa61-5c465968d4bf?digest=sha256%3Aaa02b7a32ac3cc52451474c7b78f6aea3d2c20c92aff40dcc0c5244aea5ff3ad HTTP/1.1 201 0 229  22.115.159.20 - someuser \[16/Nov/2016:21:26:56 +0000] HEAD /repository/1114/v2/1114/sample-project/blobs/sha256:aa02b7a32ac3cc52451474c7b78f6aea3d2c20c92aff40dcc0c5244aea5ff3ad HTTP/1.1 200 0 5  {quote}    We should log this at DEBUG, and remove Error from the message.  ",Bug,Major,Closed,"2016-11-17 15:02:57","2016-11-17 15:02:57",1
"Sonatype Nexus","legacy url mapping instructions are too confusing and not near enough to upgrade documentation","The [Nexus Book chapter on legacy URLs|http://books.sonatype.com/nexus-book/3.1/reference/install.html#config-legacy-url] is a little confusing, I'm not sure I could understand it if I didn't already know what it meant.    I think we just need to say:  # Nexus 3 URLs are different than Nexus 2 URLs, here's an example of each  # If you want Nexus 3 URL to match what you were using in Nexus 2, then you need to do a few things:  #* Ensure the hostname, port, and context root are the same (how to do each of those is documented elsewhere)  #* Set this system property so that the repository URLs match Nexus 2.  # Please note, there's no repository directory browsing in Nexus 3.    ---  From NEXUS-11542 (merged into 1 effort):    Based on [this ticket|https://sonatype.zendesk.com/agent/tickets/16116]:     User could not locate how to enable legacy URL mapping.    While it is documented in the book - it is not in the context of the upgrade docs. The whole legacy URL enablement section here:    https://books.sonatype.com/nexus-book/reference3/install.html#config-legacy-url    Should directly be in the After Upgrade section of the book here:    https://books.sonatype.com/nexus-book/reference3/upgrading.html#_after_the_upgrade    Configuring the legacy url is only relevant for 2.x to 3.x upgrades - putting it in the generic section of the book does not make sense.    I realize there is a link out to it, but again, it is only relevant to upgrades, and should not be in the Configuring the Runtime Environment section of the book.",Bug,Major,Closed,"2016-11-16 16:02:39","2016-11-16 16:02:39",1
"Sonatype Nexus","Search and Browse not handling leading slash properly for content selectors","Very similar to NEXUS-11632 i have content selectors setup against   Which works great for content retrieval.    In order for search/browse to work, I need to also include a  (note the lack of leading slash) content selector",Bug,Major,Closed,"2016-11-15 14:50:22","2016-11-15 14:50:22",1
"Sonatype Nexus","Content selector preview not handling leading slash properly","Suppose i have some content in a docker repository (this most likely applies to other formats, this just happens to be the format i was using), and I want to restrict access to that content, I need to create content selectors that match against paths of /v2/blah.  These paths are now secured as i expect.    Problem is, when trying to test these queries using the content selector preview, I am forced to omit the leading slash to get any results.  We should be able to use the same path matching in both cases",Bug,Major,Closed,"2016-11-15 14:14:10","2016-11-15 14:14:10",1
"Sonatype Nexus","Upgrade does not rescan repositories on back and next","I just noticed if I am Upgrading repositories and click Back to return to Repository Defaults, delete a repository and then click Next again, that repository is still on the list.  Similarly, while testing NEXUS-11530, I made a capability change that should impact the ability to Upgrade the repo but it still said un-Upgradable.    For the first case, if you click Next, it fails the Preview (with a 404).  In either case you can workaround by restarting Upgrade, however, this workaround will likely be unclear to anyone doing this.    Tested with Jelly SNAPSHOT and did not test older NX3 at this time, however, I have no reason to believe this works differently in 3.1.",Bug,Minor,Closed,"2016-11-11 16:12:54","2016-11-11 16:12:54",3
"Sonatype Nexus","Clicking on first (unlabeled) column in component browser gives an illegal argument exception","If you click on the very first (unlabeled) column of the component browser you'll get an illegal argument exception.    The component browser is unusable after doing this until you sort by another column.    ",Bug,Minor,Closed,"2016-11-11 14:27:09","2016-11-11 14:27:09",2
"Sonatype Nexus","Update documentation for nexus behind nginx proxy to also include port","Hello,    I was setting up nexus behind nginx proxy, using the documentation:  https://help.sonatype.com/display/NXRM3M/Run+Behind+a+Reverse+Proxy#RunBehindaReverseProxy-Example:ReverseProxyVirtualHostatCustomContextPath    The documentation suggests using the following configuration for the Host header:        Our nginx runs on a different port than 80, and the nexus administration UI was not working with this setup, because of wrong links to JS / Images etc - they all were missing the port number.     It took me some time to figure out, that nexus is using this Host header to generate the URLs, in the end I've updated my nginx configuration to this:      Would it be possible to update the documentation, if anyone hits the same issue? Maybe also Apache config needs something similar.",Improvement,Trivial,Open,"2016-11-10 13:33:25","2016-11-10 13:33:25",5
"Sonatype Nexus","Nexus 3.0.2_02 not updating archetype catalogs","We publish a number of internal-only archetypes for our team. Previously, in Nexus 2.x, it was something we never had to consider as it just worked. In Nexus 3.0.2_02 (Docker Container), this is not happening. Here is an example POM file we are using:        ",Bug,Major,Open,"2016-11-04 19:32:28","2016-11-04 19:32:28",3
"Sonatype Nexus","ProxyServiceException stack trace logged at WARN when remote responds with HTTP/1.1 401","When the remote proxy repository responds with 401, a stack trace at WARN is on the logs.          This is not desireable. One does not need a full stack trace at WARN level for a 401 response from the remote.    Expected    Log a message at WARN level if the outbound request failed because the expected response code did not match the received response code, with a simple message showing expected code and received HTTP status line.  If the same Logger is at DEBUG levels, print the same message using the WARN logger, but also include the full stack trace.    ",Bug,Major,Closed,"2016-11-04 14:19:58","2016-11-04 14:19:58",0.5
"Sonatype Nexus","Ability to clean up old docker images/layers from hosted repository","There is currently no way to clean up old docker images from a hosted repository.    Docker images can be very large, and are often deployed in environments where access to older versions of an image is not necessary.    There should be a scheduled task to clean up old hosted docker images, and to also clean up layers which are no longer used by any hosted images.    *Acceptance Criteria*   * A user will be able to purge Docker images older than X days from a Docker hosted repository   ** Since Docker images share layers we can't remove all of the layers attached to the image, we have to remove them after we know they aren't used anymore   ** As a part of removing the old images, we should clean up all orphaned layers    NOTE:   * More info on how Docker is handling deletes: [https://github.com/docker/distribution/blob/master/ROADMAP.md#deletes]",Story,Critical,Done,"2016-11-01 18:47:29","2016-11-01 18:47:29",5
"Sonatype Nexus","upgrade to Nexus 3 fails if Nexus 2 has no anonymous user defined","If there is no anonymous user in Nexus 2.x (that is, the user has been deleted and anonymous access is disabled) upgrade fails.    Nexus 3.1.0 log:        Nexus 2.x log:          ",Bug,Major,Closed,"2016-11-01 15:23:20","2016-11-01 15:23:20",1
"Sonatype Nexus","Unable to connect to private repository on dockerhub","Steps to reproduce:    * Set up a private repository on docker hub and add an image to it.  * Proxy Dockerhub, and add HTTP User authentication.   * Attempt to pull the image from your private repository, it fails:      If I add a basic auth header to the retrieve bearer token http request  here: https://github.com/sonatype/nexus-internal/blob/master/private/plugins/nexus-repository-docker/src/main/java/org/sonatype/nexus/repository/docker/internal/DockerProxyFacetImpl.java#L420 then the request succeeds.",Bug,Major,Closed,"2016-10-31 22:51:56","2016-10-31 22:51:56",3
"Sonatype Nexus","provide option to suppress merging metadata for the same npm package in different group members","*Background*    Consider a hypothetical npm package 'bezor' version 1.0.0 (with no namespace), which lives in an npm hosted repo in Nexus.  Various client npm projects use this package, and the dependency version is ~1.0.0 which signifies that the latest minor point release is acceptable.    The hosted repo is the first member of a group, which also contains a proxy for npmjs.org. One day, 'bezor' 1.0.5 shows up on npmjs.org, no relation to the hosted package.  Suddenly, builds start failing as the unrelated package is pulled down.    This is an inevitable consequence of a lack of namespacing with tilde-style dependency versioning, and it's also a blocker for a client adopting NX3 from a home-rolled npm repo.    *Acceptance*  * Administrators can set a system property that prevents npm groups from merging package metadata on a request-by-request basis.  * This only applies to the default namespace. Namespaced components continue to have their metadata merged, regardless of the system property's value.    If this property is set for the example, above, when a client requests metadata for package 'bezor' the client will only be shown metadata from the hosted repo. This contains 'bezor' 1.0.0 and nothing else.    *Notes*  This change won't affect the 'all' endpoint. Clients who request 'all' will still be able to see the multi-member merged metadata for a given package. We believe the exposure to this is minimal since the client doesn't use this to resolve dependencies.",Story,Major,Done,"2016-10-28 18:41:44","2016-10-28 17:41:44",2
"Sonatype Nexus","Blobstore counts inaccurate","To replicate:  # Start Nexus 3, look at the blob store stats  # Migrate content from 2x, in a single repository (<USER>linking)  # 832 changes are brought across  # Blob store stats show 2080 blobs (exactly 2.5x 832)  # In Nexus 3, delete the repository that was migrated  # Blob store stats now show 832 blobs (which is weird)  # Run the 'compact blobstore' scheduled task  # Blob store stats now show 832 blobs (still weird)  => They _should_ be zero.",Bug,Major,Closed,"2016-10-27 16:32:15","2016-10-27 15:32:15",2
"Sonatype Nexus","repodata not updated in repository group after last staging repository is dropped or released","I found out that Nexus Professional does not update Yum metadata after last staging repository present in repository group is dropped or released. Could you please report that to the development team?    Reproduction scenario on Nexus Professional 2.12.1-01:    1. Configure release repository for RPM packages (packages-el6 in our configuration) and a repository group grouping corresponding staging repositories (staged-packages-el6).   2. Configure a staging profile (packages-el6, id: 33ede191a55) that adds staged artifacts to the repository group and releases them to the release repository.   3. Configure Yum: Merge Metadata and Yum: Staging Generate Metadata capabilities for the repository group and staging profile.   4. Create and close two staging repositories containing some artifacts (packages-el6-1003 contained ns-repositories-4.1.0-1.el6; packages-el6-1004 contained ns-repositories-4.1.2-1.el6 and ns-repositories-4.1.3-1.el6).   5. Request repodata/repomd.xml from the repository group - this will merge metadata from the two staging repositories. The metadata should contain artifacts from both staging repositories.   6. Release the first staging repository (packages-el6-1003) and again request repodata/repomd.xml. The updated metadata should contain only artifacts from the remaining staging repository.   7. Release the second staging repository (packages-el6-1004) and request repodata/repomd.xml once more, so Nexus updates the metadata. Although the repository group is now empty, the yum metadata still contains artifacts from the last released staging repository.    ",Bug,Major,Closed,"2016-10-24 16:19:50","2016-10-24 15:19:50",2
"Sonatype Nexus","Drop Inactive Staging Repositories task aborts if a repository is not found","If a staging repository cleanup task encounters a staging repository that is no longer on it's clean up list it aborts running completely.        It shouldn't do this.  Having this task complete is critical to end users who have large numbers of staging repositories, when the task doesn't run it can cause the entire instance to become unstable.  ",Bug,Major,Closed,"2016-10-19 17:17:53","2016-10-19 16:17:53",2
"Sonatype Nexus","valid .woff files fail Strict Content Type Validation with 400 response","My Maven Plugin configuration is        When i execute the command          I'm getting the below error in the Maven build:          Nexus error log:      ",Bug,Major,Closed,"2016-10-19 11:46:53","2016-10-19 10:46:53",2
"Sonatype Nexus","Docker group with registry.access.redhat.com proxy as member does not work","Following set up     - 1 proxy repo of DockerHub  - 1 proxy repo of https://registry.access.redhat.com/  to get access to OpenShift and other certified images  - 1 hosted repo for internal stuff    All of those repos work.    The repos are using a HTTP connector behind a F5 reverse proxy that terminates HTTPS. But all this is working so should not matter.    Now when I create a group and add the hosted repo and the DockerHub  proxy - everything still works.    However as soon as I add the RedHat repo the group repo seems to not  work anymore. I can no longer search or pull anything. The order of the repos does not seem to matter. But we desired order would be internal, redhat, dockerhub.    NXRM is running on RedHat with Oracle Java 8.    Docker client version used was 1.12",Bug,Major,Closed,"2016-10-14 19:56:25","2016-10-14 18:56:25",3
"Sonatype Nexus","java.nio.file.NoSuchFileException for inaccessible mounts prevents support zip generation","It's not clear to me exactly what caused this, but this exception prevented a support zip from being generated on this ticket:     We should catch this exception, log it, and keep going with the system information retrieval.    Minimally we should catch this exception and allow the support zip generation to proceed, which appears to happen if a drive can't be queried for remaining size (dead mapped drive perhaps?).",Bug,Major,Closed,"2016-10-14 18:30:29","2016-10-14 17:30:29",1
"Sonatype Nexus","Error on login from anonymous from a browse details level","I noticed an error firing when I was browsing the details of a component (or asset) and logged in.  See attached.  Subsequently, login does not give the admin cog.  You have to refresh the browser to see it.  This also causes the browse details to show.    Here's the detail from my console:      I did not check older NX3 or NX2 at this time.",Bug,Minor,Closed,"2016-10-12 22:32:22","2016-10-12 21:32:22",1
"Sonatype Nexus","Upgraded (maven?) components do not show in format specific search","An EA user noticed that, post-Upgrade he could keyword search for a component and it would show up but if he searched format specific (maven) that it would not.  I was able to duplicate this by performing the below steps:  1) In your NX2 add a maven artifact like http://localhost:8082/nexus/content/repositories/central/org/stagemonitor/stagemonitor-core/0.19.0/stagemonitor-core-0.19.0.pom  2) Setup and Upgrade NX2 to NX3  3) In your NX3 UI, go to search and expand the list and select Maven specific.  4) Enter artifact ID matching your artifact above (in our case stagemonitor-core).  BUG: No components found message back.    I also see the same issue with Group ID.    The components do show on the list unfiltered, so this seems to be a filtering issue.    After doing this, I added another version to NX3 and this I *was* able to see in format specific search (but still not the original) so this seems to be a problem with Upgrade.  {quote}  http://localhost:8081/repository/maven-central/org/stagemonitor/stagemonitor-core/0.25.0/stagemonitor-core-0.25.0.pom  {quote}  I also checked with a component with no dash in it in case it was a problem with the dash (like NEXUS-9493) but didn't seem to matter.    Upgrade is new to 3.1 so no older backchecking is needed.",Bug,Minor,Closed,"2016-10-11 23:30:32","2016-10-11 22:30:32",1
"Sonatype Nexus","Update license/eula shown in About dialog","*Background*   When we created a single OSS/Pro binary, we inadvertently dropped all language associated with Nexus Repository OSS being a free product to use. This has caused user confusion and consternation.    *Acceptance*   * The about box should shows either the OSS or Pro license, depending on whether there is a license installed.   ** PRO OSS licensed instances should show the Pro license.   * The OSS license should make it clear that Nexus Repo OSS is licensed under the EPL.   * The 'license installation' dialog should show the Pro license.",Story,Major,Done,"2016-10-11 19:02:25","2016-10-11 18:02:25",3
"Sonatype Nexus","Ldap Button View Certificate does not appear on Firefox","When creating a LDAP connection, there is a display bug preventing the View Certificate button to appear, thus preventing to store the certificate.    That makes it impossible to create a LDAPS connection using firefox.    The button appears correctly on Chrome.    The bug appears on the latest version of Firefox.",Bug,Minor,Closed,"2016-10-06 17:32:39","2016-10-06 16:32:39",1
"Sonatype Nexus","support for nuget repository package-versions endpoint","Please support the nuget API endpoint package-versions (e.g.: [https://www.nuget.org/api/v2/package-versions/NUnit?includePrerelease=true]) for faster version check.",Improvement,Major,Closed,"2016-10-06 15:45:12","2016-10-06 14:45:12",1
"Sonatype Nexus","Elasticsearch (JDK) overflow on disks larger than 2^63 (Amazon EFS)","I'm using Nexus OSS 3.0.2-02 in a docker container and the /nexus-data directory is and NFS mount (Amazon EFS). This version of Nexus uses Elasticsearch 2.2 which has a bug with handling large filesystems. Check references below:    https://discuss.elastic.co/t/elasticsearch-with-amazon-elastic-file-system/55867/5  https://github.com/elastic/elasticsearch/pull/20527  https://bugs.openjdk.java.net/browse/JDK-8162520  https://www.elastic.co/guide/en/elasticsearch/reference/2.4/release-notes-2.4.1.html    Any chance you can update nexus bundles org.apache.servicemix.bundles.elasticsearch and org.sonatype.nexus.elasticsearch  to use elasticsearch 2.4.1 ?",Bug,Major,Closed,"2016-10-06 14:44:53","2016-10-06 13:44:53",2
"Sonatype Nexus","ConcurrentModificationException when deleting NPM resource","Some components in an npm repo will persistently throw ConcurrentModificationException on trying to delete them.  This seems to affect all versions of a component with a semver-patch range (every 1.1.x version of a component may be affected but 1.2.x will not be).    Using nexus 3.0.1-01 inside a docker container loosely based off the official sonatype nexus3 dockerfile.  Specifically,  https://download.sonatype.com/nexus/3/nexus-3.0.1-01-unix.tar.gz    The issue seems to be related to how the component is stored, as once it occurs it will persist across reboots.  There seems to be no way to get rid of it once it occurs, although I haven't tried dumping the repo entirely.    If the offending package is published to another npm repo on the same server, it usually is not affected, so I doubt it is related to the content of the package.  I seem to recall that some of the affected package version ranges used to delete just fine, but I can't be sure of that.    The issue happens fairly often to me, about 1 in every 5 semver-patch ranges seem to be affected.    My workflow may be causing this: I have redeploy off, but tend to play fast and loose when developing, and will commonly delete a semver-patch version if I discover a bug soon after publishing it.  Additionally, I tend to scan through the codebase and remove earlier patch versions that are no longer in use.    ",Bug,Major,Closed,"2016-10-05 20:33:09","2016-10-05 19:33:09",2
"Sonatype Nexus","accessibility problems with checkboxes","I would like to report an accessibility bug.    Some things like a field that enables using emails are reported to my screenreader as checkbox. I assume this is not a <input type='checkbox'>. The problem is that pressing a space bar on any checkbox toggles it, but screenreader does not see the state change, and checkbox is always seen unchecked.  I assume you marked a checkbox with aria state properties, so it is actually needed to change the aria state when a real state changes.",Bug,Minor,Closed,"2016-10-02 11:48:17","2016-10-02 10:48:17",1
"Sonatype Nexus","too much DEBUG logging from com.orientechnologies.orient.core.storage.impl.local.paginated.OLocalPaginatedStorage","On relatively calm instances, we ask customers to set their ROOT logger level to DEBUG to help diagnose problems they are experiencing.    But this turns on too much DEBUG logging at from orient for the simplest requests - for example the status resource the UI pings with.          Not only is it too verbose, it is relatively useless for human consumption.    Expected    - the above logging needs to be moved to TRACE in orient *and/or* we  need to add an explicit default log level for com.orientechnologies.orient.core.storage.impl.local.paginated.OLocalPaginatedStorage to level INFO  - the above logging is a huge performance suck and if enabled could contribute to system instability if enabled in a busy system.      ",Bug,Major,Closed,"2016-09-30 20:22:06","2016-09-30 19:22:06",1
"Sonatype Nexus","Get rid of connection pending... status message","The connection pending... message makes proxy repositories in Nexus 3 look broken.  We've seen this over and over now in support:    I think it would be better to change the status to OK or something similar.   I get that we don't really know if it's OK until a connection attempt is made, but this message is too much detail. It just confuses users.",Improvement,Major,Closed,"2016-09-30 14:24:05","2016-09-30 13:24:05",0.5
"Sonatype Nexus","restlet DateUtils uses non-threadsafe WeakHashMap to cache dates which can result in thread contention high CPU","Nexus 2.x may be prone to sustained high CPU and thread contention with RUNNABLE threads showing this stack:        The problem is the old version of restlet used by Nexus has a bug in that WeakHashMap is used concurrently by multiple threads to cache dates.    The restlet team has already identified this issue:    https://github.com/restlet/restlet-framework-java/issues/753    We use an old version of restlet 1.x that would need to be patched to pick up the fix:    https://github.com/sonatype/restlet1x/blob/master/restlet-1.1.6-5346-sonatype/modules/org.restlet/src/org/restlet/util/DateUtils.java#L61    h4. Short Term Fix    Restart Nexus to clear the blocked threads.    h4. Long Term Fix    This issue has affected a limited set of customers. We have no immediate plans to ship the fix in the repository manager 2.x code. You can install a patched jar attached to this issue as you upgrade your repository manager 2.x instance instead.    Attached [^org.restlet-1.1.6-SONATYPE-5348-V8.jar]  removes the DateUtils non-threadsafe ImmutableDate cache.    To install this in 2.14.x:, confirm you have an original jar of the same name as the patched jar. Make a copy of it for backup purposes. The original location will be at:    $\{NEXUS_INSTALLATION_DIR}/nexus/WEB-INF/plugin-repository/nexus-restlet1x-plugin-$\{NEXUS_VERSION}/dependencies/org.restlet-1.1.6-SONATYPE-5348-V8.jar    # Stop Nexus  # replace the original jar with the patched jar. Patched jar sha1 is: a357a6f4fdfbf7677a513fe75dc5d0a650bce777 org.restlet-1.1.6-SONATYPE-5348-V8.jar  # Start Nexus    h4. Permanent Fix    Repository Manager 3.x does not have this problem. Please plan to upgrade to Nexus 3.x latest version.    ",Bug,Minor,Open,"2016-09-29 15:00:03","2016-09-29 14:00:03",2
"Sonatype Nexus","NoClassDefFoundError for SSLSocketImpl on non-Oracle JVM prevents proxying https remote","Description    The fix for [NEXUS-6838] introduced a <USER>dependency on sun.security.ssl.SSLSocketImpl. JREs with alternative JSSE implementations like the IBM JRE do not ship this class.    This dependency leads to a NoClassDefFoundError on attempts to configure a proxy repository with a HTTPS URL, and thus renders the proxy repository feature unusable for https URLs *on non-Oracle JVMs*.    Symptoms    # Browsing remote for proxy repositories with https remote does not work  # Logfile shows        Steps to reproduce:    # download and install IBM JRE  # start nexus 2.x with IBM JRE  # configure a proxy repository with a https remote  # navigate to browse remote and try to browse the content    Suggested fix    Use the plattform independent way to set the host for SNI as documented by Oracle: https://docs.oracle.com/javase/8/docs/technotes/guides/security/jsse/JSSERefGuide.html#SNIExamples    Quick fix    Remove dependency on Oracle JRE by using reflection to access SSLSocketImpl.    The quick fix makes https usable for non-Oracle JREs, but removes SNI support for these JREs.    ---  ---  *The quick was implemented in this issue - SNI still does not work for any JVM other than Oracle JVMs. See NEXUS-6844.*  ---  ---",Bug,Minor,Closed,"2016-09-29 09:17:35","2016-09-29 08:17:35",2
"Sonatype Nexus","Admin cog appears then disappears...then reappears","Testing the past couple days, I've noticed that after signin the admin cog in the header appears briefly then disappears then reappears.  See attached.  It's just fast enough that I can't click it at first unless I try really <USER>know it's coming.    This does not impact NX2 and also seems ok in NX3.0.2 and seems recent regression.  It doesn't break anything but could be polished up.",Bug,Trivial,Closed,"2016-09-28 19:23:29","2016-09-28 18:23:29",2
"Sonatype Nexus","Pro plugins leaked into OSS version and are shown as missing","Starting a vanilla Nexus OSS shows in the plugin console that several of them are missing. Though, they are likely to be available in the Pro version only. Please see attached screenshot.",Bug,Trivial,Closed,"2016-09-28 18:12:05","2016-09-28 17:12:05",0.5
"Sonatype Nexus","UnauthenticatedException should not be logged as ERROR","When someone has an old browser session and they are viewing the Nexus UI, and they need to be authenticated again, Nexus can spit ERROR level log messages in the log related to org.apache.shiro.authz.UnauthenticatedException.        h4. Expected    - permission problems due to unauthenticated access should not be logged at ERROR level. This causes unwarranted concern from log scanners looking for more critical ERROR level server issues. It is completely normal in a server application that sessions sent from a browser can have been expired on the server. This is not an ERROR condition.",Bug,Minor,Closed,"2016-09-28 14:20:29","2016-09-28 13:20:29",1
"Sonatype Nexus","Valid NX2 Repository config fails validation in NX3","Testing 3.1EA  A negativeCache value = -1 is perfectly valid in NX2 but if you attempt to migrate that Repository to NX3 a validation error is thrown. We should set this to the maximum allowable value in NX3 when encountered (should NOT change the rules of the NX3 system to accommodate).    ",Bug,Major,Open,"2016-09-27 23:24:06","2016-09-27 22:24:06",0.5
"Sonatype Nexus","NPM package was unable to transfer from NX2 -> NX3, leading to inability to finish the process","Testing 3.1EA bundle.  Looks like something in the json we're trying to parse is giving jackson grief, and the unfortunate side effect is a broken state during the Upgrade where we're stuck at End phase: SYNC and unable to do anything other than abort the process. Then aborting took a very long time, timing out the UI while leaving the 'Abort' button active. Doing the natural thing and hitting the button again looks like it ran into issues trying to acquire needed locks(see NX3 support zip logs).  Likely there are issues with this 3vot-cli package that would cause issues regardless of Upgrade on NX3, but the forced abort scenario it leads to is not pretty. At the end of this I was left with 17+GB of deleted content in my Blobstore.     ",Bug,Major,Open,"2016-09-27 22:34:36","2016-09-27 21:34:36",3
"Sonatype Nexus","document logging configuration and output files","https://books.sonatype.com/nexus-book/3.0/reference/install.html#directories    This section of the book makes no reference to where a user can find the Nexus log files, and what the log files contain.    This makes a poor user experience if a user is trying to debug a startup problem in particular, because they do not know where to look for logs or what the different log files could contain.    Acceptance:  - document log **configuration** file locations that are visible on disk  -- what are they used for internally  -- when should they be manually edited, if at all  -- possibly do not document at all files that should never be edited manually ( see NEXUS-9304 )  - document *log output* files that are actual logs containing output of the application, located in the $data-dir/log directory  -- jvm.log  -- nexus.log  -- karaf.log  -- request.log  -- archives of nexus and request log     Probably out of scope:  - document how to customize log rotation settings, including location for output  - document console commands like nexus:logger  ","Technical Debt",Major,Closed,"2016-09-26 14:04:05","2016-09-26 13:04:05",1
"Sonatype Nexus","ETag 304 causes 404 response through npm proxy group","I'm running the latest 3.x in Docker as an npm proxy.  I have two repos setup.  One is just a proxy of https://registry.npmjs.org.  The other is a npm group containing the proxy.    I found that {{jspm install npm:string_decoder}} was failing with a 404 response while {{npm install string_decoder}} was working.    The Nexus request log showed identical requests with one returning 404 and the other 200, so I enabled trace logging and observed that the jspm request was sending an {{If-None-Match: 3SLQP4XEWUIBONOV855WOPR0B}} header while the npm request was not.  Here is the full request that was logged:        This seems to be the reason for the difference in the response.  Further in the log, I see:        I found that if I configured my npm registry to reference the proxy repository url directly, that jspm started to work.  It was only with the group repository that the ETag 304 response was being turned into a 404.  So it appears that something may be broken with how an npm group repository handles ETag headers.    A workaround is to just target the proxy repository directly or temporarily disable proxying through Nexus.  (jspm only seems to have this problem for node core modules; other npm requests came through the group just fine, but presumably w/o etags...no clue why it's requesting core modules at all, but it must have some added local metadata for them that it's using to produce the If-None-Match header for its request.)",Bug,Minor,Closed,"2016-09-24 22:30:19","2016-09-24 21:30:19",3
"Sonatype Nexus","deleting a repository may not remove it as a member from group repository","After deleting a -docker- repository (hosted or proxy) that belongs to a group, requests made through the group continue to try to access the deleted repository as seen in the logs.    If a new repository is made with the same name, it is automatically re-added to the group with the old configuration. If a bad configuration is deleted, then recreated with correct configuration, requests still fail. The work around is to remove the repo from the group, then delete it, then recreate it and add it to the group.    For example:    If npm-host-test repo is member of group npm-group-test    If you delete repository npm-host-test, from the UI npm-host-test is no longer a member of npm-group-test, but any requests made to that group generates the following warning:    Additionally the support zip will still show the repository as a member of the npm-group-test.",Bug,Major,Closed,"2016-09-22 21:04:26","2016-09-22 20:04:26",1
"Sonatype Nexus","Unable to upload Python wheel using PyBuilder","I am getting an error when I upload a wheel to Nexus using PyBuilder (http://pybuilder.github.io/). The same project can upload the wheel to pypi-server so I do not believe the problem is with the client. I can successfully install packages using pip and Nexus.    The error message in nexus log is:   ",Bug,Minor,Closed,"2016-09-21 15:28:23","2016-09-21 14:28:23",2
"Sonatype Nexus","Mask the UI on repository/blob store deletion","Because deleting a repository or blob store can be an expensive operation, we should mask the UI until it completes. [@<USER>https://sonatype.aha.io/users/6143649298277051488] noticed that things can blow up otherwise.",Story,Major,Done,"2016-09-21 03:40:12","2016-09-21 02:40:12",0.5
"Sonatype Nexus","Repository Combobox Filtering not working","It appears that ExtJS store filtering is not working properly for Repositories Combobox. It will properly filter when including a single Type/Format, but not with multiples, and also not when trying to exclude Type/Format. ",Bug,Major,Closed,"2016-09-20 19:07:29","2016-09-20 18:07:29",0.5
"Sonatype Nexus","outreach outbound HEAD request triggers OutreachServlet WARN IOException Broken Pipe","No idea why this happens, but something doesn't seem right here with this WARN message related to Outreach:        ",Bug,Minor,Closed,"2016-09-16 19:37:19","2016-09-16 18:37:19",1
"Sonatype Nexus","DEBUG level logging should print HTTP response code Nexus is sending","Nexus 3 has a debug log message indicating that it is sending a response, but it does not show what the response is:        You need to enable TRACE logging to see it:        Please just put the above at DEBUG, it's a PITA to have customers enable trace logging of any kind, because the noise makes it very difficult to go through logs.",Bug,Minor,Closed,"2016-09-15 17:07:16","2016-09-15 16:07:16",0.5
"Sonatype Nexus","Store commonly customized configuration in the data folder","There are commonly customized configuration options that are currently stored in the installation folder and a user needs to remember to copy these over every time.    As an admin, I want to be able to store the commonly customized property files inside the data folder so that I don't have to remember to reapply them or copy them every time I upgrade.    This should include things like the jetty config, port, webapp context, logging, jvm options, ha (hazelcast, orient), ehcache.xml etc.    Acceptance Criteria    * Create a single property file with commonly-changed properties  ** this lives in the data folder, which is read and pushed into other configuration via templates/property placeholders, so that (e.g.) jetty configuration files can still change structure version-to-version  ** a similarly structured default properties file provides values for properties not set by the user (e.g. in cases where Nexus 3.(n+1) adds a new user-configurable property)  ** When NX3 first boots, if the property override file does not exist, NX creates it  *** (No overrides are set in this NX-created file, but comments explain the available configuration properties)   * Subdivide the /etc directory into sub-directories to separate routinely changed configuration from rarely/never-changed configuration files   * Documentation exists to explain this, including the different manual steps needed to upgrade from pre-3.0 to 3.1   * Circulate the proposed layout with the NX team and Support prior to implementation",Story,Major,Done,"2016-09-12 19:15:05","2016-09-12 18:15:05",5
"Sonatype Nexus","publishing npm packages with wrongly encoded ISO-8859-1 JSON fails with 400","It is [common knowledge|https://issues.sonatype.org/browse/NEXUS-8043?focusedCommentId=298663&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-298663] that the official NPM registry contains packages that have wrongly encoded ( non UTF-8 ) pakage.json.     Nexus tries to handle JSON wrongly encoded as ISO-8859-1, by falling back to that encoding when parsing JSON as UTF-8 fails.    *It seems that the npm client may allow you to attempt publishing package.json that is not encoded properly - need to verify this*    The [code from here|https://github.com/sonatype/nexus-internal/blob/ee9501671d3d030a88b2bcf740538b6a706bd09b/private/plugins/nexus-repository-npm/src/main/java/com/sonatype/nexus/repository/npm/internal/NpmJsonUtils.java#L75-L75] shows how Nexus performs a fallback when UTF-8 parsing fails:    {code}  @Nonnull    static NestedAttributesMap parse(final Supplier<InputStream> streamSupplier) throws IOException {      try {        final Map<String, Object> backing =            mapper.<Map<String, Object>>readValue(streamSupplier.get(), rawMapJsonTypeRef);        return new NestedAttributesMap(String.valueOf(backing.get(NpmMetadataUtils.NAME)), backing);      }      catch (JsonParseException e) {        // fallback        if (e.getMessage().contains(Invalid UTF-8 middle byte)) {          // try again, but assume ISO8859-1 encoding now, that is illegal for JSON          final Map<String, Object> backing =              mapper.<Map<String, Object>>readValue(                  new InputStreamReader(streamSupplier.get(), Charsets.ISO_8859_1),                  rawMapJsonTypeRef              );          return new NestedAttributesMap(String.valueOf(backing.get(NpmMetadataUtils.NAME)), backing);        }        throw new InvalidContentException(Invalid JSON input, e);      }    }    {code}      However, parsing can fail with at least one other variation of exception message ( excluding any localized messages ):        ",Bug,Major,Closed,"2016-09-09 15:00:32","2016-09-09 14:00:32",1
"Sonatype Nexus","add anonymous read access support for docker repositories","Users would like to have anonymous read (pull) access to docker repositories in Nexus. This helps consume and share docker images more easily by not requiring a specific login. This is analogous to the benefits offered by anonymous access by other formats.    As an end user, I don't want to have to configure authentication for read only access to docker repositories.  Docker hub does not require this, and neither should Nexus Repository Manager.    According to this comment from a Docker developer the correct way to do this would be to implement token authentication, and to have Nexus hand out tokens for anonymous access:    https://github.com/docker/docker/issues/24129#issuecomment-230610547    There might also be a simpler implementation that should be considered for blanket anonymous access to a repository.  ",Story,Critical,Done,"2016-09-08 13:28:02","2016-09-08 12:28:02",8
"Sonatype Nexus","eager caching of nuget versions contributes to slow query performance","External Report: *Paket*: [#1912](https://github.com/fsprojects/Paket/issues/1912)    I build our solutions with FAKE. In Interaction with Nexus 3 the `paket update` took very long, if I have FAKE in it (I think the problem here is on Nexus 3 side, because it tries to download all the versions of FAKE - and there are a lot of them). And it fails.         I prepared a simple project to reproduce the steps:    https://github.com/WebDucer/Nexus3PaketIssue    1. Install the Docker container for Nexus 3        2. Use the project above to execute `paket update` against nuget.org or Nexus3 as source (comment the unneded sources out).    Expected behavior    `paket update` should update quicker for packages with a lot of versions    Actual behavior    `paket update` need a lot of time, if package `FAKE` is in it.    Known workarounds    Using of two sources (nuget.org on the first place and Nexus 3 on the second).    Thread dump shows the thread getting all versions doing this:    ",Bug,Critical,Closed,"2016-09-07 17:00:18","2016-09-07 16:00:18",3
"Sonatype Nexus","500 response ORecordDuplicatedException when the same npm package metadata is requested concurrently","While testing 3.0.2 npm, I noticed the below in the nexus.log when running the proxy tests.        I also noticed several of these (different packages) in the npm output, I believe related.      ",Bug,Medium,Closed,"2016-09-02 21:37:57","2016-09-02 20:37:57",3
"Sonatype Nexus","user tokens do not work in combination with RUT Auth and LDAP realms","h4. Setup Nexus    # Start with virgin Nexus 2.13.0-01  # Create a file at sonatype-work/nexus/conf/logback-overrides.xml with this content:    # (Optional) Add Nexus patches at https://issues.sonatype.org/browse/NEXUS-10431 and set {{nexus.usertoken.noPopUps=true}} in nexus.properties - **this step is optional to reproduce the underlying problem**  # Start Nexus  # Disable Anonymous Access  # Enable the RUT Auth capability with header value as {{REMOTE_USER}}  # Configure Enterprise LDAP to a server with at least one user in one ldap group. ( [can use Sonatype test LDAP|https://docs.sonatype.com/display/INSIGHT/Testing+IQ+LDAP+Integration] )  # Map a single external ldap role into Nexus with a role member of Nexus Administrator Role  # Configure Nexus 2.13.0-01 Realms as:  * RUT Auth  * User Token  * Xml Auth  * Xml Authz  * Enteprise LDAP    The direct Nexus URL in this case will be http://localhost:8081/nexus    **The attached nexus pro bundle has all of this configured already, with logs showing the problem**    h4. Setup Reverse Proxy    You are going to need a reverse proxy that sets REMOTE_USER header to the name of the LDAP user who is in the mapped LDAP role.    [Example using this support tool|https://github.com/sonatype/nexus-toolbox/tree/master/reverse-proxy]:  {{java -jar ./target/reverse-proxy-1.0-SNAPSHOT.jar -H REMOTE_USER:whitney.haig}}    The reverse proxy URL will be http://localhost:18081 in this case    h4. Perform Test    h5. Step 1  # Clean browser cache or open an incognito window  # Login to UI at direct URL: http://locahost:8081/nexus , using the LDAP username and password, for the user name you setup with the Reverse proxy      h5. Step 2  # Open in another browser or incognito window the reverse proxy URL http://locahost:18081/  - this should automatically log you in as the LDAP user in the REMOTE_USER header.  # Go to your profile in and Access your user token. Make note of this value.    h5. Step 3  Use curl to perform a basic auth request using the valid user token credentials obtained from step 2    Example:      **This fails with 401 instead of 200**    The Nexus log records this information:        Notice it said the token was deleted?    Now go back to the Step 2 browser window. Click Access User Token again. You still see your user token there and you can see in the logs that Nexus still gets this from the user token database.    h4. Problems    There are actually at least three bugs:    # Nexus detects a valid user token as stale when it is not stale  # Nexus claims to remove the stale user token, but it does not do this successfully, as later the same token can be retrieved from the usertoken db - it seems the query to DELETE tokens is broken  # Nexus uses the user token name code as the username to lookup in LDAP ( this is never expected to work )    h4. Expected    - a basic auth request with a valid user token should work with all the stated realms enabled.  - a request with a RUT Auth header of a valid user should authenticate and be properly authorized  - *a user account in LDAP should be able to authenticate to Nexus using either REMOTE_USER header or a valid user token name code, if both realms are enabled and set up correctly*",Bug,Major,Closed,"2016-09-02 20:05:18","2016-09-02 19:05:18",1
"Sonatype Nexus","the icon to collapse user interface feature menu can be easily confused for a back navigation button","We’ve designed our UI to work at 1024x768. Thus, the ability to collapse the feature menu isn’t really needed, and can be disabled. This will also eliminate any confusion about how the collapse arrow relates to the breadcrumb.    !https://issues.sonatype.org/secure/attachment/72950/72950_Assets+-+Nexus+Repository+Manager+2016-08-31+16-58-57.png!",Story,Minor,Done,"2016-08-31 17:13:36","2016-08-31 16:13:36",1
"Sonatype Nexus","Deleting a repository of non-trivial sizes lags and floods the log with exceptions","I tried to delete the maven-central proxy out of my dev instance which contained 1000+ assets (from building goodies or nexus-internal). After clicking Delete repository from the UI no immediate user feedback about the operation was provided, the repo screen was still there showing the deleted maven-central repo. Meanwhile, the NX log got filled with the below exception, about every 5 seconds. After some time, the delete operations seems to finally have completed.        cf. https://github.com/sonatype/nexus-internal/blob/0a364dc7b5085ad1f02781a0752f23a268c5125d/components/nexus-repository/src/main/java/org/sonatype/nexus/repository/storage/StorageFacetImpl.java#L190",Bug,Major,Closed,"2016-08-30 13:58:07","2016-08-30 12:58:07",3
"Sonatype Nexus","limit displayed search criteria to the formats of configured searchable repositories","In the UI, if you expand the Search option all types that Nexus supports are listed even if there are no repositories for a type configured.  I think it would be good if only those types that are are repos set up for in the instances are listed. Listing types that are not supported by this specific Nexus instance could possibly make the user think that there should be support. Which could cause support tickets for the Nexus admin.  For example, a user seeing Docker listed could (as Docker is hype) think that it would proxy Docker hub and try to use it. When it doesn't work (as not proxy is set up) he/she could think something is wrong in this setup starting a internal support ticket to solve this.    Acceptance criteria:    * When no repositories have been configured for a given repository format, that format should not appear as a search option.",Story,Major,Done,"2016-08-29 22:08:52","2016-08-29 21:08:52",5
"Sonatype Nexus","do not prompt for user credentials for RUT authenticated users","If a user is authenticated via RUT authorization they should not be prompted for a password from Nexus under any circumstances, since they do not have one to provide.    This applies to at least the following:    * User Token Retrieval  * NuGet API Key Access  * Support Zip Download    All destructive operations should still require a confirmation dialog ( Yes or No - but not ask for credentials) - such as:    * resetting all user tokens  * resetting NuGet API key",Bug,Major,Closed,"2016-08-24 21:44:48","2016-08-24 20:44:48",5
"Sonatype Nexus","NPM repos don't handle HEAD requests","Looks to be a regression from NX2, and a deviation from the expected behaviour of an npm registry.  While NX2 and https://registry.npmjs.org both respond with 200/404 as expected, NX3 returns 400 in the event of all HEAD requests.   ",Bug,Major,Closed,"2016-08-23 23:48:22","2016-08-23 22:48:22",2
"Sonatype Nexus","Cancel button needs clicked twice, the first time validates","While setting up an LDAP, near the end I clicked Verify login but decided not to verify and instead clicked Cancel.  When I did so, I was informed that the name field was required via validation and had to click cancel again to close the modal.    This seemed familiar ref: https://issues.sonatype.org/browse/NEXUS-8430.  The fix may also be the same.  Interestingly esc and X close implemented in NEXUS-9670 both provide a workaround without actually clicking cancel as well.    I did not check older NX3 or NX2 at this time.  It seems likely based around NEXUS-8430 that this may have been lurking for a while.",Bug,Trivial,Closed,"2016-08-17 19:34:02","2016-08-17 18:34:02",0.5
"Sonatype Nexus","add a search criteria for repository name","It would be nice to have a repository name entry in the 'More criteria' section of the search.    Acceptance    * I am able to search within a specified repository",Improvement,Major,Closed,"2016-08-15 18:10:15","2016-08-15 17:10:15",2
"Sonatype Nexus","The URL and status fields in the Repository admin table should be cloned to browse mode","We withhold important information about repositories from non-admins. Specifically, the repository status and URL fields.  * The repository status field is useful to see when a repository cannot be used by build tools.  * The URL field is necessary for folks to understand how to connect their build tools.   We should make both of these fields available in browse mode.",Story,Major,Done,"2016-08-15 18:08:18","2016-08-15 17:08:18",1
"Sonatype Nexus","Create Blobstore prompts to discard navigating away","Just noticed I went to create a blobstore but immediately backed out and was prompted to discard.  This is inconsistent with our other create options however I suspect this is because the field Type is auto filled with File.  I may be wrong because creating task Execute Script has Language auto filled and does not exhibit the same behavior.  If not a bug, I still think worth documenting.  There are several of these discard bugs floating (most fixed) and it helps at least me to see it here rather than remembering if a bug or not.  At minimum bringing up for triage.    I didn't check older NX3 at this time.  NX2 did not have a Blobstore area so there is nothing to check there.",Bug,Trivial,Closed,"2016-08-11 21:41:47","2016-08-11 20:41:47",0.5
"Sonatype Nexus","Show deployment user ID and IP address in component/asset attributes","In Nexus 2.x you can see the user ID who deployed an artifact in the artifact tab.    This information is not present in Nexus 3.  It should be.  Additionally, it would be good to show the IP address it was deployed from.",Bug,Major,Closed,"2016-08-11 18:29:14","2016-08-11 17:29:14",3
"Sonatype Nexus","Unable to push image whenever it shares layers with another image already pushed by another docker client","h1. Symptoms  When I try to push an image having layers used by other images already pushed onto the nexus docker registry (and pushed by another client) I got the following error message:   Upload failed, retrying: blob upload invalid: blob upload invalid    h1. Step to reproduce  Machine A: boot2docker (see details below)  Machine B: centos (see details below)    # Machine A: Create a Dockerfile (such as the one in attachment) set version in echo to v0.0  # Machine A: build tag and push it to a fresh nexus repository with tag 0.0  # Machine A: update dockerfile and set version in echo to 0.1  # Machine A: build tag and push it to nexus with tag 0.1  # Machine B: get Dockerfile and set version in echo to 1.0  # Machine B: build tag and push it to nexus with tag 1.0    h1. Configuration  h2. Nexus  * Nexus OSS 3.0.0-03  * Nexus running in a docker container.(sonatype/nexus3:3.0.0)  * running behind nginx (handling https)    h2. Clients  2 machines: a centos and a boot2docker hosted in windows 10. Both using the same version of docker  h3. Docker  1.12.0, build 8eab29e  h3. OS  boot2docker: docker-machine.exe version 0.8.0, build b85aac1  centos: CentOS Linux release 7.2.1511 (Core)  h1. Remarks  I tried with a very simple docker image (such as busybox instead of gocd/gocd-agent) and it seems to work.",Bug,Major,Closed,"2016-08-11 16:04:48","2016-08-11 15:04:48",2
"Sonatype Nexus","Branding headers have extraneous gray bars","The UI:Branding capability has a dark grey background by default. This might be okay or it might be better to have a default background color of white.     In addition the header capability has a margin on top and on the bottom that you can not get rid of easily. By default it should have no margin imho.    See the attached screenshot for the header and footer config and how it renders inconsistently for header and footer in terms of grey margins.",Improvement,Minor,Open,"2016-08-09 20:50:14","2016-08-09 19:50:14",1
"Sonatype Nexus","DefaultCapabilityRegistry is not thread-safe","The {{DefaultCapabilityRegistry}} uses a simple {{HashMap}} for its {{references}} field, a lock is used to protect that data structure from concurrent access. The {{getAll()}} method however hands out a direct reference to that very map (its value set actually but that's irrelevant here), exposing it to access that is not guarded by the lock, e.g. an iteration by {{get()}} or other callers which can then encounter exceptions like below.    https://github.com/sonatype/nexus-internal/blob/3ce6cd48c49603b70f3dc1e41efe53122e9ea033/components/nexus-core/src/main/java/org/sonatype/nexus/internal/capability/DefaultCapabilityRegistry.java#L362      ",Bug,Major,Closed,"2016-08-09 20:08:01","2016-08-09 19:08:01",1
"Sonatype Nexus","Staging repositories should not be included in the migration list","Staging isn't currently supported in Nexus 3, we should detect staging repositories and grey them out, similar has been done for central-m1 in this screenshot.  This will let people who have staging know that it isn't in Nexus 3, giving them an opportunity to stop migration early, rather than wasting a large amount of time trying to migrate to Nexus 3.1.",Bug,Major,Closed,"2016-08-05 17:13:30","2016-08-05 16:13:30",1
"Sonatype Nexus","document best practice for url encoding/decoding through reverse proxies","When npm clients send requests to the remote server ( ie. the registry URL ) it needlessly encodes slashs as %2f. Sonatype has filed an npm issue about this because it seems improper that npm client url encodes forward slashes: [https://github.com/npm/npm/issues/16380]    Other clients ( not npm ) may also send URLs with encoded slashes.    Unfortunately this encoding of slashes conflicts with the default settings of Apache httpd which by default DOES NOT ALLOW THEM and WILL RETURN a 404 response.    From [https://httpd.apache.org/docs/2.2/mod/core.html#allowencodedslashes]  {quote}With the default value, Off, such URLs are refused with a 404 (Not found) error.  {quote}  However, if you are running Apache httpd 2.0.52 to 2.2.8 and you set:  {noformat:title=DO NOT DO THIS in Apache httpd 2.0.52 to 2.2.8}  AllowEncodedSlashes On    *and*    The ProxyPass directive may also need nocanon option. From [https://httpd.apache.org/docs/2.2/mod/mod_proxy.html#proxypass] :  {quote}Normally, mod_proxy will canonicalise ProxyPassed URLs. But this may be incompatible with some backends, particularly those that make use of PATH_INFO. The optional nocanon keyword suppresses this and passes the URL path raw to the backend. Note that this keyword may affect the security of your backend, as it removes the normal limited protection against URL-based attacks provided by the proxy.  {quote}  {noformat:title=DO THIS: Example use of nocanon option}  ProxyPass / http://localhost:8081/ nocanon  {noformat}      Basically Sonatype server products do not rely on Apache httpd to filter out suspect URLs containing path info with encoded values, so it is OK and sometimes required to let these through to the backend servers.     Additional Reference: [http://stackoverflow.com/a/9933890/235000]",Story,Major,Done,"2016-08-04 17:06:56","2016-08-04 16:06:56",3
"Sonatype Nexus","LDAP group membership query can fail due to query size limits","When we check for a user's LDAP group membership during authorization the query issued retrieves all groups a user is a member of:        This query (like any LDAP query that retrieves a set) can fail to retreive all results due to query result size limits in the LDAP server.  When this happens there is no workaround, the user's group mapping will not work if the group is not in the returned set.    We should either use a more targeted query, or we should be using a paged result set to retreive all results, rather than trying to get them all in one shot.",Bug,Major,Closed,"2016-08-02 21:19:08","2016-08-02 20:19:08",2
"Sonatype Nexus","Bower proxy repository timeout waiting for connection from pool","# Add a bower proxy for http://bower.herokuapp.com, e.g. repo name bower-proxy  # run {{curl -I http://localhost:8081/repository/bower-proxy/packages/search/foo}} about two dozen times (IIRC, 20 is the max number of connections per route/host of the shared HTTP connection pool, that needs to be exceeded), note that this makes HEAD requests, not GETs  # Eventually observe the exception below and the client receiving 502 Bad Gateway        Part of the issue here maybe that {{DefaultHttpResponseSender}} does not consume/close the response payload for HEAD requests. If that payload is an instance of {{HttpEntityPayload}} as in this bower proxy scenario, the underlying HTTP connection is leaked.",Bug,Major,Closed,"2016-08-02 18:10:21","2016-08-02 17:10:21",2
"Sonatype Nexus","BlobStoreManagerImpl is not thread-safe","The {{BlobStoreManagerImpl}} uses a simple {{HashMap}} for its {{stores}} member which isn't properly protected from concurrent access:  # Fire NX3 up with a debugger  # Set a breakpoint in {{BlobStoreManagerImpl.track()}} (https://github.com/sonatype/nexus-internal/blob/525334ca25c2463544b12dd49aa54ef55ee2a703/components/nexus-core/src/main/java/org/sonatype/nexus/internal/blobstore/BlobStoreManagerImpl.java#L207)  # In one browser tab, create a new blob store  # Observe breakpoint gets hit, leave thread suspended at it  # In another browser tab, create another blob store  # Observe breakpoint gets hit again, i.e. a concurrent thread attempts to modify the {{stores}}  ",Bug,Major,Closed,"2016-08-01 22:45:50","2016-08-01 21:45:50",1
"Sonatype Nexus","EnterpriseLdapManager is not thread-safe","{{EnterpriseLdapManager}} contains a mutable {{ArrayList}} of LDAP connectors (cf.  https://github.com/sonatype/nexus-internal/blob/5e34c8081fa48a0aeb5545c0c7f5aeb1d5d693a3/private/plugins/nexus-ldap-plugin/src/main/java/org/sonatype/nexus/ldap/internal/realms/EnterpriseLdapManager.java#L65). which is improperly managed for concurrent access.  # While {{getLdapConnectors()}} runs and rebuilds the list, nothing prevents/blocks a concurrent invocation of {{on(LdapClearCacheEvent)}}, giving rise to concurrent {{add()}} and {{clear()}} invocations on a non-concurrent list  # While methods like {{authenticateUser()}} iterate over the returned array list from {{getLdapConnectors()}}, nothing blocks a concurrent invocation of {{on(LdapClearCacheEvent)}}, causing {{ConcurrentModificationException}} or more cryptic failures from the iteration    ",Bug,Major,Closed,"2016-07-29 15:30:49","2016-07-29 14:30:49",2
"Sonatype Nexus","Upgrade to OrientDB 2.2.x","We should upgrade to the latest release line of orientdb. This will get us a fix for a known issue: [http://www.prjhub.com/#/issues/7245]  It should also put us back on track for support until we re-up our contract in the September timeframe; plan there is to upgrade to Production support and avoid any issues about backwards support.",Story,Major,Done,"2016-07-22 18:22:04","2016-07-22 17:22:04",5
"Sonatype Nexus","Saving one capability pill erases changes on other without warning","Just noticed that if you have a capability you want to edit and you change a note via the summary pill and you change details via the settings pill, only the one that has focus when you click save saves.  The other is reverted back to it's pre-save state.    This does not occur if you click the enable button and are in the summary pill, instead warning you changes will be discarded.    Trivial workaround to save twice, this is more about potential unrealized data loss when switching.    I did not check older NX3 or NX2 at this time.",Bug,Minor,Open,"2016-07-20 18:59:32","2016-07-20 17:59:32",2
"Sonatype Nexus","Cannot create Crowd capability","I find I am unable to create a Crowd capability using valid setup while I can create my Crowd configuration using the left nav Crowd item (which subsequently creates the capability with the same values).  Editing and deleting seems fine.    I found this testing HA, however, I was able to repro on latest 3.1 SNAPSHOT.  I feel like this is recent regression, however, I have not tested older 3.1s to verify (nor have I tested older 3x as 3.1 is the first official pro release).  I also didn't check NX2.    Error (snipped; full nexus.log attached):  {quote}  2016-07-20 11:11:24,729-0400 ERROR [qtp585549155-319] admin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: capability_Capability.create, java-method: org.sonatype.nexus.coreui.capability.CapabilityComponent.create  java.lang.NumberFormatException: null   at java.lang.Integer.parseInt(Integer.java:542) [na:1.8.0_40]   at java.lang.Integer.parseInt(Integer.java:615) [na:1.8.0_40]   at com.sonatype.nexus.crowd.CrowdConfiguration.<init>(CrowdConfiguration.java:74) [na:na]  ...  {quote}",Bug,Minor,Closed,"2016-07-20 16:16:32","2016-07-20 15:16:32",1
"Sonatype Nexus","RepositoryManagerImpl is not thread-safe","# Fire up NX3 with a debugger  # Set a breakpoint in {{RepositoryManagerImpl.track()}} (https://github.com/sonatype/nexus-internal/blob/8f1102843b5c02ad05a23e1d18e9ff2e24f27ee3/components/nexus-repository/src/main/java/org/sonatype/nexus/repository/manager/RepositoryManagerImpl.java#L158)  # Create a new repo, observe the breakpoint gets hit and leave the thread suspended at it  # Create another repo, observe the breakpoint gets hit again, i.e. two concurrent threads can execute that method which modifies {{repositories}}, a simple {{HashMap}}...",Bug,Major,Closed,"2016-07-20 14:21:44","2016-07-20 13:21:44",2
"Sonatype Nexus","nexus-staging-maven-plugin does not use proxy authentication credentials","I am trying to publish a Java library to Maven Central using the nexus-staging-maven-plugin version 1.6.7 behind a corporate proxy.    In the end, I receive this error:     bq. Failed to execute goal org.sonatype.plugins:nexus-staging-maven-plugin:1.6.7:deploy (injected-nexus-deploy) on project exchange-model: Execution injected-nexus-deploy of goal org.sonatype.plugins:nexus-staging-maven-plugin:1.6.7:deploy failed: Nexus connection problem to URL https://oss.sonatype.org/: 407 - Proxy Authentication Required -> [Help 1]    It seems that the proxy authentication credentials are not picked up by the plugin, even though they are defined in my Maven settings.xml file on the proxy using the 'https' protocol.    Plugin configuration is:  {quote}  <plugin>                  <groupId>org.sonatype.plugins</groupId>                  <artifactId>nexus-staging-maven-plugin</artifactId>                  <version>1.6.7</version>                  <extensions>true</extensions>                  <configuration>                      <serverId>ossrh</serverId>                      <nexusUrl>https://oss.sonatype.org/</nexusUrl>                      <autoReleaseAfterClose>true</autoReleaseAfterClose>                  </configuration>   </plugin>  {quote}    Proxy config is:  {quote}<proxy>     <id>https_psbru</id>     <active>true</active>     <protocol>https</protocol>     <username>user</username>     <password>pass</password>     <host>psbru.cec.eu.int</host>     <port>8012</port>     <nonProxyHosts>localhost|127.0.0.1</nonProxyHosts>  </proxy>  {quote}    The proxy configuration is good since I can perform normal Maven builds and can download exte5rnal libraries. I was able to push the artefact by commenting the 'nexus-staging-maven-plugin' and just performing a 'mvn clean deploy'. My Maven version is 3.2.1.    ",Bug,Major,Closed,"2016-07-20 09:19:49","2016-07-20 08:19:49",3
"Sonatype Nexus","Warning when running installer as root.","A warning should be given when running installer as root user to correct file permissions chown -R nexus-user:nexus-group data     Ideally it would be best if the install asked for nexus user and group  to correct permissions itself.",Improvement,Minor,Closed,"2016-07-19 16:41:58","2016-07-19 15:41:58",2
"Sonatype Nexus","outbound docker proxy requests always insert /library/ and commonly return 404 at the remote","When nexus sends an outbound docker proxy request, the path gets manipulated on the fly to insert /library/.        If the remote is anything other than dockerhub, this can fail with 404, and therefore Nexus returns 404 to the docker client. If /library/ was not inserted, it might have succeeded    ",Bug,Major,Closed,"2016-07-13 16:22:54","2016-07-13 15:22:54",1
"Sonatype Nexus","SSL key/trust store is not thread-safe","# Hook NX up for debugging and set a breakpoint at https://github.com/sonatype/nexus-internal/blob/738eb86c8013f524802cef87e2961975b1f5793a/components/nexus-ssl/src/main/java/org/sonatype/nexus/ssl/internal/geronimo/FileKeystoreInstance.java#L283  # Using two browser tabs, import a SSL certificate into the trust store  # Observe that the breakpoint is reached by both HTTP request threads concurrently    {{FileKeystoreInstance}} uses several basic collections ({{ArrayList}}, {{HashMap}}) that are not thread-safe by themselves and concurrent operations on the key store can cause corruption/failure. We should synchronize all access to {{FileKeystoreInstance}}, potentially even at a higher level like the methods in {{KeyStoreManagerImpl}}.",Bug,Major,Closed,"2016-07-12 19:08:29","2016-07-12 18:08:29",1
"Sonatype Nexus","tmp files may be kept open after deletion","Tmp files seem to kept open after deletion. Maybe they are not being closed properly. There are 380 of these deleted files that kept open in this example.        ",Bug,Major,Closed,"2016-07-12 10:03:13","2016-07-12 09:03:13",2
"Sonatype Nexus","Regression: Maven snapshot remover does not remove asc, md5, and sha1 files","The snapshot remover no longer removes files with extensions of md5, sha1, and asc.     This is a regression which appears to have been introduced in 2.11.4.    ",Bug,Major,Closed,"2016-07-07 16:15:38","2016-07-07 15:15:38",3
"Sonatype Nexus","Move the default location of the data directory in the tar/zip installs out of the install directory","The Nexus installation is temporary, once you upgrade it becomes obsolete. The data directory is permanent, it needs to be preserved across all upgrades. The default data folder should be ../sonatype-work/nexus3/data    We learned the <USER>way a very long time ago that it is a therefore good idea to have the default location of the data directory be outside of the installation directory (under ../sonatype-work/). Doing this will prevent two common errors:    1. Users unpacking new installations directly on top of existing installations  2. Users mistakenly deleting or damaging work directories when they try to move them out of old installations.    An empty sonatype-work/nexus3 folder needs to be included in the bundle so the resulting folders have the correct permissions    We must call out in the release notes and upgrade notes that the data folder has been moved. At this time, we expect the move to be done one time manually by the end users, this is not being automated.    Users upgrading from pre-3.1 will need to either:    * manually move (recommended) or symlink the data folder to expose it to where pre-3.1 stored it   * configure Nexus 3.1 to point to the existing data folder inside the pre-3.1 layout (not recommended)    **Users:** Please consult the official upgrade documentation for upgrade instructions pertaining to this move",Story,Major,Done,"2016-07-06 15:43:03","2016-07-06 14:43:03",3
"Sonatype Nexus","blob store names should be case insensitive","Acceptance    * Blob store name uniqueness checks should be case insensitive",Story,Major,Done,"2016-07-05 04:46:06","2016-07-05 03:46:06",5
"Sonatype Nexus","Task produces WARN if incorrect repository is selected","Running Remove snapshots from Maven repository task with a proxy or hosted release repository selected fires the below WARN and errors the task.  Both proxy and hosted release repositories are available in the dropdown of repositories (and for maven configured by default).    I do not believe these failing repository types should be in the dropdown if they just cause errors.  This is borderline bug/improvement but I made a bug because of the error.    {quote}  016-07-01 14:40:55,715-0400 WARN  [quartz-2-thread-4] *SYSTEM org.sonatype.nexus.quartz.internal.task.QuartzTaskJob - Task 6b9d9397-3ed8-495d-923b-7c0646340fb7 : 'test2' [repository.maven.remove-snapshots] execution failure  java.lang.IllegalStateException: null   at com.google.common.base.Preconditions.checkState(Preconditions.java:158) [com.google.guava:18.0.0]   at org.sonatype.nexus.repository.RepositoryTaskSupport.findRepositories(RepositoryTaskSupport.java:83) [na:na]   at org.sonatype.nexus.repository.RepositoryTaskSupport.execute(RepositoryTaskSupport.java:53) [na:na]   at org.sonatype.nexus.scheduling.TaskSupport.call(TaskSupport.java:89) [org.sonatype.nexus.scheduling:3.1.0.SNAPSHOT]   at org.sonatype.nexus.quartz.internal.task.QuartzTaskJob.doExecute(QuartzTaskJob.java:144) [org.sonatype.nexus.quartz:3.1.0.SNAPSHOT]   at org.sonatype.nexus.quartz.internal.task.QuartzTaskJob.execute(QuartzTaskJob.java:105) [org.sonatype.nexus.quartz:3.1.0.SNAPSHOT]   at org.quartz.core.JobRunShell.run(JobRunShell.java:202) [org.quartz-scheduler.quartz:2.2.2]   at org.sonatype.nexus.thread.internal.MDCAwareRunnable.run(MDCAwareRunnable.java:40) [org.sonatype.nexus.thread:3.1.0.SNAPSHOT]   at org.apache.shiro.subject.support.SubjectRunnable.doRun(SubjectRunnable.java:120) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.SubjectRunnable.run(SubjectRunnable.java:108) [org.apache.shiro.core:1.2.4]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_40]   at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_40]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_40]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_40]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  {quote}    Specifically seems to be happening because Repositories with a policy of RELEASE can be selected, even though they can't possibly contain SNAPSHOT jars. Note that this is stored in Repository attributes, which presently aren't exposed as a criteria to choose from in RepositoryComboBox definition.",Bug,Minor,Closed,"2016-07-01 20:15:50","2016-07-01 19:15:50",1
"Sonatype Nexus","NPM proxy repository Timeout waiting for connection from pool","npm install <package> is returning HTTP 500 errors.    In the logs we are seeing the following connection pool time outs. Restarting Nexus resolved the issue.    ",Bug,Critical,Closed,"2016-06-30 17:07:16","2016-06-30 16:07:16",2
"Sonatype Nexus","Docker pull through proxy repository fails if remote is not available","Set up a docker proxy repository against dockerhub, pull an image through it.    Then disable outbound network access (for testing, I did this by setting an http proxy server that doesn't exist in the HTTP settings).    Then try to pull the image again.  This fails with a 502 error.    {quote}  docker pull 192.168.1.83:18887/tomcat  Using default tag: latest  Error response from daemon: Received unexpected HTTP status: 502 Bad Gateway  {quote}    The nexus.log shows what you would expect:    ",Bug,Major,Closed,"2016-06-29 18:49:08","2016-06-29 17:49:08",3
"Sonatype Nexus","nested webapp context path Nexus 3 breaks the UI","Edit $NEXUS_HOME/etc/org.sonatype.nexus.cfg, and set:        After doing this, the UI heartbeat does not work, the request is sent to http://localhost:8081/foo/service/extdirect rather than http://localhost:8081/foo/nexus/service/extdirect.    This sort of context path works in Nexus 2.x.      ",Bug,Major,Closed,"2016-06-29 16:09:33","2016-06-29 15:09:33",2
"Sonatype Nexus","automatically clear the karaf bundle cache on startup","NEXUS-10014 has a good summary of the options for clearing bundle cache on startup.    The resolution of NEXUS-10014 meant:    - the UI installer touches a clean_cache file inside the chosen data directory so that the bundle cache is cleared on startup  - the archive installers include a clean_cache file inside their default ( but not optimal ) data subdirectory    According to some recent analysis we still have significant user base using the archives (zip/tgz) to install Nexus. In the use case of upgrade using the archive bundle, a user needs to edit bin/nexus.vmoptions and change the karaf.data property value to reference their existing, to be upgraded data directory. They then also need to manually create a clean_cache file there so that on startup the cache is cleared.    This issue is about eliminating the step of creating the clean_cache file and instead, configuring Nexus to always reload the bundle cache on startup. Other than some so far reportedly insignificant startup processing of bundle caching, I haven't heard of a good reason not to do this. Implementing this aims to make the upgrade process simpler.  ",Improvement,Major,Closed,"2016-06-28 18:23:43","2016-06-28 17:23:43",0.5
"Sonatype Nexus","Bower hosted does not use 404 framework","Hitting a non-existant mapping.json in a bower hosted repository returns a blank page.  However, page debug shows Failed to load resource: the server responded with a status of 404 (Not Found) so the suspicion is that it's just not utilizing the 404 page we have in general place.    Example (with bower-hosted repository newly setup): http://localhost:8081/repository/bower-hosted/test2/mapping.json    I did not back check older NX3 versions.  This bug does not affect NX2 as it this format is not implemented there.",Bug,Trivial,Closed,"2016-06-24 16:52:42","2016-06-24 15:52:42",1
"Sonatype Nexus","Nexus 3 Basic realm name does not equal Nexus 2 realm name","*For repository content* the Basic auth realm name of nexus 2 when accessing content is Sonatype Nexus Repository Manager.    The Basic auth realm name of nexus 3.0.0 is Sonatype Nexus.    We have seen at least one instance of breakage when changing realm names:     https://issues.sonatype.org/browse/OSSRH-19926    When a user migrates from Nexus 2 to Nexus 3, this realm name change could cause builds using IVY based deployments ( SBT, ANT ) to start failing. Fixing this on the client side could require a huge set of ivysettings.xml changes in source control or build jobs. ivysettings.xml fils can contain sections with credentials such as         While 'realm' [is an optional configuration attribute|http://ant.apache.org/ivy/history/latest-milestone/settings/credentials.html] - even if it is left out, then credentials will not be found that match the realm name and authentication fails with 401 like it does when the realm name is specified but does not match exactly the realm name sent in the Nexus WWW-Authenticate header.    Should the Nexus 3 realm equal the Nexus 2 realm name?",Bug,Major,Closed,"2016-06-22 15:05:39","2016-06-22 14:05:39",1
"Sonatype Nexus","Page warns of lack of access despite handling it","I granted a user a role with the nx-repository-admin-*-*-* privilege and noticed when I accessed repository (in pro) that I got a warning about healthcheck.  Results do appear and the healthcheck column is hidden/missing, so it seems this warning is not necessary.    Error also appears in nexus.log:      Filing for triage discussion as there may be a reason this occurs (like we want users to know there are things they can't see?).  If this is intentional, that error level seems high to me.    I did not backcheck older NX3, mostly because 3.1 will be the first version we support PRO and OSS is not affected.  I didn't check NX2 either.",Bug,Trivial,Closed,"2016-06-20 21:02:10","2016-06-20 20:02:10",1
"Sonatype Nexus","RubyGems assets have horizontal scroll that remains regardless of browser width","Just noticed that my rubygems asset had a horizontal scroll, so I made my browser bigger and it remained.  I fullsized my browser and it still remained.  I scrolled right to see what I wasn't seeing and it shows the right border.  Apparently the only way to get this displayed is to scroll right not browser size...I think this is a bug.    I did not back check older NX3.  I noticed that with docker assets this does not happen so made the title format specific for now.  If I see any other component types this is affecting I'll update.  I am surprised that this is not format generic, but there we have it.",Bug,Trivial,Closed,"2016-06-20 20:04:57","2016-06-20 19:04:57",1
"Sonatype Nexus","Can't find packages registered to hosted repository with 'bower search ...'","I've succesfully registered a private package to a hosted repository but I can't find this package via 'bower search ...'    Here is my .bowerrc file:      ",Bug,Major,Closed,"2016-06-16 14:06:35","2016-06-16 13:06:35",3
"Sonatype Nexus","docker pull fails for certain images from docker hub","Configure a standard docker proxy repository (named docker-proxy) to docker hub. Enable V1 support.    Using Docker 1.8.2 client/daemon, execute this command    docker pull rabbitmq:3-management    This works fetching from the official repo.    This does not work against Nexus:    docker pull 192.168.2.97:9540/rabbitmq:3-management    Where 192.168.2.97 is the Nexus IP and 9540 is the https port for docker-proxy.    Installing the patch at https://support.sonatype.com/hc/en-us/articles/218729178-Nexus-Repository-Manager-3-0-0-03-Docker-Rollup-Patch does not seem to help.    ",Bug,Major,Closed,"2016-06-14 17:04:53","2016-06-14 16:04:53",3
"Sonatype Nexus","Set the CONNECT user-agent header value as Nexus user agent","Regression of NEXUS-7575 from Nexus 2.    In Nexus 3, the User-Agent value is set on CONNECT to the HTTPClient value instead of the Nexus user agent. This matters because some orgs look at the value and filter requests based on it.     Nexus 3 CONNECT example - it is set - but incorrectly:          Nexus 2 CONNECT example:        h3. Expected  - all outbound HTTP requests should have the Nexus User-Agent value NOT some other value ( unless doing this would violate a repository format protocol )      ",Bug,Major,Closed,"2016-06-10 14:13:58","2016-06-10 13:13:58",1
"Sonatype Nexus","invalid json in bower authentication documentation","missing comma in bower authentication documentation    at the end of the section 11.6 in this page    https://books.sonatype.com/nexus-book/3.0/reference/bower.html#bower-download    valid json is     ",Bug,Major,Closed,"2016-06-02 11:21:24","2016-06-02 10:21:24",0.5
"Sonatype Nexus","Docker client <= 1.9.1 cannot pull images which are push by a docker client >= 1.10.0","An image has been pushed to Nexus 3.0 by a Docker client which version was 1.10.0 or later. Now I cannot pull this image with a Docker client which version is <= 1.9.1.  I get following error:      I can successfully pull images which has been pushed with an 1.9.1 Docker client.    I tried without success the following:  * to disable V1 support for the group repository  * configure nginx to apply headers to all GET requests in order to enforce V1 or V2 manifests:    {{add_header Docker-Distribution-Api-Version registry/2.0 always;}}    {{add_header Accept application/vnd.docker.distribution.manifest.v2+json;}}    {{proxy_set_header  Accept application/vnd.docker.distribution.manifest.v2+json;}}    With version 1.10.0 of Docker the format of the manifest has changed. I'm using an Nginx configuration as described in chapter [Example: Reverse Proxy SSL Termination at Base Path| https://books.sonatype.com/nexus-book/3.0/reference/install.html#_example_reverse_proxy_ssl_termination_at_base_path].",Bug,Major,Closed,"2016-05-31 17:50:18","2016-05-31 16:50:18",3
"Sonatype Nexus","* dependency not resolved by nexus proxy whereas resolved by bower repo","add a star dependencies in bower,json.  e.g.       try to to install dependencies with bower install  get error      Work around is to replace * by master.  e.g.       ",Bug,Major,Closed,"2016-05-31 14:09:13","2016-05-31 13:09:13",3
"Sonatype Nexus","Long delay after large maven artifact is uploaded, results in failure due to jetty idle timeout","I'm seeing a long delay uploading large Maven artifacts.   The entire artifact is uploaded, and then the maven build just sits there for a long time waiting for an HTTP response.    A thread dump taken tat this time shows that Nexus is computing the checksum of the artifact.  Is it possible we've regressed and lost the fix for NEXUS-4194?    ",Bug,Major,Closed,"2016-05-26 20:49:01","2016-05-26 19:49:01",3
"Sonatype Nexus","pushing NuGet packages larger than 2GB fails","Push of a very large NuGet package fails.  This one is about 2.5Gb:    {quote}  $ ls -l  total 5734448  -rw-r--r--   1 <USER> staff  2935807073 May 26 14:13 NUnit.2.6.3.nupkg  {quote}    This fails due to a number format error trying to convert the string to an integer:      ",Bug,Major,Closed,"2016-05-26 20:24:38","2016-05-26 19:24:38",2
"Sonatype Nexus","Upgrade cannot abort in between stages","While testing various migration items, it seemed weird to me that you *can't* abort when you've finished a substep (and can progress to the next step) but that you *can* abort when you proceed to the next step.  For example, if you're in preperation and it's done, you can't abort but if you proceed to synchronizing you can.    I think this is weird to me, because you're not aborting the step, you're aborting migration.  So if you prepare then decide you want to do this later, I think it makes sense to be able to without clicking next.  NOTE: Clicking away preserves the state so does not abort.  I'm assuming shutting down the server would however might be messy.  Am filing, at least for triage, after discussion with [~<USER>.  I mentioned this in HC as well (migrate room) and didn't get an immediate explain or contradiction.    Let me know if not clear, I didn't feel like screen or vid would explain so didn't do it.  I could do a screenshare or do a vid with sound.",Bug,Trivial,Closed,"2016-05-26 18:21:12","2016-05-26 17:21:12",2
"Sonatype Nexus","extremely poor performance in user role/privilege resolution for LDAP users","When an LDAP mapped user uses Nexus we are repeated looping through all of their LDAP groups. This is done for every single privilege check.  The comparison done is very inefficient, and an exception is thrown for each group not found mapped to a nexus role.    Here's an example, there were 970 of these just for this one group in 11 seconds. All I did was click around the UI a bit while logged in as an LDAP user mapped to nx-admin. This is repeated for every group my test user is a member of.        Acceptance Criteria:  * Examine how to reduce the exception count as a bare minimum  * Some minimal tuning to identify what the deeper issue is  * Solve low hanging fruit, gain information on larger issues  ** Get together to produce follow up issues/stories based on deeper understanding    NOTE:  * We will need to test this against a large LDAP instance to verify the fixes if we make any",Bug,Critical,Closed,"2016-05-20 14:56:44","2016-05-20 13:56:44",3
"Sonatype Nexus","npm package version-specific requests respond '404 not found' instead of version-specific JSON metadata","We are having an issue proxying npm artifacts in our nexus3 repo from the official npm repostiory. Some artifacts are being proxied but others are failing. It seems that any artifact that is requested with a specific version identifier is failing. For example you can see below the 304 were successful because there was no version at the end of the url, whereas the 404 failures were all on urls with a version at the end of the url. Is this a bug or a configuration issue? I attached the full npm-debug log.    [INFO] npm http 304 https://internal.nexus.company.com:8450/repository/npmjs/grunt-contrib-less  [INFO] npm http 304 https://internal.nexus.company.com:8450/repository/npmjs/grunt-contrib-watch  [INFO] npm http 304 https://internal.nexus.company.com:8450/repository/npmjs/grunt-karma  [INFO] npm http 304 https://internal.nexus.company.com:8450/repository/npmjs/grunt-contrib-uglify  [INFO] npm http 404 https://internal.nexus.company.com:8450/repository/npmjs/grunt-bump/0.0.6  [INFO] npm ERR! registry error parsing json  [INFO] npm http 404 https://internal.nexus.company.com:8450/repository/npmjs/karma-phantomjs-launcher/0.1.4  [INFO] npm ERR! registry error parsing json  [INFO] npm http 404 https://internal.nexus.company.com:8450/repository/npmjs/karma-junit-reporter/0.2.1  [INFO] npm ERR! registry error parsing json  [INFO] npm http 404 https://internal.nexus.company.com:8450/repository/npmjs/karma/0.10.10  [INFO] npm ERR! registry error parsing json  [INFO] npm http 304 https://internal.nexus.company.com:8450/repository/npmjs/grunt-html2js  [INFO] npm http 404 https://internal.nexus.company.com:8450/repository/npmjs/karma-chrome-launcher/0.1.2  [INFO] npm ERR! registry error parsing json  [INFO] npm http 404 https://internal.nexus.company.com:8450/repository/npmjs/karma-coffee-preprocessor/0.1.3  [INFO] npm ERR! registry error parsing json  [INFO] npm http 404 https://internal.nexus.company.com:8450/repository/npmjs/karma-firefox-launcher/0.1.3",Bug,Major,Closed,"2016-05-19 18:33:08","2016-05-19 17:33:08",2
"Sonatype Nexus","Content type exception uploading tar files - identified as application-gtar instead of application/tar","When uploading a tar file, Nexus throws an {{InvalidContentException}} complaining that it detected content type {{application/x-gtar}}, but expected {{application/x-tar}}. Internally Nexus uses the Apache Tika library for determining content type and first we do a detection by file extension, and then we do a detection by file contents, and throw an exception if they don't match. For Tar files Tika will return {{application/x-tar}} for name and {{application-x/gtar}} for contents. This is because most modern tar implementation will default to the 'gnu' format (i.e. a gtar), but most users still call it a tar.         *Original Bug Report Description:*    While testing initial pypi implementation, we attempted to upload a tar file into our pypi hosted but were blocked by content validation. tar files were one of the listed file extensions that pypi supported.    From the pypi cli:    From the nexus.log:    After investigation, we found the same thing occurs when you try and push the tar into a raw hosted repository.    Once you have the tar file in the hosted repository, it proxies however you need to turn strict content validation off for your proxy as well.    Since the team could not find any tar files that could be proxied from pypi.python.org and there is a workaround, as well as affects other repository types, we decided this was a non-blocker for now. We will watch for <USER>feedback and see if it hits anyone.  h3. Workaround    The workaround is to turn strict content validation off for the hosted pypi repository.",Bug,Minor,Closed,"2016-05-17 19:16:00","2016-05-17 18:16:00",1
"Sonatype Nexus","Capture stdout and stderr to logfile","Nexus 3 has no default log that captures stdout/stderr. This means that the most reliable way to get a thread dump from a hung instance (kill -3) will not work.    This is a regression from Nexus 2, and has serious implications for support. Other methods of getting thread dumps such as jstack require that a JDK is available, and even when these tools are available they are not as reliable as sending a SIGQUIT.    *Acceptance*     Output written to stdout and stderror are written to the standard logs",Story,Major,Done,"2016-05-17 18:47:32","2016-05-17 17:47:32",2
"Sonatype Nexus","PyPI: Search custom only finds results on lower case","While testing the pypi implementation, I found that searching on custom fields only found results (of either case) if I searched using lower case.  For example, apple will find Apple, apple and APPLE but Apple will not find Apple.  This was decided out of scope for PyPI and a general search issue.  I do not recall I've seen in any other format however.  In fact, NEXUS-8879 speaks to the reverse.  This is especially confusing because as far as I can tell all the PyPI classifiers start with capital letters.  This renders this search custom field useless unless you know this workaround or are lazy about case.",Bug,Minor,Closed,"2016-05-16 23:11:03","2016-05-16 22:11:03",0.5
"Sonatype Nexus","Maven httpclient may receive SocketException Broken pipe instead of expected status code on deploy","Using the standard {{mvn deploy:deploy-file}} to a Nexus 3 maven repository, **when a server section with matching id in ~/.m2/settings.xml is not configured properly**, then Maven throws a broken pipe exception instead of reporting the 401 unauthorized from Nexus. This causes a retry death spiral and changes the behaviour of how Maven would normally react.    Using the same scenario with Nexus 2 causes Maven to report the 401 as expected and stop immediately.    {noformat:title=Nexus 3}  [DEBUG] Configuring mojo org.apache.maven.plugins:maven-deploy-plugin:2.8.2:deploy-file from plugin realm ClassRealm[plugin>org.apache.maven.plugins:maven-deploy-plugin:2.8.2, parent: sun.misc.Launcher$AppClassLoader@45ee12a7]  [DEBUG] Configuring mojo 'org.apache.maven.plugins:maven-deploy-plugin:2.8.2:deploy-file' with basic configurator -->  [DEBUG]   (f) artifactId = project  [DEBUG]   (f) file = /app/clm-testing/jenkins/hudson-2.2.1.war  [DEBUG]   (f) generatePom = true  [DEBUG]   (f) groupId = com.somecompany  [DEBUG]   (s) localRepository =       id: local        url: file:///Volumes/OSX/m2r/     layout: default  snapshots: [enabled => true, update => always]   releases: [enabled => true, update => always]    [DEBUG]   (f) offline = false  [DEBUG]   (f) packaging = war  [DEBUG]   (f) project = MavenProject: org.apache.maven:standalone-pom:1 @   [DEBUG]   (f) repositoryId = local-nexu  [DEBUG]   (f) repositoryLayout = default  [DEBUG]   (f) retryFailedDeploymentCount = 1  [DEBUG]   (f) uniqueVersion = true  [DEBUG]   (f) updateReleaseInfo = false  [DEBUG]   (f) url = http://localhost:9081/repository/maven-releases/  [DEBUG]   (f) version = 1.0.0  [DEBUG] -- end configuration --  [DEBUG] Using transporter WagonTransporter with priority -1.0 for http://localhost:9081/repository/maven-releases/  [DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://localhost:9081/repository/maven-releases/ via 127.0.0.1:8888  Uploading: http://localhost:9081/repository/maven-releases/com/somecompany/project/1.0.0/project-1.0.0.war  May 16, 2016 10:14:55 AM org.apache.maven.wagon.providers.http.httpclient.impl.execchain.RetryExec execute  INFO: I/O exception (java.net.SocketException) caught when processing request to {}->http://127.0.0.1:8888->http://localhost:9081: Broken pipe  May 16, 2016 10:14:55 AM org.apache.maven.wagon.providers.http.httpclient.impl.execchain.RetryExec execute  INFO: Retrying request to {}->http://127.0.0.1:8888->http://localhost:9081  May 16, 2016 10:14:55 AM org.apache.maven.wagon.providers.http.httpclient.impl.execchain.RetryExec execute  INFO: I/O exception (java.net.SocketException) caught when processing request to {}->http://127.0.0.1:8888->http://localhost:9081: Broken pipe  May 16, 2016 10:14:55 AM org.apache.maven.wagon.providers.http.httpclient.impl.execchain.RetryExec execute  INFO: Retrying request to {}->http://127.0.0.1:8888->http://localhost:9081  May 16, 2016 10:14:55 AM org.apache.maven.wagon.providers.http.httpclient.impl.execchain.RetryExec execute  INFO: I/O exception (java.net.SocketException) caught when processing request to {}->http://127.0.0.1:8888->http://localhost:9081: Broken pipe  May 16, 2016 10:14:55 AM org.apache.maven.wagon.providers.http.httpclient.impl.execchain.RetryExec execute  INFO: Retrying request to {}->http://127.0.0.1:8888->http://localhost:9081  Uploading: http://localhost:9081/repository/maven-releases/com/somecompany/project/1.0.0/project-1.0.0.pom  [INFO] ------------------------------------------------------------------------  [INFO] BUILD FAILURE  [INFO] ------------------------------------------------------------------------  [INFO] Total time: 0.628 s  [INFO] Finished at: 2016-05-16T10:14:55-03:00  [INFO] Final Memory: 12M/309M  [INFO] ------------------------------------------------------------------------  [ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.8.2:deploy-file (default-cli) on project standalone-pom: Failed to deploy artifacts: Could not transfer artifact com.somecompany:project:war:1.0.0 from/to local-nexu (http://localhost:9081/repository/maven-releases/): Broken pipe -> [Help 1]  org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.8.2:deploy-file (default-cli) on project standalone-pom: Failed to deploy artifacts: Could not transfer artifact com.somecompany:project:war:1.0.0 from/to local-nexu (http://localhost:9081/repository/maven-releases/): Broken pipe   at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:216)   at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)   at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)   at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)   at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)   at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)   at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)   at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)   at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)   at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)   at org.apache.maven.cli.MavenCli.execute(MavenCli.java:862)   at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:286)   at org.apache.maven.cli.MavenCli.main(MavenCli.java:197)   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:498)   at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)   at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)   at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)   at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)  Caused by: org.apache.maven.plugin.MojoExecutionException: Failed to deploy artifacts: Could not transfer artifact com.somecompany:project:war:1.0.0 from/to local-nexu (http://localhost:9081/repository/maven-releases/): Broken pipe   at org.apache.maven.plugin.deploy.DeployFileMojo.execute(DeployFileMojo.java:284)   at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)   at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208)   ... 20 more  Caused by: org.apache.maven.artifact.deployer.ArtifactDeploymentException: Failed to deploy artifacts: Could not transfer artifact com.somecompany:project:war:1.0.0 from/to local-nexu (http://localhost:9081/repository/maven-releases/): Broken pipe   at org.apache.maven.artifact.deployer.DefaultArtifactDeployer.deploy(DefaultArtifactDeployer.java:143)   at org.apache.maven.plugin.deploy.AbstractDeployMojo.deploy(AbstractDeployMojo.java:171)   at org.apache.maven.plugin.deploy.DeployFileMojo.execute(DeployFileMojo.java:280)   ... 22 more  Caused by: org.eclipse.aether.deployment.DeploymentException: Failed to deploy artifacts: Could not transfer artifact com.somecompany:project:war:1.0.0 from/to local-nexu (http://localhost:9081/repository/maven-releases/): Broken pipe   at org.eclipse.aether.internal.impl.DefaultDeployer.deploy(DefaultDeployer.java:317)   at org.eclipse.aether.internal.impl.DefaultDeployer.deploy(DefaultDeployer.java:245)   at org.eclipse.aether.internal.impl.DefaultRepositorySystem.deploy(DefaultRepositorySystem.java:413)   at org.apache.maven.artifact.deployer.DefaultArtifactDeployer.deploy(DefaultArtifactDeployer.java:139)   ... 24 more  Caused by: org.eclipse.aether.transfer.ArtifactTransferException: Could not transfer artifact com.somecompany:project:war:1.0.0 from/to local-nexu (http://localhost:9081/repository/maven-releases/): Broken pipe   at org.eclipse.aether.connector.basic.ArtifactTransportListener.transferFailed(ArtifactTransportListener.java:43)   at org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run(BasicRepositoryConnector.java:355)   at org.eclipse.aether.connector.basic.BasicRepositoryConnector.put(BasicRepositoryConnector.java:274)   at org.eclipse.aether.internal.impl.DefaultDeployer.deploy(DefaultDeployer.java:311)   ... 27 more  Caused by: org.apache.maven.wagon.TransferFailedException: Broken pipe   at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.put(AbstractHttpClientWagon.java:646)   at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.put(AbstractHttpClientWagon.java:541)   at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.put(AbstractHttpClientWagon.java:523)   at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.put(AbstractHttpClientWagon.java:517)   at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.put(AbstractHttpClientWagon.java:497)   at org.eclipse.aether.transport.wagon.WagonTransporter$PutTaskRunner.run(WagonTransporter.java:644)   at org.eclipse.aether.transport.wagon.WagonTransporter.execute(WagonTransporter.java:427)   at org.eclipse.aether.transport.wagon.WagonTransporter.put(WagonTransporter.java:410)   at org.eclipse.aether.connector.basic.BasicRepositoryConnector$PutTaskRunner.runTask(BasicRepositoryConnector.java:510)   at org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.run(BasicRepositoryConnector.java:350)   ... 29 more  Caused by: java.net.SocketException: Broken pipe   at java.net.SocketOutputStream.socketWrite0(Native Method)   at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)   at java.net.SocketOutputStream.write(SocketOutputStream.java:153)   at org.apache.maven.wagon.providers.http.httpclient.impl.io.SessionOutputBufferImpl.streamWrite(SessionOutputBufferImpl.java:123)   at org.apache.maven.wagon.providers.http.httpclient.impl.io.SessionOutputBufferImpl.flushBuffer(SessionOutputBufferImpl.java:135)   at org.apache.maven.wagon.providers.http.httpclient.impl.io.SessionOutputBufferImpl.write(SessionOutputBufferImpl.java:164)   at org.apache.maven.wagon.providers.http.httpclient.impl.io.ContentLengthOutputStream.write(ContentLengthOutputStream.java:115)   at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon$RequestEntityImplementation.writeTo(AbstractHttpClientWagon.java:205)   at org.apache.maven.wagon.providers.http.httpclient.impl.DefaultBHttpClientConnection.sendRequestEntity(DefaultBHttpClientConnection.java:155)   at org.apache.maven.wagon.providers.http.httpclient.impl.conn.CPoolProxy.sendRequestEntity(CPoolProxy.java:149)   at org.apache.maven.wagon.providers.http.httpclient.protocol.HttpRequestExecutor.doSendRequest(HttpRequestExecutor.java:236)   at org.apache.maven.wagon.providers.http.httpclient.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:121)   at org.apache.maven.wagon.providers.http.httpclient.impl.execchain.MainClientExec.execute(MainClientExec.java:254)   at org.apache.maven.wagon.providers.http.httpclient.impl.execchain.ProtocolExec.execute(ProtocolExec.java:195)   at org.apache.maven.wagon.providers.http.httpclient.impl.execchain.RetryExec.execute(RetryExec.java:86)   at org.apache.maven.wagon.providers.http.httpclient.impl.execchain.RedirectExec.execute(RedirectExec.java:108)   at org.apache.maven.wagon.providers.http.httpclient.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:184)   at org.apache.maven.wagon.providers.http.httpclient.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:82)   at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.execute(AbstractHttpClientWagon.java:832)   at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.put(AbstractHttpClientWagon.java:592)   ... 38 more  [ERROR]   [ERROR]         h3. Expected    Nexus should report the 401 and fail immediately instead of getting a broken pipe - act like Nexus 2.x does.",Bug,Major,Closed,"2016-05-16 14:31:57","2016-05-16 13:31:57",1
"Sonatype Nexus","Central automatic routing results discarded because Prefix file size exceeds maximum allowed","Some people had problems with accessing artifacts, that had a transitive dependency to Maven Central using a standard proxy repository. I was digging into it and I found out, that the routing file of Maven Central became too big and therefore Nexus refuses to load it and therefore it stays with an old version of the prefix file. Error message on the routing tab is:     Remote strategy prefix-file on M2Repository(id=central) detected invalid input, results discarded: Prefix file size exceeds maximum allowed size (100000), refusing to load it.    --Therefore https://repository.jboss.org/nexus/content/repositories/central/org/wildfly/extras/creaper/creaper-core/0.9.6/creaper-core-0.9.6.jar?describe=1 is not able to find the file despite it is in Maven Central.--    {quote}  **We have no evidence this blocks retrieval of remote artifacts - however the issue may result in a slight decrease in performance determining if remote artifacts exist in central**  {quote}    h4. Workaround until upgrading:    Add inside nexus.properties this line:    *org.sonatype.nexus.proxy.maven.routing.Config.prefixFileMaxSize=500000*    Then restart Nexus.",Bug,Critical,Closed,"2016-05-16 10:29:06","2016-05-16 09:29:06",1
"Sonatype Nexus","requests to rubygems repositories /api/v1/dependencies should not 302 redirect","rubygems repositories have an endpoint /api/v1/dependencies    clients like bundler hit this endpoint to test if the repository supports the API. They expect response code 200 and 0 content if supported.    Nexus responds with a 302 redirect to /api/v1/dependencies/ . The clients follow this and this causes nexus to try and render an html content listing of all the dependencies cached in the local repository. Since rubygems dependencies are a flat structure, this can result is a large response that takes considerable time to render.     By the time Nexus is trying to write the HTML content back to the client, the client may have broken the connection ( Broken pipe ), while Nexus has had a significant performance impact.    In some cases (depending on bundler version) the failing requests can cause Bundler to fall back to retrieving all versions of all dependencies. This in turn puts an additional burden on Nexus performance.    The confluence of the performance impact may eventually lead to an OOM in Nexus. The root cause seems to start from nexus initially returning a 302 redirect.     Expected  - Nexus should return 200 and 0 content for requests to /api/v1/dependencies and not a 302 redirect to a content listing, just like the official registry does:    https://rubygems.org/api/v1/dependencies      ",Bug,Major,Closed,"2016-05-13 16:26:11","2016-05-13 15:26:11",0.5
"Sonatype Nexus","non-admin users may be unable to see or edit IQ Server Application in staging profile edit screen","A non-admin user who is allowed to crate staging profiles is unable to see or edit _IQ Server Application_ in staging profile edit screen , after the staging profile has been created.    You can see IQ Server Application when creating a staging profile , but not after when once it has been set and saved and you go back into that staging profile.    The default admin user is able to see and amend this value.    The odd thing is, if you login as admin user, logout and then login as the original user, then you can see the _IQ Server Application_ setting in staging profile edit screen.    See attached screenshots.    ",Bug,Major,Closed,"2016-05-12 13:52:09","2016-05-12 12:52:09",0.5
"Sonatype Nexus","product license mangement","After doing the Paid/OSS Bundle work, we noticed that our experience was a bit funny :). We'd like to address that through the following improvements for a user's experience.   Acceptance Criteria:  * If a user license becomes invalid or expired in Nexus Repository Manager Pro  ** Send all users to a lightweight UI  ** Lightweight UI should only allow login/logout and the ability to install a license  ** All APIs should quit working (Maven, Docker, etc...)  * If a user installs a valid license Repository Manager Pro will start functioning again without a restart  * If a user's license is about to expire (30 days) we should provide a warning message in the UI to all Users (including anonymous) that shows the license is about to expire   NOTE:  * Ability to remove a user license in NX3 was removed. If they can figure out how, it will revert down to OSS. Changed original AC to match this updated (intentional) behavior.",Story,Major,Done,"2016-05-09 22:01:55","2016-05-09 21:01:55",3
"Sonatype Nexus","add log message if the data directory bundle cache contents are updated with new bundles","We are asking persons to install a patched osgi bundle and either delete the data cache directory or add a clean_cache file.    Then we may get a response the patch didn't work.    We are left wondering if there could have been a mistake removing the cache directory but we have no log message to verify.    One might get confused about where the data directory is because there also may be a data directory in the install directory as well.    h3. Expected    - a single log line at INFO on Nexus startup that summarizes that the cache directory was updated with *n* bundles ",Improvement,Minor,Open,"2016-05-05 17:55:17","2016-05-05 16:55:17",1
"Sonatype Nexus","The nexus-staging-maven-plugin treats a read timeout as a rule failure, and drops repositories","The nexus-staging-maven-plugin treats a timeout as a staging rule failure, and (by default) automatically drops the repository.     This is a bug, it means a slow Lifecycle scan will result in losing a staging repository.    For reference, the default timeout for the nexus-staging-maven-plugin is 5 minutes.  This can be configured via the stagingProgressTimeoutMinutes parameter.    ",Bug,Major,Closed,"2016-05-03 16:58:29","2016-05-03 15:58:29",2
"Sonatype Nexus","Invalid MIME-Type identification ","Hi,     I have a Nexus 3 with a Maven proxy to Maven Central. I try to download the artefact org.apache.jmeter:ApacheJMeter_parent:2.11:pom and it refuses with the attached log.   We can verify that the files served by maven central is ok (Content and Content-type header) :  http://repo1.maven.org:80/maven2/org/apache/jmeter/ApacheJMeter_parent/2.11/ApacheJMeter_parent-2.11.pom  but the identification by Tika of the file is incorrect.   Our current workaround is to disable the Strict Content Type Validation.    Thanks in advance,    Regards,    <USER>",Bug,Major,Closed,"2016-05-03 15:15:48","2016-05-03 14:15:48",2
"Sonatype Nexus","RedHat docker 1.8.2 push HTTP PUT uploads tar content instead of gzip and triggers JsonParseException 400","These commands can trigger Nexus to return a HTTP 400 response while reading already stored docker blob data.    docker import rhel7.tar   docker tag nexusrepo:port/foo   docker push nexusrepo:port/foo    To review, Docker Client 1.8.2 is submitting a JSON payload as part of PATCH requests that Nexus 3.0.0 stores into blobs - at the end of all the chunked uploads, the docker client tries to end the upload with a HTTP PUT request. The PUT request of zero (0) content fails when the blob data is read from disk on the Nexus side.    Nexus 3.0.0 is working correctly with docker client 1.9 using the same commands. Also Nexus 3 m7 and m6 was working with docker client 1.8.2 with the same commands. Nexus 3.0.0 was upgraded from a Nexus 3 M7 data directory. Redhat (OpenShift owner) is requiring the 1.8.2 version of docker as part of the OpenShift platform.    Docker requests fail with this pattern:    {quote}  127.0.0.1 - bakersi [29/Apr/2016:13:46:03 +0100] PATCH /repository/debug/v2/sdfsdfsdf/blobs/uploads/995080e6-f979-4c0d-8e43-93a1f0979362 HTTP/1.1 202 0 12166  127.0.0.1 - bakersi [29/Apr/2016:13:46:04 +0100] PUT /repository/debug/v2/sdfsdfsdf/blobs/uploads/995080e6-f979-4c0d-8e43-93a1f0979362?digest=sha256%3A2500e7958c9e79466f7ed72a4f4ad917f532fef9c34a2d4d74aa0f9f61cef3ca HTTP/1.1 400 192 564  {quote}    Notice it is the PUT that is trying to complete the upload and sending 0 content which fails.    A closer look at the stack trace tells us that Nexus fails when it tries to parse the content already stored inside uploaded blobs. So in some way nexus should try to report more precisely the actual problem or prevent getting into this state in the first place.          h3. Workaround    At least one of:    - upgrade to a newer version of docker  - [install the patch on Nexus 3.0.0-03|https://support.sonatype.com/hc/en-us/articles/218729178]  - upgrade to a newer release version of Nexus that contains the fix  ",Bug,Critical,Closed,"2016-05-02 17:55:13","2016-05-02 16:55:13",1
"Sonatype Nexus","add support proxying maven.oracle.com in nexus 3","*Acceptance*     * Nexus 3 maven2 proxy repo configuration should have an option for supporting circular redirects (as NX2 does)   * This setting should be migrated from NX2 during maven2 proxy repo migration.   * This feature should be documented in the book.     I configured my maven-oracle repo after migration to have the right credentials but I am not sure how to configure the rest of the setup so it continues to work as it did in 2.x.    See    [http://maven.oracle.com]   and [https://support.sonatype.com/hc/en-us/articles/213465728-How-to-configure-a-proxy-repository-to-maven-oracle-com]   for more info.    At the very least it should throw some sort of warning during the migration if this circula redirect is configured for a repo.",Story,Major,Done,"2016-04-30 01:07:30","2016-04-30 00:07:30",5
"Sonatype Nexus","HTTP authentication lost in migration","I migrated my sonatype-grid-releases as well as my maven-oracle proxy repo across. Both had HTTP authentication defined (and required) and that was no longer configured in 3.x after the migration.     This essentially breaks those repositories, but there was no error message in the migration process at all. ",Bug,Major,Closed,"2016-04-30 01:04:59","2016-04-30 00:04:59",1
"Sonatype Nexus","migrating NXRM2 to NXRM3 automatically enables legacy content URLs","According to the requirements in ----NEXUS-9976---- a migrated 3.x installation should automatically support the old legacy URL patterns. For v2 content URLs to work, however, a system property must be defined org.sonatype.nexus.repository.httpbridge.internal.HttpBridgeModule.legacy=true, and this isn't happening automatically.    *Acceptance*   * 2x-3x upgrade should automatically enable the v2 content URLs   * implementing this as a capability that gets injected and activated in Nexus 3 on migration start would be great! - otherwise if a property is used, inject it into nexus.properties under the work directory. Support still needs to have a way to tell this is enabled ( currently we just look in nexus-default.properties or nexus.properties ) and the end user still needs to have an easy way to tell as well ( presence of property in nexus.properties or capability in UI )   * Minimize upgrade impact to users that have already migrated and made decisions about turning this feature on or off    *Notes*   * There's value in having this as a capability   * While you're in there, make a mental note if you spot any obvious signs that a given NXRM3 instance (or individual repos) were migrated from NXRM2",Story,Minor,Done,"2016-04-29 21:15:15","2016-04-29 20:15:15",5
"Sonatype Nexus","Excessive WARN when pulling from docker group","I noticed a bunch of warns like this when testing docker 1.11.1.  It appeared there was one for every layer I pulled that wasn't in the repository when I pulled from a docker group.  For reference, some images can have 5-7+ layers.  Pulling from proxy generated no such warn.  There was no warn for layers that already existed so hypothetically this would be a diminishing concern over time (tho you could be utilizing new layers everyday, not sure how it works in practice).        This seems excessive to do on the WARN level when there is no (as far as I can tell) adverse behavior.  Filing for triage discussion.    I did not check older NX3 or older docker at this time.",Bug,Trivial,Closed,"2016-04-28 23:33:56","2016-04-28 22:33:56",1
"Sonatype Nexus","OrientDb allocates massive disk cache on large systems","OrientDB uses an automatic tuning algorithm to determine the upper size of its native memory disk cache. This algorithm assumes that serving Orient is the primary function of the box, and on larger system can end up allocating gigantic caches (on a system with a 1TB drive and 32Gb memory, Orient set an upper cache size of 29Gb).    A pmap will show a large number of 'anon' segments:    {{00007f67dc000000  65508K rw---   [ anon ]  00007f67dfff9000     28K -----   [ anon ]  00007f67e0000000  65508K rw---   [ anon ]  00007f67e3ff9000     28K -----   [ anon ]  00007f67e4000000  65508K rw---   [ anon ]  00007f67e7ff9000     28K -----   [ anon ]  00007f67e8000000  65508K rw---   [ anon ]  00007f67ebff9000     28K -----   [ anon ]  00007f67ec000000  65504K rw---   [ anon ]  00007f67efff8000     32K -----   [ anon ]  }}    [~<USER> points out that a system property can be used to set an explicit cache size (in Mb):    storage.diskCache.bufferSize=4096    We should consider:  * Setting an appropriate maximum  * Writing an algorithm that will replace Orient's tuning calculation, given that we're using Orient in an embedded mode  * Documenting this property as something clients might tune on large installations",Bug,Major,Closed,"2016-04-28 19:40:07","2016-04-28 18:40:07",3
"Sonatype Nexus","Migration - Can't migrate empty group","Currently, NX prevents migration of groups without all of their members, but it should be legal to migrate a group that has no members whatsoever. Currently this causes migration to hang.",Bug,Major,Closed,"2016-04-28 02:16:22","2016-04-28 01:16:22",2
"Sonatype Nexus","npm login returns 404 for npm proxy repositories","npm login commands work with NPM group repos and hosted repos.    npm login commands for proxy repositories return 404.    npm login should work with Nexus NPM proxy repositories.    Our book does not make this distinction and there is no reason I know of that you would not want npm login to work with an npm proxy repository.    ",Bug,Major,Closed,"2016-04-27 22:21:29","2016-04-27 21:21:29",1
"Sonatype Nexus","add ability to dump invalid JSON payloads submitted by docker on parse errors","Nexus may fail parsing docker client JSON payloads. When this happens we see an exception that refers to a token, but we have no easy way inside Nexus to get the complete invalid payload.        Acceptance  - print the full JSON payload in the nexus.log if there is a parse error  - -ideally print the line/character number in the JSON payload where the error is detected- parse exception already does this  - make it configurable to print or not print the payload ( in case the payload could contain sensitive data )",Bug,Major,Closed,"2016-04-27 19:24:15","2016-04-27 18:24:15",1
"Sonatype Nexus","improve robustness of NuGet case insensitive package ID matching","Background:  NEXUS-8941 implements a fix for Nexus handling Nuget package IDs in a case-sensitive manner, but because it doesn't have the benefit of upgrade, it's implemented by modifying queries.    Acceptance Criteria:   Once upgrade is in place, pull out the query-modifying and use (e.g.) DB-level case-insensitive collation.     Developer's Notes:  Note that because of an Orient bug we can't completely rely on case-insensitive semantics working, so there is still the need for some query-modifying, just that we can limit it to particular situations in a more targeted way now. For now working on the basis that we should try to remove as much of the cruft as possible.",Improvement,Major,Closed,"2016-04-27 17:59:25","2016-04-27 16:59:25",3
"Sonatype Nexus","Page unresponsive if no Internet access","Starting Nexus 3.0.0 for the first time and logging in (admin) the page becomes unresponsive for a long time if there is no Internet access, which is due to no web proxy yet configured. I see lots of exceptions in nexus.log wrt ConnectionTimeoutException, Could not download page bundle.",Bug,Trivial,Open,"2016-04-26 16:26:19","2016-04-26 15:26:19",3
"Sonatype Nexus","“Stop Monitoring” button should not be displayed when no repositories are being synced","During migration, we show a “Stop Monitoring” button so people can tell the system to stop looking for changes in repositories that are being migrated. If no repositories are migrated, this button is not needed (in fact, it currently prevents you from finalizing the migration).    We need an additional check to ensure that the “Stop Monitoring” button is not displayed when no repositories are migrated (and to display the “Finish” button instead).",Bug,Major,Closed,"2016-04-25 18:43:16","2016-04-25 17:43:16",0.5
"Sonatype Nexus","Docker proxy repository ConnectionPoolTimeoutException Timeout waiting for connection from pool","After nexus3 has been running for a few days, the docker proxy repositories start timing out.  We have nginx in front of nexus3 and see the following message:           Looking at the nexus log file there is a timeout trying to get a connection from the pool.  I would guess at some point connections are not being returned to the pool:          Restarting the nexus3 service temporarily resolves the issue.  As a work around, we schedule a daily restart.    We are running OSS 3.0.0-03, but saw the same issue in m7.",Bug,Critical,Closed,"2016-04-20 17:44:33","2016-04-20 16:44:33",0.5
"Sonatype Nexus","Publish Maven Indexes task does not always fetch remote index to make it searchable","I configured a proxy repo called nx2-proxy-hosted in nx3 proxying a hosted release repo that is publishing indexes in Nexus 2. While I can directly confirm using curl that the nx 2 repo is publishing a Maven index, Nexus 3 does not want to seem to get it when the Publish Indexes task is run in Nexus 3        Notice the Nexus 3 logs says it tried to get the index properties file, but there was no http traffic recorded even though org.apache.http logger  was set to DEBUG and I had Nexus 3 using charles proxy monitoring traffic.  ",Bug,Major,Closed,"2016-04-19 16:50:39","2016-04-19 15:50:39",2
"Sonatype Nexus","repository health check RHC DefaultClientScanner logs WARN Could not locate scanner descriptor","[~<USER> noted that he was seeing messages like: 2016-04-18 15:03:58,726-0300 WARN  [quartz-2-thread-1] *SYSTEM com.sonatype.insight.scan.client.DefaultClientScanner - Could not locate scanner descriptor  This message was listed in NEXUS-8239 (#5) but I believe at the time got mixed in with the actual #5 report (the double message) and I overlooked making a cleanup ticket against it.  This occurs when you run the RHC tasks against a repository.    Possible quick fix might be to add an empty properties file but code check would need to be done.",Bug,Minor,Open,"2016-04-18 19:32:53","2016-04-18 18:32:53",1
"Sonatype Nexus","generating support zip with configuration option requires external internet access","Generating support zip with configuration requires access to “eclipse.org”    Nexus is tryiing to contact http://198.41.30.198/ which is the main Eclipse web site.    With external internet access blocked, Support zip generation (with configuration)  fails with the following:      h3. Expected    - when generating a support zip, generation must not fail if external network access is not available  - do NOT attempt any external network access when generating support zip",Bug,Major,Closed,"2016-04-18 16:24:18","2016-04-18 15:24:18",0.5
"Sonatype Nexus","Valid Maven POM is misidentified as HTML by content verification","On a fresh Nexus instance create a proxy repository called RSO for https://repository.sonatype.org/content/repositories/sonatype-internal/ and make sure content verification is enabled (it should be on by default)    Now try to access http://127.0.0.1:8081/repository/RSO/com/sonatype/insight/ci/insight-ci-parent/2.14.4/insight-ci-parent-2.14.4.pom you will receive a 404 with the following message:  {quote}  Detected content type \[text/html], but expected \[application/xml, text/xml, application/x-xml]: com/sonatype/insight/ci/insight-ci-parent/2.14.4/insight-ci-parent-2.14.4.pom.xml  {quote}    Turning off content verification allows this POM to be downloaded, but we should investigate why it misidentified the content in this case.",Improvement,Major,Closed,"2016-04-15 13:27:35","2016-04-15 12:27:35",1
"Sonatype Nexus","npm install against a group repository with nested group member fails with 500 status","npm install <package> from a nested group repo fails with a 500 response from Nexus.    This is easily to setup and reproduce.    npmjs (proxy) and npm-internal (hosted) -> nmp-all (group) -> npm-top-group (group)    npm registry setting is pointing to npm-top-group    Acceptance Criteria:  * All metadata should be merged, respecting the order of the repositories, first in the tree should win  * A user should be able to install a package from a nested group    NOTES:  * Check Maven to see if this issue also occurs here            ",Bug,Major,Closed,"2016-04-14 11:06:33","2016-04-14 10:06:33",2
"Sonatype Nexus","Startup Java version check is fragile, blocks startup in cases where it shouldn't","An end user has has this Java:        Using this, they cannot start Nexus 3:        This seems wrong to me. I think it's find to log a warning for an unsupported version, but we shouldn't flat out prevent startup.  ",Bug,Major,Closed,"2016-04-11 18:41:41","2016-04-11 17:41:41",1
"Sonatype Nexus","NuGet server does not comply to the standard of defining dependencies","With the release of NuGet version 3.4, we (the NuGet team) tightened the validation of dependencies. We found that NuGet used to take any invalid dependency and turn it into an empty one. That could lead into problems in package resolution or updates.    It turns out that the nexus server is sending the string null to represent an empty dependency, which was not something the version parser could parse, and it turned into an error.    We are going to allow it going forward (3.4.2+), but we recommend rectifying the string to be empty like all other servers do.    Here is the bug in NuGet https://github.com/NuGet/Home/issues/2426  Specifically this is the offending xml snippet:    <d:Dependencies>XXXX.XX.XXX.Customer.Data{color:#f6c342}:null{color}|EntityFramework:6.1.3|YYYY.YY.YY.YYY.Security:3.7.0.15</d:Dependencies>  ",Bug,Minor,Open,"2016-04-08 21:18:37","2016-04-08 20:18:37",3
"Sonatype Nexus","404 response from Nexus 2 proxying Nexus 3 due to auto-routing","Topology is as follows:    RSO -> Nexus 3 -> Nexus 2 -> Maven    Output of the build command:    https://gist.github.com/djsauble/ed607c27e48356750d0b1a55d37c6cec    I checked, and the Nexus 3 instance does have the missing JAR, so that proxy appears to be set up correctly.    Support ZIPs from both the Nexus 3 and Nexus 2 instances are attached.",Bug,Major,Closed,"2016-04-08 18:02:56","2016-04-08 17:02:56",2
"Sonatype Nexus","Documentation image off","To me in both pdf and website, the image http://books.sonatype.com/nexus-book/3.0/reference/figs/web/users-create.png appears off.  Specifically, the bottom seems shifted (see attached - arrow added by me).    If this seems familiar, I noticed it previously in NEXUS-9906 but seems to have been deployed like that.  Since I think this can be tweaked better, I am filing.    For ref this shows in http://books.sonatype.com/nexus-book/3.0/reference/security.html",Bug,Minor,Closed,"2016-04-08 16:46:17","2016-04-08 15:46:17",0.5
"Sonatype Nexus","Double image not accepted as leadin header","Noticed the attached in http://books.sonatype.com/nexus-book/3.0/reference/using.html specifically that the usual text image lead to describe the sections seems to be failing for 2 sections/images at once.    I included the working work above it (Help) in the attachment for comparison.    This affects both the html site and the pdf.",Bug,Trivial,Closed,"2016-04-08 15:56:23","2016-04-08 14:56:23",0.5
"Sonatype Nexus","Bower does not work with context path","Noticed that when using a context path in Nexus when you put that path into your .bowerrc the resultant interactions error with errors like below.  Only workaround seems to be not to use a context path.  I am not sure how critical context path is for people so leaving major for now.    On sudo bower --allow-root install jquery  {quote}  bower not-cached    nexus+http://localhost:8081/nexus/repository/bower-group/jquery#*  bower resolve       nexus+http://localhost:8081/nexus/repository/bower-group/jquery#*  bower error         http://localhost:8081/repository/repository/bower-group/versions.json (HTTP 404)    Stack trace:  Error: http://localhost:8081/repository/repository/bower-group/versions.json (HTTP 404)      at Request._callback (/usr/local/lib/node_modules/bower-nexus3-resolver/src/index.js:212:20)      at Request.self.callback (/usr/local/lib/node_modules/bower-nexus3-resolver/node_modules/request/request.js:198:22)      at Request.emit (events.js:110:17)      at Request.<anonymous> (/usr/local/lib/node_modules/bower-nexus3-resolver/node_modules/request/request.js:1035:10)      at Request.emit (events.js:129:20)      at IncomingMessage.<anonymous> (/usr/local/lib/node_modules/bower-nexus3-resolver/node_modules/request/request.js:962:12)      at IncomingMessage.emit (events.js:129:20)      at _stream_readable.js:908:16      at process._tickCallback (node.js:355:11)    Console trace:  Error      at StandardRenderer.error (/usr/local/lib/node_modules/bower/lib/renderers/StandardRenderer.js:83:37)      at Logger.<anonymous> (/usr/local/lib/node_modules/bower/lib/bin/bower.js:110:26)      at Logger.emit (events.js:107:17)      at Logger.emit (/usr/local/lib/node_modules/bower/lib/node_modules/bower-logger/lib/Logger.js:29:39)      at /usr/local/lib/node_modules/bower/lib/commands/index.js:48:20      at _rejected (/usr/local/lib/node_modules/bower/lib/node_modules/q/q.js:844:24)      at /usr/local/lib/node_modules/bower/lib/node_modules/q/q.js:870:30      at Promise.when (/usr/local/lib/node_modules/bower/lib/node_modules/q/q.js:1122:31)      at Promise.promise.promiseDispatch (/usr/local/lib/node_modules/bower/lib/node_modules/q/q.js:788:41)      at /usr/local/lib/node_modules/bower/lib/node_modules/q/q.js:604:44  System info:  Bower version: 1.7.7  Node version: 0.12.9  OS: Darwin 15.4.0 x64  {quote}    Setup was with a single bower group containing a bower proxy and context path /nexus/.    Bower is new to 3.0.0 so no backcheck (or NX2 check) can be done.",Bug,Major,Closed,"2016-04-07 21:00:08","2016-04-07 20:00:08",0.5
"Sonatype Nexus","First time starting nexus via Docker has karaf log warn","Starting nexus for the first time via docker generates the below warn.  No adverse behavior is noted so far but keeping for record and to avoid log spam.        This file is new to 3.0.0.  Did not check NX2 at this time.",Bug,Minor,Closed,"2016-04-06 23:05:32","2016-04-06 22:05:32",0.5
"Sonatype Nexus","StackOverflowError when a group repository has itself as a member","# Start with a stock Nexus 3 setup.  # Create a new maven 2 group repository, add the maven public group to it, save  # Go the the maven public group repository configuration, add the new group you just created to it, save  # Go to browse/components/maven public    Result is a stack overflow.      ",Bug,Major,Closed,"2016-04-06 15:07:09","2016-04-06 14:07:09",1
"Sonatype Nexus","IOException Pipe not connected prevents generating support zip on Windows","I found I cannot generate a support.zip file from the UI including everything checked in Windows.  This does not occur in MacOSX.  I checked with [~<USER> who was also able to see this, so not just my env.  See below for long stack trace with several errors.  On screen appears Cannot get property 'file' on null object.    This does not affect m7.  I did not check NX2 at this time.  Debug was off during this test.    ",Bug,Critical,Closed,"2016-04-04 20:32:02","2016-04-04 19:32:02",3
"Sonatype Nexus","nx-userschangepw not included in nx-all","While creating NEXUS-10040, I found that users could not update their own passwords via profile and instead got the error below.  However, this is not because it is broken (like NEXUS-10040 where you can't save or at all) but because nx-userschangepw permission is not included in nx-all.  This surprised me, since nx-all sounds like it should be everything AND because default admin role subsequently does not have the permission to change password (via profile, they still can via security-users).    I did not check older NX3 at this time however I recall this being different in the past.  I also did not check NX2, however, I also recall this working without hijinx.  Debug was off during this test.",Bug,Minor,Closed,"2016-04-04 20:14:06","2016-04-04 19:14:06",1
"Sonatype Nexus","Users cannot update their profiles","Does not appear a user can update their profile (NOT including password change).  Specifically the save button is disabled no matter what change you make.  This is with admin access.  Workaround is to have admin update from Security->User.  This is regression from NX2 however because of the workaround, I am making minor for now.    I did not check older NX3 at this time.  Debug was off for this test.",Bug,Minor,Closed,"2016-04-04 20:00:31","2016-04-04 19:00:31",1
"Sonatype Nexus","NPM tarballs proxied over http may be fetched remotely over https","This is the opposite problem described in NEXUS-6889.    Configure an NPM proxy repository in Nexus to http://registry.npmjs.org. The intent to do this is to avoid going through an internal HTTP proxy server that affects requests using HTTPS.    Nexus makes primary metadata outbound requests to http://registry.npmjs.org, however metadata at that site may contain links to https://registry.npmjs.org tarballs. These https tarball urls are cached inside Nexus.    When a user configures Nexus to talk to http://registry.npmjs.org, they expect all communication to the remote to be over http - where this may matter is if they have Nexus configured with an HTTP proxy server that rewrites SSL certificates of the remote. They do not realize they need to explicitly trust the certificate that the proxy to https://registry.npmjs.org is returning because they have told Nexus to use *http* to the remote.    Example:    * Configure npm proxy to http://registry.npmjs.org  * Configure Nexus with an HTTP proxy that rewrites SSL certs that nexus will not implictly trust.  * curl -v http://localhost:8081/repository/npmjs-proxy/requirejs -o requirejs.json  * examine the metadata, it contains tarball urls to https://registry.npmjs.org  * curl -v http://localhost:8081/repository/npmjs-proxy/requirejs/-/requirejs-2.2.0.tgz -o /dev/null  * This fails, Nexus returns 502 Bad Gateway to the client.  * The nexus logs show Nexus tried to go to https://registry.npmjs.org/requirejs/-/requirejs-2.2.0.tgz and this failed because the certificate is not trusted.          ",Bug,Major,Open,"2016-04-04 18:58:24","2016-04-04 17:58:24",5
"Sonatype Nexus","Errors/warns on delete of proxy while it's being used","In NEXUS-10017, adverse behavior was reported when you deleted a npm proxy repository in NX2.  In NX3, this behavior did not exist however, I noticed an error and a warn that might be worth persuing to make sure other adverse behavior wasn't occurring.    Steps to Reproduce:  1) Have a npmgroup containing npmproxy to https://registry.npmjs.org (I also had npm hosted tho I am skeptical that matters).  2) Run an npm search, something like npm s engine.io. This can take some time if run for the first time as it indexes.  3) While index is processing, delete the npmjs repository.  Notice the below error/warn in log.    ",Bug,Minor,Closed,"2016-04-02 00:14:31","2016-04-01 23:14:31",2
"Sonatype Nexus","Nuget 3.4 breaking semver change","As of Nuget 3.4/Visual Studio 2015, NuGet now uses a much stricter policy for semantic versioning. c.f. http://docs.nuget.org/Create/Versioning#Normalized_Version_Numbers    In order for Nexus to behave correctly, it will need to address how it sorts version numbers, and how it decides packages are pre-release or release.    Unfortunately, there are some popular package on nuget.org that don't abide by this strictness - NLog, for instance, has gotten into the habit of labelling (in ODATA) versions like 4.4.0-beta3 as _release_ versions.    As of NuGet 3.4, the (new) _Normalized Version_ ODATA field is the definitive version for uniqueness purposes, as well as the definitive indicator as to whether a package is pre-release or not. Visual Studio will actually prune packages with pre-release semvers out of the search results it gets from Nexus.    Unfortunately, for now, Nexus defers to the metadata, not the semver. As a result:    1. Create a Nexus proxy to nuget.org  2. Open Visual Studio 2015  3. Make the Nexus proxy the only nuget source  4. In VS/NuGet, search for 'nlog'. Currently, NLog 4.2.3 is the latest release version, according to semver. It should appear in the search results.  5. Now search for 'nlog', with the 'pre-release versions' option checked. Currently, this will bring down the badly-tagged NLog 4.4.0-beta3. Nexus now considers this the latest  6. Perform the first search again, looking for release-only versions of 'nlog'  => NLog has now completely disappeared from the VS search results. Nexus is returning 4.4.0-beta3 as the latest release version (as per the metadata), but VS prunes it out (as per its pre-release style semver)",Bug,Major,Closed,"2016-04-01 21:20:21","2016-04-01 20:20:21",5
"Sonatype Nexus","Authentication-less Email Server config does not work","When configuring the Email Server in Nexus 3.0.0-m7 without username or password, the Verify email server action produces a stacktrace in the Nexus log. It appears that Nexus sets a property to use auth, but no credentials are available other than empty strings.    Nexus 3 should support an Email Server configuration without authentication.    Log from Verify email server      ",Bug,Major,Closed,"2016-03-31 07:47:26","2016-03-31 06:47:26",1
"Sonatype Nexus","Deletion of asset from single asset component causes failure in UI","If you have a component with a single asset (as all npm components do) and navigate through Components -> Repo -> Component -> Asset, and then delete the asset using the provided button, the UI attempts to reload the parent component. Problem here is that components are removed when their last asset is deleted, which leads to an error message being shown in the UI and the view not updating.  I saw this with NPM but likely it's a problem with any format anytime the last asset is deleted.  http://screencast.com/t/Lfz7oaFIFgiC",Bug,Minor,Closed,"2016-03-31 00:23:38","2016-03-30 23:23:38",0.5
"Sonatype Nexus","Unable to delete npmjs proxy repo","Customer reported that they when they tried to delete the npmjs proxy repo, Nexus stopped responding and CPU/Memory shot up. Nexus had to be restarted, but the repository is not removed.    I have reproduced this same issue on a clean install of 2.12.1.    Steps to Reproduce:  1) Ensure that you have proxy to https://registry.npmjs.org and is part of npm group. npm client should be configured to point use the npm group.    2) Run an npm search, something like npm s engine.io. This can take some time if run for the first time.      3) Delete the npmjs repository. Within a minute the Nexus UI will stop responding and CPU for the java process should go up to 100%. You will see following in the logs.  ",Bug,Major,Closed,"2016-03-30 16:55:04","2016-03-30 15:55:04",0.5
"Sonatype Nexus","scheduled task form values cannot be blanked out when a blank value is valid","While testing the Remove Snapshots From Maven Repository task, I had it saved with a value in the Grace Period after release (days) field.  When I tried to erase this value and save, the value restored.  This field is not required (is optional) so there is no reason the value should not be able to be erased.    On analysis is was speculated this behavior would affect all tasks however this is the first task where there is a number value that can be nulled out in this way.  In fact, I tried to find a number example against the entire site but could not find one (there are string examples but string is much easier to be empty).    This behavior does not affect NX2.  This task is new to Homeslice so I did not check older NX3 as I don't believe it'd be anywhere.  But further fields (tasks but maybe any fields) created in this way will likely be affected.    The workaround is to delete the task and recreate it, however, I am leaving major as that workaround is pretty annoying.",Bug,Major,Closed,"2016-03-28 15:52:46","2016-03-28 14:52:46",0.5
"Sonatype Nexus","proxy repository HTTP request settings form fields cannot be saved","I noticed that if you attempt to enter a value into Connection timeout: field within the HTTP request settings section of a proxy repository configuration you get an error Failed to Validate Facets, 1 Failure and the below in the nexus.log.    This occurs with debug on or off.  I did not check older NX3 at this time.  This does not occur in NX2(12.1).    {quote}  2016-03-25 16:24:47,155-0400 ERROR [qtp1034682762-1599] admin org.sonatype.nexus.repository.manager.RepositoryImpl - Failed to validate facet: org.sonatype.nexus.repository.httpclient.HttpClientFacetImpl$$EnhancerByGuice$$c1b95983@64d9fd78  java.lang.IllegalArgumentException: Can not instantiate value of type [simple type, class org.sonatype.goodies.common.Time] from Floating-point number (100.0); no one-double/Double-arg constructor/factory method   at [Source: N/A; line: -1, column: -1] (through reference chain: org.sonatype.nexus.repository.httpclient.Config[connection]->org.sonatype.nexus.httpclient.config.ConnectionConfiguration[timeout])   at com.fasterxml.jackson.databind.ObjectMapper._convert(ObjectMapper.java:3512) [na:na]   at com.fasterxml.jackson.databind.ObjectMapper.convertValue(ObjectMapper.java:3431) [na:na]   at org.sonatype.nexus.repository.config.ConfigurationFacetImpl.convert(ConfigurationFacetImpl.java:72) [na:na]   at org.sonatype.nexus.repository.config.ConfigurationFacetImpl.readSection(ConfigurationFacetImpl.java:81) [na:na]   at org.sonatype.nexus.repository.config.ConfigurationFacetImpl.validateSection(ConfigurationFacetImpl.java:118) [na:na]   at org.sonatype.nexus.repository.httpclient.HttpClientFacetImpl.doValidate(HttpClientFacetImpl.java:84) [na:na]   at org.sonatype.nexus.repository.FacetSupport.validate(FacetSupport.java:112) [na:na]   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [na:na]   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:270) [na:na]   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53) [na:na]   at org.sonatype.nexus.repository.manager.RepositoryImpl.validate(RepositoryImpl.java:160) [na:na]   at org.sonatype.nexus.repository.manager.RepositoryManagerImpl.update(RepositoryManagerImpl.java:277) [na:na]   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [na:na]   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:270) [na:na]   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53) [na:na]   at org.sonatype.nexus.repository.manager.RepositoryManager$update$7.call(Unknown Source) [na:na]   at org.sonatype.nexus.coreui.RepositoryComponent.update(RepositoryComponent.groovy:147) [na:na]   at org.sonatype.nexus.validation.internal.ValidationInterceptor.invoke(ValidationInterceptor.java:53) [org.hibernate.validator:5.1.2.Final]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet$3.invokeMethod(ExtDirectServlet.java:221) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.StandardRequestProcessorBase.dispatchStandardMethod(StandardRequestProcessorBase.java:73) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:502) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequestsInThisThread(JsonRequestProcessor.java:150) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.process(JsonRequestProcessor.java:133) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.RequestRouter.processJsonRequest(RequestRouter.java:83) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.processRequest(DirectJNgineServlet.java:617) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.doPost(DirectJNgineServlet.java:580) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet.doPost(ExtDirectServlet.java:127) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:707) [javax.servlet-api:3.1.0]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:71) [com.google.inject:4.0.0]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.4]   at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.4]   at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.base:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:97) [org.sonatype.nexus.base:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1668) [org.eclipse.jetty.servlet:9.3.7.v20160115]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581) [org.eclipse.jetty.servlet:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548) [org.eclipse.jetty.security:9.3.7.v20160115]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1158) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511) [org.eclipse.jetty.servlet:9.3.7.v20160115]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1090) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.7.v20160115]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:109) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.Server.handle(Server.java:517) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:308) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:242) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:197) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:75) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:213) [org.eclipse.jetty.util:9.3.7.v20160115]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:147) [org.eclipse.jetty.util:9.3.7.v20160115]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654) [org.eclipse.jetty.util:9.3.7.v20160115]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572) [org.eclipse.jetty.util:9.3.7.v20160115]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  Caused by: com.fasterxml.jackson.databind.JsonMappingException: Can not instantiate value of type [simple type, class org.sonatype.goodies.common.Time] from Floating-point number (100.0); no one-double/Double-arg constructor/factory method   at [Source: N/A; line: -1, column: -1] (through reference chain: org.sonatype.nexus.repository.httpclient.Config[connection]->org.sonatype.nexus.httpclient.config.ConnectionConfiguration[timeout])   at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:216) [na:na]   at com.fasterxml.jackson.databind.DeserializationContext.mappingException(DeserializationContext.java:894) [na:na]   at com.fasterxml.jackson.databind.deser.std.StdValueInstantiator.createFromDouble(StdValueInstantiator.java:335) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromDouble(BeanDeserializerBase.java:1222) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:148) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:135) [na:na]   at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:490) [na:na]   at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:95) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:260) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:125) [na:na]   at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:490) [na:na]   at com.fasterxml.jackson.databind.deser.impl.FieldProperty.deserializeAndSet(FieldProperty.java:101) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:260) [na:na]   at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:125) [na:na]   at com.fasterxml.jackson.databind.ObjectMapper._convert(ObjectMapper.java:3507) [na:na]   ... 102 common frames omitted  2016-03-25 16:24:47,161-0400 ERROR [qtp1034682762-1599] admin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: coreui_Repository.update, java-method: org.sonatype.nexus.coreui.RepositoryComponent.update  org.sonatype.goodies.common.MultipleFailures$MultipleFailuresException: Failed to validate facets; 1 failure   at org.sonatype.goodies.common.MultipleFailures.maybePropagate(MultipleFailures.java:95) [org.sonatype.goodies.common:2.1.0.SNAPSHOT]   at org.sonatype.nexus.repository.manager.RepositoryImpl.validate(RepositoryImpl.java:171) [na:na]   at org.sonatype.nexus.repository.manager.RepositoryManagerImpl.update(RepositoryManagerImpl.java:277) [na:na]   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [na:na]   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:270) [na:na]   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53) [na:na]   at org.sonatype.nexus.repository.manager.RepositoryManager$update$7.call(Unknown Source) [na:na]   at org.sonatype.nexus.coreui.RepositoryComponent.update(RepositoryComponent.groovy:147) [na:na]   at org.sonatype.nexus.validation.internal.ValidationInterceptor.invoke(ValidationInterceptor.java:53) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet$3.invokeMethod(ExtDirectServlet.java:221) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.StandardRequestProcessorBase.dispatchStandardMethod(StandardRequestProcessorBase.java:73) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:502) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequestsInThisThread(JsonRequestProcessor.java:150) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.process(JsonRequestProcessor.java:133) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.RequestRouter.processJsonRequest(RequestRouter.java:83) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.processRequest(DirectJNgineServlet.java:617) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.doPost(DirectJNgineServlet.java:580) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet.doPost(ExtDirectServlet.java:127) [org.sonatype.nexus.extdirect:3.0.0.SNAPSHOT]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:707) [javax.servlet-api:3.1.0]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:71) [com.google.inject:4.0.0]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.4]   at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.4]   at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.base:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:97) [org.sonatype.nexus.base:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1668) [org.eclipse.jetty.servlet:9.3.7.v20160115]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581) [org.eclipse.jetty.servlet:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548) [org.eclipse.jetty.security:9.3.7.v20160115]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1158) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511) [org.eclipse.jetty.servlet:9.3.7.v20160115]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1090) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.7.v20160115]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:109) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.Server.handle(Server.java:517) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:308) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:242) [org.eclipse.jetty.server:9.3.7.v20160115]   at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:197) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:75) [org.eclipse.jetty.io:9.3.7.v20160115]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:213) [org.eclipse.jetty.util:9.3.7.v20160115]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:147) [org.eclipse.jetty.util:9.3.7.v20160115]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654) [org.eclipse.jetty.util:9.3.7.v20160115]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572) [org.eclipse.jetty.util:9.3.7.v20160115]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]   Suppressed: java.lang.IllegalArgumentException: Can not instantiate value of type [simple type, class org.sonatype.goodies.common.Time] from Floating-point number (100.0); no one-double/Double-arg constructor/factory method   at [Source: N/A; line: -1, column: -1] (through reference chain: org.sonatype.nexus.repository.httpclient.Config[connection]->org.sonatype.nexus.httpclient.config.ConnectionConfiguration[timeout])    at com.fasterxml.jackson.databind.ObjectMapper._convert(ObjectMapper.java:3512) [na:na]    at com.fasterxml.jackson.databind.ObjectMapper.convertValue(ObjectMapper.java:3431) [na:na]    at org.sonatype.nexus.repository.config.ConfigurationFacetImpl.convert(ConfigurationFacetImpl.java:72) [na:na]    at org.sonatype.nexus.repository.config.ConfigurationFacetImpl.readSection(ConfigurationFacetImpl.java:81) [na:na]    at org.sonatype.nexus.repository.config.ConfigurationFacetImpl.validateSection(ConfigurationFacetImpl.java:118) [na:na]    at org.sonatype.nexus.repository.httpclient.HttpClientFacetImpl.doValidate(HttpClientFacetImpl.java:84) [na:na]    at org.sonatype.nexus.repository.FacetSupport.validate(FacetSupport.java:112) [na:na]    at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [na:na]    at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:270) [na:na]    at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53) [na:na]    at org.sonatype.nexus.repository.manager.RepositoryImpl.validate(RepositoryImpl.java:160) [na:na]    ... 92 common frames omitted   Caused by: com.fasterxml.jackson.databind.JsonMappingException: Can not instantiate value of type [simple type, class org.sonatype.goodies.common.Time] from Floating-point number (100.0); no one-double/Double-arg constructor/factory method   at [Source: N/A; line: -1, column: -1] (through reference chain: org.sonatype.nexus.repository.httpclient.Config[connection]->org.sonatype.nexus.httpclient.config.ConnectionConfiguration[timeout])    at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:216)    at com.fasterxml.jackson.databind.DeserializationContext.mappingException(DeserializationContext.java:894)    at com.fasterxml.jackson.databind.deser.std.StdValueInstantiator.createFromDouble(StdValueInstantiator.java:335)    at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromDouble(BeanDeserializerBase.java:1222)    at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:148)    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:135)    at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:490)    at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:95)    at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:260)    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:125)    at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:490)    at com.fasterxml.jackson.databind.deser.impl.FieldProperty.deserializeAndSet(FieldProperty.java:101)    at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:260)    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:125)    at com.fasterxml.jackson.databind.ObjectMapper._convert(ObjectMapper.java:3507)    ... 102 common frames omitted  {quote}",Bug,Minor,Closed,"2016-03-25 20:51:21","2016-03-25 20:51:21",0.5
"Sonatype Nexus","ui spinbutton form controls should not react to mouse scroll wheel movement","When a spinbutton field has focus and the cursor is over the field, moving the scroll wheel - or doing the trackpad equivalent - changes the spinbutton field value. No other field type exhibits this behavior.    For consistency with other field types, scrolling within a spinbutton field should not change the value, but should scroll the containing panel / page.  ",Bug,Minor,Closed,"2016-03-25 05:53:38","2016-03-25 05:53:38",0.5
"Sonatype Nexus","Assigning nx-users privileges does nothing on its own","Just noticed that assigning a role (and a user) nx-users privileges (first tried nx-users-all then all of them) does not seem to grant any access in the UI.  I expected (and believed it used to based around NEXUS-8778 documentation) that it'd grant permission to the Security-Users administration items.  If I'm right (and the affects version of NEXUS-8778 is right) this changed (regressed) sometime between m4 and now.  I did not check older NX3 at this time.  NX2 seems to behave this way, though the permission structure is slightly different.    Only workaround I know is to be admin but there may be another as admin just seems to have nx-admin which should be everything.  I'm leaving major until it's found however.",Bug,Medium,Open,"2016-03-23 20:02:44","2016-03-23 20:02:44",1
"Sonatype Nexus","Error on LDAP Realm activeness; can stop LDAP logins","I noticed the below error when I have the LDAP realm active.  This occurs whether or not I have an LDAP configured (validly or invalidly).  As far as I can tell there's no adverse behavior occurring with this enabled, which prompts me to file to make sure everything is OK and if so, have it tempered and if not have it investigated.    NOTE: This error occurs before the Nexus has started seperation.    I checked m7 and this is occurring there.  It's also occurring with rut-auth realm despite the fact the rut-auth realm isn't enabled.  I did not see that similar behavior with Homeslice, so it's possible this was partially fixed (or my applications are just at different configured states).  I didn't check further back than that.  I also didn't check NX2.    {quote}  2016-03-21 16:07:48,344-0400 ERROR [FelixStartLevel] *SYSTEM org.sonatype.nexus.security.internal.RealmManagerImpl - Unable to lookup security realms  java.lang.ClassNotFoundException: LdapRealm   at java.lang.ClassLoader.findClass(ClassLoader.java:530) [na:1.8.0_40]   at java.lang.ClassLoader.loadClass(ClassLoader.java:424) [na:1.8.0_40]   at com.google.inject.internal.BytecodeGen$BridgeClassLoader.classicLoadClass(BytecodeGen.java:331) [na:na]   at com.google.inject.internal.BytecodeGen$BridgeClassLoader.loadClass(BytecodeGen.java:325) [na:na]   at java.lang.ClassLoader.loadClass(ClassLoader.java:357) [na:1.8.0_40]   at org.sonatype.nexus.security.internal.RealmManagerImpl.resolveRealms(RealmManagerImpl.java:212) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.sonatype.nexus.security.internal.RealmManagerImpl.installRealms(RealmManagerImpl.java:190) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.sonatype.nexus.security.internal.RealmManagerImpl.doStart(RealmManagerImpl.java:93) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.sonatype.nexus.common.stateguard.StateGuardLifecycleSupport.start(StateGuardLifecycleSupport.java:67) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]   at org.sonatype.nexus.security.internal.RealmManagerImpl$$EnhancerByGuice$$b5f6f1e0.CGLIB$start$11(<generated>) [!/:na]   at org.sonatype.nexus.security.internal.RealmManagerImpl$$EnhancerByGuice$$b5f6f1e0$$FastClassByGuice$$6b159d10.invoke(<generated>) [!/:na]   at com.google.inject.internal.cglib.proxy.$MethodProxy.invokeSuper(MethodProxy.java:228) [com.google.inject:4.0.0]   at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:75) [com.google.inject:4.0.0]   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]   at org.sonatype.nexus.common.stateguard.StateGuard$TransitionImpl.run(StateGuard.java:191) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]   at org.sonatype.nexus.common.stateguard.TransitionsInterceptor.invoke(TransitionsInterceptor.java:56) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]   at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:75) [com.google.inject:4.0.0]   at com.google.inject.internal.InterceptorStackCallback.intercept(InterceptorStackCallback.java:55) [com.google.inject:4.0.0]   at org.sonatype.nexus.security.internal.RealmManagerImpl$$EnhancerByGuice$$b5f6f1e0.start(<generated>) [!/:na]   at org.sonatype.nexus.security.internal.DefaultSecuritySystem.doStart(DefaultSecuritySystem.java:115) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.sonatype.goodies.lifecycle.LifecycleSupport.start(LifecycleSupport.java:104) [org.sonatype.goodies.lifecycle:2.1.0.SNAPSHOT]   at org.sonatype.nexus.extender.NexusLifecycleManager.startComponent(NexusLifecycleManager.java:154) [org.sonatype.nexus.extender:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extender.NexusLifecycleManager.to(NexusLifecycleManager.java:94) [org.sonatype.nexus.extender:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extender.NexusContextListener.contextInitialized(NexusContextListener.java:152) [org.sonatype.nexus.extender:3.0.0.SNAPSHOT]   at org.sonatype.nexus.bootstrap.osgi.ListenerTracker.addingService(ListenerTracker.java:47) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.sonatype.nexus.bootstrap.osgi.ListenerTracker.addingService(ListenerTracker.java:1) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.osgi.util.tracker.ServiceTracker$Tracked.customizerAdding(ServiceTracker.java:941) [org.osgi.core-6.0.0.jar:na]   at org.osgi.util.tracker.ServiceTracker$Tracked.customizerAdding(ServiceTracker.java:870) [org.osgi.core-6.0.0.jar:na]   at org.osgi.util.tracker.AbstractTracked.trackAdding(AbstractTracked.java:256) [org.osgi.core-6.0.0.jar:na]   at org.osgi.util.tracker.AbstractTracked.track(AbstractTracked.java:229) [org.osgi.core-6.0.0.jar:na]   at org.osgi.util.tracker.ServiceTracker$Tracked.serviceChanged(ServiceTracker.java:901) [org.osgi.core-6.0.0.jar:na]   at org.apache.felix.framework.util.EventDispatcher.invokeServiceListenerCallback(EventDispatcher.java:991) [org.apache.felix.framework-5.4.0.jar:na]   at org.apache.felix.framework.util.EventDispatcher.fireEventImmediately(EventDispatcher.java:839) [org.apache.felix.framework-5.4.0.jar:na]   at org.apache.felix.framework.util.EventDispatcher.fireServiceEvent(EventDispatcher.java:546) [org.apache.felix.framework-5.4.0.jar:na]   at org.apache.felix.framework.Felix.fireServiceEvent(Felix.java:4557) [org.apache.felix.framework-5.4.0.jar:na]   at org.apache.felix.framework.Felix.registerService(Felix.java:3549) [org.apache.felix.framework-5.4.0.jar:na]   at org.apache.felix.framework.BundleContextImpl.registerService(BundleContextImpl.java:348) [org.apache.felix.framework-5.4.0.jar:na]   at org.sonatype.nexus.extender.NexusBundleExtender.start(NexusBundleExtender.java:54) [org.sonatype.nexus.extender:3.0.0.SNAPSHOT]   at org.apache.felix.framework.util.SecureAction.startActivator(SecureAction.java:697) [org.apache.felix.framework-5.4.0.jar:na]   at org.apache.felix.framework.Felix.activateBundle(Felix.java:2226) [org.apache.felix.framework-5.4.0.jar:na]   at org.apache.felix.framework.Felix.startBundle(Felix.java:2144) [org.apache.felix.framework-5.4.0.jar:na]   at org.apache.felix.framework.Felix.setActiveStartLevel(Felix.java:1371) [org.apache.felix.framework-5.4.0.jar:na]   at org.apache.felix.framework.FrameworkStartLevelImpl.run(FrameworkStartLevelImpl.java:308) [org.apache.felix.framework-5.4.0.jar:na]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  {quote}",Bug,Major,Closed,"2016-03-21 21:14:13","2016-03-21 21:14:13",0.5
"Sonatype Nexus","com.sun.jndi.ldap.connect.pool.protocol in etc/system.properties has quotes around its value (it shouldn't)","In etc/system.properties we have:         This results in the system property actually getting set to plain ssl (with quotes), you can verify this using the support/system information UI    If the quotes are removed the value shows up correctly in the support/system information UI, no quotes are present.    I'm pretty sure this means LDAP connection pooling is not currently enabled in Nexus 3m7.",Bug,Major,Closed,"2016-03-18 21:47:28","2016-03-18 21:47:28",0.5
"Sonatype Nexus","increase default max heap for Nexus","In our support experience the default heap of Nexus of 768MB is too low for the majority of production installations.    We should increase this default to some value between 1GB and 2GB before Nexus 3 is released.    Any book or articles which reference the default for nexus 3 should be updated if changed. (ie system requirements ).  ",Bug,Major,Closed,"2016-03-17 15:16:58","2016-03-17 15:16:58",0.5
"Sonatype Nexus","Collapse Add/Edit privilege distinction","I created a new raw hosted repository and then created a new role with read and edit repository view privileges to that new repository. Then I created a new user and gave it that new role.  I noticed that I was able to add a file to that raw repository despite not having add privilege. As far as I know, add is not contained in edit and this seems a bug.  I did not back check older NX3 or NX2 at this time. NX2 did use CRUD rather than BREAD which is testable however not sure the comparison is worth it unless to regression check.",Story,Major,Done,"2016-03-16 21:35:29","2016-03-16 21:35:29",8
"Sonatype Nexus","Cannot edit docker repository","I just noticed that if you're attempting to edit a docker repository, the port has validation over it that says Port is already in use and thus the saves cannot happen.  Really annoying workaround is to delete the repo and recreate it.  I doubt that will fly in a production env.  Less (but still) annoying workaround is to change the port 1 number and make your changes then edit it back up and save again.    I did not check older NX3 at this time but I suspect this is regression caused by a too tight NEXUS-9572.  No docker in NX2 so no test needed there.  Debug was off during this test.    From nexus.log  {quote}  2016-03-22 13:52:34,086-0400 WARN  [qtp872875942-278] admin org.sonatype.nexus.repository.docker.internal.DockerConnectorFacetImpl - Validation failed; 1 constraints violated:    1) Port is already in use, type: class org.sonatype.nexus.validation.ConstraintViolationFactory$HelperBean, property: attributes.docker.httpsPort, value: org.sonatype.nexus.validation.ConstraintViolationFactory$HelperBean@2967a181  {quote}",Bug,Major,Closed,"2016-03-15 19:35:00","2016-03-15 19:35:00",1
"Sonatype Nexus","Non-editable privilege fields show as editable","I noticed that in repository admin and repository view default privileges showed the repository field non-grey so appeared editable on the quick.  More careful inspection reveals that the field is a dropdown and interaction with it is not possible, however, it still does not have the same treatment as the other non-editable fields.    Field of the same type (dropdown) appears as non-editable in repository (in the blobstore field) once you create the repository, so I do believe this is possible to fix.    Noticed while testing [-NEXUS-9858-|https://issues.sonatype.org/browse/NEXUS-9858] but filing seperately after talking to [<USER>https://issues.sonatype.org/secure/ViewProfile.jspa?name=<USER> .    I did not check older NX3 or NX2 at this time. Debug was off for this test.",Bug,Trivial,Closed,"2016-03-09 00:02:59","2016-03-09 00:02:59",2
"Sonatype Nexus","Incorrect config path in the documentation for How to Enable the HTTPS Connector","In section How to Enable the HTTPS Connector, Step 3 says to add {karaf.etc}/etc/jetty-https.xml to the config file $install-dir/etc/org.sonatype.nexus.cfg, but the other references in that file do not have the /etc/.    This needs to be corrected to {karaf.etc}/jetty-http.xml.    https://books.sonatype.com/nexus-book/3.0/reference/security.html#ssl-inbound",Bug,Major,Closed,"2016-03-01 10:09:54","2016-03-01 10:09:54",0.5
"Sonatype Nexus","Rebrand can leave cached header image","While testing the rebranded NX3 UI, various team members noticed that in some browser/OS permutations, the header image was cached leaving the old N image and no version (see attached).  If dev believes this should be 2 different tickets (or wants me to make subtasks) let me know.  This did not happen in all browser/OS permutations.    You can force this to happen by clearing browser cache, loading a pre-rebrand version of Nexus to get the N image there and then loading the new version of Nexus.    See attached let me know if unclear.    As far as I can tell this does not affect the 404 page or the describe page which I think are templated slightly differnetly, so that may help.  It may affect them and I did not have them cached tho...I am not 100% certain of that and have not double checked.",Bug,Major,Closed,"2016-02-29 22:34:14","2016-02-29 22:34:14",2
"Sonatype Nexus","If there is only one blobstore then just select it in the new repository screen","Every time I create a repository I have to select the blobstore, which is pretty annoying.  Granted, if there are multiple blobstores defined this isn't easily avoidable.  But I'm betting 90% of our users will only ever have one.      If there is only one blobstore available we should just select it in the new repository screen, rather than forcing the user to do it.",Story,Minor,Done,"2016-02-29 21:13:55","2016-02-29 21:13:55",0.5
"Sonatype Nexus","misconfigured docker proxy URL should log more details about critical failures at default log levels","Create a Docker proxy repository using [https://registry.hub.docker.com|https://registry.hub.docker.com/] instead of [https://registry-1.docker.io|https://registry-1.docker.io/] .    Do a pull with docker and the nexus.log will contain some WARN messages that are not helpful to understand what is wrong.    The Docker client merely reports the image is not found.    Now change the ROOT logger to DEBUG in nexus and you get more exact information that the remote content is not in the expected format, albeit the error is still obfuscated even for a nexus administrator:    h3. Problem    For unexpected conditions, Nexus WARN level nexus.log message is not providing enough detail at default log levels in order to diagnose the real problem. This leads to a support ticket and investigation.  h3. Expected    When the configured Docker registry URL does not respond in the expected manner according to the supported API, then Nexus should log a more exact WARN level message with stack trace or better summary message describing the problem.    WARN or ERROR Log messages about critical failures should not merely repeat what a client tool message already explains.    *Note that [https://registry.hub.docker.com|https://registry.hub.docker.com/] is NOT a valid endpoint for supported API*    Suggested log message instead of Tag not found or invalid data _when the remote does not return valid data_:    It is debateable, that a 500 error be returned to the client instead of 404 when Nexus is knowingly misconfigured. However it is standard practice that when Nexus cannot find content for whatever reason, it returns 404. ( the fix keeps 404 being returned )",Improvement,Major,Closed,"2016-02-29 20:20:35","2016-02-29 20:20:35",1
"Sonatype Nexus","rewrite ssl tips for Docker","I recently created new advice for using SSL with Docker.    https://support.sonatype.com/hc/en-us/articles/217542177    Now we need to rewrite the book section    https://books.sonatype.com/nexus-book/3.0/reference/docker.html#_tips_for_ssl_certificate_usage",Story,Major,Done,"2016-02-29 18:39:35","2016-02-29 18:39:35",0.5
"Sonatype Nexus","InvalidPathException prevents installing gems when Nexus is running on Windows","Install Nexus 2.12.0-01 on Windows.  [Install Nexus 2.12.0-01 rubygems rollup patch.|https://support.sonatype.com/hc/en-us/articles/216185198-Nexus-Repository-Manager-2-12-0-01-RubyGems-plugin-rollup-patch]  Create a Rubygems proxy repo to https://rubygems.org  Create a Rubygems group repo with the proxy repo as member.  Install Rubygems on Windows.  Add the group repo as a source ie. gem sources --add http://localhost:8081/nexus/content/repositories/ruby-group  Remove the default source (optional) gem sources --remove https://rubygems.org  Issue a command to install a gem.    gem install bundle    Client response is:        Stack Trace in nexus.log is:    ",Bug,Major,Closed,"2016-02-26 14:29:40","2016-02-26 14:29:40",0.5
"Sonatype Nexus","Change order of LDAP connections does not refresh list","Follow these steps to replicate:    - Create  ldap configuration A, it will have order value of 1  - Create LDAP configuration B, it will have order value of 2  - Press 'Change order' button  - in the dialog change it so that B is above A (B has value 1, A value 2)  - Press save    Observe how the order in the list is NOT changed.    Now press the refresh icon in the UI nav bar.    The order is changed to the correct value.",Bug,Minor,Closed,"2016-02-25 23:57:23","2016-02-25 23:57:23",0.5
"Sonatype Nexus","support npm dist-tag command","*Acceptance*  * NXRM supports {{npm dist-tag add}}, {{npm dist-tag ls}}, {{npm dist-tag rm}}  * A user can add multiple tags to a package  * A user can install  by tag (with 'latest' being the default)  * in general, this command behaves as described in https://docs.npmjs.com/cli/dist-tag  * npm dist-tag ls should work against proxy, hosted and group repositories.  * npm dist-tag add, rm should work against hosted repositories.",Story,Major,Done,"2016-02-25 21:10:02","2016-02-25 21:10:02",5
"Sonatype Nexus","running rebuild npm hosted metadata scheduled task can change repository value","I make several scheduled task with type Rebuild hosted npm metadata/  Choose different repository on them.  Run one of tasks.  I see that Repository parameters is change in all Rebuild hosted npm metadata tasks and value of Repository in all tasks is a value from last run schedule.  ",Bug,Major,Closed,"2016-02-25 08:14:45","2016-02-25 08:14:45",0.5
"Sonatype Nexus","Creating a second duplicate blobstore errors and deletes the path","While testing the new provisioning API, I created a blobstore for a second time in a test to make sure updates could not be made.  Script was:      The second time I ran this it gave the below error.  In addition to this, I noticed that the location I gave /Users/<USER>Documents/Work/temp was deleted (folder and contents).  The error didn't concern me as much as the deletion, which caused a bunch of test/temp data to be removed.  In a real world scenario, it seems possible to accidentially delete your entire blobstore this way.    This occurs if you do this from the UI as well as if you do this from the provisioning script.  In the event you do this, you also see an error on the screen.  I did not include this below but can if you like.  I did not check this in older versions of NX3.  Blobstores did not exist in NX2 so there's no check there.    Note, you MUST use the same name and location.  If you use a distinct name, no deletion/error occurs.    Please be very careful reproing/testing this and make sure you don't care about the contents of whatever path you use.  Luckily I didn't do /Users/<USER> or something more broad spanning.  Scary stuff.    {quote}  2016-02-23 13:04:56,246-0500 ERROR [Karaf local console user karaf]  org.apache.karaf.shell.support.ShellUtil - Exception caught while executing command  javax.script.ScriptException: javax.script.ScriptException: com.orientechnologies.orient.core.storage.ORecordDuplicatedException: Cannot index record repository_blobstore{name:test6,type:File,attributes:[1]}: found duplicated key 'test6' in index 'repository_blobstore_name_idx' previously assigned to the record #20:6 RID=#20:6   at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:130) [na:na]   at org.sonatype.nexus.internal.script.ScriptServiceImpl.eval(ScriptServiceImpl.java:153) [na:na]   at org.sonatype.nexus.common.script.ScriptService$eval$1.call(Unknown Source) [na:na]   at org.sonatype.nexus.internal.script.ScriptAction.execute(ScriptAction.groovy:119) [na:na]   at org.apache.karaf.shell.impl.action.command.ActionCommand.execute(ActionCommand.java:83) [na:na]   at org.apache.karaf.shell.impl.console.osgi.secured.SecuredCommand.execute(SecuredCommand.java:67) [na:na]   at org.apache.karaf.shell.impl.console.osgi.secured.SecuredCommand.execute(SecuredCommand.java:87) [na:na]   at org.apache.felix.gogo.runtime.Closure.executeCmd(Closure.java:480) [na:na]   at org.apache.felix.gogo.runtime.Closure.executeStatement(Closure.java:406) [na:na]   at org.apache.felix.gogo.runtime.Pipe.run(Pipe.java:108) [na:na]   at org.apache.felix.gogo.runtime.Closure.execute(Closure.java:182) [na:na]   at org.apache.felix.gogo.runtime.Closure.execute(Closure.java:119) [na:na]   at org.apache.felix.gogo.runtime.CommandSessionImpl.execute(CommandSessionImpl.java:94) [na:na]   at org.apache.karaf.shell.impl.console.ConsoleSessionImpl.run(ConsoleSessionImpl.java:270) [na:na]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  Caused by: javax.script.ScriptException: com.orientechnologies.orient.core.storage.ORecordDuplicatedException: Cannot index record repository_blobstore{name:test6,type:File,attributes:[1]}: found duplicated key 'test6' in index 'repository_blobstore_name_idx' previously assigned to the record #20:6 RID=#20:6   at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:326) [na:na]   at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:124) [na:na]   ... 14 common frames omitted  Caused by: com.orientechnologies.orient.core.storage.ORecordDuplicatedException: Cannot index record repository_blobstore{name:test6,type:File,attributes:[1]}: found duplicated key 'test6' in index 'repository_blobstore_name_idx' previously assigned to the record #20:6   at com.orientechnologies.orient.core.index.OIndexTxAwareOneValue.checkEntry(OIndexTxAwareOneValue.java:224) [na:na]   at com.orientechnologies.orient.core.index.OClassIndexManager.checkIndexedPropertiesOnCreation(OClassIndexManager.java:341) [na:na]   at com.orientechnologies.orient.core.index.OClassIndexManager.checkIndexes(OClassIndexManager.java:592) [na:na]   at com.orientechnologies.orient.core.index.OClassIndexManager.onRecordBeforeCreate(OClassIndexManager.java:410) [na:na]   at com.orientechnologies.orient.core.hook.ODocumentHookAbstract.onTrigger(ODocumentHookAbstract.java:226) [na:na]   at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.callbackHooks(ODatabaseDocumentTx.java:1069) [na:na]   at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.executeSaveRecord(ODatabaseDocumentTx.java:1966) [na:na]   at com.orientechnologies.orient.core.tx.OTransactionNoTx.saveRecord(OTransactionNoTx.java:159) [na:na]   at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.save(ODatabaseDocumentTx.java:2568) [na:na]   at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.save(ODatabaseDocumentTx.java:121) [na:na]   at com.orientechnologies.orient.core.record.impl.ODocument.save(ODocument.java:1768) [na:na]   at com.orientechnologies.orient.core.record.impl.ODocument.save(ODocument.java:1759) [na:na]   at org.sonatype.nexus.orient.entity.EntityAdapter.writeEntity(EntityAdapter.java:187) [na:na]   at org.sonatype.nexus.orient.entity.EntityAdapter.addEntity(EntityAdapter.java:215) [na:na]   at org.sonatype.nexus.internal.blobstore.BlobStoreConfigurationStoreImpl.create(BlobStoreConfigurationStoreImpl.java:82) [na:na]   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [na:na]   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:270) [na:na]   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53) [na:na]   at org.sonatype.nexus.internal.blobstore.BlobStoreManagerImpl.create(BlobStoreManagerImpl.java:139) [na:na]   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [na:na]   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:270) [na:na]   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53) [na:na]   at org.sonatype.nexus.blobstore.api.BlobStoreManager$create$6.call(Unknown Source) [na:na]   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125) [na:na]   at org.sonatype.nexus.internal.provisioning.BlobStoreApiImpl.createFileBlobStore(BlobStoreApiImpl.groovy:40) [na:na]   at org.sonatype.nexus.BlobStoreApi$createFileBlobStore.call(Unknown Source) [na:na]   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:133) [na:na]   at Script34.run(Script34.groovy:10) [na:na]   at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:323) [na:na]   ... 15 common frames omitted  {color:red}Error executing command: javax.script.ScriptException: com.orientechnologies.orient.core.storage.ORecordDuplicatedException: Cannot index record repository_blobstore{name:test6,type:File,attributes:[1]}: found duplicated key 'test6' in index 'repository_blobstore_name_idx' previously assigned to the record #20:6 RID=#20:6{color}  {quote}",Bug,Critical,Closed,"2016-02-23 18:07:37","2016-02-23 18:07:37",1
"Sonatype Nexus","Content validation fails when pushing images from Docker 1.8.2 on RHEL/CentOS 7","Pushing images from Docker 1.8.2 into Nexus 3.0m7 fails with a content validation error.  Disabling file content validation seems to fix this problem.    I've captured this in a Charles Proxy session, output is attached.        ",Bug,Major,Closed,"2016-02-22 21:07:30","2016-02-22 21:07:30",2
"Sonatype Nexus","Wrong max component age pre-set for release Maven proxy","When creating a Maven Proxy repository it is set as release type by default. However, max component age is then pre-set to 1440 but should be -1 according to the help text.  I think that the Max component age should be set automatically to the recommended value when selecting either release (-1) or snapshot (1440). Not sure how to handle mixed. If not I suspect that a lot of people will have a not-so-good value here.    * If the user enters a value manually, then changing the version policy should not override a value they've already entered.",Bug,Minor,Closed,"2016-02-19 15:50:37","2016-02-19 15:50:37",0.5
"Sonatype Nexus","improve logging when a retry is made in response to remote socket exceptions","I have latest Nexus OSS version 2.12.0-01. It seems that connection reset during download causing problem. Re-try is not happing.     This can be tested with Smartbearsoftware (Soapui) Maven repository http://smartbearsoftware.com/repository/maven2/    When I try to download this file with browser through Nexus OSS server and connection reset is received from smartbearsoftware url, Nexus does not re-try (for example like Chrome browser or wget works): http://smartbearsoftware.com/repository/maven2/com/smartbear/soapui/soapui/5.1.0/soapui-5.1.0.jar",Improvement,Major,Closed,"2016-02-19 12:41:30","2016-02-19 12:41:30",0.5
"Sonatype Nexus","Some fields allow adding but not removal via keyboard","I noticed recently, that on fields which are for numbers that have arrows to increase or decrease, that you can add numbers to them via keyboard but you cannot remove them via delete.  So, in attached screen (for example) I can make Connection/Socket timeout equal to 2 by typing 2 into the field.  I can subsequently make it 20 by adding a 0.  But I cannot make it 2 again by deleting the 0.  If you do this, nothing happens.  Workaround is to use the arrow keys which can be annoying to impossible with bigger numbers (like docker port).  You can now also workaround using provisional scripting.  ADDENDUM: It was noticed while this was in progress you can also workaround this issue by highlighting the number and overwriting it.    I checked m6 and this does not occur there so I believe recent regression.  I did not check m7 or older NX3 at this time.  I also did not check NX2 at this time.  Debug was off during this test.",Bug,Minor,Closed,"2016-02-18 16:15:23","2016-02-18 16:15:23",0.5
"Sonatype Nexus","Pre-defined central proxy has incorrect maximum component age","The bundled/pre-defined maven proxy for Maven central has Maximum Component age configured to 1440. But the help text says that release repositories should use -1. Maven central is a release repository and should then use -1 and not 1440.",Bug,Major,Closed,"2016-02-18 15:02:34","2016-02-18 15:02:34",0.5
"Sonatype Nexus","Invalid scope specification for Docker hub authentication","*Description*  ----  The Docker proxy recipe for Docker hub may perform a pull using the v1 API for the registry, but not v2.  The basis for this following explanation is the [Docker Registry v2 authentication via central service|https://docs.docker.com/registry/spec/auth/token/] and [Docker Registry v2 Bearer token specification|https://docs.docker.com/registry/spec/auth/jwt/].    When attempt to perform a pull from an official library    {code:bash}  $ docker pull centos:5      The request that should be made is the following    {quote}  https://auth.docker.io/token?service=registry.docker.io&scope=repository:library/centos:pull  {quote}    Notice the inclusion of the library and the result when the token is requested is    {code:json}  {      access: [          {              type: repository,              name: library/centos,              actions: [                  pull              ]          }      ]  }  {code}    The request for the manifest should also include library    {quote}  GET /v2/library/centos/manifests/5  {quote}    The documentation for 3.0 alludes to the library in _section 9.10. Pulling Images_.  However, the examples do not include the library and, when not included, the application, as it should, reverts to v1 and produces the following warning    {quote}  $ docker pull private-registry:18444/centos:5  ...  private-registry:18444/centos: this image was pulled from a legacy registry.  Important: This registry version will not be supported in future versions of docker.  {quote}    *Suggested Actions*  ----  In order to avoid confusion    * the documentation should be updated to explain the need to include the library registry  * the code should be updated to include library when not specified in the pull request    *Workaround*  ----  In order to avoid falling back to v1 and the warning message, include the library when needed.    {quote}  $ docker pull private-registry:18444/library/centos:5  {quote}",Bug,Minor,Closed,"2016-02-18 03:53:07","2016-02-18 03:53:07",3
"Sonatype Nexus","REST client JerseyArtifactMaven does not properly handle packaging parameter","https://github.com/sonatype/nexus-public/pull/1    The packaging parameter is populated with the version currently. This looks like a typo.  Unsure of where the client code is on master, but this is observed in nexus 2.x for the {{nexus-client-core}}  {{org/sonatype/nexus/client/internal/rest/jersey/subsystem/JerseyArtifactMaven.java}}",Bug,Major,Closed,"2016-02-16 12:55:38","2016-02-16 12:55:38",0.5
"Sonatype Nexus","case insensitive matched userids do not map assigned roles","Per NEXUS-4115, Nexus needs to allow case insensitive userid matching.    There is a bug in nexus 3 LDAP user role mapping where this fails.    Create an LDAP configuration as in the attached screenshots and map an LDAP user with 'test0002' user id. Assign the user the nx-admin role.    You can successfully authenticate with this user as expected with *test0002*, *TEST0002*, or *tEsT002*, however the roles are not mapped correctly unless you use the exact case userid that was mapped `test0002`.    This results in being able to signin into the UI using any case, but not seeing the Administration cog or getting any admin privileges unless using an exact case match to *test0002*.    h3. Expected    Correctly map all roles to a successfully authenticated user.",Bug,Major,Closed,"2016-02-12 17:52:50","2016-02-12 17:52:50",1
"Sonatype Nexus","Exception installing JNA native bundle on Windows 2012","http://stackoverflow.com/questions/35163442/cannot-run-sonatype-nexus-repository-manager-3-0-on-windows-2012  ",Bug,Major,Closed,"2016-02-12 12:46:55","2016-02-12 12:46:55",0.5
"Sonatype Nexus","IllegalArgumentException Tar does not contains /package.json rebuilding metadata for some npm packages","I have a pair of npm repository. One of them is a proxy repo to http://registry.npmjs.org  Other is a hosted repo, that is a mirror of the first. Artifacts from first repo is copying to the second.  And than I build metadata on second hosted repository I see error, that some artifact Tar does not contains /package.json (see error.txt attach)  What else, if I unpack a pair of artifact, I can see that they have different structures. ftp-0.3.6.tgz - I can see on hosted repository, ftp-0.3.9.tgz - I couldn't see and have error    2016-02-12 11:14:06 INFO  [ool-1-thread-13] - com.bolyuba.nexus.plugin.npm.hosted.RecreateMetadataWalkerProcessor - Failed to extract or malformed package.json from npmjs:/ftp/-/ftp-0.3.9.tgz    ",Bug,Major,Closed,"2016-02-12 08:57:12","2016-02-12 08:57:12",1
"Sonatype Nexus","Nexus startup no longer logs the edition","Nexus had a single log line you could grep for Nexus startup AND determine the edition being started.    OSS      PRO      Now the edition is no longer present and there is no simple way to determine which edition of Nexus the log is from.    In 2.12.0-01, both editions print this:        h3. Expected    Support staff need a way to quickly determine the edition being used only based on a single line of the log file. When this is especially important is during startup where errors may prevent getting a complete support bundle.    h3. Workarounds    - look at the plugins being loaded ( one per plugin) - from the reduced number of these log lines, one can guess that OSS is being used.  - grep for {{org.sonatype.nexus.bootstrap.ConfigurationBuilder -   nexus-app}} and look at the app directory - the path printed at that line may include something like nexus-2.12.0-01-bundle instead of nexus-professional-2.12.0-01-bundle    h3. Other Ideas    If the new line format must be kept, add a new log line with the text Nexus Pro so that our old method of grepping for edition can work.",Bug,Major,Closed,"2016-02-11 19:27:47","2016-02-11 19:27:47",0.5
"Sonatype Nexus","LDAP user profile fields are editable (they shouldn't be)","The fields in an LDAP user's profile n Nexus 3 are all editable, and the save button is enabled.    This shouldn't be the case, LDAP user information is read only.                                                               This was a mapped external user.",Bug,Major,Closed,"2016-02-10 21:12:11","2016-02-10 21:12:11",1
"Sonatype Nexus","UI javascript files are not compressed/minimized","h3. Problem    Noticed all the Javascript files that are requested using the UI ( ExtJS)  are not of the compressed/condensed form in 2.12.0-01 - previous releases had these compressed to improve UI loading times.    h3. Expected    Javascript files for the UI should be minimized to improve loading times/reduce bandwidth",Bug,Major,Closed,"2016-02-10 16:50:28","2016-02-10 16:50:28",0.5
"Sonatype Nexus","User not found warning on assign roles to LDAP users ","When trying to assign a role to a ldap user (ldap2), a warning is given stating that User (ldap2) not found, but also states that role mapping were updated.    Moving to another page, you have to discard the change, but when you go back to that  ldap users setting, you can see that the role was assigned.",Bug,Major,Closed,"2016-02-10 11:53:34","2016-02-10 11:53:34",1
"Sonatype Nexus","External Realm (LDAP, Crowd) cache duration setting","*Background*  NX2 allows for the configuration of the LDAP query cache duration (as per http://books.sonatype.com/nexus-book/reference/ldap-sect-enterprise.html). This is pretty important to control the impact of a busy repo manager onto the LDAP server.  The NX3 apparently does have cache support, but lack the ability to control the duration.    *Acceptance*  * NX3 admins can configure the LDAP query cache duration   ** *REFINE* the definition of this field - what zero or -1 means, for instance  * The 2x-3x upgrade process brings this setting over from NX2",Story,Major,Done,"2016-02-02 00:26:34","2016-02-02 00:26:34",3
"Sonatype Nexus","URL hostname displayed in repository list cannot be influenced by incoming HTTP headers","h3. Problem    Login to Nexus 3 at a host name other than localhost. The URL column always lists a hostname matching the hostname that the internal host IP resolves to. In some cases this is literally the IP address that Jetty is listening on, in most cases this is literally 'localhost'.    The point is that the host name does not match the Host headers for the inbound requests rendering the UI.    This means that X-Forwarded-Host values and Host header values have no influence over the URL hostname, making copying and using the URL fundamentally useless for real use cases such as using it with tools.    h3. Expected    Nexus should render the URL with the hostname/IP address being used during access.    Nexus should not render a URL that has no useful purpose to an end user.",Bug,Major,Closed,"2016-01-28 20:59:02","2016-01-28 20:59:02",2
"Sonatype Nexus","invalid npm search results in 404 error page rather than a handled error","[~<USER> noticed in NX3 when you search for an unknown component it returns our 404 html rather than the handled error.    Example of current:      Example of expected:      After checks with [~<USER> and [~<USER>, he asked me to file if I saw the same (which I do).  I did not back check older versions of NX3, but I recall seeing this for a while and just assumed it was as it was supposed to be.  Might be we deployed this way.  I did not check NX2 at this time.",Bug,Minor,Closed,"2016-01-27 19:37:55","2016-01-27 19:37:55",1
"Sonatype Nexus","Logging creation message box not fully displayed","Noticed that when creating a logger the created message box does not show the right border or the close X as the other creation (and deletion, and saving, etc) message boxes do.  I find it unlikely this is intentionally inconsistent because even deletion on the same page shows this border/X.  Filing for eventual investigation.  See attached.  NOTE: Screen is NOT cutoff.    I did not check older NX3 at this time.  This does not affect NX2 (checked 2.12.0-01).  Debug was off during this check.    I also noted this does not happen with Tasks creation (same build).",Bug,Trivial,Closed,"2016-01-26 21:53:02","2016-01-26 21:53:02",2
"Sonatype Nexus","licensing UI should show distinction between recent connections and total licensed users","We believe that there is some confusion in the field introduced by the Licensed Connections: field in the Licensing screen of NX2. We license by Users even though we provide a connection count and report as a mechanism for judging compliance.    Current Screen:    !https://sonatype.aha.io:443/attachments/token/2e8f7e1177bda3609e23501d1fe46c0d219dd4b663ea3f7e142b5d7b3785e56c!     Acceptance Criteria:    # Split this into two fields:  ## Licensed Users  ### 1000 Licensed Users  ## Connections  ### X Connections",Improvement,Minor,Closed,"2016-01-25 18:21:04","2016-01-25 18:21:04",1
"Sonatype Nexus","NuGet custom search shows no results if you come to a custom search with results","Just noticed that my custom nuget search had no results, despite the fact I had uploaded components earlier.  I was able to repro this behavior by coming into the custom nuget search from another custom search that had results.  If you enter the custom search from a fresh page load or from another custom search with no results everything displays correctly.    See attached vid.    I did not test older versions of NX3 at this time nor did I check NX2.",Bug,Minor,Closed,"2016-01-22 19:51:06","2016-01-22 19:51:06",1
"Sonatype Nexus","expire cache task on rubygems repositories may lead to /api/v1/dependecies api performance degradation","h3. Problem    Expiring Cache on a rubygems proxy repository can cause Nexus to make a single HEAD and GET request for every gem and dependency gem referenced by a single request listing gems to */api/v1/dependencies?gems=<list-of-gems>*.    Before the Expire cache task is run, Nexus will not do this. Instead it passes the request to the remote as received.    For example:    - request /api/v1/dependencies?gems=foo,bar  - Nexus passes this single request as is, to any remote repository it is proxying  - Expire Cache on the Nexus repository  - sending the same request to Nexus causes Nexus to send both a HEAD and a GET as follows:  HEAD /api/v1/dependencies?gems=foo  GET /api/v1/dependencies?gems=foo  HEAD /api/v1/dependencies?gems=bar  GET /api/v1/dependencies?gems=bar    For long lists of gems, the many additional outbound requests can lead to a significant drop in response time as compared to when the single request is passed through to the remote 'as is'.    I've attached a jmeter test one can use the reproduce the issue. The attachment also contains a nexus log, conf directory, and csv format of performance data before and after expiring cache.    The key log lines in the attached nexus.log are as follows:        As you can see, it takes 3m47s for the first run, the second run takes 6m33 seconds for the same set of 20 requests repeated 10 times.",Bug,Major,Closed,"2016-01-21 00:50:19","2016-01-21 00:50:19",1
"Sonatype Nexus","Make ESC work in modal dialogs","Modal dialogs can&rsquo;t be quit by hitting ESC when the &ldquo;x&rdquo; icon is not shown. This is the default behavior for most of our modals, and should not be due to accessibility/usability reasons.    From Jason:    I belive we should use the window.closable:true feature to gain ESC functionality at the expense of the additional (x). I have no issue with the 2 buttons which do the same thing in this case. I prefer it actually. But abs want to ensure that ESC works properly and to hack in our own impl for this would be bloated waste and would rely on private internals of Ext.window.Window which could cause problems for any upgrade.    Acceptance:    * Modal dialogs can be quit with the ESC button   * Choosing to quit a dialog should result in no state change to the system.   ** It is essentially the same as Cancel",Story,Major,Done,"2016-01-18 19:39:25","2016-01-18 19:39:25",2
"Sonatype Nexus","Docker usage with self signed certs","We have users struggling with this. Usage of insecure config parameter and so on should at least be mentioned.  ",Bug,Major,Closed,"2016-01-15 22:39:37","2016-01-15 22:39:37",1
"Sonatype Nexus","xml:base URL in proxied yum metadata files is not rewritten","The base:xml URL's in proxied yum metadata (repomd/repodata.xml)  are no longer rewritten.  This is a regression from 2.11.0.    Reproduce steps:    # Set up 2.9.1 with base URL forced (this is needed to get base:url set in the metadata)  # Add a hosted yum repository into 2.9.1, populate it with something.  # Now set up 2.12.0 with a yum enabled proxy.    Observe that proxied metadata has xml:base URL of the remote:    {code:XML}  <?xml version=1.0 encoding=UTF-8 standalone=no?><repomd xmlns=http://linux.duke.edu/metadata/repo xmlns:rpm=http://linux.duke.edu/metadata/rpm>   <revision>1452869080</revision>  <data type=filelists>    <checksum type=sha256>bdc5e634c890e48f3e30ed99ce39ec19e93c057be28b391a9b786a527e00270d</checksum>    <open-checksum type=sha256>88e9e1509ddbe17b977d9a3e6da66b6ae76717ac8c4aed248220e1fb5908f304</open-checksum>    <location href=repodata/bdc5e634c890e48f3e30ed99ce39ec19e93c057be28b391a9b786a527e00270d-filelists.xml.gz xml:base=http://192.168.1.24:8081/nexus/content/repositories/releases/>    <timestamp>1452869080</timestamp>    <size>429</size>    <open-size>1482</open-size>  </data>  {code}    This is a regression, in NEXUS-6702 a fix was put in place to remove the xml:base URL from the proxied repomd.xml file.    Note that this will not just affect proxies of older Nexus versions, any remote metadata that has base:xml URL set in it's metadata will be affected.",Bug,Major,Closed,"2016-01-15 16:41:09","2016-01-15 16:41:09",1
"Sonatype Nexus","infinite timeout on sockets performing CONNECT tunneling through a HTTP Proxy server","h3. Problem    Sockets which perform CONNECT tunneling have an infinite timeout. These sockets could be used whenever Nexus makes a secure TLS connection through a proxy server - for example certificate retriever, automatic routing, repository status checker, etc.     https://en.wikipedia.org/wiki/HTTP_tunnel#HTTP_tunneling_without_using_CONNECT    h3. Symptoms    Thread dumps contain unexplained RUNNABLE threads stuck on socketRead which never go away.        Alternative stack which one may see ( stepping through a debugger can prove the socket being used in this stack also has infinite timeout ). Note the call to 'upgrade' the connection:          h3. Reproduce    - an auto-blocking enabled proxy repository with https remote url  - an HTTP proxy server in Nexus which handles CONNECT tunnel upgrade of the proxy server connection to the secure TLS remote url ( proxy servers must support this if they are to be used with Nexus )  - the HTTP Proxy server hangs on the CONNECT/initial handshake    Simple reproduce is configure Charles Proxy throttling to have Download and Upload speeds of zero ( 0 ). Another alternative is have something listening on the proxy server port which never responds to CONNECT. For example use [bane|https://github.com/danielwellman/bane].        Then refresh the Nexus repository list or reboot Nexus. This causes a status check and a CONNECT which hangs forever.        h3. Supplemental    Connections which do not use CONNECT ( plain http urls ) but attempt to use the Nexus HTTP proxy server which does not respond do have their socket timeout set correctly and respect the standard retries and connect timeout settings in Nexus.    h3. Workaround    Use the plain HTTP remote url of the target repository if one is available. This bypasses CONNECT and the problem.    Do not configure your HTTP proxy or firewall to hang socket connections.  ",Bug,Major,Closed,"2016-01-14 04:41:02","2016-01-14 04:41:02",2
"Sonatype Nexus","rubygems proxy repository does not respect Artifact Max Age for gem files","h3. Reproduce    Configure the following:    rubygems-group  - rubygems-proxy ( -> http://rubygems.org )    rubygems-proxy is configured with     Artifact Max Age: -1  Item Max Age: 1440    Configure remote.storage.outbound logger at DEBUG level.    Request a gem file through the group found on rubygems.org    curl -u admin:admin123 http://localhost:8081/nexus/content/repositories/rubygems-group/gems/spreadsheet-1.1.1.gem -o /dev/null -v    This should return 200 response with correct content, and nexus should go remote since it does not have it cached yet.    Confirm the file is now cached at sonatype-work/nexus/storage/rubygems-proxy/gems/s/spreadsheet-1.1.1.gem    Make the same request again. Nexus goes remote again for the same file.    h3. Expected    Since Artifact Max Age is -1, and the gem is already cached, Nexus should not go remote again until the actual gem file itself is no longer in the proxy repository cache or the max age for the specific gem is expired. Nexus should always check local first and serve it if present in storage. Once found, it should not continue to check any other member repositories of a group for the same gem.    Make sure Artifact Max Age works when the proxy is accessed directly also, or there is an equivalent request which requires resolution of the specific gem file requested.    ",Bug,Major,Closed,"2016-01-12 19:10:14","2016-01-12 19:10:14",1
"Sonatype Nexus","revert Basic auth realm name change introduced in 2.12.0","The Nexus Basic Auth realm name changed in version 2.12.0 due to unintended branding changes.    This could affect some use cases where the exact name of the realm was depended on, so we restored the original name to Sonatype Nexus Repository Manager    Related issue: https://issues.sonatype.org/browse/OSSRH-19926",Bug,Major,Closed,"2016-01-12 18:27:38","2016-01-12 18:27:38",1
"Sonatype Nexus","/service/local/staging/bulk/promote resource does not check drop privilege","h3. Problem    If a user is not granted the Staging: Drop Repository privilege, they can still drop a repository upon release of that repository using the /service/local/staging/bulk/promote resource.    h3. Reproduce    Configure a user `sonatype` with UI Basic and a custom staging role:        The user can login to the UI and view the staging repository list. The Drop button is disabled, implying they do not have the drop permission.    However the Release button is not disabled as expected. The Release confirmation dialog includes a checkmark to Automatically Drop a repository upon release. When selected, the repository is dropped upon release, despite the user not having Staging: Drop Repository privilege.    h3. Expected    The bulk/promote resource should only perform the release if the drop checkbox is not selected ( payload implies do not drop) when the user does not have permission to drop a repository. The UI should display a permission error. Keep in mind the maven staging plugin also uses this resource.  ",Bug,Major,Closed,"2016-01-12 15:46:33","2016-01-12 15:46:33",0.5
"Sonatype Nexus","rubygems proxy repository not found cache not consulted","Configure this:    rubygems-group ( group repo )  - rubygems.org-proxy -> https://rubygems.org ( member )    Connect to nexus with JMX to monitor the path cache ( see attached ) Object Count attribute.    Configure remote.storage.outbound logger to DEBUG and tail nexus.log.    Request a non-existent gem file.    curl -v -o /dev/null http://localhost:8081/nexus/content/groups/rubygems-group/gems/fake-5.0.1.gem    Expected 404 response.    Notice the path-cache Object Count is now 1.    Delete the cache item to prove that was the path that was cached    curl -v -o /dev/null -X DELETE http://localhost:8081/nexus/service/local/data_cache/repositories/rubygems.org/content/gems/fake-5.0.1.gem -u admin:admin123    Notice the Object Count is 0.    Request the gem two more times. Notice the Object Count becomes 1 as expected.        Notice in the nexus.log, nexus sends the request remote 2 times when only 1 time was expected.    ----    Effectively this means the not-found cache for rubygems proxy repositories is used, but not consulted.",Bug,Major,Closed,"2016-01-08 20:12:55","2016-01-08 20:12:55",1
"Sonatype Nexus","Eliminate Ext JS tech debt","Things to address:    * -Replace toolbar hack which renders the border in feature header- (implemented in migration2 branch)  * -Use {{statics}} to manage modal sizes- (implemented in migration2 branch)  * Prefer {{initComponent}} to class refs ([#451|https://github.com/sonatype/nexus-internal/pull/451]) (implemented in master)","Technical Debt",Major,Closed,"2016-01-07 22:11:30","2016-01-07 22:11:30",1
"Sonatype Nexus","Task last run and last result not persisted correctly","The last run time of scheduled tasks is not persisted correctly. The symptom is that a task runs(starts) on a regular schedule ( ie. weekly) and may have a last run time that is much farther in the past than the actual last start of the task.  h4. Expected    When a task is started and then running while Nexus is stopped, then on restart   - last run time shows when that task was last started   - last result duration will be time of server shutdown ( or very close to it) minus (-) last start time   - last result will NOT be Ok since the task was abruptly stopped while running by server shutdown. Error may not be good enough either. Need a state that suggests task was forcibly stopped, not by a request from the UI or REST call, but server shutdown, clean or otherwise.",Bug,Major,Closed,"2016-01-07 19:18:39","2016-01-07 19:18:39",2
"Sonatype Nexus","LDAP's Verify User Mapping shows badly formed results","Noticed that in Gnarly  the Verify user mapping results from LDAP show results however, there's no modal title, columns or close button and the results are half off the screen and unscrollable to.  You can however close the modal with the escape key as a workaround (though there's no workaround I see to seeing the full results or sorting).    This behavior is specific to Gnarly as it works correctly in m6.  I've included screens of both.  [~<USER> noted this was this way when he started work on NEXUS-9370.    There were a couple LDAP fixes in Gnarly however none I saw/believe specific to this button/modal.  Debug was off during this test.  I cleared my browser cache before each attempt to be sure nothing odd was caching.",Bug,Trivial,Closed,"2016-01-05 22:50:25","2016-01-05 22:50:25",0.5
"Sonatype Nexus","Problem in accessing docker repository","Hello All,    I have Installed and configured Nexus 3.0 m6 in my Redhat 7.1. I had created the docker repositories in Nexus, i had followed the following document https://books.sonatype.com/nexus-book/3.0/reference/docker.html.     I have the nexus running on both http and https ports. When i run dcoker push <nexus-host>:<nexus-port>/<image>:<tag>    i am getting following error..    [<USER><nexus-hostname> etc]$ docker push <nexus-hostname>.geicoddc.net:18443/calendar:latest  The push refers to a repository [<nexus-hostname>.geicoddc.net:18443/calendar] (len: 1)  unable to ping registry endpoint https://<nexus-hostname>.geicoddc.net:18443/v0/  v2 ping attempt failed with error: Get https://<nexus-hostname>.geicoddc.net:18443/v2/: x509: certificate signed by unknown authority   v1 ping attempt failed with error: Get https://<nexus-hostname>.geicoddc.net:18443/v1/_ping: x509: certificate signed by unknown authority  [<USER><nexus-hostname> etc]$      Thanks in advance  ",Bug,Critical,Closed,"2016-01-05 18:55:18","2016-01-05 18:55:18",2
"Sonatype Nexus","all proxied repository items should have remoteUrl attribute set","All the cached/proxied items in NX2 should have remoteUrl attribute set. Known affected formats so far:  * npm This is the bug in alternative npm specific transport, that is used by NPM to circumvent some format peculiarities (and NX2 core deficiencies).    Acceptance Criteria:  * all formats should be reviewed (and fixed where needed) for lack of attribute",Bug,Major,Closed,"2016-01-04 17:44:49","2016-01-04 17:44:49",2
"Sonatype Nexus","do not allow arbitrary http access through docker repository specific ports","If you configure a port on a docker repository, you can also access the rest of Nexus through this port, including the UI.    You can also configure the port to be the same as an existing connector defined manually in jetty.xml.    You cannot configure the port to be the same as another docker repository connector.    Regardless, this is much more access than a docker specific repository port implies.    Suggest we limit accessible URLs through a docker repository port to only those known to map correctly to docker repositories.    Alternately, do we have a use case for allowing to use the same port as one configured in the jetty configuration files manually? The only benefit might be that one might want to reduce the ports to be managed through firewalls. However does this lead to potential exposure to URL conflicts with other parts of Nexus?",Bug,Major,Closed,"2016-01-04 17:16:29","2016-01-04 17:16:29",1
"Sonatype Nexus","npm version not found results in error 500","Noticed that if you hit an npm component whose versions does not exist (cannot be found) you get the attached error 500.  This is different than NuGet (for example) where you get an error 404 (as I expected).  I asked [~<USER> and he asked me to ticket as this is not expected behavior.    Can reproduce fairly easily by creating an npm proxy (to npmjs.org) and hitting a component with a version that doesn't exist (example: http://localhost:8081/repository/npmproxy/npm/-/npm-18.1.25.tgz)    There is an error in the nexus.log as well (below) however it appears appropriate (warning the package isn't found) to me.  {quote}  2015-12-24 09:33:00,347-0500 WARN  [qtp479482432-288] admin org.sonatype.nexus.repository.httpbridge.internal.ViewServlet - Service failure  java.lang.RuntimeException: java.io.IOException: Could not find package npm version for npm-18.1.25.tgz   at com.google.common.base.Throwables.propagate(Throwables.java:160) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmProxyFacetImpl.getUrl(NpmProxyFacetImpl.java:127) [na:na]   at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.fetch(ProxyFacetSupport.java:198) [na:na]   at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.get(ProxyFacetSupport.java:163) [na:na]   at org.sonatype.nexus.repository.proxy.ProxyHandler.handle(ProxyHandler.java:48) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.storage.UnitOfWorkHandler.handle(UnitOfWorkHandler.java:39) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.Context$proceed.call(Unknown Source) [na:na]   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:117) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmProxyRecipe$_closure1.doCall(NpmProxyRecipe.groovy:141) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [na:na]   at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [na:na]   at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1084) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [na:na]   at groovy.lang.Closure.call(Closure.java:426) [na:na]   at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [na:na]   at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [na:na]   at com.sun.proxy.$Proxy157.handle(Unknown Source) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.handlers.ContentHeadersHandler.handle(ContentHeadersHandler.java:44) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.handlers.ConditionalRequestHandler.handle(ConditionalRequestHandler.java:72) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.partial.PartialFetchHandler.handle(PartialFetchHandler.java:58) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.negativecache.NegativeCacheHandler.handle(NegativeCacheHandler.java:50) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmHandlers$1.handle(NpmHandlers.java:110) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.security.SecurityHandler.handle(SecurityHandler.java:45) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.handlers.TimingHandler.handle(TimingHandler.java:46) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.Context.start(Context.java:102) [na:na]   at org.sonatype.nexus.repository.view.Router.dispatch(Router.java:58) [na:na]   at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:43) [na:na]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.dispatchAndSend(ViewServlet.java:198) [na:na]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.doService(ViewServlet.java:160) [na:na]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.service(ViewServlet.java:117) [na:na]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:70) [com.google.inject:4.0.0]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.4]   at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.4]   at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:101) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1668) [org.eclipse.jetty.servlet:9.3.5.v20151012]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581) [org.eclipse.jetty.servlet:9.3.5.v20151012]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.3.5.v20151012]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548) [org.eclipse.jetty.security:9.3.5.v20151012]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226) [org.eclipse.jetty.server:9.3.5.v20151012]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1158) [org.eclipse.jetty.server:9.3.5.v20151012]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511) [org.eclipse.jetty.servlet:9.3.5.v20151012]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.3.5.v20151012]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1090) [org.eclipse.jetty.server:9.3.5.v20151012]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.3.5.v20151012]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.5.v20151012]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:109) [org.eclipse.jetty.server:9.3.5.v20151012]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.5.v20151012]   at org.eclipse.jetty.server.Server.handle(Server.java:517) [org.eclipse.jetty.server:9.3.5.v20151012]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:306) [org.eclipse.jetty.server:9.3.5.v20151012]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:242) [org.eclipse.jetty.server:9.3.5.v20151012]   at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:261) [org.eclipse.jetty.io:9.3.5.v20151012]   at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.5.v20151012]   at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:75) [org.eclipse.jetty.io:9.3.5.v20151012]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:213) [org.eclipse.jetty.util:9.3.5.v20151012]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:147) [org.eclipse.jetty.util:9.3.5.v20151012]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654) [org.eclipse.jetty.util:9.3.5.v20151012]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572) [org.eclipse.jetty.util:9.3.5.v20151012]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  Caused by: java.io.IOException: Could not find package npm version for npm-18.1.25.tgz   at com.sonatype.nexus.repository.npm.internal.NpmProxyFacetImpl.retrievePackageVersionTx(NpmProxyFacetImpl.java:301) [na:na]   at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:54) [na:na]   at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:53) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmProxyFacetImpl.retrievePackageVersion(NpmProxyFacetImpl.java:285) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmProxyFacetImpl.getUrl(NpmProxyFacetImpl.java:123) [na:na]   ... 116 common frames omitted  {quote}    I did not check older NX3 or NX2 at this time.  Debug was off during this testing effort.",Bug,Minor,Closed,"2015-12-24 14:37:58","2015-12-24 14:37:58",1
"Sonatype Nexus","installing gems with long dependency chains can trigger IOException File name too long","Using bundler in particular, installing a gem through a rubygems proxy repository in Nexus can cause Nexus to return a 404 response and print java.io.IOException: File name too long in the logs.  ",Bug,Major,Closed,"2015-12-18 20:47:43","2015-12-18 20:47:43",1
"Sonatype Nexus","Content type validation blocks some docker fetching","Looking at a support issue I attempted *docker pull 192.168.1.3:18079/ksdn117/test-page* (proxy pull) and got this:      The below error was present in the logs.  {quote}  2015-12-11 10:09:09,996-0500 WARN  [qtp913947442-124] *UNKNOWN org.sonatype.nexus.repository.httpbridge.internal.ViewServlet - Service failure  org.sonatype.nexus.repository.InvalidContentException: Detected content type [text/html], but expected [application/json]: /v1/images/b3e2623757ce549a3898fe1b64a52be833fe93b95517e65a97f0913ec4060f7a/json.json  at org.sonatype.nexus.repository.storage.DefaultContentValidator.determineContentType(DefaultContentValidator.java:95) [na:na]  at org.sonatype.nexus.repository.docker.internal.DockerContentValidator.determineContentType(DockerContentValidator.java:61) [na:na]  at org.sonatype.nexus.repository.storage.StorageTxImpl.determineContentType(StorageTxImpl.java:631) [na:na]  at org.sonatype.nexus.repository.storage.StorageTxImpl.createBlob(StorageTxImpl.java:522) [na:na]  at org.sonatype.nexus.repository.storage.StorageTxImpl.setBlob(StorageTxImpl.java:596) [na:na]  at sun.reflect.GeneratedMethodAccessor93.invoke(Unknown Source) [na:na]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_60]  at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_60]  at org.sonatype.nexus.common.stateguard.SimpleMethodInvocation.proceed(SimpleMethodInvocation.java:53) [na:na]  at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [na:na]  at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:267) [na:na]  at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53) [na:na]  at org.sonatype.nexus.common.stateguard.StateGuardAspect$1.invoke(StateGuardAspect.java:59) [na:na]  at com.sun.proxy.$Proxy153.setBlob(Unknown Source) [na:na]  at org.sonatype.nexus.repository.docker.internal.DockerFacetUtils.saveAsset(DockerFacetUtils.java:303) [na:na]  at org.sonatype.nexus.repository.docker.internal.DockerFacetUtils.saveAsset(DockerFacetUtils.java:292) [na:na]  at org.sonatype.nexus.repository.docker.internal.DockerProxyFacetImpl.doPutAsset(DockerProxyFacetImpl.java:471) [na:na]  at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:54) [na:na]  at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:53) [na:na]  at org.sonatype.nexus.repository.docker.internal.DockerProxyFacetImpl.putLayerMetadata(DockerProxyFacetImpl.java:577) [na:na]  at org.sonatype.nexus.repository.docker.internal.DockerProxyFacetImpl.store(DockerProxyFacetImpl.java:187) [na:na]  at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.get(ProxyFacetSupport.java:171) [na:na]  at org.sonatype.nexus.repository.proxy.ProxyHandler.handle(ProxyHandler.java:48) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.storage.UnitOfWorkHandler.handle(UnitOfWorkHandler.java:39) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.Context$proceed.call(Unknown Source) [na:na]  at org.sonatype.nexus.repository.docker.internal.V1Handlers$_closure20.doCall(V1Handlers.groovy:296) [na:na]  at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source) [na:na]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_60]  at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_60]  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [groovy-all:2.4.4]  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [groovy-all:2.4.4]  at groovy.lang.Closure.call(Closure.java:426) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [groovy-all:2.4.4]  at com.sun.proxy.$Proxy120.handle(Unknown Source) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.Context$proceed.call(Unknown Source) [na:na]  at org.sonatype.nexus.repository.docker.internal.V1Handlers$_closure19.doCall(V1Handlers.groovy:268) [na:na]  at sun.reflect.GeneratedMethodAccessor102.invoke(Unknown Source) [na:na]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_60]  at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_60]  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [groovy-all:2.4.4]  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [groovy-all:2.4.4]  at groovy.lang.Closure.call(Closure.java:426) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [groovy-all:2.4.4]  at com.sun.proxy.$Proxy120.handle(Unknown Source) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.partial.PartialFetchHandler.handle(PartialFetchHandler.java:58) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.handlers.ContentHeadersHandler.handle(ContentHeadersHandler.java:44) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.handlers.ConditionalRequestHandler.handle(ConditionalRequestHandler.java:72) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.Context$proceed.call(Unknown Source) [na:na]  at org.sonatype.nexus.repository.docker.internal.V1Handlers$_closure12.doCall(V1Handlers.groovy:181) [na:na]  at sun.reflect.GeneratedMethodAccessor101.invoke(Unknown Source) [na:na]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_60]  at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_60]  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [groovy-all:2.4.4]  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [groovy-all:2.4.4]  at groovy.lang.Closure.call(Closure.java:426) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [groovy-all:2.4.4]  at com.sun.proxy.$Proxy120.handle(Unknown Source) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.Context$proceed.call(Unknown Source) [na:na]  at org.sonatype.nexus.repository.docker.internal.V1Handlers$_closure18.doCall(V1Handlers.groovy:248) [na:na]  at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source) [na:na]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_60]  at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_60]  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [groovy-all:2.4.4]  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [groovy-all:2.4.4]  at groovy.lang.Closure.call(Closure.java:426) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [groovy-all:2.4.4]  at com.sun.proxy.$Proxy120.handle(Unknown Source) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.negativecache.NegativeCacheHandler.handle(NegativeCacheHandler.java:50) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.security.SecurityHandler.handle(SecurityHandler.java:45) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.Context$proceed.call(Unknown Source) [na:na]  at org.sonatype.nexus.repository.docker.internal.V1Handlers$_closure17.doCall(V1Handlers.groovy:243) [na:na]  at sun.reflect.GeneratedMethodAccessor99.invoke(Unknown Source) [na:na]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_60]  at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_60]  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [groovy-all:2.4.4]  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [groovy-all:2.4.4]  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1084) [groovy-all:2.4.4]  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [groovy-all:2.4.4]  at groovy.lang.Closure.call(Closure.java:426) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [groovy-all:2.4.4]  at com.sun.proxy.$Proxy120.handle(Unknown Source) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.handlers.TimingHandler.handle(TimingHandler.java:46) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.Context.start(Context.java:102) [na:na]  at org.sonatype.nexus.repository.view.Router.dispatch(Router.java:58) [na:na]  at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:43) [na:na]  at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.dispatchAndSend(ViewServlet.java:198) [na:na]  at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.doService(ViewServlet.java:160) [na:na]  at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.service(ViewServlet.java:117) [na:na]  at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]  at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]  at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]  at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]  at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:70) [com.google.inject:4.0.0]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.4]  at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.0.0.b2015110601]  at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.4]  at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.4]  at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.4]  at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.4]  at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.0.0.b2015110601]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.core:3.0.0.b2015110601]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:101) [org.sonatype.nexus.core:3.0.0.b2015110601]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]  at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.b2015110601]  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1668) [org.eclipse.jetty.servlet:9.3.5.v20151012]  at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581) [org.eclipse.jetty.servlet:9.3.5.v20151012]  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.3.5.v20151012]  at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548) [org.eclipse.jetty.security:9.3.5.v20151012]  at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226) [org.eclipse.jetty.server:9.3.5.v20151012]  at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1158) [org.eclipse.jetty.server:9.3.5.v20151012]  at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511) [org.eclipse.jetty.servlet:9.3.5.v20151012]  at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.3.5.v20151012]  at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1090) [org.eclipse.jetty.server:9.3.5.v20151012]  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.3.5.v20151012]  at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.5.v20151012]  at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]  at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:109) [org.eclipse.jetty.server:9.3.5.v20151012]  at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.5.v20151012]  at org.eclipse.jetty.server.Server.handle(Server.java:517) [org.eclipse.jetty.server:9.3.5.v20151012]  at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:306) [org.eclipse.jetty.server:9.3.5.v20151012]  at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:242) [org.eclipse.jetty.server:9.3.5.v20151012]  at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:261) [org.eclipse.jetty.io:9.3.5.v20151012]  at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.5.v20151012]  at org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:192) [org.eclipse.jetty.io:9.3.5.v20151012]  at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:261) [org.eclipse.jetty.io:9.3.5.v20151012]  at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.5.v20151012]  at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:75) [org.eclipse.jetty.io:9.3.5.v20151012]  at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:213) [org.eclipse.jetty.util:9.3.5.v20151012]  at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:147) [org.eclipse.jetty.util:9.3.5.v20151012]  at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654) [org.eclipse.jetty.util:9.3.5.v20151012]  at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572) [org.eclipse.jetty.util:9.3.5.v20151012]  at java.lang.Thread.run(Thread.java:745) [na:1.8.0_60]  {quote}    All works with strict content type validation off.  This is NOT the issue the user was seeing, however, does show a possible issue with content type validation and docker.",Bug,Minor,Closed,"2015-12-16 21:26:11","2015-12-16 21:26:11",1
"Sonatype Nexus","concurrent requests to ruby proxy at /api/v1/dependencies resource using the same url can hang","Configure a rubygems.org proxy repository  Send concurrent requests to this url.    /nexus/content/repositories/rubygems.org/api/v1/dependencies?gems=gem_version,rake,nexus,gherkin,cucumber,bundler,qa_lib_store,qa_steps_support_jruby,qa_steps_files_jruby,qa_steps_remote_jruby,qa_steps_httpcalls_jruby,qa_lib_dbservices_jruby,qa_gridconfig_jruby    - nexus sends outbound requests one at a time for the same url  - most of these timeout after 30 seconds  - client starts to get 503 and 500 responses for some requests  - thread dumps show multiple threads waiting for uid locks    The same test using Nexus 2.5 and OSS rubygems plugin worked fine in this scenario",Bug,Major,Closed,"2015-12-16 20:31:57","2015-12-16 20:31:57",1
"Sonatype Nexus","Hang on analyzing stops all further analysis","While testing NEXUS-8239, I noticed (#6) that occasionally one of my repos would get stuck on Analyzing....  Also all the healthcheck tasks end up Blocked so no further analysis of any type can be done.  Workaround I've found is if you remove Healthcheck from repos, eventually it'll unlock and finish analyzing.    [~<USER> attempted a fix based around findings with nuget and asked me to recheck.  I noticed this again (post-fix) with no nuget involved, just Maven.  Attached is a support.zip.  If there's anything else I can provide please let me know.  I have not found a reproducable case for this yet but still seems an issue.    Original #6 text:  {quote}  Joe: 6) Twice now, I've been hung at the Analyzing... state. I suspect there may be a conflict with having multiple repos analyzed at once. I don't have a repoducable scenario (yet). This may also be an issue with tasks conflicts that Tamas is working on however the quartz entries in the Nexus log shows everything waiting (while the UI shows everything as blocked). Hopefully can run it down.    Alin: Accidentally I got the same state and looks like it happens when RHC task fails. E.g. I get now an  java.lang.IllegalStateException: Missing: {attributes::checksum} sha1  Looking into it    Alin: I merged a fix related to nuget assets sha1, https://github.com/sonatype/nexus-internal/pull/385, so please retest if you still get stuck in Analysing...  {quote}",Bug,Major,Closed,"2015-12-16 19:52:30","2015-12-16 19:52:30",1
"Sonatype Nexus","allow setting java.naming.referral for LDAP connections","Nexus 2.11.4-01    We're trying to force the referral setting of LDAP to 'ignore' for all connections instead of the default 'follow'.    According to NEXUS-5870 we should be able to inject additional properties into the LDAP connection context by setting nexus.ldap.env.<property name>    That works - *except* for referral. In  org.sonatype.security.ldap.realms.DefaultLdapContextFactory.getSetupEnvrironment()    You can see the additional properties are added just fine and then the referral setting is overwritten.    Is there a way of setting this in the LDAP configuration?    Thanks",Improvement,Major,Closed,"2015-12-16 16:31:03","2015-12-16 16:31:03",1
"Sonatype Nexus","Starting to leave the browser with a dirty page but staying can break the UI","I noticed that if you can break the Nexus UI (no content or breadcrumbs show until browser refresh) by performing the following steps:    1) Start filling out a newly created scheduled task by selecting a task frequency  2) Go to close the browser.  On prompt, choose to stay on page.  3) Navigate away from the page.  On prompt, choose to discard changes.  BUG: Subsequent UI breadcrumbs and page content is broken.  This restores when you refresh the browser.    See vid.  As far as I can tell this is something specific to the Tasks and Task frequency field.  I atttempted the same test in Capabilities and had no issue.  I attempted the same test in Tasks but with a repository field (also a dropdown) and had no issue.  Because of this and the workaround to refresh to fix, I am filing minor.    Debug was off initially during these checks but I turned it on and saw no errors in the console.  Also no errors in the log.  I did not check older NX3 or NX2 at this time.",Bug,Minor,Closed,"2015-12-09 16:10:43","2015-12-09 16:10:43",2
"Sonatype Nexus","Group cache invalidation unnoticed after reboot","Spotted while working around Purge Snapshots work...    Steps to reproduce:  - deploy a 1.0-SNAPSHOT artifact to NX3 as usual (would land in maven-snapshots)  - deploy same as above with 1.0 release version artifact to NX3 as usual (would land in maven-releases)  - query for metadata via group, in my case http://localhost:8081/repository/maven-public/org/test/test/maven-metadata.xml -- ensure that both versions are enlisted: 1.0, and 1.0-SNAPSHOT  - remove maven-snapshots from maven-public group  - reboot nexus  - query for metadata via group, in my case http://localhost:8081/repository/maven-public/org/test/test/maven-metadata.xml -- both versions still enlisted, but maven-snapshots is _not member of maven-public anymore_.    This is applicable to proxy caches too, and is in relation how CacheController works today, cache token is not persisted but starts off with {{null}} (no token validation applied).     This means, that if cached item is untouched between invalidation and reboot, it will be not invalidated. Basically, cache invalidation as today is in effect only during lifespan of the instance, and as soon it gets rebooted, the invalidation is forgotten. Still, you may have entries in cache that were left untouched (nothing requested them), and those entries will not be invalidated.      ",Bug,Major,Open,"2015-12-07 14:05:22","2015-12-07 14:05:22",3
"Sonatype Nexus","NFC Duration of -1 cripples repository","1) Go to NX3, create or edit a proxy  2) Set the 'Not Found Cache TTL' to -1  3) Click Save    Notice that the log fills up with continually repeating exceptions, and the repo appears to be in an unusable state:    https://gist.githubusercontent.com/mrprescott/efd54cb2863acca1f358/raw/1566907249d4c8cfed747ecf846aa408b2d5f970/nfc_ttl_-1.txt",Bug,Major,Closed,"2015-12-04 21:23:08","2015-12-04 21:23:08",0.5
"Sonatype Nexus","NuGet proxy repository responds with 502 status instead of 404 for missing content","Noticed this when I typed in the wrong version populating content into a nuget repo for testing. The code explicitly throws an IOException when remote content isn't found. I would (perhaps naively) expect that this would just result in a 404. Truncated exception from log shown below:       This was triggered with a request against the api for a version that does not exist: http://localhost:8081/repository/nuget.org-proxy/jQuery/7.1.4",Bug,Major,Closed,"2015-12-03 18:37:58","2015-12-03 18:37:58",0.5
"Sonatype Nexus","make capability validation message for URL type fields consistent and less confusing","Base URL capability has a validation message for the URL field must be a valid URL - rest of the site has 'This field should be a URL in the format http://www.example.com'.  I looked to make it consistent but couldn't find it in github so I am ticketing instead.  I made this a bug rather than an improvement because I think the level of confusion is potentially high if you enter www.example.com and it asks for a valid URL.  I did not check older NX3 or NX2 at this time.",Improvement,Trivial,Closed,"2015-12-02 23:05:00","2015-12-02 23:05:00",0.5
"Sonatype Nexus","NPM search does not find components with dash in name","When using the preconfigured npm search with e.g. coffee-script no results are returned even if coffee-script is available locally.    In Maven search commons-io on the other hand works.",Bug,Major,Closed,"2015-11-26 00:24:40","2015-11-26 00:24:40",2
"Sonatype Nexus","Last accessed not updating consistently","[~<USER> noticed that raw hosted last accessed in the UI did not appear to be updating.  He asked me to check.  I noticed similar behavior but I did notice it updating sometimes.  Mostly it seems to be updating once and then stop.  I however noticed similar behavior with a maven pom so am not convinced it's specific to raw.  In addition, what is displayed in the UI seems to match what is shown in the DB.    Rather than delve further, on discussion with <USER> he believes it's worth filing and have someone investigate while tracing through the code.  If I can provide further information/support please let me know.  I did not back check older NX3 (or NX2) at this time.  Debug was off during my testing.",Bug,Minor,Closed,"2015-11-25 19:17:08","2015-11-25 19:17:08",0.5
"Sonatype Nexus","Unable to install npm package due to external reference in package.json","Unable to install npm package engine.io-client 1.5.4 due to external reference to https://github.com/rase-/node-XMLHttpRequest/archive/a6b6f2.tar.gz in the Package.json. This is an issue where external access is not allowed.    This is a known design issue with the npm client and package specification by the npmjs.org authors as explained in our knowledge base article below, with a workaround given:  [https://support.sonatype.com/hc/en-us/articles/213465048-Why-does-npm-client-need-access-to-URLs-other-than-my-private-registry-].    For this example there is no workaround even when you amend the package and upload to a hosted repo, as the group Package.json merges the dependences. Not sure if there is possibility to use routing rules when merging dependences or some other solution.    Dependencies in the Package.json of engine.io-client in the hosted repo   dependencies: {   has-cors: 1.1.0,   xmlhttprequest-ssl: 1.5.1,   component-emitter: 1.1.2,   indexof: 0.0.1,   engine.io-parser: 1.2.1,   debug: 2.1.3,   parsejson: 0.0.1,   parseqs: 0.0.2,   component-inherit: 0.0.3   }    Dependencies in the Package.json of engine.io-client in the proxy repo   dependencies: {   component-emitter: 1.1.2,   component-inherit: 0.0.3,   debug: 1.0.4,   engine.io-parser: 1.2.2,   has-cors: 1.0.3,   indexof: 0.0.1,   parsejson: 0.0.1,   parseqs: 0.0.2,   parseuri: 0.0.4,   ws: 0.8.0,   xmlhttprequest: https://github.com/rase-/node-XMLHttpRequest/archive/a6b6f2.tar.gz   }    Dependencies in the Package.json of engine.io-client in the group repo   dependencies: {   component-emitter: 1.1.2,   component-inherit: 0.0.3,   debug: 2.1.3,   engine.io-parser: 1.2.1,   has-cors: 1.1.0,   indexof: 0.0.1,   parsejson: 0.0.1,   parseqs: 0.0.2,   parseuri: 0.0.4,   ws: 0.8.0,   xmlhttprequest: https://github.com/rase-/node-XMLHttpRequest/archive/a6b6f2.tar.gz,   xmlhttprequest-ssl: 1.5.1   }",Bug,Major,Open,"2015-11-24 16:16:28","2015-11-24 16:16:28",5
"Sonatype Nexus","Restore Task's notification email help text","While testing scheduled tasks and email server, I configured a notification email against a scheduled task and on run did not see it send.  After reading, I found that this notification email only sends when a scheduled task fails.  To me this was not intuitive.  NX2 has helper text as follows The email address where a mail will be sent in case that task execution will fail.  I am not sure why this was not moved over (would have saved me time/confusion) so making ticket to do so.    I did verify the mail does send when the task fails.",Bug,Trivial,Closed,"2015-11-24 15:42:27","2015-11-24 15:42:27",0.5
"Sonatype Nexus","Hourly scheduled tasks can not run when UI next reports","While testing, I noticed an hourly scheduled task not running (see attached).  On follow up test I was able to get it to run.    I am able to reproduce this intermittancy consistantly by making the start time for the scheduled task in the past. For example, the one from the screenshot, I set to 1:30 (AM) before remembering that this was military (24-hour clock) time. Nexus is smart and updates next run to the next hour, however, it seems the task never fires. If you have the start time in the future it seems to work fine.    [~<USER> noticed similar in his NEXUS-7797 revamp I believe.  He wrote:  {quote}  <snip>  Start time: 00:45    logs show:      2015-11-02 15:31:35,024-0800 INFO  [qtp1974005016-47] admin org.sonatype.nexus.quartz.internal.orient.OrientJobStore - Store trigger: newTrigger=Trigger 'nexus.f81853fe-869e-4646-8a1a-4416bbabe031':  triggerClass: 'org.quartz.impl.triggers.SimpleTriggerImpl calendar: 'null' misfireInstruction: 0 nextFireTime: Mon Nov 02 00:45:00 PST 2015, replaceExisting=false    UI shows:   Next run Mon Nov 02 2015 15:45:00 GMT-0800 (PST)  </snip>  {quote}    I actually do not see this log message line, but I believe it's the same issue after his comment in NEXUS-7797 in response to my test notes.    I did not check older NX3 or NX2 at this time.  Debug was off during these tests.",Bug,Minor,Closed,"2015-11-23 21:40:38","2015-11-23 21:40:38",1
"Sonatype Nexus","Adjusting a schedule task updates last run and last result fields","I noticed that when you have a scheduled (non-manual) task, if you update the start time, on the tasks list the Last run shown is the time you saved the update not the last time the task was actually run.  Similarly the last result shows Cancelled even if you have never run the task before.    [~<USER> also noticed this on his work on NEXUS-7797.  I have not checked older NX3 or NX2 at this time.  Debug was off during this test.  Leaving minor since it could erase useful data.    NOTES:  - Could be because the API is too narrow to deal with this interaction  - Likely need to group some of these issues together so that we revisit the API if needed  - Quartz might not be keeping the date correctly?",Bug,Minor,Closed,"2015-11-23 20:46:57","2015-11-23 20:46:57",2
"Sonatype Nexus","Clicking away from a scheduled task prompts for discard despite no changes","If you have an existing non-manual scheduled task (iow a task with a start time set) if you click into it to see details then click away without making any adjustments you are prompted to discard changes or remain on the page.  If you remain then click the discard button the start time goes blank and you are able to traverse away without prompt (on weekly schedule, the day to run the tasks also clears).  Leaving minor since this is especially confusing since that field is required.  This does not affect manual tasks because they have no start time.    I did not check older NX3 or NX2 at this time however I do not believe it was related to the change (discovered while testing link) since it occurred in m6.  [~<USER> also noticed this while performing the change itself (and relayed in an email).  Debug was off during this test.",Bug,Minor,Closed,"2015-11-23 19:06:41","2015-11-23 19:06:41",0.5
"Sonatype Nexus","Blocking repository does nothing","Just performed the following events in a fresh build of Gnarly:  * Invalidated cache (now one button post-NEXUS-9182)  * Cleared local .m2 repository folder  * Marked default maven central proxy repository blocked  * Hit http://localhost:8081/repository/maven-central/abbot/abbot/0.13.0/abbot-0.13.0.pom  The pom was returned.    Unless I am really confused I believe block setting is not working.  I attempted the same test except instead of being blocked I disconnected from the internet and got back the (expected) 502 error.  I tried again but did not clear cache and was able to see the pom (so it was cached).  I attempted this in m6 and experienced the same behavior so do not believe it related to NEXUS-9182.    No errors in log, debug was off during these tests.  I did not check NX2 at this time.    If this turns out to be NOTABUG, I would like to recommend we reevaluate the help and documentation text to be a smidge more clear.",Bug,Major,Closed,"2015-11-20 21:32:34","2015-11-20 21:32:34",0.5
"Sonatype Nexus","valid npm package names not unescaped properly","Sadly, there is a package in the npm registry with a / in it's name.    Direct access of this works via npm, the slash is escaped:    https://registry.npmjs.org/@reactivex%2frxjs    Retrieving this package through a nexus proxy does not work, the slash is unescaped.    Inbound request to nexus:    {quote}  http://localhost:8081/nexus/content/repositories/npm-proxy/@reactivex%2frxjs  {quote}    Outbound request from nexus:        So the %2f is getting un-escaped back into a /.    This issue is reproducible in 2.11.4-01 and 3.0m6.",Bug,Major,Closed,"2015-11-19 14:11:55","2015-11-19 14:11:55",1
"Sonatype Nexus","Email validation in 3.0-m6","Looks like the email validation is being a bit too strict - my email address is <USER>uncharted.software, but when creating a user in 3.0-m6, the email is marked as invalid.",Bug,Minor,Closed,"2015-11-17 17:36:30","2015-11-17 17:36:30",0.5
"Sonatype Nexus","deadlock between mergeropo and staging promotion","A GET request comes into a group repository which triggers a yum metadata merge.  It can't proceed because it can't get a lock to schedule the task:    {quote}  qtp1444610073-5921 id=5921 state=WAITING      - waiting on <0x631ba521> (a java.util.concurrent.FutureTask$Sync)      - locked <0x631ba521> (a java.util.concurrent.FutureTask$Sync)      at sun.misc.Unsafe.park(Native Method)      at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:994)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1303)      at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:248)      at java.util.concurrent.FutureTask.get(FutureTask.java:111)      at org.sonatype.scheduling.DefaultScheduledTask.get(DefaultScheduledTask.java:260)      at org.sonatype.nexus.yum.internal.YumGroupImpl.getYumRepository(YumGroupImpl.java:91)      at org.sonatype.nexus.yum.internal.MergeMetadataRequestStrategy.onHandle(MergeMetadataRequestStrategy.java:90)      at org.sonatype.nexus.proxy.repository.AbstractRepository.checkRequestStrategies(AbstractRepository.java:1201)      at org.sonatype.nexus.proxy.repository.AbstractRepository.checkConditions(AbstractRepository.java:1193)      at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:590)      at org.sonatype.nexus.proxy.router.DefaultRepositoryRouter.retrieveItem(DefaultRepositoryRouter.java:155)      at org.sonatype.nexus.content.internal.ContentServlet.doGet(ContentServlet.java:376)      at org.sonatype.nexus.content.internal.ContentServlet.service(ContentServlet.java:342)      at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)      at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:288)      at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:278)      at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182)      at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:93)      at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85)      at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112)      at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)      at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120)      at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82)      at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89)      at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120)      at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82)      at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89)      at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61)      at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)      at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)      at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)      at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)      at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)      at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)      at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)      at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)      at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)      at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)      at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)      at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)      at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)      at org.sonatype.nexus.web.internal.SecurityFilter.executeChain(SecurityFilter.java:90)      at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)      at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)      at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)  {quote}    It can't get a lock to do this because another thread has the default configuration lock because it is promoting a staging repository.  This thread can't proceed because it is trying to acquire a lock held by the first thread:    {quote}  pxpool-1-thread-4 id=124 state=WAITING      - waiting on <0x13ccef4e> (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)      - locked <0x13ccef4e> (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)       owned by qtp1444610073-5921 id=5921      at sun.misc.Unsafe.park(Native Method)      at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:867)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1197)      at java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.lock(ReentrantReadWriteLock.java:945)      at org.sonatype.nexus.yum.internal.YumGroupImpl.markDirty(YumGroupImpl.java:109)      at org.sonatype.nexus.yum.internal.EventsRouter.on(EventsRouter.java:96)      at sun.reflect.GeneratedMethodAccessor209.invoke(Unknown Source)      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)      at java.lang.reflect.Method.invoke(Method.java:606)      at org.sonatype.sisu.goodies.eventbus.internal.guava.EventHandler.handleEvent(EventHandler.java:80)      at org.sonatype.sisu.goodies.eventbus.internal.guava.EventBus.dispatch(EventBus.java:329)      at org.sonatype.sisu.goodies.eventbus.internal.DefaultGuavaEventBus.dispatch(DefaultGuavaEventBus.java:34)      at org.sonatype.sisu.goodies.eventbus.internal.ReentrantGuavaEventBus.dispatchQueuedEvents(ReentrantGuavaEventBus.java:57)      at org.sonatype.sisu.goodies.eventbus.internal.guava.EventBus.post(EventBus.java:281)      at org.sonatype.sisu.goodies.eventbus.internal.DefaultEventBus.post(DefaultEventBus.java:78)      at org.sonatype.nexus.proxy.repository.AbstractGroupRepository.prepareForSave(AbstractGroupRepository.java:125)      at org.sonatype.nexus.configuration.AbstractConfigurable.onEvent(AbstractConfigurable.java:105)      at sun.reflect.GeneratedMethodAccessor51.invoke(Unknown Source)      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)      at java.lang.reflect.Method.invoke(Method.java:606)      at org.sonatype.sisu.goodies.eventbus.internal.guava.EventHandler.handleEvent(EventHandler.java:80)      at org.sonatype.sisu.goodies.eventbus.internal.guava.SynchronizedEventHandler.handleEvent(SynchronizedEventHandler.java:49)      at org.sonatype.sisu.goodies.eventbus.internal.guava.EventBus.dispatch(EventBus.java:329)      at org.sonatype.sisu.goodies.eventbus.internal.DefaultGuavaEventBus.dispatch(DefaultGuavaEventBus.java:34)      at org.sonatype.sisu.goodies.eventbus.internal.ReentrantGuavaEventBus.dispatchQueuedEvents(ReentrantGuavaEventBus.java:57)      at org.sonatype.sisu.goodies.eventbus.internal.guava.EventBus.post(EventBus.java:281)      at org.sonatype.sisu.goodies.eventbus.internal.DefaultEventBus.post(DefaultEventBus.java:78)      at org.sonatype.nexus.configuration.application.DefaultNexusConfiguration.applyConfiguration(DefaultNexusConfiguration.java:339)        - locked org.sonatype.nexus.configuration.application.DefaultNexusConfiguration@1a90baa2      at org.sonatype.nexus.configuration.application.DefaultNexusConfiguration.saveConfiguration(DefaultNexusConfiguration.java:363)        - locked org.sonatype.nexus.configuration.application.DefaultNexusConfiguration@1a90baa2      at com.sonatype.nexus.staging.internal.DefaultStagingRepositoryManager.setRepositoryGroupStaged(DefaultStagingRepositoryManager.java:265)      at com.sonatype.nexus.staging.internal.task.RepositoryPromoteTask$PromoteOperation.perform(RepositoryPromoteTask.java:200)      at com.sonatype.nexus.staging.internal.task.OperationTaskSupport.executeOperations(OperationTaskSupport.java:434)      at com.sonatype.nexus.staging.internal.task.OperationTaskSupport.doCall(OperationTaskSupport.java:415)      at com.sonatype.nexus.staging.internal.task.RepositoryPromoteTask.doCall(RepositoryPromoteTask.java:365)      at com.sonatype.nexus.staging.internal.task.RepositoryPromoteTask.doCall(RepositoryPromoteTask.java:1)      at com.sonatype.nexus.staging.internal.task.TaskSupport.call(TaskSupport.java:37)      at com.sonatype.nexus.staging.internal.task.StagingTaskSupport.call(StagingTaskSupport.java:133)      at com.sonatype.nexus.staging.internal.task.StagingBackgroundTask.execute(StagingBackgroundTask.java:67)      at com.sonatype.nexus.staging.internal.task.NexusTaskSupport.doRun(NexusTaskSupport.java:52)      at com.sonatype.nexus.staging.internal.task.NexusTaskSupport.doRun(NexusTaskSupport.java:1)      at org.sonatype.nexus.scheduling.AbstractNexusTask.call(AbstractNexusTask.java:163)      at org.sonatype.scheduling.DefaultScheduledTask.call(DefaultScheduledTask.java:418)      at org.sonatype.nexus.threads.MDCAwareCallable.call(MDCAwareCallable.java:44)      at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)      at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)      at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)      at java.util.concurrent.FutureTask.run(FutureTask.java:166)      at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)      at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)      at java.lang.Thread.run(Thread.java:724)  {quote}",Bug,Major,Closed,"2015-11-13 14:35:49","2015-11-13 14:35:49",0.5
"Sonatype Nexus","unable to start nexus when run_as_user is set","There is a serious problem starting the m6 release on ubuntu server without X11 installed and the documentation is not up to date.    After unpacking nexus-installer-3.0.0-m6-unix-archive.tar.gz on my server I changed run_as_user in nexus.rc. I tried to start it with     *./nexus-3.0.0-b2015110601/bin/nexus run*  su: invalid option -- 'D'  Usage: su [options] [LOGIN]    Options:    -c, --command COMMAND         pass COMMAND to the invoked shell    -h, --help                    display this help message and exit    -, -l, --login                make the shell a login shell    -m, -p,    --preserve-environment        do not reset environment variables, and                                  keep the same shell    -s, --shell SHELL             use SHELL instead of the default in passwd    After debuging the scipt I tried to start the Nexus server outside the script with     nexus@node01:*/opt/nexus$ /usr/lib/jvm/java-8-oracle/jre/bin/java -server -Dinstall4j.jvmDir=/usr/lib/jvm/java-8-oracle/jre -Dexe4j.moduleName=/opt/nexus/nexus-3.0.0-b2015110601/bin/nexus -Dinstall4j.launcherId=245 -Dinstall4j.swt=false -Di4jv=0 -Di4jv=0 -Di4jv=0 -Di4jv=0 -Di4jv=0 -Xms256M -Xmx768M -XX:+UnlockDiagnosticVMOptions -XX:+UnsyncloadClass -Djava.net.preferIPv4Stack=true -Dkaraf.home=. -Dkaraf.base=. -Dkaraf.etc=etc -Djava.util.logging.config.file=etc/java.util.logging.properties -Dkaraf.data=data -Dkaraf.instances=data/instances -Djava.io.tmpdir=data/tmp -Dkaraf.startLocalConsole=false -Di4j.vpt=true -classpath /opt/nexus/nexus-3.0.0-b2015110601/.install4j/i4jruntime.jar:/opt/nexus/nexus-3.0.0-b2015110601/lib/karaf.jar:/opt/nexus/nexus-3.0.0-b2015110601/lib/karaf-org.osgi.core.jar:/opt/nexus/nexus-3.0.0-b2015110601/lib/karaf-jmx-boot.jar:/opt/nexus/nexus-3.0.0-b2015110601/lib/karaf-jaas-boot.jar:/opt/nexus/nexus-3.0.0-b2015110601/lib/karaf-nexus-branding.jar com.install4j.runtime.launcher.UnixLauncher run 9d17dc87   org.apache.karaf.main.Main*  java.util.NoSuchElementException   at java.util.LinkedList.removeFirst(LinkedList.java:270)   at com.exe4j.runtime.util.ArgumentStack.popString(ArgumentStack.java:14)   at com.install4j.runtime.launcher.UnixLauncher.main(UnixLauncher.java:37)  java.util.NoSuchElementException  Exception in thread main java.awt.HeadlessException:   No X11 DISPLAY variable was set, but this program performed an operation which requires it.   at java.awt.GraphicsEnvironment.checkHeadless(GraphicsEnvironment.java:204)   at java.awt.Button.<init>(Button.java:152)   at com.exe4j.runtime.util.MessageBox.addChoice(MessageBox.java:151)   at com.exe4j.runtime.util.MessageBox.addChoice(MessageBox.java:163)   at com.install4j.runtime.launcher.ErrorHandler.displayGuiErrorMessage(ErrorHandler.java:14)   at com.install4j.runtime.launcher.ErrorHandler.reportError(ErrorHandler.java:22)   at com.install4j.runtime.launcher.UnixLauncher.main(UnixLauncher.java:71)  ",Bug,Major,Closed,"2015-11-13 10:15:08","2015-11-13 10:15:08",1
"Sonatype Nexus","npm repository URLs error","When you attempt to browse the URLs displayed for npm repositories in the Manage Repositories list (via Repository->Repositories) you get error 400s for hosted and group and error 404 for proxy.  We modified other non-browsable repositories to link to the component/asset browse section and browsable repositories to work.  npm seems to have neither.    This occurs in m6 where npm for NX3 was introduced.  I did not check NX2 at this time.",Bug,Trivial,Closed,"2015-11-11 18:39:42","2015-11-11 18:39:42",0.5
"Sonatype Nexus","v1 docker proxy assets 404 on download click","While testing the docker branch, I noticed that assets from the docker proxy labelled v1 were 404ing on download.  v2 assets were ok.  [~<USER> noted that the URL contained an extra /v1/images.  Removing it caused the download to work.  I am leaving major because the workaround is not intuitive.  See vid.  This is regression from m5 where this works.    You can (currently) get v1 assets by pulling hello-world or ubuntu.  You can (currently) get v2 assets by pulling baselibrary/ubuntu.    Docker is not in NX2 so this does that affect that.",Bug,Major,Closed,"2015-10-30 23:01:59","2015-10-30 23:01:59",0.5
"Sonatype Nexus","repodata/repomd.xml isn't recognized as metadata in YUM proxy repository","Currently the _repodata/repomd.xml_ path is handled as regular item in proxied repository.  and its age is checked by _getItemMaxAge()_ instead of _getMetadataMaxAge()_. So the max age of _repodata/repomd.xml_ and the max age of RPM files are same  that can be configured as Item Max Age in the configuration. I think that checking the age of _repodata/repomd.xml_ with _getMetadataMaxAge()_ is a right thing to do",Bug,Major,Closed,"2015-10-30 02:39:17","2015-10-30 02:39:17",0.5
"Sonatype Nexus","Browse asset sort is case sensitive for some repo types","I just noticed that Browse Assets sort by name sorted in a case sensitive way.  See attached.  Specifically, caps showed after numbers but before lower case.    Components is not affected.  I dug around and found NEXUS-8844 which seems to have fixed Components (before there was a differnentiation).  I believe this should be the same for assets.  I am marking trivial because the assets are all there and some may disagree this is how it should be anyway (but it is currently inconsistent which I believe is at least confusing).    Debug was ON during this test.  I did not check older versions of NX3.  I do not believe this issue affects NX2 (but NEXUS-8844 might have).",Bug,Trivial,Closed,"2015-10-29 20:17:47","2015-10-29 20:17:47",1
"Sonatype Nexus","Impossible to map LDAP groups if remote server's query limit is reached","Active Directory will only return a certain number of results for an LDAP query.  This means that the external role mapping UI will not show all available groups in the drop list box.    In Nexus 2.x there are workarounds to this problem as documented here:    [Nexus does not list all avaliable LDAP groups in external role mapping dialog|https://support.sonatype.com/entries/30579397]    In Nexus 3 the external role mapping is done via a non-editable drop-list control.  So there is no workaround, if the LDAP group you need isn't in the list it cannot be mapped.    ",Bug,Major,Closed,"2015-10-29 15:15:13","2015-10-29 15:15:13",1
"Sonatype Nexus","Installer does not create desktop icon in CentOS KDE","While testing the installer (nexus-3.0.0-SNAPSHOT-unix.sh), I ran a basic setup and at the end Completing the Sonatype Nexus Setup Wizard, I kept 'Create Desktop Icons' checked.  On CentOS KDE the icon did not create.  I tried several permutations of installs and no dice.  This blocked testing of several issues I was trying to test in Linux.  On CentOS GNOME it did create so nothing is currently blocked however, I am filing at least because I believe it's worth documenting something not working when it is checked.  Marking minor however I guess it's arguable if you're using CentOS KDE=)    --    Recommendation to send to install4j.  Review with Joe to see if increasing the logging levels gives better information.",Bug,Minor,Closed,"2015-10-20 23:09:39","2015-10-20 22:09:39",0.5
"Sonatype Nexus","bin/nexus-run helper app does not function if installer had unselected service start","While testing the installer, I ran a basic setup but unchecked 'Start service' from the advanced options (Service tab).  At the end Completing the Sonatype Nexus Setup Wizard, I kept 'Create Desktop Icons' checked.  When I double clicked the icon, I got the attached errors (one on screen, the other in console log).  I first noticed this on Mac running the .sh file, then subsequently in Linux CentOS GNOME.  I was unable to test this in CentOS KDE due to an error with the icon not creating.    These errors occur regardless of if Nexus is started or not.  Running with start service checked seems to work.",Bug,Major,Closed,"2015-10-20 22:53:40","2015-10-20 21:53:40",0.5
"Sonatype Nexus","Logger related(?) error at top of console after reset","I noticed this line at the top of my nexus.log when I restarted my nexus:  'ERROR in ch.qos.logback.core.joran.action.PropertyAction - In <property> element, either the file attribute alone, or the resource element alone, or both the name and value attributes must be set.'    Earlier I had rebuilt and written up NEXUS-9350 and not done anything else noteworthy.  I was subsequently able to repro this by building a new nexus, starting it, resetting logs to default level and restarting nexus.  As far as I could tell this did not occur on the initial post-install start.    I did not check older NX3 or NX2 at this time.  Debug was off during this test.",Bug,Minor,Closed,"2015-10-20 22:20:18","2015-10-20 21:20:18",0.5
"Sonatype Nexus","logback-overrides not respected always","[~<USER> noticed that he set the org.apache.http.wire logger to TRACE, restarted nexus, and the logger value of org.apache.http.wire was reset to ERROR.  I was able to repro this but it does not happen for all loggers.  I checked logback-overrides.xml and the values are defined there but for some reason it is not picked up.  We discussed whether this was a feature or not and also discussed if it has to do with customized loggers (and potentially the change from NEXUS-9327).  When testing NEXUS-9327 I did not include restarting in the test=\  Despite that discussion I did not check older NX3 at this time, nor did I check NX2.  Debug was off during this test.",Bug,Major,Closed,"2015-10-20 18:47:58","2015-10-20 17:47:58",1
"Sonatype Nexus","Docker and context path","It is not clear if our Docker support works with a context path configured in org.sonatype.nexus.cfg    The following steps need to be taken    - test if it works or not  - decide if we want it to work or not (if thats even possible)  - update docker chapter in documentation accordingly  - update section about configuring context path accordingly  - answer http://stackoverflow.com/questions/33021350/trouble-connecting-to-docker-registry-stored-on-nexus-3-preview-on-azure-vm    ",Bug,Major,Closed,"2015-10-14 17:42:58","2015-10-14 16:42:58",0.5
"Sonatype Nexus","Docker search can show too much from Nexus hosted/groups","I just ran a search docker search 192.168.1.4:18075/jprjr/docker-tinyfs with the following results:      It seems to show the proxied docker item as well as each docker hosted image I have in my hosted repo.  The same occurs for just searching the hosted repo (without the proxy result).  Narrowing the search seems to give the correct results, making me wonder if searching the broader item is somehow including / as something to be searched (though just for hosted as there are any number of proxied items with / out there).    This was untestable in NX3 because of NEXUS-9159, however, spoke with [~<USER> and decided to give it a distinct ticket rather than reopen that one soas not to cloudy the waters.  Docker does not exist in NX2 so cannot be checked there.  I am leaving this major as I can imagine this will render results less and less useful the more things you have in the hosted repo.  You also cannot perform this exact search in the NX3 search UI because of NEXUS-8801 so the workaround is partial search.    NOTE:  - Could be tokenizing the / in the image name",Bug,Major,Closed,"2015-10-09 21:07:36","2015-10-09 20:07:36",0.5
"Sonatype Nexus","System Information does not wrap (well) but cannot scroll","Just noticed that in my system information, some of the fields are longer, however do not wrap after one page width (at least not at my maximum laptop size [1440]).  There is however no scroll available.  Workarounds are to copy the line and paste it into an external document or to click download.  Both of those are an additional step to someone who might just want to read this info.    Test done with debug off.  I did not check older NX3 or NX2 at this time.",Bug,Trivial,Closed,"2015-10-09 15:54:51","2015-10-09 14:54:51",0.5
"Sonatype Nexus","NPM group json shows last uploaded not ordered","While reviewing group ordering, I uploaded the same npm project into two different hosted directories and had those hosted directories in a group.  I noticed that the json information in the UI for the project via the group showed the second project that I had uploaded (see 12.33 screen).  However, because of the ordering I expected it to show the first json.  The metadata did show the proper ordering so that ticket passed (see 12.34 screen).  I spoke with [~<USER> and he said to file and he would review/debug.  He noted that the json is(may be) going away with https://github.com/sonatype/nexus-internal/pull/230 which may make this difficult to repro and/or test.    Test done with debug off.  npm is new to Fabtastic and I did not check any other repo types in NX3.  I did not check NX2 at all.",Bug,Minor,Closed,"2015-10-08 21:05:41","2015-10-08 20:05:41",1
"Sonatype Nexus","temporary nx-tmp-content-locator files may not be reliably cleaned up","Two reports that files in the nexus tmp directory do not get cleaned up, which ends with Nexus consuming large amounts of temporary directory storage.     These files are all named with the prefix *nx-tmp-content-locator*. The dates of these files are commonly very old.    Example:    nx-tmp-content-locator1014323857838974667tmp   nx-tmp-content-locator1032224857888386839tmp   nx-tmp-content-locator1043108959261760507tmp   nx-tmp-content-locator1044225560407544424tmp   nx-tmp-content-locator1050863577721459092tmp     We should figure out the cause and clean these up more reliably.    NOTE:  - This may be due to the file stream not being closed properly  - Maybe we are creating these files and not consuming, or a client/network break   - More than likely this is in P2 code    Technical Direction:  - Maybe look at the thread and see if it can be cleaned up?  ",Bug,Critical,Closed,"2015-10-08 14:05:56","2015-10-08 13:05:56",2
"Sonatype Nexus","Administration cog icon may not be initially visible after successful sign in","# Let Nexus UI time out, on the Repository list screen   # Sign in   # Notice that there's no configuration cog   # Sign out   # Sign in again ( or refresh browser tab/window)  # Notice there's a cog now.     Happened on commit dad4714    NOTE:    - Let's look into this, the proposed solution is to remove it but we want to make sure this doesn't have ripple effects",Bug,Minor,Closed,"2015-10-06 18:19:39","2015-10-06 17:19:39",1
"Sonatype Nexus","add a task to purge dangling docker images","Typically we build images tagged as latest after SCM change automatically in CI and we push them to registry. It is basically the same as with SNAPSHOT deployed by maven. As result there are many dangling images that in our case take significant amount of space.    Usually when you re-build image, meaning you tag newly build image with an already existing tag, you will see dangling image in docker images output. And you would delete it with:  *_docker rmi $(docker images -q -f dangling=true)_*    Basically what we need is something similar to scheduled task named Remove Snapshots From Repository for removing old SNAPSHOTs deployed by maven.    For example Docker registry V2, provides maintenance function called upload purging for this purpose. See [https://docs.docker.com/registry/configuration/]     Acceptance Criteria:    * A user with sufficient privileges will be able to schedule a task to delete orphaned Docker layers   ** This should be able to run on Hosted and Proxy     NOTE:    * To figure out which layers are orphaned, you need to look at existing manifests to see essentially which layers are not referenced   * More info on how Docker is handling deletes: [https://github.com/docker/distribution/blob/master/ROADMAP.md#deletes]     TECHNICAL NOTE:    * Do not purge any layer newer than when the task started running",Improvement,Major,Closed,"2015-10-03 16:52:20","2015-10-03 15:52:20",5
"Sonatype Nexus","Specific actions in search can cause list not to load","When testing npm, I just noticed a very similar thing to NEXUS-9109 (pre-fix).  I had a bunch of npm components and was doing a non-custom keyword search. Searching for test shows over a page worth of component results. I searched for testproject1 and there was one result (as expected, I had created it). Limiting to testp shows no results (because of lack of wildcard/* - aka NEXUS-8884). However, then limiting back to test seemed to show no results. After a couple times reproing this, I noticed a scroll on the right side.  This occurs despite the fix for NEXUS-9109.  See attached vids.    Setup/config steps:  //setup of data  1) Setup your npm instance as https://docs.sonatype.com/display/Nexus/NPM+Testing (.npmrc edits and nexus repos). WARN: Due to not committed fix turn strict content validation off for Proxy or step 4 will fail to build.  2) Download user package from https://issues.sonatype.org/browse/NEXUS-8043 and unzip  3) From that directory, run Kelly's script (https://gist.github.com/kellyrob99/8e86227da5c8fd7d7a30) to get everything into Nexus Hosted. NOTE: This takes a while. Some will error but most should go through = +  {package}   [no errors or subsequent/following lines]. Can recheck browse assets/components for npmhosted if you're unsure.  4) Following https://docs.sonatype.com/display/Nexus/NPM+Testing, test hosted and proxy. Note repository differences in configuration of package local. This further populates each repo; I did 2 hosted tests. Let me know if you need more details here. Trying not to retype what's already documented  //performing bug (as vid)  5) Go to Search  6) Type in test  7) After results, adjust to testproject1 (or whatever you named your hosted package)  8) After result, adjust to testp. Should see no results because of lack of wildcard symbol.  9) After a few seconds, adjust to test. No results show. Scroll shows (on my machine/setup). Scrolling reveals results.",Bug,Minor,Closed,"2015-10-01 19:01:42","2015-10-01 18:01:42",3
"Sonatype Nexus","> placement in wrong place","While demoing Tuesday, the team noticed that on Search the > sign that usually is at the end of the row on search to indicate that you can click and see more was not in the last column but in the second to last column.  This does not occur on normal search and in fact seems to only occur when you have a component twice in different repositories like attached screen (dated 10/1).  This was demoed in NPM and that is how I reproduced it - creating two npm hosted repos and publishing the same package to both and then searching on the name.    In addition, I tangentially noticed similar behavior on the Capabilities screen right out of the box.  The differences seem to be that it does not take any special circumstances to get it to break and the > is in the second column instead of the last.  See attached screen (dated 9/30).    I was waffling whether this should be two issues or one.  I conferred with [~<USER> who said start with one.  <USER>suspects as I do, that the Capabilities issue (at least) is recent regression.  I have not checked older NX3 or NX2 at this time.  Test performed with debug off.  Nothing in the log or JS console.",Bug,Trivial,Closed,"2015-10-01 18:52:40","2015-10-01 17:52:40",1
"Sonatype Nexus","ldap Check Authentication IOException bind failures may not be logged a default log levels","Configure an LDAP server in Nexus OSS using valid bind credentials and an ldaps connection. Make sure Nexus does not trust the ldaps certificate provided by the remote.    Use the Check Authentication button in Nexus OSS LDAP configuration to try and verify the connection works. When the SSL certificate of the remote is not trusted ( PKIX path building fails ), then the only message in the UI states bind failed with no mention of an SSL certificate issue.    At INFO level logging, the nexus.log does _not contain anything_ about the bind failure for the check, let alone anything to do with PKIX path building problems.    Only when the ROOT logger is set to DEBUG, do we see the real cause of the problem, at the bottom of a large stack trace.    Expected: End user should get informative message from the UI, or at least in the Nexus log at INFO level, referencing an SSL certificate trust issue so they know the real cause of the error instead of guessing it is a credential issue. The user is checking authentication - they are explicitly trying to verify and debug if the connection is working. If they get no actionable help about why it isn't working, what is the point? If the message references a bind issue, their first reaction is there is a problem with the credentials.    A similar problem may be present with logging when an LDAP bind fails due to Caused by: java.net.NoRouteToHostException: No route to host.    Should not have to enable DEBUG logging for such common IOException root cause problems.",Bug,Major,Open,"2015-09-29 17:05:14","2015-09-29 16:05:14",2
"Sonatype Nexus","Can't create external LDAP Role mapping","I have a LDAP instance and I am able to verify user mapping with it.    Under Security -> Roles  I push Create role -> External role mapping -> LDAP I get     Uncaught TypeError: a.setItemName is not a function (https://mydockerhub.example.com/static/rapture/nexus-coreui-plugin-prod.js?_v=3.0.0-b2015091801:1)",Bug,Major,Closed,"2015-09-28 14:30:27","2015-09-28 13:30:27",0.5
"Sonatype Nexus","Document UI:Settings capability","Its a bit of a mixture of things... but document what they are and link to sections that explain related use cases.    Acceptance   * Find out what each of these settings does   * Document them in help.sonatype.com (e.g. as a page under Configuration?)   * Revise the help text in the application to clarify what the two 'user status interval' parameters mean.",Story,Major,"Ready for Development","2015-09-23 22:30:27","2015-09-23 21:30:27",2
"Sonatype Nexus","Remove doc references to sonatype-work folder","It is now internal in the Nexus folder data .. so all text about separation and such should also be updated",Task,Major,Closed,"2015-09-23 21:37:22","2015-09-23 20:37:22",1
"Sonatype Nexus","Strict Content Validation prevents npm install","Running https://docs.sonatype.com/display/Nexus/NPM+Testing proxy test against NX3, I found that I was getting the below errors (500s) when installing insight-brain.  After reading them, I tried again with strict content validation off (proxy) and everything worked.  This is reproducable by following the guide steps after clearing npm cache (if you don't clear npm cache, ala npm cache clean,  after successful install, it continues to be successful).  One deviance from the guide is I have not checked groups yet, so my configuration (.npmrc) was to proxy.  I do not think this matters but if I remember and this is not addressed, I will check once I get to groups.    I have not seen this elsewhere in NX3 and npm is new to Fabtastic so I did no NX3 back checking.  This does not affect NX2 (testguide passes with file checking on).    NOTE: This happens with 2 different files.  Both retry 3 times before giving up and the install fails.    {quote}  npm http 500 http://localhost:8081/repository/npmproxy/marked  npm ERR! registry error parsing json  npm info retry will retry, error on last attempt: SyntaxError: Unexpected token <  npm info retry <html>  npm info retry <head>  npm info retry   <title>500 - Sonatype Nexus</title>  npm info retry   <meta http-equiv=Content-Type content=text/html; charset=UTF-8/>  npm info retry   npm info retry   <link rel=icon type=image/png href=http://localhost:8081/favicon.png$?3.0.0-SNAPSHOT>  npm info retry   <!--[if IE]>  npm info retry   <link rel=SHORTCUT ICON href=http://localhost:8081/favicon.ico?3.0.0-SNAPSHOT/>  npm info retry   <![endif]-->  npm info retry   npm info retry   <link rel=stylesheet type=text/css href=http://localhost:8081/static/css/nexus-content.css?3.0.0-SNAPSHOT/>  npm info retry </head>  npm info retry <body>  npm info retry <div class=nexus-header>  npm info retry   <a href=http://localhost:8081>  npm info retry     <img src=http://localhost:8081/static/images/nexus.png?3.0.0-SNAPSHOT/>  npm info retry     <span class=name>Sonatype Nexus</span>  npm info retry   </a>  npm info retry   <span class=version>OSS 3.0.0-SNAPSHOT</span>  npm info retry </div>  npm info retry   npm info retry <div class=nexus-body>  npm info retry   <div class=content-header>  npm info retry     <img src=http://localhost:8081/static/rapture/resources/icons/x32/exclamation.png?3.0.0-SNAPSHOT/>  npm info retry     <span class=title>Error 500</span>  npm info retry     <span class=description>Internal Server Error</span>  npm info retry   </div>  npm info retry   <div class=content-body>  npm info retry     <div class=content-section>  npm info retry       javax.servlet.ServletException: org.sonatype.nexus.repository.InvalidContentException: Detected content type [text/html], but expected [application/json]: marked.json  npm info retry     </div>  npm info retry       </div>  npm info retry </div>  npm info retry </body>  npm info retry </html>  npm info retry   npm info retry   {quote}    & (2 occurances)    {quote}  npm http 500 http://localhost:8081/repository/npmproxy/jade  npm ERR! registry error parsing json  npm info retry will retry, error on last attempt: SyntaxError: Unexpected token <  npm info retry <html>  npm info retry <head>  npm info retry   <title>500 - Sonatype Nexus</title>  npm info retry   <meta http-equiv=Content-Type content=text/html; charset=UTF-8/>  npm info retry   npm info retry   <link rel=icon type=image/png href=http://localhost:8081/favicon.png$?3.0.0-SNAPSHOT>  npm info retry   <!--[if IE]>  npm info retry   <link rel=SHORTCUT ICON href=http://localhost:8081/favicon.ico?3.0.0-SNAPSHOT/>  npm info retry   <![endif]-->  npm info retry   npm info retry   <link rel=stylesheet type=text/css href=http://localhost:8081/static/css/nexus-content.css?3.0.0-SNAPSHOT/>  npm info retry </head>  npm info retry <body>  npm info retry <div class=nexus-header>  npm info retry   <a href=http://localhost:8081>  npm info retry     <img src=http://localhost:8081/static/images/nexus.png?3.0.0-SNAPSHOT/>  npm info retry     <span class=name>Sonatype Nexus</span>  npm info retry   </a>  npm info retry   <span class=version>OSS 3.0.0-SNAPSHOT</span>  npm info retry </div>  npm info retry   npm info retry <div class=nexus-body>  npm info retry   <div class=content-header>  npm info retry     <img src=http://localhost:8081/static/rapture/resources/icons/x32/exclamation.png?3.0.0-SNAPSHOT/>  npm info retry     <span class=title>Error 500</span>  npm info retry     <span class=description>Internal Server Error</span>  npm info retry   </div>  npm info retry   <div class=content-body>  npm info retry     <div class=content-section>  npm info retry       javax.servlet.ServletException: org.sonatype.nexus.repository.InvalidContentException: Detected content type [text/html], but expected [application/json]: jade.json  npm info retry     </div>  npm info retry       </div>  npm info retry </div>  npm info retry </body>  npm info retry </html>  npm info retry   npm info retry   {quote}    Errors from nexus.log  {quote}  2015-09-23 11:38:39,499-0400 WARN  [qtp1623599577-217] admin org.sonatype.nexus.repository.httpbridge.internal.ViewServlet - Service failure  org.sonatype.nexus.repository.InvalidContentException: Detected content type [text/html], but expected [application/json]: marked.json   at org.sonatype.nexus.repository.storage.DefaultContentValidator.determineContentType(DefaultContentValidator.java:95) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmContentValidator.determineContentType(NpmContentValidator.java:60) [na:na]   at org.sonatype.nexus.repository.storage.StorageTxImpl.determineContentType(StorageTxImpl.java:573) [na:na]   at org.sonatype.nexus.repository.storage.StorageTxImpl.createBlob(StorageTxImpl.java:478) [na:na]   at sun.reflect.GeneratedMethodAccessor263.invoke(Unknown Source) [na:na]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at org.sonatype.nexus.common.stateguard.SimpleMethodInvocation.proceed(SimpleMethodInvocation.java:53) [na:na]   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [na:na]   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:267) [na:na]   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53) [na:na]   at org.sonatype.nexus.common.stateguard.StateGuardAspect$1.invoke(StateGuardAspect.java:59) [na:na]   at com.sun.proxy.$Proxy160.createBlob(Unknown Source) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmFacetUtils.toBlob(NpmFacetUtils.java:128) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmFacetUtils.savePackageRoot(NpmFacetUtils.java:304) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmProxyFacetImpl.doPutPackageRoot(NpmProxyFacetImpl.java:182) [na:na]   at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:54) [na:na]   at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:45) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmProxyFacetImpl.putPackageRoot(NpmProxyFacetImpl.java:162) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmProxyFacetImpl.store(NpmProxyFacetImpl.java:84) [na:na]   at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.get(ProxyFacetSupport.java:163) [na:na]   at org.sonatype.nexus.repository.proxy.ProxyHandler.handle(ProxyHandler.java:48) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.storage.UnitOfWorkHandler.handle(UnitOfWorkHandler.java:39) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.Context$proceed$0.call(Unknown Source) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmHandlers$_closure10.doCall(NpmHandlers.groovy:201) [na:na]   at sun.reflect.GeneratedMethodAccessor261.invoke(Unknown Source) [na:na]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [na:na]   at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [na:na]   at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1084) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [na:na]   at groovy.lang.Closure.call(Closure.java:426) [na:na]   at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [na:na]   at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [na:na]   at com.sun.proxy.$Proxy159.handle(Unknown Source) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.handlers.ContentHeadersHandler.handle(ContentHeadersHandler.java:44) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.handlers.ConditionalRequestHandler.handle(ConditionalRequestHandler.java:72) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.partial.PartialFetchHandler.handle(PartialFetchHandler.java:58) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.negativecache.NegativeCacheHandler.handle(NegativeCacheHandler.java:50) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.Context$proceed$0.call(Unknown Source) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmHandlers$_closure1.doCall(NpmHandlers.groovy:90) [na:na]   at sun.reflect.GeneratedMethodAccessor258.invoke(Unknown Source) [na:na]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [na:na]   at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [na:na]   at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [na:na]   at groovy.lang.Closure.call(Closure.java:426) [na:na]   at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [na:na]   at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [na:na]   at com.sun.proxy.$Proxy159.handle(Unknown Source) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.security.SecurityHandler.handle(SecurityHandler.java:45) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.handlers.TimingHandler.handle(TimingHandler.java:46) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.Context.start(Context.java:102) [na:na]   at org.sonatype.nexus.repository.view.Router.dispatch(Router.java:58) [na:na]   at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:43) [na:na]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.dispatchAndSend(ViewServlet.java:198) [na:na]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.doService(ViewServlet.java:160) [na:na]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.service(ViewServlet.java:117) [na:na]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:70) [com.google.inject:4.0.0]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.4]   at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.4]   at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:101) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) [org.eclipse.jetty.servlet:9.3.3.v20150827]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581) [org.eclipse.jetty.servlet:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548) [org.eclipse.jetty.security:9.3.3.v20150827]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1156) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511) [org.eclipse.jetty.servlet:9.3.3.v20150827]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1088) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.3.v20150827]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:109) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.Server.handle(Server.java:517) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:306) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:242) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:245) [org.eclipse.jetty.io:9.3.3.v20150827]   at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.3.v20150827]   at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:75) [org.eclipse.jetty.io:9.3.3.v20150827]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:213) [org.eclipse.jetty.util:9.3.3.v20150827]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:147) [org.eclipse.jetty.util:9.3.3.v20150827]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654) [org.eclipse.jetty.util:9.3.3.v20150827]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572) [org.eclipse.jetty.util:9.3.3.v20150827]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  2015-09-23 11:38:40,002-0400 INFO  [qtp1623599577-228] admin com.sonatype.nexus.repository.npm.internal.NpmProxyFacetImpl - Storing package: jade  2015-09-23 11:38:40,023-0400 WARN  [qtp1623599577-228] admin org.sonatype.nexus.repository.httpbridge.internal.ViewServlet - Service failure  org.sonatype.nexus.repository.InvalidContentException: Detected content type [text/html], but expected [application/json]: jade.json   at org.sonatype.nexus.repository.storage.DefaultContentValidator.determineContentType(DefaultContentValidator.java:95) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmContentValidator.determineContentType(NpmContentValidator.java:60) [na:na]   at org.sonatype.nexus.repository.storage.StorageTxImpl.determineContentType(StorageTxImpl.java:573) [na:na]   at org.sonatype.nexus.repository.storage.StorageTxImpl.createBlob(StorageTxImpl.java:478) [na:na]   at sun.reflect.GeneratedMethodAccessor263.invoke(Unknown Source) [na:na]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at org.sonatype.nexus.common.stateguard.SimpleMethodInvocation.proceed(SimpleMethodInvocation.java:53) [na:na]   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [na:na]   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:267) [na:na]   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53) [na:na]   at org.sonatype.nexus.common.stateguard.StateGuardAspect$1.invoke(StateGuardAspect.java:59) [na:na]   at com.sun.proxy.$Proxy160.createBlob(Unknown Source) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmFacetUtils.toBlob(NpmFacetUtils.java:128) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmFacetUtils.savePackageRoot(NpmFacetUtils.java:304) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmProxyFacetImpl.doPutPackageRoot(NpmProxyFacetImpl.java:182) [na:na]   at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:54) [na:na]   at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:45) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmProxyFacetImpl.putPackageRoot(NpmProxyFacetImpl.java:162) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmProxyFacetImpl.store(NpmProxyFacetImpl.java:84) [na:na]   at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.get(ProxyFacetSupport.java:163) [na:na]   at org.sonatype.nexus.repository.proxy.ProxyHandler.handle(ProxyHandler.java:48) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.storage.UnitOfWorkHandler.handle(UnitOfWorkHandler.java:39) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.Context$proceed$0.call(Unknown Source) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmHandlers$_closure10.doCall(NpmHandlers.groovy:201) [na:na]   at sun.reflect.GeneratedMethodAccessor261.invoke(Unknown Source) [na:na]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [na:na]   at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [na:na]   at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1084) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [na:na]   at groovy.lang.Closure.call(Closure.java:426) [na:na]   at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [na:na]   at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [na:na]   at com.sun.proxy.$Proxy159.handle(Unknown Source) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.handlers.ContentHeadersHandler.handle(ContentHeadersHandler.java:44) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.handlers.ConditionalRequestHandler.handle(ConditionalRequestHandler.java:72) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.partial.PartialFetchHandler.handle(PartialFetchHandler.java:58) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.negativecache.NegativeCacheHandler.handle(NegativeCacheHandler.java:50) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.Context$proceed$0.call(Unknown Source) [na:na]   at com.sonatype.nexus.repository.npm.internal.NpmHandlers$_closure1.doCall(NpmHandlers.groovy:90) [na:na]   at sun.reflect.GeneratedMethodAccessor258.invoke(Unknown Source) [na:na]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [na:na]   at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [na:na]   at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]   at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [na:na]   at groovy.lang.Closure.call(Closure.java:426) [na:na]   at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [na:na]   at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [na:na]   at com.sun.proxy.$Proxy159.handle(Unknown Source) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.security.SecurityHandler.handle(SecurityHandler.java:45) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.handlers.TimingHandler.handle(TimingHandler.java:46) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]   at org.sonatype.nexus.repository.view.Context.start(Context.java:102) [na:na]   at org.sonatype.nexus.repository.view.Router.dispatch(Router.java:58) [na:na]   at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:43) [na:na]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.dispatchAndSend(ViewServlet.java:198) [na:na]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.doService(ViewServlet.java:160) [na:na]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.service(ViewServlet.java:117) [na:na]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:70) [com.google.inject:4.0.0]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.4]   at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.4]   at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:101) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) [org.eclipse.jetty.servlet:9.3.3.v20150827]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581) [org.eclipse.jetty.servlet:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548) [org.eclipse.jetty.security:9.3.3.v20150827]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1156) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511) [org.eclipse.jetty.servlet:9.3.3.v20150827]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1088) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.3.v20150827]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:109) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.Server.handle(Server.java:517) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:306) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:242) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:245) [org.eclipse.jetty.io:9.3.3.v20150827]   at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.3.v20150827]   at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:75) [org.eclipse.jetty.io:9.3.3.v20150827]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:213) [org.eclipse.jetty.util:9.3.3.v20150827]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:147) [org.eclipse.jetty.util:9.3.3.v20150827]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654) [org.eclipse.jetty.util:9.3.3.v20150827]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572) [org.eclipse.jetty.util:9.3.3.v20150827]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  {quote}",Bug,Major,Closed,"2015-09-23 18:50:41","2015-09-23 17:50:41",1
"Sonatype Nexus","Deleting a npm asset then republishing errors","I noticed that if I publish then delete the related assets (via browse assets/components UI) and publish again that I am getting the below error.  This happens despite allow redeploy being on.  If I do not delete the republish works as does the first publish.    Debug was off during this test.  NPM is new to Fabtastic so no backcheck of NX3 is possible. I did not check NX2 at this time.    {quote}    2015-09-22 17:36:46,247-0400 WARN [qtp658827638-536] admin org.sonatype.nexus.repository.httpbridge.internal.ViewServlet - Service failure  java.lang.NullPointerException: null  at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:210) [na:na]  at org.sonatype.nexus.repository.storage.StorageTxImpl.attachBlob(StorageTxImpl.java:489) [na:na]  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]  at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]  at org.sonatype.nexus.common.stateguard.SimpleMethodInvocation.proceed(SimpleMethodInvocation.java:53) [na:na]  at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [na:na]  at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:267) [na:na]  at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53) [na:na]  at org.sonatype.nexus.common.stateguard.StateGuardAspect$1.invoke(StateGuardAspect.java:59) [na:na]  at com.sun.proxy.$Proxy154.attachBlob(Unknown Source) [na:na]  at com.sonatype.nexus.repository.npm.internal.NpmHostedFacetImpl.putTarball(NpmHostedFacetImpl.java:158) [na:na]  at com.sonatype.nexus.repository.npm.internal.NpmHostedFacetImpl.putPackageRoot(NpmHostedFacetImpl.java:119) [na:na]  at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:54) [na:na]  at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:45) [na:na]  at com.sonatype.nexus.repository.npm.internal.NpmHostedFacetImpl.putPackage(NpmHostedFacetImpl.java:86) [na:na]  at com.sonatype.nexus.repository.npm.internal.NpmHostedFacet$putPackage$0.call(Unknown Source) [na:na]  at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:141) [groovy-all:2.4.4]  at com.sonatype.nexus.repository.npm.internal.NpmHandlers$_closure3.doCall(NpmHandlers.groovy:123) [na:na]  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]  at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [groovy-all:2.4.4]  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [groovy-all:2.4.4]  at groovy.lang.Closure.call(Closure.java:426) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [groovy-all:2.4.4]  at com.sun.proxy.$Proxy120.handle(Unknown Source) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.storage.UnitOfWorkHandler.handle(UnitOfWorkHandler.java:39) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.handlers.ContentHeadersHandler.handle(ContentHeadersHandler.java:44) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.Context$proceed.call(Unknown Source) [na:na]  at com.sonatype.nexus.repository.npm.internal.NpmHandlers$_closure1.doCall(NpmHandlers.groovy:89) [na:na]  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]  at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93) [groovy-all:2.4.4]  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:325) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:294) [na:na]  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1019) [groovy-all:2.4.4]  at groovy.lang.Closure.call(Closure.java:426) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConvertedClosure.invokeCustom(ConvertedClosure.java:53) [groovy-all:2.4.4]  at org.codehaus.groovy.runtime.ConversionHandler.invoke(ConversionHandler.java:105) [groovy-all:2.4.4]  at com.sun.proxy.$Proxy120.handle(Unknown Source) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.handlers.ConditionalRequestHandler.handle(ConditionalRequestHandler.java:72) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.security.SecurityHandler.handle(SecurityHandler.java:45) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.handlers.TimingHandler.handle(TimingHandler.java:46) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [na:na]  at org.sonatype.nexus.repository.view.Context.start(Context.java:102) [na:na]  at org.sonatype.nexus.repository.view.Router.dispatch(Router.java:58) [na:na]  at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:43) [na:na]  at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.dispatchAndSend(ViewServlet.java:198) [na:na]  at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.doService(ViewServlet.java:160) [na:na]  at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.service(ViewServlet.java:117) [na:na]  at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]  at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]  at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]  at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]  at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:70) [com.google.inject:4.0.0]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.4]  at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]  at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.4]  at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.4]  at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.4]  at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.4]  at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:101) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]  at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) [org.eclipse.jetty.servlet:9.3.3.v20150827]  at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581) [org.eclipse.jetty.servlet:9.3.3.v20150827]  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548) [org.eclipse.jetty.security:9.3.3.v20150827]  at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1156) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511) [org.eclipse.jetty.servlet:9.3.3.v20150827]  at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1088) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.3.v20150827]  at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]  at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:109) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.Server.handle(Server.java:517) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:306) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:242) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:245) [org.eclipse.jetty.io:9.3.3.v20150827]  at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.3.v20150827]  at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:75) [org.eclipse.jetty.io:9.3.3.v20150827]  at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:213) [org.eclipse.jetty.util:9.3.3.v20150827]  at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:147) [org.eclipse.jetty.util:9.3.3.v20150827]  at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654) [org.eclipse.jetty.util:9.3.3.v20150827]  at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572) [org.eclipse.jetty.util:9.3.3.v20150827]  at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]    {quote}     STEPS:  1) Setup NPM hosted repo  2) npm publish (I used my own creation, ala [https://docs.sonatype.com/display/Nexus/NPM+Testing] )  3) Go to browse asset UI and delete all assets in the NPM hosted repo  4) npm publish; BUG: WARN in log, 500 on console, no republish is done",Bug,Major,Closed,"2015-09-23 14:55:04","2015-09-23 13:55:04",0.5
"Sonatype Nexus","Deleting an NuGet asset then repushing nupkg errors","Just noticed that if I delete a nuget asset then repush the nupkg to get the asset back it gives me the below error.  If I delete the repo and push there is no error nor is there an error the first time, so I assume this Nexus and not the package.    In the offchance this is intentional/expected behavior, I wanted to note I found the error strange.  It reads like it's missing a download count however that doesn't make any sense to me since those kinds of attributes would seem to always be read or never (not the second time and fail).    I did not check older NX3 or NX2 at this time.  I was on MacOSX using curl to push, an unlikely use case however I did that both times (the first successful and the second errorful).  I also did not check Windows at this time.    {quote}  2015-09-22 17:48:03,931-0400 ERROR [qtp658827638-557] admin com.sonatype.nexus.repository.nuget.internal.NugetPushHandler - Unknown error  java.lang.IllegalStateException: Missing: {attributes::nuget} version_download_count   at com.google.common.base.Preconditions.checkState(Preconditions.java:173) [com.google.guava:18.0.0]   at org.sonatype.nexus.common.collect.AttributesMap.require(AttributesMap.java:190) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]   at org.sonatype.nexus.common.collect.AttributesMap.require(AttributesMap.java:208) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]   at org.sonatype.nexus.common.collect.AttributesMap.require(AttributesMap.java:217) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]   at com.sonatype.nexus.repository.nuget.internal.NugetGalleryFacetImpl.maintainAggregateInfo(NugetGalleryFacetImpl.java:521) [na:na]   at com.sonatype.nexus.repository.nuget.internal.NugetGalleryFacetImpl.maintainAggregateInfo(NugetGalleryFacetImpl.java:502) [na:na]   at org.sonatype.nexus.transaction.TransactionalWrapper.proceedWithTransaction(TransactionalWrapper.java:54) [org.sonatype.nexus.transaction:3.0.0.SNAPSHOT]   at org.sonatype.nexus.transaction.TransactionInterceptor.invoke(TransactionInterceptor.java:45) [org.sonatype.nexus.transaction:3.0.0.SNAPSHOT]   at com.sonatype.nexus.repository.nuget.internal.NugetGalleryFacetImpl.put(NugetGalleryFacetImpl.java:334) [na:na]   at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]   at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:267) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]   at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]   at com.sonatype.nexus.repository.nuget.internal.NugetPushHandler.storePayload(NugetPushHandler.java:76) [na:na]   at com.sonatype.nexus.repository.nuget.internal.NugetPushHandler.push(NugetPushHandler.java:63) [na:na]   at com.sonatype.nexus.repository.nuget.internal.NugetPushHandler.handle(NugetPushHandler.java:45) [na:na]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.storage.UnitOfWorkHandler.handle(UnitOfWorkHandler.java:39) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.view.handlers.ExceptionHandler.handle(ExceptionHandler.java:41) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.security.SecurityHandler.handle(SecurityHandler.java:45) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.view.handlers.TimingHandler.handle(TimingHandler.java:46) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.view.Context.proceed(Context.java:79) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.view.Context.start(Context.java:102) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.view.Router.dispatch(Router.java:58) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:43) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.dispatchAndSend(ViewServlet.java:198) [org.sonatype.nexus.plugins.nexus-repository-httpbridge:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.doService(ViewServlet.java:160) [org.sonatype.nexus.plugins.nexus-repository-httpbridge:3.0.0.SNAPSHOT]   at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.service(ViewServlet.java:117) [org.sonatype.nexus.plugins.nexus-repository-httpbridge:3.0.0.SNAPSHOT]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:70) [com.google.inject:4.0.0]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.4]   at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.4]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.4]   at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:101) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) [org.eclipse.jetty.servlet:9.3.3.v20150827]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581) [org.eclipse.jetty.servlet:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548) [org.eclipse.jetty.security:9.3.3.v20150827]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1156) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511) [org.eclipse.jetty.servlet:9.3.3.v20150827]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1088) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.3.v20150827]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:109) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.Server.handle(Server.java:517) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:306) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:242) [org.eclipse.jetty.server:9.3.3.v20150827]   at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:245) [org.eclipse.jetty.io:9.3.3.v20150827]   at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.3.v20150827]   at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:75) [org.eclipse.jetty.io:9.3.3.v20150827]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:213) [org.eclipse.jetty.util:9.3.3.v20150827]   at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:147) [org.eclipse.jetty.util:9.3.3.v20150827]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654) [org.eclipse.jetty.util:9.3.3.v20150827]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572) [org.eclipse.jetty.util:9.3.3.v20150827]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  {quote}",Bug,Major,Closed,"2015-09-22 22:56:29","2015-09-22 21:56:29",0.5
"Sonatype Nexus","Extend search/browse results to show levels more cleanly","While reviewing NPM, I noticed looking at browse/search results all the json details were smushed together making IMO a tough reading experience. In fact, I believe it's much easier to read the json file itself (the contents are the same but the whitespace/linebreaks are not stripped).  [<USER>https://issues.sonatype.org/secure/ViewProfile.jspa?name=<USER> noted that 'we implemented nice display of attributes only for 1 level' and if extended it would show nicer. He also noted that some docker attributes have the same issue. This is an improvement ticket in that regard. I included a screen of current npm as well as a screen of current NuGet (which looks much better; though not a fair comparison provides a vision of something to strive towards).  NPM browse/search is new to NX3 and to Fabtastic so no back checking was done. I do not recall seeing the docker portion myself (implemented in m5, new to NX3), so did not attach screens/cases however if I run across it, I will try and remember to do so.",Bug,Minor,Closed,"2015-09-22 18:58:09","2015-09-22 17:58:09",2
"Sonatype Nexus","Capabilities: Save/discard does not disable after save","I noticed that after saving a Capability change _on the Summary tab_ that the Save/Discard buttons remain enabled. This does not happen on the Settings tab, so I surmise this may have been fixed one place (by [-NEXUS-8833-|https://issues.sonatype.org/browse/NEXUS-8833] ?) but not another. Similar tickets have definately existed (see some linked).  There are no errors in the JS console/nexus.log. Debug was off during this test. I did not check older NX3 or NX2 at this time.",Bug,Minor,Closed,"2015-09-21 21:13:33","2015-09-21 20:13:33",0.5
"Sonatype Nexus","Roles page warns of read permissions when it can be used","While running through security, I noticed that if you have just Roles permission, you get a warning that you cannot read privilges.  While this is true, it is not necessary to create a role.  Similarly, I think the placement of the warning is confusing.  You get the warning before you enter the place where the fact you cannot read potentially matters (drilling down into/creating the role).    Note, that the users page has a similar issue when it comes to listing roles however that page CANNOT be used without, so there is no ticket for that.  The combination of the ability for it to be used and confusing warning are causing me to file.    See attached screen, let me know if unclear.  I had debug off during this test.  No errors appeared in the js console.  Below appeared in the nexus.log.  I did not check older NX3 or NX2 at this time.    {quote}  2015-09-17 11:58:47,887-0400 ERROR [pool-6-thread-10] joedragons org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: coreui_Privilege.read, java-method: org.sonatype.nexus.coreui.PrivilegeComponent.read  org.apache.shiro.authz.AuthorizationException: User is not permitted: nexus:privileges:read   at org.sonatype.nexus.security.authz.ExceptionCatchingModularRealmAuthorizer.checkPermission(ExceptionCatchingModularRealmAuthorizer.java:66) [na:na]   at org.apache.shiro.mgt.AuthorizingSecurityManager.checkPermission(AuthorizingSecurityManager.java:137) [na:na]   at org.apache.shiro.subject.support.DelegatingSubject.checkPermission(DelegatingSubject.java:205) [org.apache.shiro.core:1.2.4]   at org.apache.shiro.authz.aop.PermissionAnnotationHandler.assertAuthorized(PermissionAnnotationHandler.java:74) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.assertAuthorized(AuthorizingAnnotationMethodInterceptor.java:84) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:67) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet$3.invokeMethod(ExtDirectServlet.java:201) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.StandardRequestProcessorBase.dispatchStandardMethod(StandardRequestProcessorBase.java:73) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:502) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.DefaultJsonRequestProcessorThread.processRequest(DefaultJsonRequestProcessorThread.java:72) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.ssm.SsmJsonRequestProcessorThread.processRequest(SsmJsonRequestProcessorThread.java:43) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectJsonRequestProcessorThread.access$1(ExtDirectJsonRequestProcessorThread.java:1) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectJsonRequestProcessorThread$1.call(ExtDirectJsonRequestProcessorThread.java:59) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectJsonRequestProcessorThread$1.call(ExtDirectJsonRequestProcessorThread.java:1) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletScopes$3.call(ServletScopes.java:232) [com.google.inject:4.0.0]   at org.sonatype.nexus.extdirect.internal.ExtDirectJsonRequestProcessorThread.processRequest(ExtDirectJsonRequestProcessorThread.java:73) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.DefaultJsonRequestProcessorThread.call(DefaultJsonRequestProcessorThread.java:56) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.DefaultJsonRequestProcessorThread.call(DefaultJsonRequestProcessorThread.java:30) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_40]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_40]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_40]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  Caused by: org.apache.shiro.authz.AuthorizationException: Not authorized to invoke method: public java.util.List org.sonatype.nexus.coreui.PrivilegeComponent.read()   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.assertAuthorized(AuthorizingAnnotationMethodInterceptor.java:90) [na:na]   ... 26 common frames omitted  {quote}",Bug,Minor,Closed,"2015-09-21 21:09:15","2015-09-21 20:09:15",0.5
"Sonatype Nexus","NPM specific document versioning","Acceptance Criteria:  - Implement a separate ability to keep track of npm package document version   Right now, the NPM specific document version field {{_rev}} is getting populated with actual underlying ODocument.version ({{packageRootAsset.getEntityMetadata().getVersion()}}, which completely suites the use case. npm CLI does retries 3 times in case of MVCC conflict (client {{_rev}} and server {{_rev}} mismatch).  Still, as per phone with Alin, this can lead to many false positives (unsuccessful edits and retries), due to the fact that {{packageRootAsset.markAsAccessed()}} will also modify ODocument.version, so multiple clients reading/accessing one package, while one client trying to update it might lead that updating client fails (even after retries).  Proper solution would be to implement manually NPM document versioning, it could be another NPM format specific asset attribute, maintained by NPM format code only. This way, we could circumvent also any future change that might spin ODocument.version faster than we currently expect.",Bug,Minor,Open,"2015-09-21 10:38:50","2015-09-21 09:38:50",2
"Sonatype Nexus","npm Performance ITs","Add npm hosted, group and proxy performance ITs to the performance-testsuite.",Bug,Major,Closed,"2015-09-15 19:39:47","2015-09-15 18:39:47",3
"Sonatype Nexus","Clicking to run and running a scheduled task shows repository field briefly as required","I noticed that when you click to run a scheduled task (before running) and when you run a scheduled task, the repository field briefly displays it's required despite it being filled in.  No other required field does this as far as I can tell.  This seems familiar but I did not see a ticket regarding this already.  I did not check older NX3 or NX2 at this time.  See vid, let me know if unclear.",Bug,Trivial,Closed,"2015-09-15 17:34:18","2015-09-15 16:34:18",0.5
"Sonatype Nexus","Docker search against group is incorrectly sorted","Setup:     - docker group docker-all exposed at 18443  - group contains empty hosted repo and proxy to Docker Hub    Expectation:    Search results for a specific term like 'ubuntu' are the same    Observed:    Not the same at all. All official results that show up in direct search to Docker Hub are omitted. E.g. the official ubuntu image is missing. Typically those have the biggest number of stars and are the desired ones.   ",Bug,Critical,Closed,"2015-09-11 23:01:13","2015-09-11 22:01:13",0.5
"Sonatype Nexus","IE(11): Column sort arrows on smaller columns collide with text","See attached (from Blobstores page).  On smaller columns in IE(11), the sort arrow collides with the text.  I noticed this first on Support>Analytics>Events where the default column sizes are pretty small (lots of data) and the initial sort (Timestamp) is affected.  This does not happen in Chrome (Windows7) so this seems to be an IE specific issue.  Working browsers have the arrow on the right and if the column gets too small, not shown at all.  Being that the sort arrow is not first and on the same line, this is what I would have expected.  Workaround, widen the column.    I am pretty sure I have seen this before but did not see a ticket.  Did not test older NX3 or NX2 at this time.  Debug was off during this test.    NOTE:  Maybe talk to Sencha about this one",Bug,Trivial,Closed,"2015-09-11 21:55:35","2015-09-11 20:55:35",0.5
"Sonatype Nexus","'Locally cached' status doesn't update when downloading NuGet assets for the first time","When NuGet searches are performed, the search cache is primed with data from the result but the actual binaries are not yet downloaded. When you navigate to the Assets view for one of these and click the download link the content is fetched, but the status shown on the screen does not update until after you navigate away and back. The refresh button does nothing in this context.  The expectation is that the info about the asset should be updated, which might include a refresh of the store after the content is fetched.    Recreation steps:  - execute a search against our nuget.org proxy repo: curl -u admin:admin123 -X GET -v http://localhost:8081/repository/nuget.org-proxy/Search()?\$filter=IsLatestVersion&searchTerm='Web'&targetFramework='net45'&includePrerelease=false&\$top=65  - Browse in the UI to any of the results of the above search; on a newly installed system this should be all results  - note that 'Locally cached' is false  - click the path link and download the asset  - observe that the UI does not update 'Locally cached' and other related info (File size and Blob Ref)",Bug,Trivial,Closed,"2015-09-11 17:22:30","2015-09-11 16:22:30",1
"Sonatype Nexus","Going to custom search from non-parent has continual mask","I noticed that if I went to Custom Search from any of the other child searches (Docker, Maven, NuGet, Raw) I got a continual loading mask that did not go away.  If you go from Search parent or outside stuff (such as Welcome or Browse) it works.  This occurs with Debug on and off and nothing in the log/js console shows (though I mull if it's really continual that's why).  This occurs with contents in the repos or with a fresh (content free) install.  None of the other child searches seem affected in this way.    I've attached a screen since it's about the same info as a vid, but if you want a vid let me know.    I did not check older NX3 or NX2 at this time.",Bug,Minor,Closed,"2015-09-11 15:37:38","2015-09-11 14:37:38",0.5
"Sonatype Nexus","Save button remains enabled after changes to LDAP users/groups are saved","Demo: http://take.ms/ClOBU    Despite what the messaging says, the changes _are_ saved. Only the *User and group* tab is affected.",Bug,Minor,Closed,"2015-09-10 14:52:17","2015-09-10 13:52:17",0.5
"Sonatype Nexus","Numerical drop down rendering issue","The numerical drop down for Docker connector ports looses the lower outline when a value is defined in the control. This looks broken to a user.",Bug,Trivial,Closed,"2015-09-09 23:34:34","2015-09-09 22:34:34",0.5
"Sonatype Nexus","Help text in routing rules is wrong","The help text on routing rules is incorrect. It says that the path in the expression will include the repository name. This is wrong.  It also implies that a leading .* is needed in the path before the start of the group ID, this is also wrong.  This was previously fixed in [-NEXUS-3583-|https://issues.sonatype.org/browse/NEXUS-3583] , so somehow this regressed.",Bug,Major,Closed,"2015-09-09 14:08:39","2015-09-09 13:08:39",0
"Sonatype Nexus","Update indexes run from context menu doesn't work","Running update indexes by clicking within the browse storage tab of a repository does not work in Nexus 2.11.4.  The log shows that the path is incorrect:  {quote}  2015-09-01 16:21:50 INFO [pxpool-1-thread-10] admin org.sonatype.nexus.index.tasks.UpdateIndexTask - Scheduled task (UpdateIndexTask) finished :: Updating repository index Releases from path /content/com/foo/project/ and below. (started 2015-09-01T16:21:49-05:00, runtime 0:00:00.827)  {quote}   Note that the path starts with /content. It should not.  The request sent from the UI is correct, so this isn't a UI issue:  {quote}  192.168.0.2 - admin [01/Sep/2015:16:21:49 -0500] DELETE /nexus/service/local/data_incremental_index/repositories/releases/content/com/foo/project/ HTTP/1.1 204 0 6  {quote}   I'm not sure exactly when this regressed, but the end user reported that it worked in 2.3.1, and I can confirm, it did.",Bug,Major,Open,"2015-09-01 22:46:42","2015-09-01 21:46:42",1
"Sonatype Nexus","Should not be allowed to delete assets from a group repository","There’s a delete button when viewing an asset in a group repository. We don’t support delete in that scenario, so the button shouldn’t be there, and if we do try to use it an NPE is thrown since the Asset id doesn't exist in the group repo bucket.    Acceptance Criteria:    - Remove the button from group repositories!     NOTE:    - The information to remove this _easily_ is not currently available, we'd have to figure something out to indicate your are in a group repository     {quote}    2015-10-02 13:50:52,366-0400 INFO [qtp1124904898-174] admin org.sonatype.nexus.coreui.ComponentComponent - Deleting asset: null  2015-10-02 13:50:52,371-0400 ERROR [qtp1124904898-174] admin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: coreui_Component.deleteAsset, java-method: org.sonatype.nexus.coreui.ComponentComponent.deleteAsset  java.lang.NullPointerException: null  at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:210) [com.google.guava:18.0.0]  at org.sonatype.nexus.repository.storage.StorageTxImpl.deleteAsset(StorageTxImpl.java:421) [na:na]  at org.sonatype.nexus.repository.storage.StorageTxImpl.deleteAsset(StorageTxImpl.java:417) [na:na]  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]  at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]  at org.sonatype.nexus.common.stateguard.SimpleMethodInvocation.proceed(SimpleMethodInvocation.java:53) [na:na]  at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39) [na:na]  at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:267) [na:na]  at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53) [na:na]  at org.sonatype.nexus.common.stateguard.StateGuardAspect$1.invoke(StateGuardAspect.java:59) [na:na]  at com.sun.proxy.$Proxy155.deleteAsset(Unknown Source) [na:na]  at org.sonatype.nexus.repository.storage.StorageTx$deleteAsset$9.call(Unknown Source) [na:na]  at org.sonatype.nexus.coreui.ComponentComponent.deleteAsset(ComponentComponent.groovy:289) [na:na]  at org.sonatype.nexus.validation.internal.ValidationInterceptor.invoke(ValidationInterceptor.java:53) [na:na]  at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]  at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]  at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]  at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]  at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]  at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]  at org.sonatype.nexus.extdirect.internal.ExtDirectServlet$3.invokeMethod(ExtDirectServlet.java:201) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]  at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]  at com.softwarementors.extjs.djn.router.processor.standard.StandardRequestProcessorBase.dispatchStandardMethod(StandardRequestProcessorBase.java:73) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]  at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:502) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]  at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequestsInThisThread(JsonRequestProcessor.java:150) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]  at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.process(JsonRequestProcessor.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]  at com.softwarementors.extjs.djn.router.RequestRouter.processJsonRequest(RequestRouter.java:83) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]  at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.processRequest(DirectJNgineServlet.java:617) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]  at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.doPost(DirectJNgineServlet.java:580) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]  at org.sonatype.nexus.extdirect.internal.ExtDirectServlet.doPost(ExtDirectServlet.java:121) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]  at javax.servlet.http.HttpServlet.service(HttpServlet.java:707) [javax.servlet-api:3.1.0]  at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]  at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]  at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]  at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]  at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:70) [com.google.inject:4.0.0]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.4]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.4]  at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]  at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.4]  at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.4]  at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.4]  at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.4]  at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.4]  at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.4]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:101) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]  at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) [org.eclipse.jetty.servlet:9.3.3.v20150827]  at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581) [org.eclipse.jetty.servlet:9.3.3.v20150827]  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548) [org.eclipse.jetty.security:9.3.3.v20150827]  at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1156) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511) [org.eclipse.jetty.servlet:9.3.3.v20150827]  at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1088) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.3.v20150827]  at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]  at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:109) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.Server.handle(Server.java:517) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:306) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:242) [org.eclipse.jetty.server:9.3.3.v20150827]  at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:245) [org.eclipse.jetty.io:9.3.3.v20150827]  at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95) [org.eclipse.jetty.io:9.3.3.v20150827]  at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:75) [org.eclipse.jetty.io:9.3.3.v20150827]  at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:213) [org.eclipse.jetty.util:9.3.3.v20150827]  at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:147) [org.eclipse.jetty.util:9.3.3.v20150827]  at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654) [org.eclipse.jetty.util:9.3.3.v20150827]  at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572) [org.eclipse.jetty.util:9.3.3.v20150827]  at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]    {quote}",Bug,Minor,Closed,"2015-08-28 21:09:05","2015-08-28 20:09:05",1
"Sonatype Nexus","Update security entity bits to use use common entity support bits","The entities and orientdb usage of things in nexus-security should be able to use the nexus-common provided Entity interface and allow the impls to use EntityAdapter support classes.",Improvement,Minor,Closed,"2015-08-27 02:16:37","2015-08-27 01:16:37",2
"Sonatype Nexus","Support Zip page prompts for discard","I noticed when I created a Support Zip (via Admin>Support) that when I removed some of the check boxes (I left System information report as well as the two Options) then closed the browser or navigated away I was prompted to discard changes or go back.  This page is not able to be saved to my knowledge, so I think this prompt is out of place.    Test done with debug off.  NX2 is not affected by this.  I did not check older NX3.",Bug,Trivial,Closed,"2015-08-25 16:36:27","2015-08-25 15:36:27",0.5
"Sonatype Nexus","Eclipse update site with relative paths cannot be proxied.","Create a p2 update site proxy repository with this URL for the remote:    http://www3.software.ibm.com/ibmdl/pub/software/rationalsdp/clearcase/60/update/windows/    This fails due to the fix for NEXUS-7839:    {quote}  2015-08-25 09:53:51,546-0500 WARN  [pxpool-1-thread-1] admin org.sonatype.nexus.plugins.p2.repository.updatesite.UpdateSiteProxyRepositoryImpl - Could not download feature com.ibm.rational.clearcase.ccrefresh_7.6.2.v201309301552 referenced by update site aaa  java.lang.IllegalArgumentException: Repository UID path may NOT contain relative tokens: /../all_os/features/com.ibm.rational.clearcase.ccrefresh_7.6.2.v201309301552.jar      at com.google.common.base.Preconditions.checkArgument(Preconditions.java:148) ~[guava-16.0.1.jar:na]      at org.sonatype.nexus.proxy.item.DefaultRepositoryItemUidFactory.createUid(DefaultRepositoryItemUidFactory.java:79) ~[nexus-core-2.11.4-01.jar:2.11.4-01]      at org.sonatype.nexus.proxy.item.DefaultRepositoryItemUidFactory.createUid(DefaultRepositoryItemUidFactory.java:43) ~[nexus-core-2.11.4-01.jar:2.11.4-01]      at org.sonatype.nexus.proxy.repository.AbstractRepository.createUid(AbstractRepository.java:1078) ~[nexus-core-2.11.4-01.jar:2.11.4-01]      at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:753) ~[nexus-core-2.11.4-01.jar:2.11.4-01]      at org.sonatype.nexus.plugins.p2.repository.updatesite.UpdateSiteProxyRepositoryImpl.mirrorRelativeItem(UpdateSiteProxyRepositoryImpl.java:452) [nexus-p2-repository-plugin-2.11.4-01/:na]  {quote}    This is due to this entries like this one in the site.xml:        This is a regression from Nexus 2.11.0.",Bug,Major,Open,"2015-08-25 16:06:58","2015-08-25 15:06:58",1
"Sonatype Nexus","Initial navigation to browse assets/components does not load list","When navigating to browse repository assets/components the first time, the list of assets/components is not loaded. The list is loaded on subsequent navigations and when using a bookmark URL.    This problem does not exhibit when using {{?debug}} in the URL or when using the browser's debug/developer mode.",Bug,Major,Closed,"2015-08-23 14:57:03","2015-08-23 13:57:03",0.5
"Sonatype Nexus","Apply Codahale metrics to Facets","There's a limitation in codahale's guice integration that restricts the use of @Timed (and related) annotations to plain components. It won't instrument assisted-inject factories.    As a result, we can't use Codahale annotations for facet methods, which is big limitation given NX3's repository architecture.",Improvement,Major,Closed,"2015-08-20 18:35:08","2015-08-20 17:35:08",1
"Sonatype Nexus","Realm dropdown initially disabled on Anonymous page","[~<USER> noticed that on the Security>Anonymous page the Realm list dropdown initially shows no items in it unless you go to the Security>Realms page first.  This can be reproed both by logging in directly to http://localhost:8081/#admin/security/anonymous or by logging in normally and navigating to Security>Anonymous before going to Security>Realms.  Then click on the realm dropdown.  See vid.    Both of us recall seeing this or something akin before but could not find a related ticket.  I suspect this affects older versions of NX3 because of this but did not back check at this time.  This does not affect NX2 because the setup is different.    Testing done with debug off.",Bug,Major,Closed,"2015-08-19 14:25:13","2015-08-19 13:25:13",1
"Sonatype Nexus","Removing certificate from trust store errors","I tried to remove a certificate from the trust store via the repository admin and got the attached error.  I am 95% sure this worked at some point but did not check older NX3 (or NX2) at this time.  This occurs with debug on and off.  Screen/snip are with debug on.    Removing the certificate via SSL _does_ work so that's the workaround.    JS Console:  {quote}  Uncaught TypeError: model.get is not a function  VM433 SslCertificates.js?_dc=1439930849262:134    Ext.define.getDescription @ VM433 SslCertificates.js?_dc=1439930849262:134  Ext.define.deleteModel @ VM433 SslCertificates.js?_dc=1439930849262:298  fire @ VM312 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1439930848524&debug=true:10813  Ext.define.dispatch @ VM312 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1439930848524&debug=true:43613  prototype.fireEventArgs @ VM312 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1439930848524&debug=true:43707  fireEvent @ VM312 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1439930848524&debug=true:12200  Ext.define.fireHandler @ VM312 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1439930848524&debug=true:50078  Ext.define.onClick @ VM312 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1439930848524&debug=true:50064  (anonymous function) @ VM839:6  Ext.apply.createListenerWrap.wrap @ VM312 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1439930848524&debug=true:11583  {quote}",Bug,Minor,Closed,"2015-08-18 21:52:08","2015-08-18 20:52:08",1
"Sonatype Nexus","Adding certificate to trust store does not close modal","[~<USER> noted earlier today that he had noticed that when adding a certificate to a proxy repository (via repository administration), that the modal to add the certificate did not close.  He and [~<USER> do not believe this is intentional so I am filing a ticket.  I did not go back and check older NX3 (or NX2) at this time however the current behavior is not familiar.  My repro test was done with debug off however I doubt that matters.    Let any of us know if unclear.",Bug,Minor,Closed,"2015-08-18 21:45:25","2015-08-18 20:45:25",0.5
"Sonatype Nexus","Docker repo admin form always treated as 'dirty'","If you've navigated to a Docker repo admin screen it is automatically treated as dirty even though no changes are made. This is annoying as you can't view the config and navigate away without a modal warning that changes will be lost.  ",Bug,Major,Closed,"2015-08-18 21:09:28","2015-08-18 20:09:28",0.5
"Sonatype Nexus","IE(11): Errors & non-functional pages after minimal site use","In IE11, when I go to create a repository, on select a repository type, I am getting the attached errors.  I had limited success bypassing this with debug on however it does occur with debug on as well.  I have had 100% success rate reproducing this without debug on.  I have not seen this in Chrome either Windows or MacOSX, so assume this is IE related.    From JS console:  SCRIPT5007: Unable to get property 'removeAll' of undefined or null reference  File: Drilldown.js, Line: 624, Column: 11    I did not check older NX3 or NX2 at this time.  I am fairly sure I've been able to create repos in NX3 (and NX2) at some point in IE however.  Leaving major because of this.  Workaround is obviously use another browser.",Bug,Critical,Closed,"2015-08-17 21:35:07","2015-08-17 20:35:07",0.5
"Sonatype Nexus","Be more opinionated about Docker HTTP and HTTPS config options","Docker repositories may be accessed in four basic configurations:    * Using the default URL we provide (doesn’t support push/pull with Docker)  * Using the default URL _or_ HTTP (when NX is behind a secure proxy)  * Using the default URL _or_ HTTPS (intended for a proxy-less scenario)  * Using the default URL _or_ HTTP _or_ HTTPS    We need to make these options more explicit in the UI. There are a few things we could do to make the UI clearer:    * List every URL that a user can use to interact with a repository (not just the default URL)  * Briefly describe how we expect each kind of URL to be used (supplemented by online docs)  * Put the HTTP and HTTPS fields in an optional fieldset, to make it clear that you don’t need one to retrieve images from Nexus (in fact, the only reason you need HTTP or HTTPS is if you want to push/pull images to Nexus using the Docker CLI)  * HTTPS is the preferred way of interacting with Nexus using the Docker CLI. Consider saying this in the help text, or selecting it by default (once the optional fieldset has been checked).",Improvement,Minor,Closed,"2015-08-17 20:39:16","2015-08-17 19:39:16",2
"Sonatype Nexus","Unselecting form checkboxes causes discard and save state to mess up","I noticed that when I went to put a repository offline, right after I went to navigate away, I got a discard changes prompt.  On repro attempt, I noticed when I unselected any checkboxes on the form, the save buttons remain enabled and the discard prompts fire.  If you discard however, you will return to a screen where everything is saved NOT discarded.  This is pretty confusing.  See attached movie, let me know if unclear.    It's even more confusing that it does not appear to affect the opposite way (selecting checkboxes) or using other field types (that I saw/tried).  While I originally saw this on repository, I was able to reproduce using Capabilities, so it's not repository specific.    I did not check older NX3 or NX2 at this time.  Test done with debug off.",Bug,Major,Closed,"2015-08-17 19:15:07","2015-08-17 18:15:07",1
"Sonatype Nexus","Logging in from anonymous searching has weird redraw","While testing NEXUS-9031, I tangentially checked from a custom search logged in anonymously, logging in to make sure all areas were covered (search is the last area currently outside of component and asset browse you can access not being logged in).  When I did this, I noticed a weird redraw (see attached).    This occurs no matter what custom search level you are on (overall type search, inside a component, inside an asset).  It occurs with debug on and off.  I further noticed that if you open the developer console or the javascript console, the page corrects itself.  Refreshing also corrects the page.    I have not checked against NX2 at this time.",Bug,Trivial,Closed,"2015-08-17 16:39:15","2015-08-17 15:39:15",5
"Sonatype Nexus","remove codehaus snapshots from default configuration","The codehaus snapshots repo is gone, we should remove it from our default configuration.",Improvement,Major,Closed,"2015-08-05 22:28:32","2015-08-05 21:28:32",0.5
"Sonatype Nexus","Errors after logging in from anonymous to some pages","While on a browse repository asset detail page anonymously, I logged in as admin and saw an error.  I was able to get the same error logging into a component detail page.  I also saw errors (though a different one) logging in to the file list (before details) as well as the component list (before file list on browse Components).  Despite the error, everything appears fine to me.  This also does not occur when you directly hit the URL so seems indirectly related to what I was testing.    I decided to file one ticket as the behavior is identical, despite the differences in error; I suspect there will be two very similar fixes.  If you'd like this broken out let me know.    If this seems familiar, NEXUS-8728 is almost the exact same thing for search but no longer occurs in search.  I did not check older NX3 or NX2 at this time.  This occurs with debug on or off.    Asset details error:  {quote}  Uncaught TypeError: Cannot read property 'getView' of undefined  VM258 nexus-rapture-plugin-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1    Ext.define.onModelChanged @ VM258 nexus-rapture-plugin-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  (anonymous function) @ VM262 nexus-coreui-plugin-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.apply.callback @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.cmd.derive.onProxyLoad @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.cmd.derive.processResponse @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  (anonymous function) @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  (anonymous function) @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.cmd.derive.runCallback @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.cmd.derive.onData @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.apply.callback @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.cmd.derive.onComplete @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.cmd.derive.onStateChange @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  (anonymous function) @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  {quote}    File list and component list error:    {quote}  Uncaught TypeError: Cannot read property 'getStore' of undefined  2VM258 nexus-rapture-plugin-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1    Ext.define.selectModel @ VM258 nexus-rapture-plugin-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  (anonymous function) @ VM258 nexus-rapture-plugin-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  fire @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  continueFireEvent @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  fireEventArgs @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  a.fireEventArgs @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  fireEvent @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.cmd.derive.onProxyLoad @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.cmd.derive.processResponse @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  (anonymous function) @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  (anonymous function) @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.cmd.derive.runCallback @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.cmd.derive.onData @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.apply.callback @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.cmd.derive.onComplete @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  Ext.cmd.derive.onStateChange @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  (anonymous function) @ VM246 baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1438631658809:1  {quote}",Bug,Minor,Closed,"2015-08-03 21:18:46","2015-08-03 20:18:46",0.5
"Sonatype Nexus","orientdb may not fully recover from a restore process due to OCommandExecutionException: Class 'OUSER' was not found in current database","If Nexus is forcefully killed during the startup process, while the OrientDB ( used by NPM in Nexus 2.x ) is being loaded, the database will not be properly closed and will start recovery on next startup.    The problem is, it is possible the automated recovery process may not fully recover the database.  The recovery fails with {{OQueryParsingException: Error on parsing query at position #6: Error on parsing query Query:  OUser where name = 'admin' limit 1}}. This subsequently leaves the NPM plugin features unusable. The only workaround appears to be renaming/deleting the db/npm directory and have Nexus recreate it from scratch.    For example:        On restart, Nexus tries to recover the db and it mostly succeeds but ultimately fails:    ",Bug,Major,Closed,"2015-07-31 16:23:07","2015-07-31 15:23:07",1
"Sonatype Nexus","Endpoint to retrieve asset and component models by ID","The asset and component lists in the UI are infinite. Because we can’t guarantee that a given model has been loaded into these stores, we need a way to retrieve them from the backend directly, by ID.    This is needed when loading a bookmarked URL in the UI. If we can’t retrieve the model, we can’t show the corresponding view in the drilldown. I’ve stubbed this for now:     https://github.com/sonatype/nexus-oss/commit/204f43634f470427053b9cdd0d138fbba85cdd07",Task,Major,Closed,"2015-07-28 20:03:12","2015-07-28 19:03:12",2
"Sonatype Nexus","Sort fails when you drill in, drill out, then attempt to sort a grid","Demo: http://take.ms/y5ZXa    This bug only occurs in ?debug mode.    This bug appears to be tied to infinite scrolling lists only, so only browse and search are affected. Looking at the trace, this may be a bug with the fix Sencha gave us to a grid issue we filed awhile back.    https://support.sencha.com/index.php#ticket-22557    ",Bug,Minor,Closed,"2015-07-27 15:11:39","2015-07-27 14:11:39",2
"Sonatype Nexus","NX3 logger creating is not actually creating loggers on server","When creating a logger in the UI, no remote communication is being done to inform the server that it has a new logger.    Update seems to work, so the work-around now is to create a logger and then update it.    We should understand why this broke, as this feature is critical to development.",Bug,Critical,Closed,"2015-07-23 22:13:15","2015-07-23 21:13:15",2
"Sonatype Nexus","On discard, filter remains but filtered items restore","I noticed that when I filtered by an item (in this case realm list) and discarded (button at bottom), the filter remained but the list items restored.  This is strange because it subsequently appears the filter is broken (not filtering).  I believe it should clear the filter or not make any changes to the list.  I don't feel strongly one fix or the other.    I did not check older NX3 or NX2 at this time.  Noticed this with Debug on.",Bug,Trivial,Closed,"2015-07-22 15:17:42","2015-07-22 14:17:42",2
"Sonatype Nexus","RepositoryCombobox#includeAnEntryForAllRepositories() fails on UI","Seems that tasks having descriptors using {{RepositoryCombobox#includeAnEntryForAllRepositories()}} causes UI errors, rendering UI unusable.",Bug,Major,Closed,"2015-07-22 13:53:59","2015-07-22 12:53:59",0.5
"Sonatype Nexus","NuGet group repository does not respect latest version filters","When searching for components across members of a group repository, a component ID at 2 different versions (one in each member repository) both report that they are the latest version in the generated feed, which is logically impossible.   Recreation:   - publish SONATYPE.TEST.1.0.nupkg to a hosted repo   - publish SONATYPE.TEST.1.1.nupkg to another hosted repo   - search for SONATYPE.TEST on a group repo containing both of the above host repos   - observe that both entries claim to be for the latest version of the component    Test for this condition is presently commented out in NugetGroupIT(search for this ticket), and should be re-enabled to confirm this when fixed.    *Acceptance Criteria:*    XML feed should only contain one latest version of a given package    *Note:*    Browse functionality works as is and hasn't been touched     ",Bug,Major,Closed,"2015-07-22 00:50:08","2015-07-21 23:50:08",3
"Sonatype Nexus","Browse Repository scroll not infinite","Earlier today I built NX3 using NX3 and had the normal 3000+ assets in my system.  I noticed while reviewing something unrelated that on Browse UI, I only saw As and Bs in my component list for my dev group and central repo.  Similarly, in Browse UI for assets I only saw As and Bs.  I checked internal repos and more stuff than As/Bs showed so the items are browsable.  It appears that infinite scrolling is not infinite and it's stopping after 2.5-3 pages.  See attached vid.    I thought maybe this was NEXUS-8988 but the workaround given there (going to a working repo then back) does not fix this.  Also, I don't believe this is an issue with inclusion and more an issue with not being able to see everything.  Because this was working with NEXUS-8988, I believe this recent regression.  The behavior persists even after a browser restart.  It occurs with both Debug on and off.  I see no errors in nexus log or js console (or dev console).    Workaround would be to search, which is lame, but I gave minor priority since it is valid.",Bug,Major,Closed,"2015-07-21 22:19:11","2015-07-21 21:19:11",3
"Sonatype Nexus","NuGet group repository only shows content already cached in proxies","Might need discussion as to how we want this to behave, but presently queries to a NuGet group do not forward to proxies but only consult already cached data for proxies. This is definitely not the behaviour a client would expect when interacting with the group repo; the expectation is that queries to the group repo will do what is required to consult any member repositories and fulfill client requests transparently.  ",Bug,Major,Closed,"2015-07-20 23:07:14","2015-07-20 22:07:14",0.5
"Sonatype Nexus","Publishing to a hosted nuget repo affects the count of components in a proxy repo","I executed a count query against the default nuget.org-proxy repository, published a test package to nuget-hosted, and then re-executed the count query - and the count incremented.    Reproduction:  1. Execute this query to see how many components are available in the nuget.org feed.      2. Publish SONATYPE.TEST.1.0.nupkg to the nuget-hosted repository.  3. Execute the count query again and note that it has incremented despite the activity happening on a different repo      Test for this condition is presently commented out in NugetGroupIT(search for this ticket), and should be re-enabled to confirm this when fixed.      ",Bug,Major,Closed,"2015-07-16 23:33:05","2015-07-16 22:33:05",1
"Sonatype Nexus","NuGet Component fetch from group repo does not respect repository ordering","The expectation is that if a component is present in more than one repository, the ordering of group members will determine which one is returned. Presently we just return the first matching record, regardless of the configuration, although the query executed is indeed different.  Given a hosted repository to which I've published a component downloaded from a proxy, both of these queries return the same result regardless of the group membership configuration:      Similarly, browsing a group repository will show the same component regardless of the group membership ordering.    Test for this condition is presently @Ignore in NugetGroupIT, and should be re-enabled to confirm this when fixed.",Bug,Major,Closed,"2015-07-16 22:30:40","2015-07-16 21:30:40",2
"Sonatype Nexus","NuGet assets do not download with correct filename","Finishing asset detail page testing (NEXUS-8255), I noticed that NuGet assets were being listed and downloaded in the form of /SONATYPE.TEST/1.0.  If you rename the download to it's proper name (in this case original file was SONATYPE.TEST.1.0.nupkg) or even improper with a nupkg extension (tried test.nupkg) they work.  So the data is there, I think maybe just malformed slightly somehow.  However, as far as download goes, I imagine it'd be pretty annoying to NuGet users trying to get their assets this way.  Left major because of this.    Asset details are new to Edgy so does not affect older NX3.  I did not check NX2 at this time, tho I suspect unaffected.  Test performed with Debug off.",Bug,Major,Closed,"2015-07-16 18:50:12","2015-07-16 17:50:12",0.5
"Sonatype Nexus","Error switching from second level detail to first level nav","Testing NEXUS-8848, I noticed that I changed from asset details to search another type (raw to maven) and got the attached error.  On further exploration this error seems to fire anytime you switch from a second level detail (such as result from search or a repository from repositories) to another left nav item and does not seem search specific.  Example: Select Repositories, select to edit an existing repository and select Blobstores.    This error occurs with Debug on or off.  Screens are with debug on.  After the error occurs, you cannot see details any longer in the UI.  You can navigate but no new data appears in the frame.  Also expanding the dev console is largely unreadable (though since this occurs with debug off, I doubt this is related).  Thus I am leaving this major.  Refreshing the UI does fix this however.  I did not check older versions of NX3 at this time.  Since there are really no levels I recall in NX2, I doubt this affects NX2 but did not check at this time.  Nothing in the nexus.log.    Full JS:  {quote}  Uncaught TypeError: Cannot read property 'getElementsByTagName' of undefinedExt.define.onModelChanged @ VM2838 Drilldown.js?_dc=1437059614451:203Ext.define.selectModel @ VM2838 Drilldown.js?_dc=1437059614451:348Ext.define.navigateTo @ VM2838 Drilldown.js?_dc=1437059614451:323Ext.define.reselect @ VM2838 Drilldown.js?_dc=1437059614451:176componentListener.(anonymous function).resetdrilldown @ VM2838 Drilldown.js?_dc=1437059614451:101fire @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:10813Ext.define.dispatch @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:43613prototype.fireEventArgs @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:43707fireEvent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:12200Ext.define.loadDrilldown @ VM2877 Drilldown.js?_dc=1437059614587:117fire @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:10813continueFireEvent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:12236fireEventArgs @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:12214prototype.fireEventArgs @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:43704fireEvent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:12200Ext.define.getRenderTree @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:30626Ext.define.render @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:30752Ext.define.renderItem @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:37990Ext.define.renderItems @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:37937Ext.define.renderChildren @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:38450Ext.define.invalidate @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:86323Ext.define.flushInvalidates @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:86161Ext.define.run @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:86604Ext.define.statics.flushLayouts @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:31606Ext.define.statics.resumeLayouts @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:31614Ext.resumeLayouts @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:34197Ext.define.add @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:40221Ext.define.onFeatureSelected @ VM2731 Content.js?_dc=1437059614272:117fire @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:10813Ext.define.dispatch @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:43613prototype.fireEventArgs @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:43707fireEvent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:12200Ext.define.selectFeature @ VM2735 Menu.js?_dc=1437059614276:242Ext.define.onSelection @ VM2735 Menu.js?_dc=1437059614276:225fire @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:10813Ext.define.dispatch @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:43613prototype.fireEventArgs @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:43707createRelayer @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:12521fire @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:10813continueFireEvent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:12236fireEventArgs @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:12214fireEvent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:12200Ext.define.onSelectChange @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:136739Ext.define.doSingleSelect @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:100235Ext.define.doSelect @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:100079Ext.define.selectWithEvent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:99796Ext.define.processSelection @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:136705Ext.define.onRowClick @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:136698fire @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:10813continueFireEvent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:12236fireEventArgs @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:12214prototype.fireEventArgs @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:43704fireEvent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:12200Ext.define.processUIEvent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:102173Base.implement.callParent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:4568Ext.define.processUIEvent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:126587Ext.define.handleEvent @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:102096(anonymous function) @ VM3199:5Ext.apply.createListenerWrap.wrap @ VM2653 baseapp-debug.js?_v=3.0.0-SNAPSHOT&_dc=1437059613505&debug=true:11583  {quote}",Bug,Major,Closed,"2015-07-16 16:30:05","2015-07-16 15:30:05",0.5
"Sonatype Nexus","Yum updates to build promotion repositories are not propagated to their parent group repositories"," Create a yum enabled build promotion profile, and set it up so that it makes it's repositories appear in a yum enabled group repository.    Promote a staging repository into the build promotion profile, then retrieve repodata/repomd.xml through the group repository.  This works.    Now promote a second staging repository into the build promotion repository, and retrieve the repodata/repomd.xml through the group repository again.  The mergerepo command is not run, and the group repository still has the old yum metadata.    I've verified this is still a problem in both 2.11.3 and 2.11.4.  ",Bug,Major,Closed,"2015-07-14 21:49:27","2015-07-14 20:49:27",1
"Sonatype Nexus","Modern testsuite's FormatClientSupport is not thread safe","This is a utility class used by all the modern ITs to derive format specific clients. While the fact it's single threaded did not bother so far, on implementing NEXUS-8839 Concurrency Hotspot ITs the problem popped out.    Circumvention as done in Maven2Client is simple, but fixing the FormatClientSupport itself should be trivial too, we just need to decide what we want.",Bug,Major,Closed,"2015-07-14 16:24:27","2015-07-14 15:24:27",0.5
"Sonatype Nexus","Maven2 group metadata handling bug","In short, the setup: group, that contains two members, one proxy and one hosted. The requested metadata is contained in a proxy (but is also deployed on same path in hosted repeatedly). This setup group should _never_ return 404, as the requested metadata does exists, even under load.    Current code does not uses the fact that merged metadata content is _reusable_, and does an unneeded roundtrip to Storage that introduces concurrency issues with group cache.    ",Bug,Major,Closed,"2015-07-14 16:19:36","2015-07-14 15:19:36",0.5
"Sonatype Nexus","org.sonatype.nexus.proxy.walker.WalkerException: Aborted walking on repository ID='npmjs' from path='/.nexus/trash/'.","Seeing same issue as Nexus-8248 but I am on 2.11.3  What is weird is I've been on 2.11.3 for over a week with NPM repository configured.  This job runs daily and I've only received this error today, and any time I try manually running it today.    {{Task ID: 2  Task Name: Empty the trash every morning  Stack trace:  org.sonatype.nexus.proxy.walker.WalkerException: Aborted walking on repository ID='npmjs' from path='/.nexus/trash/'.   at org.sonatype.nexus.proxy.walker.DefaultWalker.reportWalkEnd(DefaultWalker.java:153)   at org.sonatype.nexus.proxy.walker.DefaultWalker.walk(DefaultWalker.java:118)   at org.sonatype.nexus.proxy.wastebasket.DefaultWastebasket.purge(DefaultWastebasket.java:208)   at org.sonatype.nexus.proxy.wastebasket.DefaultWastebasket.purgeAll(DefaultWastebasket.java:147)   at org.sonatype.nexus.tasks.EmptyTrashTask.doRun(EmptyTrashTask.java:66)   at org.sonatype.nexus.scheduling.AbstractNexusTask.call(AbstractNexusTask.java:163)   at org.sonatype.scheduling.DefaultScheduledTask.call(DefaultScheduledTask.java:418)   at org.sonatype.nexus.threads.MDCAwareCallable.call(MDCAwareCallable.java:44)   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)   at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)   at java.util.concurrent.FutureTask.run(FutureTask.java:166)   at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)   at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   at java.lang.Thread.run(Thread.java:724)  Caused by: org.sonatype.nexus.proxy.ItemNotFoundException: Request is marked as local-only, remote access not allowed from DefaultNpmProxyRepository(id=npmjs)   at org.sonatype.nexus.proxy.repository.AbstractProxyRepository.doRetrieveItem0(AbstractProxyRepository.java:1251)   at org.sonatype.nexus.proxy.repository.AbstractProxyRepository.doRetrieveItem(AbstractProxyRepository.java:1034)   at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:760)   at org.sonatype.nexus.proxy.walker.DefaultWalker.walk(DefaultWalker.java:84)   ... 15 more  Caused by: org.sonatype.nexus.proxy.ItemNotFoundException: Request is marked as local-only, remote access not allowed from DefaultNpmProxyRepository(id=npmjs)   at org.sonatype.nexus.proxy.repository.AbstractProxyRepository.shouldTryRemote(AbstractProxyRepository.java:1050)   at com.bolyuba.nexus.plugin.npm.proxy.DefaultNpmProxyRepository.shouldTryRemote(DefaultNpmProxyRepository.java:281)   at org.sonatype.nexus.proxy.repository.AbstractProxyRepository.doRetrieveItem0(AbstractProxyRepository.java:1068)   ... 18 more  }}",Bug,Major,Closed,"2015-07-14 16:05:36","2015-07-14 15:05:36",1
"Sonatype Nexus","Blobstore size calculations incorrect","Looks like the Blobstore is only reporting back the size of its metadata files and not the actual blob content size. The calculation is set to report on the parent directory of the db file, while the blobs themselves are stored in a sibling folder called 'content'  ",Bug,Minor,Closed,"2015-07-13 22:32:21","2015-07-13 21:32:21",0.5
"Sonatype Nexus","Name field in repository admin needs required field treatment",,Improvement,Minor,Closed,"2015-07-09 18:51:11","2015-07-09 17:51:11",0.5
"Sonatype Nexus","We need help text for everything","Here’s a list of places in the UI missing help text:    + Strict content type validation (repository config)  + Name (repository config, make it clear that we expect an ID, not a human-readable string.)  -+ Raw repository (repository config/browse, need a better name and/or description)- Removed based on discussion on https://groups.google.com/a/sonatype.com/forum/?hl=en#!topic/sonatype-nexus-dev-group/2_GR2cC6jP0  + Query cache size/Nexus trust store (repository config, need better descriptions)  + Not Found Cache enabled (repository config, the intent is clear but not what this does)    (add here!)",Improvement,Minor,Closed,"2015-07-09 18:40:38","2015-07-09 17:40:38",1
"Sonatype Nexus","Drilldown needs a clearer “back” affordance","People don’t trust the browser back button, so we need to provide a way to reset the drilldown that looks like it does what it says it does.",Improvement,Minor,Closed,"2015-07-09 18:38:57","2015-07-09 17:38:57",2
"Sonatype Nexus","Nuget packageId case sensitivity","Nuget presumes that packageId searches will be case insensitive, but our Orient/NuGet component metadata searches are case sensitive.    Symptom:    1. Define a proxy repo for nuget.org  2. Request http://localhost:8081/repository/[repo]/NUGET.CORE/2.8.5    ..throws:    Caused by: java.lang.IllegalStateException: Component metadata does not exist yet          at com.google.common.base.Preconditions.checkState(Preconditions.java:173) [na:na]          at com.sonatype.nexus.repository.nuget.internal.NugetGalleryFacetImpl$3.execute(NugetGalleryFacetImpl.java:273) [na:na]          at org.sonatype.nexus.repository.storage.StorageFacetImpl.perform(StorageFacetImpl.java:249) [na:na]          ... 92 common frames omitted    What's happening is:  1. proxy facet looks for the component by the passed-in package id, 'NUGET.CORE'.  2. It find nothing.  3. NugetProxyFacet.fetch() obtains metadata for 'NUGET.CORE' '2.8.5' - nuget.org is case insensitive, and so returns the feed entry for NuGet.Core 2.8.5, which Nexus stores.  4. Nexus then requests content for NUGET.CORE 2.8.5 - nuget.org complies, but when Nexus tries to look up component metadata to attach the content to, it fails, because it's looking up NUGET.CORE.",Bug,Major,Closed,"2015-07-03 19:14:06","2015-07-03 18:14:06",1
"Sonatype Nexus","Cannot create LDAP with specific settings","I just went to create LDAP and noticed that when configuring User and Group, I could not save with Group Type being Dynamic or without mapping LDAP groups as roles.  There was a validation firing that (if reading correctly) Group Member Format (a variable under Static Group configuration) was required.  See attached and log snip below.  I was able to change to Static Group configuration and create my LDAP.    If you then go back and edit, you can make it dynamic group configuration or remove mapping LDAP groups as roles altogether, but you cannot remove the value from that field.  If you do, it restores it to what you did before you saved.    This occurs with ?Debug on and off.    Editing post-creating is a pretty poor workaround and also 3 of our templates use dynamic groups so appear not to work with this as is, so leaving major.    This worked in some builds of m4, so is at least semi-recent regression.  I did not go back and check pre-Edgy so am not sure how recent.  I also didn't check against NX2, tho this was working last time I attempted it, assuming NX3 specific.  I don't believe this has anything to do with the linked issue, however, linking for thoroughness.    {quote}  2015-07-03 10:57:50,101-0400 ERROR [qtp845392291-218] admin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: ldap_LdapServer.create, java-method: org.sonatype.nexus.ldap.internal.ui.LdapServerComponent.create  com.orientechnologies.orient.core.exception.OValidationException: The field 'ldap_mapping.groupMemberFormat' cannot be null, record: ldap_mapping{emailAddressAttribute:mail,ldapGroupsAsRoles:false,groupBaseDn:null,groupIdAttribute:null,groupMemberAttribute:null,groupMemberFormat:null,groupObjectClass:null,userPasswordAttribute:,userIdAttribute:sAMAccountName,userObjectClass:user,ldapFilter:,userBaseDn:cn=users,userRealNameAttribute:cn,userSubtree:false,groupSubtree:false,userMemberOfAttribute:null}   at com.orientechnologies.orient.core.record.impl.ODocument.validateField(ODocument.java:251) [na:na]   at com.orientechnologies.orient.core.record.impl.ODocument.validate(ODocument.java:1932) [na:na]   at com.orientechnologies.orient.core.record.impl.ODocument.validateEmbedded(ODocument.java:489) [na:na]   at com.orientechnologies.orient.core.record.impl.ODocument.validateField(ODocument.java:302) [na:na]   at com.orientechnologies.orient.core.record.impl.ODocument.validate(ODocument.java:1932) [na:na]   at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.commit(OAbstractPaginatedStorage.java:947) [na:na]   at com.orientechnologies.orient.core.tx.OTransactionOptimistic.doCommit(OTransactionOptimistic.java:590) [na:na]   at com.orientechnologies.orient.core.tx.OTransactionOptimistic.commit(OTransactionOptimistic.java:145) [na:na]   at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.commit(ODatabaseDocumentTx.java:2548) [na:na]   at com.orientechnologies.orient.core.db.document.ODatabaseDocumentTx.commit(ODatabaseDocumentTx.java:2517) [na:na]   at org.sonatype.nexus.ldap.internal.persist.orient.OrientDBLdapConfigurationSource.create(OrientDBLdapConfigurationSource.java:105) [na:na]   at org.sonatype.nexus.ldap.internal.persist.DefaultLdapConfigurationManager.addLdapServerConfiguration(DefaultLdapConfigurationManager.java:133) [na:na]   at org.sonatype.nexus.ldap.internal.persist.LdapConfigurationManager$addLdapServerConfiguration$0.call(Unknown Source) [na:na]   at org.sonatype.nexus.ldap.internal.ui.LdapServerComponent.create(LdapServerComponent.groovy:121) [na:na]   at org.sonatype.nexus.validation.internal.ValidationInterceptor.invoke(ValidationInterceptor.java:53) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet$3.invokeMethod(ExtDirectServlet.java:201) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.StandardRequestProcessorBase.dispatchStandardMethod(StandardRequestProcessorBase.java:73) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:502) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequestsInThisThread(JsonRequestProcessor.java:150) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.process(JsonRequestProcessor.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.RequestRouter.processJsonRequest(RequestRouter.java:83) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.processRequest(DirectJNgineServlet.java:617) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.doPost(DirectJNgineServlet.java:580) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet.doPost(ExtDirectServlet.java:121) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:707) [javax.servlet-api:3.1.0]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:70) [com.google.inject:4.0.0]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.3]   at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.3]   at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:130) [com.sonatype.nexus.plugins.nexus-licensing-plugin:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:92) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) [org.eclipse.jetty.servlet:9.2.9.v20150224]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) [org.eclipse.jetty.servlet:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) [org.eclipse.jetty.security:9.2.9.v20150224]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) [org.eclipse.jetty.servlet:9.2.9.v20150224]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.9.v20150224]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.Server.handle(Server.java:497) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [org.eclipse.jetty.io:9.2.9.v20150224]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) [org.eclipse.jetty.util:9.2.9.v20150224]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) [org.eclipse.jetty.util:9.2.9.v20150224]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  {quote}",Bug,Major,Closed,"2015-07-03 16:13:37","2015-07-03 15:13:37",0.5
"Sonatype Nexus","LastModified time not updating","While testing NEXUS-8255, [~<USER> noticed that in one of my tests, I had uploaded a SNAPSHOT pom and then uploaded it again to see if the fields were updating in the UI but that LastModified was not being updated either in the DB or in the UI.    He writes:  looking at the code in MavenFacetImpl it only updates the last-modified time if this is the first time the file was deployed, or the content attributes passed along with the payload contain a last-modified time. I couldn't spot anywhere that sets the last-modified time in the content attributes before they reached the put method, so this looks like a bug (or there's some code missing). This explains why you didn't see the last-modified time change when you deployed the file again. Also note that when you re-deploy a Maven artifact it will keep the same asset record, but update the blob field in that record to point to the new content.    Since this is a deeper issue than just asset details, I am filing seperately.  I have not checked older NX3 at this time, nor have I checked NX2.  I also haven't checked other repo types at this time either so only put the Maven component above.",Bug,Major,Closed,"2015-07-02 21:02:37","2015-07-02 20:02:37",0.5
"Sonatype Nexus","NX3 conditional GET bugs","This issue gather multiple bugs present in NX3 related to conditional GET support:  - Similarly to NX2 NEXUS-8930, NX3 sends too much headers violating the RFC  - Response 304 to conditional GET via groups result in 404 final response  ",Bug,Major,Closed,"2015-07-02 13:25:48","2015-07-02 12:25:48",1
"Sonatype Nexus","outbound http connections may be immediately closed on 304 response with ETAG instead of pooled","This affects latest NX2 it seems. NX2 claims it will keep alive the connection (default with HTTP/1.1) and even ensures it with a header if client is HTTP/1.0 (as with that protocol level extra header {{Connection: keep-alive}} is needed), but then immediately drops connection on response is sent. This leaves no chance for connection pooling clients (like NX2/NX3, unlike Wagons) to properly handle connections, as connections returned to pool and believed to be alive will be actually immediately closed.    OOTB Jetty 8 does not do this, this has to be something in NX2.    Either fix the   a) connection to remain alive if said so, or   b) as simpler fix just add Connection: close header when client is HTTP/1.1 and prevent addition of (done by Jetty) Connection: keep-alive header when client is HTTP/1.0    Marked as affects 2.11.3, but it might affect other 2.x versions too.",Bug,Major,Closed,"2015-07-02 11:24:26","2015-07-02 10:24:26",1
"Sonatype Nexus","Browse UI requires repository-admin privileges","In order to use the Browse UI, you need repository-admin read privileges (like below example).  This is contradictory to search which you just need repository-view-* privileges (you need these for Browse UI as well).  I am pretty confident this is a bug, because anonymous by default cannot use Browse UI (because of this).  By default, anonymous shows it has no permission to see any repositories in Browse UI.    Bringing up at least for triage; in case not a bug, don't think intuitive so I think worth documenting.    Browse UI is new to Edgy so does not affect older NX3.  I did not check NX2 at this time.    Example:  ",Bug,Major,Closed,"2015-07-01 21:54:28","2015-07-01 20:54:28",0.5
"Sonatype Nexus","Messages slow to fully appear sometimes","I noticed that saving a repository has a slower save message appearing than other pages (see vid).  Notibly it seems to pause about 1/2 through it's travel to appear and then hang for a brief period of time.  This does not occur on other pages, so I feel something weird with repository.  I tried creating a raw hosted and the same issue occurs so is not just Central (shown in vid).  It was a little better tho, so either proxies may be slower or Central may be slower.    I was waffling whether to file or not but am concerned something else might be going on that might cause this behavior (though nothing obvious on screen).  I asked [~<USER> who recommended I go ahead as we need to resolve performance related problems.    This does occur in m4 in OSS, so is not caused by the link, as far as I can tell (was initially testing in Edgy PRO bundle).  I did not check NX2 at this time.  This occurs with debug on and off.  Nothing notable in Console or log at default levels.",Bug,Trivial,Closed,"2015-07-01 15:40:48","2015-07-01 14:40:48",0.5
"Sonatype Nexus","Proxy repo remote storage validation overly restrictive","Create a maven2 proxy repo, the allowed values for the remote storage location seem overly restrictive.    Allowed:  http://localhost:8082/nexus/content/groups/public/    Not allowed (but should be allowed, no?)  http://strident:8082/nexus/content/groups/public/    Allowed:  http://strident.com:8082/nexus/content/groups/public/",Bug,Major,Closed,"2015-07-01 00:07:44","2015-06-30 23:07:44",0.5
"Sonatype Nexus","Raw repository does not emit any content modified header and does not support inbound conditional GETs","This has an implication, that in case of a Maven Site deploy into raw-hosted, on browser load everything is served up up to the last CSS, JS etc bits. And this repeats over and over for every page load putting unnecessary load on NX3.",Bug,Major,Open,"2015-06-30 19:44:06","2015-06-30 18:44:06",1
"Sonatype Nexus","Seeing undefined: in NX.Permissions usage","... almost certainly a bug somewhere in how permissions are being used in the UI.",Bug,Minor,Closed,"2015-06-30 19:06:57","2015-06-30 18:06:57",1
"Sonatype Nexus","archived request.log name format should be more easily recognized as a log file","Current Nexus request log archive name format is: {{request.log.%d{yyyy-MM-dd}.gz}}        {noformat:title=Example archive names}  request.log.2015-01-01.gz  request.log.2015-01-02.gz  request.log.2015-01-03.gz      It is more convenient for names to end with .log so that they can be more easily recognized as log files by tools and shell.     The default archive name could be changed to {{request-%d{yyyy-MM-dd}.log.gz}} which would result in names like this when unpacked:    {noformat:title=Example new format unpacked archive names}  request-2015-01-01.log  request-2015-01-02.log  request-2015-01-03.log  {noformat}            ",Improvement,Minor,Closed,"2015-06-30 18:28:56","2015-06-30 17:28:56",0.5
"Sonatype Nexus","NX3 proxy fetches more than should","It seems we have a bug in ProxyFacetSupport: indicate verified is invoked only after remote responds with 304, but it never happens with servers not supporting conditional GETs. Also, on servers supporting conditional GETs, it will be (potentially close) GET request that will mark the cache content as verified, not honoring maxItemAge to perform re-check.    Problems in short:  1. - _refetches always_ if remote does not support conditional GET (as no 304 arrives)  2. - fetches _two times_ if remote does support conditional GET (as 304 will arrive on 2nd fetch, that is made conditional from cached content)  3. - fetches on every stale detected content if the format does not support lastModified and/or ETag. In this case _unconditional GET_ is issued, and remote item is refetched _over and over again, even if the locally cached one is same_.    Fix for first two should be trivial in ProxyFacetSupport, just indicate verified on initial fetch too (200). For 3rd issue, proper Content support is needed.",Bug,Major,Closed,"2015-06-29 17:10:04","2015-06-29 16:10:04",1
"Sonatype Nexus","add elapsed request time to request.log","Our request logs log by default using the 'common' pattern:    {{%h %l %u [%t] %r %s %b}}    The {{%t}} field prints the response time instant. Example:    127.0.0.1 - - [29/Jun/2015:12:32:15 -0300] GET /nexus/service/local/lvo/nexus-pro/2.11.4-SNAPSHOT?_dc=1435591934977 HTTP/1.1 404 657    When correlating when the  request is first received ( useful when coordinating requests with builds or other external scheduled jobs, it would be helpful to determine the elapsed time of the request from the request logs. This can be accomplished by using this pattern in logback-access.xml:    {{%h %l %u [%t] %r %s %b %elapsedTime}}    We should adjust the default request log pattern to include elapsed time.  ",Improvement,Minor,Closed,"2015-06-29 16:41:22","2015-06-29 15:41:22",0.5
"Sonatype Nexus","releasing a yum enabled staging repository overwrites yum metadata in release repository","When a yum enabled staging repository is released it's yum metadata is copied into the target release repository.  This is incorrect, it means that the only rpm's available through the release repository are the ones that were in staging until the createrepo command finishes running.    The contents of the repodata directory should not be copied from the staging repository to the target release repository.    Note that this also occurs with build promotion repositories.    ",Bug,Major,Closed,"2015-06-26 20:24:31","2015-06-26 19:24:31",0.5
"Sonatype Nexus","Exception when clicking into Unattached asset details","While testing the Browse UI (NEXUS-8888 and various other tickets), I clicked into Unattached Assets and into details and got the attached errors (and it does not show more details).  While NEXUS-8255 is not complete, I mentioned to [~<USER> and he asked me to file seperately.  This is that ticket.    There is nothing in the nexus.log for this error (at default levels).    This is a recent error, likely caused by initial NEXUS-8255 efforts, however, there were limited details shown before NEXUS-8255 efforts.  Just stating this because I know this error does not occur in m4.  This also does not occur in NX2.",Bug,Major,Closed,"2015-06-24 17:18:42","2015-06-24 16:18:42",0.5
"Sonatype Nexus","If CLM server is configured, but CLM server isn't running, capabilities UI will not render","Configure a CLM server under administration/clm.  Then shut down the CLM server.  Now go to administration/capabilities.   This will fail with a UI timeout.    This is particularly bad because there is no way to clear out the CLM server settings under administration/clm, the UI won't let you.    To fix this, you need to temporarily increase your UI timeout to be > 90 seconds, then go to the CLM capability (when it finally loads) and disable it.",Bug,Major,Closed,"2015-06-24 16:28:53","2015-06-24 15:28:53",0.5
"Sonatype Nexus","Task state says Starting even when task is complete and refreshed","While testing NEXUS-8857, I noticed that after you had run a task and even after you clicked refresh (in the header), the task state said Starting.  I have seen this before (maybe talked to someone about it) but the test made me see it again.  I did not see a ticket so am filing one to get this cleaned up.  I do not believe it was caused by NEXUS-8857 fix however am linking for completion.  [~<USER> noted he preferred another ticket as well.    You can workaround this by leaving the page and returning (like click to HTTP and then back to Tasks) or by refreshing the browser (or more drastic ways=)).    Steps to repro:  1) Create a task (which doesn't seem to matter)  2) Run said task  3) BUG: On the Summary page Status says Starting.  If you follow the Breadcrumb back to the Tasks page the Status of task says Starting.  If you click refresh (in the header) from either scenario, a note says Refreshed but the tasks say starting.",Bug,Minor,Closed,"2015-06-22 19:19:57","2015-06-22 18:19:57",0.5
"Sonatype Nexus","Raw group repo throws exception trying to browse","Attempting to browse a Raw group repo throws this error:  ",Bug,Major,Closed,"2015-06-19 23:22:13","2015-06-19 22:22:13",0.5
"Sonatype Nexus","Most search fields have no partial matching ability","There are two issues with search fields that make them <USER>to use.   # Most fields don’t partial match (e.g. searching for “aether” in the group field will not match “org.eclipse.aether”)   # Fields that do wildcard only match tokens (e.g. searching for “aether” in the keyword field will match “aether-api”, but “aeth” will not match “aether-api”)    Acceptance criteria:  * All fields will behave the same as the keyword field (, *, booleans, etc are all added explicitly if the user wants them)    *Technical Notes*  * This approach may require a reindex. We should either do this automatically on upgrade, or provide a way for folks to reindex if they want the new functionality (the caveat is that this could cause support issues, since support will need to figure out if poor quality search results are stemming from the fact that people haven't reindexed yet).  * Many of the fields that users can search are marked as (string, not_analyzed) which means that to do partial matching we need to use a wildcard query.  * Another approach would be to do a re-index and use an ngram analyzer to get partial matching, but the first approach is simpler (if slower).    The query would look something like this (not valid ES, just pseudo-code to show the structure):    We should also probably switch to a pure term filter if the user quotes the string so they have a way to escape partial matching.",Bug,Major,Closed,"2015-06-18 22:47:24","2015-06-18 21:47:24",5
"Sonatype Nexus","Sorting search results by Repository errors","Testing NEXUS-8846, I noticed that sorting by repository errors.  See attached (screen and dev console) and below (nexus log).  No errors in JS console w/ debug on or off.  I'm 99% sure this was not erroring before NEXUS-8846 but I did not back check at this time.  I also did not check NX2.    I decided to file seperately since sort does work and since [~<USER> is on vacation in case someone else wants to take on this effort.    Making priority minor as this is only important on base search and custom search.    {quote}  2015-06-18 16:55:02,796-0400 ERROR [qtp2087290632-190] admin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: coreui_Search.read, java-method: org.sonatype.nexus.coreui.SearchComponent.read  org.elasticsearch.action.search.SearchPhaseExecutionException: Failed to execute phase [query], all shards failed; shardFailures {[S6eRMgmOTAulJtVqtJMthw][maven-central][0]: SearchParseException[[maven-central][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-central][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-releases][0]: SearchParseException[[maven-releases][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-releases][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-snapshots][0]: SearchParseException[[maven-snapshots][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-snapshots][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget-group][0]: SearchParseException[[nuget-group][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget-group][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget-hosted][0]: SearchParseException[[nuget-hosted][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget-hosted][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget.org-proxy][0]: SearchParseException[[nuget.org-proxy][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget.org-proxy][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][sonatype-grid.release][0]: SearchParseException[[sonatype-grid.release][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[sonatype-grid.release][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][sonatype-grid.snapshot][0]: SearchParseException[[sonatype-grid.snapshot][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[sonatype-grid.snapshot][0]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-central][1]: SearchParseException[[maven-central][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-central][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-releases][1]: SearchParseException[[maven-releases][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-releases][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-snapshots][1]: SearchParseException[[maven-snapshots][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-snapshots][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget-group][1]: SearchParseException[[nuget-group][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget-group][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget-hosted][1]: SearchParseException[[nuget-hosted][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget-hosted][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget.org-proxy][1]: SearchParseException[[nuget.org-proxy][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget.org-proxy][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][sonatype-grid.release][1]: SearchParseException[[sonatype-grid.release][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[sonatype-grid.release][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][sonatype-grid.snapshot][1]: SearchParseException[[sonatype-grid.snapshot][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[sonatype-grid.snapshot][1]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-central][2]: SearchParseException[[maven-central][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-central][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-releases][2]: SearchParseException[[maven-releases][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-releases][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-snapshots][2]: SearchParseException[[maven-snapshots][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-snapshots][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget-group][2]: SearchParseException[[nuget-group][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget-group][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget-hosted][2]: SearchParseException[[nuget-hosted][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget-hosted][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget.org-proxy][2]: SearchParseException[[nuget.org-proxy][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget.org-proxy][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][sonatype-grid.release][2]: SearchParseException[[sonatype-grid.release][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[sonatype-grid.release][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][sonatype-grid.snapshot][2]: SearchParseException[[sonatype-grid.snapshot][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[sonatype-grid.snapshot][2]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-central][3]: SearchParseException[[maven-central][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-central][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-releases][3]: SearchParseException[[maven-releases][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-releases][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-snapshots][3]: SearchParseException[[maven-snapshots][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-snapshots][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget-group][3]: SearchParseException[[nuget-group][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget-group][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget-hosted][3]: SearchParseException[[nuget-hosted][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget-hosted][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget.org-proxy][3]: SearchParseException[[nuget.org-proxy][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget.org-proxy][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][sonatype-grid.release][3]: SearchParseException[[sonatype-grid.release][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[sonatype-grid.release][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][sonatype-grid.snapshot][3]: SearchParseException[[sonatype-grid.snapshot][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[sonatype-grid.snapshot][3]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-central][4]: SearchParseException[[maven-central][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-central][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-releases][4]: SearchParseException[[maven-releases][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-releases][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][maven-snapshots][4]: SearchParseException[[maven-snapshots][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[maven-snapshots][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget-group][4]: SearchParseException[[nuget-group][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget-group][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget-hosted][4]: SearchParseException[[nuget-hosted][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget-hosted][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][nuget.org-proxy][4]: SearchParseException[[nuget.org-proxy][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[nuget.org-proxy][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][sonatype-grid.release][4]: SearchParseException[[sonatype-grid.release][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[sonatype-grid.release][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }{[S6eRMgmOTAulJtVqtJMthw][sonatype-grid.snapshot][4]: SearchParseException[[sonatype-grid.snapshot][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [Failed to parse source [{from:0,size:50,query:{filtered:{filter:{bool:{must:{term:{format:maven2}}}}}},sort:[{repositoryName:{order:asc}}]}]]]; nested: SearchParseException[[sonatype-grid.snapshot][4]: query[ConstantScore(BooleanFilter(+cache(format:maven2)))],from[0],size[50]: Parse Failure [No mapping found for [repositoryName] in order to sort on]]; }   at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.onFirstPhaseResult(TransportSearchTypeAction.java:238) [na:na]   at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction$1.onFailure(TransportSearchTypeAction.java:184) [na:na]   at org.elasticsearch.search.action.SearchServiceTransportAction$23.run(SearchServiceTransportAction.java:565) [na:na]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_40]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_40]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  {quote}",Bug,Minor,Closed,"2015-06-18 22:04:32","2015-06-18 21:04:32",0.5
"Sonatype Nexus","Change default nuget proxy remote storage URL to https","While testing NEXUS-8454, I noticed that the default nuget proxy remote storage URL was http://www.nuget.org/api/v2/.  I was able to add the s (https://www.nuget.org/api/v2/) and test without issue.  Maven's (Central) defaults to secure.  I asked [~<USER> and he said it was worth filing to add here too.  Imagine this is a superquick change (probably could do it myself) however I wanted to triage in case anyone had any concerns.  So here's the ticket.    This is not a concern in NX2 and affects m4.  I believe the default (CMA) repos were added in m4 but did not check older NX3 than m4 at this time.",Improvement,Minor,Closed,"2015-06-18 17:10:56","2015-06-18 16:10:56",0.5
"Sonatype Nexus","Nuget Passthrough Fails for Skip Tokens","To reproduce:  1. Create a nuget proxy that points to nuget.org, call it 'nuget-proxy'  2. Hit this URL:  http://localhost:8081/nexus/service/local/nuget/nuget-proxy/Search()?$filter=IsLatestVersion&$orderby=DownloadCount%20desc,Id&$skip=0&$top=1000&searchTerm=''&targetFramework='net45'&includePrerelease=false    3. At the bottom of the XML reply, there's a skip link: <link rel=next href=...> After decoding from it being an XML attribute, and URL decoding, it will probably look like:    http://localhost:8082/nexus/service/local/nuget/nuget-proxy/Search?searchterm=''&$filter=IsLatestVersion&$orderby=DownloadCount desc,Id&$top=960&$skiptoken=1871245,'Microsoft.AspNet.WebPages.WebData','Microsoft.AspNet.WebPages.WebData','3.2.3'    4. Visit that URL in a browser.  5. Nexus will, in turn, try to get appropriate content from Nuget.org - unfortunately, the Nexus-specific $skiptoken makes no sense to Nuget, which returns a 400 error, with a big exception in the Nexus console.    FTR this is only visible to administrators, since the client is shielded from Nexus<->upstream errors; Nexus returns page 2 to the client just fine.",Bug,Minor,Closed,"2015-06-17 22:21:52","2015-06-17 21:21:52",2
"Sonatype Nexus","Capabilities: Changing state does not change related aspects of UI","In Capabilities when you change the state the following items do not immediately update which could lead to confusion.    * The enable/disable buttons do not switch to reflect that one is no longer selectable and the other is  * The state (in the summary tab) text remains as it was  * If using the buttons, the enable this capability checkbox does not check/uncheck.  If using the checkbox, it remains correct.    If you leave the Capability and return, everything shows correct but then can get out of sync again upon next action.    See attached vid with one example.  If you need more, let me know.    If this seems familiar, I believe [~<USER> had mentioned this before but I could not repro so he said maybe fixed.  If not regression, this may be intermittant but does not seem so to me right now.  [~<USER> also asked if there was already a ticket for this but I did not see one.    This occurs with Debug on and off.  No errors in nexus log or js console.  I did not back check NX3 or NX2 at this time.    Steps to reproduce:  1) Load fresh NX install  2) From System>Capabilities, Create Capability - Base URL: Force (for example, any one should do; one already created probably ill advised)  3) Click to edit.  Note State on the Summary tab is Active.  4) Click Settings tab.  Note active button is Disable and checkbox is checked (signifying Enabled).  5) Click Disable button.  BUG: Checkbox remains checked (signifying Enabled) and active button remains Disable.  If you click back to the Summary tab, you'll note the state is still active.",Bug,Minor,Closed,"2015-06-17 19:03:23","2015-06-17 18:03:23",0.5
"Sonatype Nexus","Task shows Unknown running on STARTING","After running the Rebuild Maven Repository Metadata task, I refreshed to see the status and noticed it said Unknown running.  This appears to be the default return.  Analysis from [~<USER> states the task may be STARTING and suggestion is to add a state for that.    I feel like this may be a recent change but maybe just unlucky timing on my side.  I did not check older NX3 (task (re)added in m4) or NX2 at this time.  I waffled between Bug and Improvement; bug for now but made it trivial.  Debug was off when I noticed this.",Bug,Trivial,Closed,"2015-06-17 16:50:28","2015-06-17 15:50:28",0.5
"Sonatype Nexus","outbound ssl sockets do not timeout if the remote does not respond","Nexus versions 2.8.0 through to 2.11.3 are vulnerable to outbound SSL Socket Connections never timing out if the remote server HTTPS socket does not respond.    h4. Cause    - Nexus 2.8 introduced a dependency on an HTTP client version ( 4.3.x ) that had a SSL socket timeout bug: [HTTPCLIENT-1478|https://issues.apache.org/jira/browse/HTTPCLIENT-1478]  - the fix for the HTTPCLIENT bug also requires a code change in the SSLConnectionFactory that Nexus uses, so upgrading to httpclient-4.3.6 is not enough to fix the issue.    h4. Symptoms  - the Nexus outbound HTTP connection pool for the host in question can become depleted  - inbound requests to a proxy repository mapped to a https://remotehost can become blocked waiting for other socket bound threads to complete. This includes requests to group repositories that have the proxy repository as a member.  - multiple thread dumps take over serveral minutes will show the same thread ids stuck on socket reads ( at java.net.SocketInputStream.socketRead0(Native Method) )  {noformat:title=Example Waiting Thread}  qtp812882942-195540 id=195540 state=RUNNABLE (running in native)  at java.net.SocketInputStream.socketRead0(Native Method)  at java.net.SocketInputStream.read(SocketInputStream.java:152)  at java.net.SocketInputStream.read(SocketInputStream.java:122)  at sun.security.ssl.InputRecord.readFully(InputRecord.java:442)  at sun.security.ssl.InputRecord.read(InputRecord.java:480)  at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:927)  at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1312)  \- locked java.lang.Object@63017956  at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1339)  at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1323)  at org.sonatype.nexus.apachehttpclient.NexusSSLConnectionSocketFactory.connectSocket(NexusSSLConnectionSocketFactory.java:127)  at org.apache.http.impl.conn.HttpClientConnectionOperator.connect(HttpClientConnectionOperator.java:125)  at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:319)  at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:363)  at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:219)  {noformat}    h4. Temporary Workaround  If available, change the remote URL of the proxy repository to an http connection instead of an https connection.    Restart nexus to clear any stuck sockets.      ",Bug,Critical,Closed,"2015-06-17 16:24:59","2015-06-17 15:24:59",0.5
"Sonatype Nexus","remote.storage.outbound logging reports protocol downgrade when there isn't one","Configure a Maven 2 snapshots proxy to http://repo.fusesource.com/nexus/content/repositories/snapshots/    Enable remote.storage.outbound logging in Nexus.     Make any artifact request to this proxy. You will see log messages printed that a protocol downgrade occurred. This is not true. Protocol was always http.        Expected:   - avoid this misleading logging message  - include the absolute source URI if possible, not just the relative path  - include the source repository id if possible  - indicate status code causing the redirection 302 or 301",Bug,Minor,Closed,"2015-06-17 15:02:07","2015-06-17 14:02:07",0.5
"Sonatype Nexus","Anonymous admin errors when creating/verifying LDAP","While logged in as anonymous with admin role, I was creating an LDAP connection and noticed that when I tried to Verify Mapping or Create, I got the below error.  It appears you have to be authenticated to do this, which to me infers the anonymous role should not be granted this capability at all (or this is wrong).    I did not check older NX3 or NX2 at this time.    ",Bug,Minor,Closed,"2015-06-16 22:44:02","2015-06-16 21:44:02",1
"Sonatype Nexus","add uptime log message on shutdown","Bad things can sometimes happen during a Nexus shutdown process. Usually Nexus is restarted soon after. A support zip includes the Nexus intialization time/start time. However if something bad happens during shutdown, it is sometimes useful from examining log files to know how long Nexus had been running just before the shutdown.    These messages are currently printed on shutdown start:        This is a request that as early as possible ( perhaps as part of the rather generic Destroying message ), Nexus also print a log line on shutdown initialization which indicates the total 'uptime' Nexus had before being asked to shutdown.    Something like: uptime 11 days 12 hours 13 seconds. This way, we know what log files to look at for the last Nexus startup before shutdown.  ",Improvement,Minor,Closed,"2015-06-16 22:12:56","2015-06-16 21:12:56",0.5
"Sonatype Nexus","improve robustness to orientdb shutdown after stopping the store","The attached log shows a graceful shutdown on Windows and a message about a corrupt OrientDB because the database.ocf file was zero bytes.    There's a potential flaw in the NPM shutdown logic where an exception while stopping the store means we don't go on and cleanly shutdown OrientDB: https://github.com/sonatype/nexus-oss/blob/nexus-2.11.x/plugins/npm/nexus-npm-repository-plugin/src/main/java/com/bolyuba/nexus/plugin/npm/service/internal/orient/OrientMetadataStoreLifecycle.java#L56    This doesn't explain why the state transition failed ( in the attached log ), but adding a try...finally block here should avoid leaving OrientDB in an odd state when it does happen.  ",Bug,Minor,Closed,"2015-06-16 20:48:16","2015-06-16 19:48:16",0.5
"Sonatype Nexus","Error/non-action when searching while searching","[~<USER> noted the attached; you receive an error with ?debug on if you are drilled down into search results and attempt a search again.  With debug off, there is no error, however, the second search still does not work.    He writes:  Uncaught Ext.data.Store.getById(): getById called for ID that is not present in local cache    Repro steps:  search for something, drill down into it, then use the search in the top nav bar to look for something else    Did not check older NX3 or NX2 at this time.",Bug,Minor,Closed,"2015-06-16 20:11:41","2015-06-16 19:11:41",0.5
"Sonatype Nexus","Browse repository filtering of components shows results from outside of repo","Filtering on component/asset list for a specific repository seems to show matching names/groups from other repositories.  For example, if filter in the nuget hosted repo, I see results from the maven proxy.  Version seems unaffected by this, so may be a fix there.    Browse UI is new to Edgy so did not back check NX3.  I did not check NX2 at this time.  This occurs with debug on and off.",Bug,Major,Closed,"2015-06-16 18:34:37","2015-06-16 17:34:37",0.5
"Sonatype Nexus","Column sorting search does nothing?","Noticed that sorting by column does not appear to do anything now with infinate scroll implemented.  If this is intentional, recommend disabling the column sorting on Search because it gives a false impression it will do something.  I doubt this is intentional though, since it works with Browse UI.    Infinate scroll was removed in Edgy so did not back check NX3 (where I believe this works).  I did not check NX2 at this time.  Debug was off for this test.",Bug,Major,Closed,"2015-06-16 15:28:55","2015-06-16 14:28:55",1
"Sonatype Nexus","Group and version can show blank even when not used","Testing Browse UI, I noticed that there was cases where the group and version showed blank even when not used.  There's an acceptance criteria to 'Output Zero with a slash for unattached assets that we don't have version/group data on' but none for group or version.  I believe this was discussed in phone or hipchat however, so am making an improvement ticket.    Scenarios I noticed:  * Nuget items have no group but have no Zero with a slash. Field currently displays blank.  * Raw items have no version but have no Zero with a slash. Field currently displays blank.  * Raw items interestingly have group defined as /. I feel like this could potentially be Zero with a slash as well, but I may be missing a level of detail. Maybe / is useful?  * -- Unattached Assets -- have no group or version but show blank.  This is even weirder to me considering the criteria (stated above) says use it for the other fields.",Improvement,Trivial,Closed,"2015-06-16 15:08:36","2015-06-16 14:08:36",0.5
"Sonatype Nexus","Browse UI sort order is case sensitive","I noticed that the Browse UI sort order is case sensitive.  I assume this is a bug, as if I am looking for U, I prefer not to look 2 places.    I did not check NX2 at this time.  This function is new to NX3.  Debug was off during this test.    NOTE: I got this data by building NX3 using NX3.",Bug,Minor,Closed,"2015-06-16 15:02:23","2015-06-16 14:02:23",0.5
"Sonatype Nexus","UI Component and Asset details page urls should be transportable","As a User I would be able to copy the link for the page I am looking at and share that link with someone else.    [~<USER> noticed that if you copy a link for an element you are looking at details for, when you hit the bookmark it takes you to the base Browse UI page (selecting a repo).  I verified this and the fact it does not occur for search, although likely will be an issue for any of our Drilldown views which require multiple levels of context during normal navigation.    This is new to NX3 and NX2 is not browsable in this exact way (but is bookmarkable for the non-tree/path version).",Bug,Major,Closed,"2015-06-15 18:54:06","2015-06-15 17:54:06",0.5
"Sonatype Nexus","remote.storage.outbound logger should include http response status and have consistent format","remote.storage.outbound logger prints useful outbound request information in a compact format.    One useful addition to the log message would be the response http status code. This can help detect remote problems more quickly, and can help infer what/why Nexus responded to an inbound request.    Additionally, the npm plugin should log outbound requests in the same format as other proxy repositories do.",Improvement,Minor,Closed,"2015-06-15 18:18:52","2015-06-15 17:18:52",0.5
"Sonatype Nexus","Improve browse no results message","The new browse UI simply says Undefined when there are no contents (see attached).  Filing to get this message improved.    NX2 does not have this issue because as far as I can tell there's always content (even just an empty base folder).  This is newly introduced to NX3 (post-legacy).    Up for discussion but recommend a message like: There are no _ in this repository (that you have permission to see) where _ is component or asset, I think for now, component.  I am unsure about the security portion but it would be more clear were we to have restriction on viewing specific components within a repo.",Improvement,Minor,Closed,"2015-06-15 17:14:41","2015-06-15 16:14:41",0.5
"Sonatype Nexus","service/local/repository_statuses can have performance implications with large numbers of repositories","When Nexus has a large number of repositories, particularly staging repositories, performance of the UI can degrade viewing the  repository list, and this can also impact the performance of the server overall.    h4. Setup  Configure Nexus with  - a single hosted maven 2 release repo  - a single Central Repository proxy repo  - a staging profile and single staging repository ( represents a Nexus managed repo )  - a single maven 2 group repo containing both all other repos    h4. Test 1  h5. Steps  1. Login to Nexus as an admin user.  2. Click Repositories list to show it.  3. Notice Nexus sends two requests to /nexus/service/local/repository_statuses - for each repository, Nexus decides if the user has view/read permissions.  - the first request responds with 202 accepted and a list of the statuses of all repositories  - the second request approx. 5 seconds later responds with 200 and data including remoteStatus of all proxy repositories is included - the statuses of the proxy repositories are updated with the remoteStatus value changed from UNKNOWN to their blocked status ( AVAILABLE, AUTO_BLOCKED, etc. )    h4. Test 2  h5. Steps  1. Configure your browser to use an intercepting proxy. Set a breakpoint to never respond to ( block but do not return ) /nexus/service/local/repository_statuses requests - this is to simulate a Nexus instance which is slow to respond because it is busy evaluating permissions.  2. Login to Nexus as an admin user.  3. Click Repositories list to show it.  4. Notice Nexus sends a *new* /nexus/service/local/repository_statuses request every 5 seconds until very first request times out due to UI timeout. Nexus decides if the user has view/read permissions per repository for each of these requests.    h4. Expected  - When the repository list UI filter is displaying the User Managed repositories list, the repository_statuses resource need not include data for, or perform permissions checks on Nexus managed repos not even displayed to the end user.  - Nexus UI should limit number of repository status requests made to the backend. For example, can the two requests be combined? Can only proxy repos be evaluated when the remote status needs updating in the UI.  - Nexus should not retry these potentially expensive requests every 5 seconds if the first request is simply slow to respond    NOTES:  - Potentially explore a no op function for status  - Potentially only show status for Admin users",Bug,Major,Closed,"2015-06-15 16:04:58","2015-06-15 15:04:58",0.5
"Sonatype Nexus","outreach does not detect http global configuration changes","Configure nexus with proxy host {{a.proxy:8888}}.  Disable Caching in the outreach capability. ( only required to make validation easier )  Configure org.apache.http logger at DEBUG level.  Trigger an outreach bundle fetch ( reload welcome page )  Notice proxy is used :     jvm 1    | 2015-06-12 17:05:07,071-0300 DEBUG [qtp333052202-88] anonymous org.apache.http.impl.execchain.MainClientExec - Opening connection {}->http://a.proxy:8888->http://sonatype-download.global.ssl.fastly.net:80    Change the http proxy in nexus to be {{b.proxy:8888}} and save.  Trigger an outreach bundle fetch again.  Notice that the connection is still being made to a.proxy and not b.proxy.    Expected: b.proxy should be used for all existing connections.  ",Bug,Minor,Closed,"2015-06-12 21:10:16","2015-06-12 20:10:16",0.5
"Sonatype Nexus","ConcurrentCleanupTest is flaky","This test seems to be timing-sensitive to a degree that causes Bamboo builds to fail from time to time.  We should tighten this or perhaps jettison it.    For instance: http://bamboo.s/browse/NX3-OSSF425-1    The exception is:    {{java.lang.AssertionError:   Expected: a collection with size <0>       but: collection size was <1>   at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)   at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:8)   at org.hamcrest.MatcherAssert$assertThat.callStatic(Unknown Source)   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:53)   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:157)  (2 more lines...)}}",Bug,Major,Closed,"2015-06-11 19:41:12","2015-06-11 18:41:12",1
"Sonatype Nexus","add useful logging for siesta/wonderland/authenticate resource username mismatch","When a request as follows, end user gets a 400 status response and message Username mismatch:        The problem is the user was authenticated as anonymous user because credentials were only in the payload and not in Basic Auth headers. Since anonymous username != payload username, we return 400.    Problem is this is <USER>to diagnose without debug logging and a better understanding of what username mismatches.    For example, end user may also send basic auth header username which can authenticate, but the encoded payload values are encoded incorrectly - same problem, user is left wondering where the problem lies.    This can be improved with a simple logging adjustment.    Expected:  - log at WARN the authenticated username and payload username if they do not match  - log at DEBUG the decoded usernames before the match attempt    Reference: https://sonatype.zendesk.com/entries/39800446",Improvement,Major,Closed,"2015-06-11 16:38:17","2015-06-11 15:38:17",0.5
"Sonatype Nexus","Only show latest SNAPSHOT version in Search results","Published SNAPSHOTs appear in search results with their raw timestamped version, when the expectation is that we can search at the x-SNAPSHOT version and find only the latest one.    *Acceptance criteria*  * Show only the latest snapshot in the search results (our assumption is that people don't care about older snapshots)    h5. Technical Notes  * To accomplish this we'll have to parse the version string from the results to pull out the timestamp.  * Possibly also we can pull the latest version from maven-metadata.xml",Story,Minor,Done,"2015-06-09 18:01:20","2015-06-09 17:01:20",5
"Sonatype Nexus","Outreach content not showing","With todays build at least (not sure about last couple of days) the outreach content no longers seems to show in the Welcome feature view.    The bundle seems to be downloaded into /data/tmp/outreach (two in fact in my case) with zero byte .metadata files.    Nothing is showing in the UI though.",Bug,Major,Closed,"2015-06-09 18:00:51","2015-06-09 17:00:51",1
"Sonatype Nexus","Equivalent attribute treatment in search","Component search in Nexus 3 has a bunch of attributes, where conceptually the following should be the case.    group = maven.groupId  name = maven.artifactId    Respectively a custom search for the same term e.g. 'maven-surefire-plugin' or 'junit' using either criteria should show the same results.    This is not the case.",Bug,Major,Closed,"2015-06-09 16:53:57","2015-06-09 15:53:57",1
"Sonatype Nexus","KAR files cannot be proxied with strict content validation","I attempted to build NX3 using the m4 rc (what I assume will be rc 2) running mvn clean install -f nexus-oss/pom.xml -U -Dtest=skip.  About 4/5ths in, I got a build failure with:  {quote}  [ERROR] Failed to execute goal on project nexus-base-template: Could not resolve dependencies for project org.sonatype.nexus.assemblies:nexus-base-template:karaf-assembly:3.0.0-SNAPSHOT: Could not find artifact org.apache.karaf.features:framework:kar:3.0.3 in local-nexus (http://localhost:8081/repository/dev/) -> [Help 1]  {quote}    The component appeared to be there however (http://repo1.maven.org/maven2/org/apache/karaf/features/framework/3.0.3/).    With help from the [~<USER> and the team, we discovered that strict content validation was preventing KAR files from being proxied.  [~<USER> noted that 'looking at the describe output with validation unchecked Nexus seems to think the kar file is audio/midi which is odd'.    This should be reproducable by building Nexus as above.  On repro, recommend clearing repository (rm -rf ~/.m2/repository) to make sure you don't get a cached copy.  I did this before I tested the build as well.    I did not check older NX3 at this time.  I'm pretty sure NX2 is unaffected.",Bug,Blocker,Closed,"2015-06-09 16:42:48","2015-06-09 15:42:48",0.5
"Sonatype Nexus","Maven model and search are missing version","The maven component model contains maven2.artifactId and maven2.groupId but it is missing maven2.version. This is a bug according to discussions with Jason",Bug,Major,Closed,"2015-06-09 16:39:03","2015-06-09 15:39:03",0.5
"Sonatype Nexus","Modal not bound to enter key","While changing a users password through Security>Users, I entered the new password twice and hit enter.  Nothing happened.  I was able to continue using the mouse and clicking Change Password.  The authentication modal just before this allowed enter, so I'm assuming this is a bug.",Bug,Trivial,Closed,"2015-06-08 14:34:42","2015-06-08 13:34:42",0.5
"Sonatype Nexus","task-update permission required to create","With tasks-read and tasks-create permissions, I can click the button to create a new task however, I cannot access some of the fields (including the required ones in both of the current tasks).  Oddly, I can access some of the fields.    Once I add tasks-update permission, the tasks become creatable.  Not only does this seem odd but it's not how any of the other permissions I've tested function, so I'm filing for eval.    I did not test older NX3 or NX2 at this time.  Debug off during these tests.",Bug,Major,Closed,"2015-06-05 23:29:10","2015-06-05 22:29:10",0.5
"Sonatype Nexus","Index creation does not take name case into account","When checking to see if an index already exists the raw repository name is used, but elasticsearch stores indices in lowercase only. This leads to an exception being thrown on update as we try to create the same index again.        Any repository created with uppercase letters can be used to trigger this behaviour; on an update from the UI you will be greated with a 'facet failed to start' message.",Bug,Major,Closed,"2015-06-04 18:18:39","2015-06-04 17:18:39",0.5
"Sonatype Nexus","HTTP retry does not retry in expected situations","While testing NEXUS-8712, I was attempting to verify that the HTTP timeout retry actually worked.  After some discussion with [~<USER>, [~<USER> and [~<USER>, I was unable to find a situation where the HTTP retry functioned.    Alin noted that:  Not every exception will result in a retry.  The following will not be retried:  InterruptedIOException  UnknownHostException  ConnectException  SSLException    <USER>and Rich believe InterruptedIOException (more specifically SocketTimeout) and ConnectException should retry.",Bug,Major,Open,"2015-06-04 14:57:59","2015-06-04 13:57:59",2
"Sonatype Nexus","NuGet push causes 500 errors when nuget realm not active","Testing NEXUS-8721, I changed a file from xml into a nupkg file then tried to upload it to Nexus using curl (curl -u admin:admin123 -X PUT -v -include -F package=@fake.nupkg http://localhost:8081/repository/nuget-hosted/) [strict content validation on]  As expected it errored, but the error is error 500 the debug starts  2015-06-03 17:44:45,516-0400 ERROR [qtp2060633588-111] admin com.sonatype.nexus.repository.nuget.internal.NugetPushHandler - Unknown error .    I asked [~<USER> and he said worth filing to fix up.    I did not check older NX3 at this time (NX2 is older code and not relavent to check against).    Full trace here:  ",Bug,Minor,Closed,"2015-06-03 22:56:48","2015-06-03 21:56:48",2
"Sonatype Nexus","Nexus startup script error","Starting nexus on Ubuntu 14.04 with the following commands    {code:none}  nexus-3.0.0-b2015020701/bin/nexus      This is caused because of the == operator(bashism) used in here and ubuntu defaults at linking /bin/sh to dash. Can consider replacing the == operator with = operator ?    {code:none}  ls -la /bin/sh    lrwxrwxrwx 1 root root 4 Jul 20  2014 /bin/sh -> dash  {code}    Note that nexus is started although the error is thrown.",Bug,Trivial,Closed,"2015-06-03 22:43:16","2015-06-03 21:43:16",0.5
"Sonatype Nexus","Generic exception occurs with some NuGet errors","With help from [~<USER> and [~<USER>, it was revealed that the error I received while testing NuGet was a generic 500 and that needs to be made into a specific error.    I noticed this twice and will put details below, however, only one case was reproducable.    A) While testing NEXUS-8714 (MacOSX), I unintentionally left my HTTP Proxy configured when running the curl.  This generated the error every time.    Steps to repro:  1) From Security>HTTP, check HTTP Proxy.  Configure a non-working proxy (mine was Charles defaults without Charles on; so HTTP proxy host = localhost, HTTP proxy port = 8888).  Save.  2) From console run curl from NEXUS-8714, curl -v --user admin:admin123 http://127.0.0.1:8081/repository/nuget-group/Microsoft.AspNet.WebApi.Client/5.2.2 -o test.nupkg    B) While testing NEXUS-8611 (Windows7), I tried to use the nuget command line to install FaceSharp (nuget install FaceSharp -source NX3Proxy).  This did not complete with an error 500 on the command line screen (see attached) but also with the error occurring.  This was not reproducable.  I suspect after successful install this was caused by a timeout that may be able to be reproduced with throttling if my suspicions are right.  But as such there are no steps at this time.    I did not test older NX3 or NX2 at this time, though I suspect (at least in the case of NX3) the issue is because of new NuGet (revamped in m4).    Error in both cases:  {quote}  2015-06-02 17:45:03,698-0400 WARN [qtp756632732-53] admin org.sonatype.nexus.repository.httpbridge.internal.ViewServlet - Service failure  java.lang.UnsupportedOperationException: null  at com.sonatype.nexus.repository.nuget.internal.proxy.NugetProxyFacet.getUrl(NugetProxyFacet.java:115) [na:na]  at org.sonatype.nexus.repository.proxy.ProxyFacetSupport.get(ProxyFacetSupport.java:163) [na:na]  at org.sonatype.nexus.repository.proxy.ProxyHandler.handle(ProxyHandler.java:49) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:78) [na:na]  at org.sonatype.nexus.repository.view.ExceptionHandler.handle(ExceptionHandler.java:38) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:78) [na:na]  at org.sonatype.nexus.repository.security.SecurityHandler.handle(SecurityHandler.java:46) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:78) [na:na]  at org.sonatype.nexus.repository.view.handlers.TimingHandler.handle(TimingHandler.java:46) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:78) [na:na]  at org.sonatype.nexus.repository.view.Context.start(Context.java:116) [na:na]  at org.sonatype.nexus.repository.view.Router.dispatch(Router.java:58) [na:na]  at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:43) [na:na]  at org.sonatype.nexus.repository.group.GroupHandler.getFirst(GroupHandler.java:119) [na:na]  at org.sonatype.nexus.repository.group.GroupHandler.doGet(GroupHandler.java:97) [na:na]  at org.sonatype.nexus.repository.group.GroupHandler.handle(GroupHandler.java:81) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:78) [na:na]  at org.sonatype.nexus.repository.view.ExceptionHandler.handle(ExceptionHandler.java:38) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:78) [na:na]  at org.sonatype.nexus.repository.security.SecurityHandler.handle(SecurityHandler.java:46) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:78) [na:na]  at org.sonatype.nexus.repository.view.handlers.TimingHandler.handle(TimingHandler.java:46) [na:na]  at org.sonatype.nexus.repository.view.Context.proceed(Context.java:78) [na:na]  at org.sonatype.nexus.repository.view.Context.start(Context.java:116) [na:na]  at org.sonatype.nexus.repository.view.Router.dispatch(Router.java:58) [na:na]  at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:43) [na:na]  at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.dispatchAndSend(ViewServlet.java:198) [na:na]  at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.doService(ViewServlet.java:160) [na:na]  at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.service(ViewServlet.java:117) [na:na]  at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]  at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]  at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]  at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]  at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:70) [com.google.inject:4.0.0]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.3]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.3]  at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]  at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.3]  at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.3]  at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.3]  at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.3]  at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.3]  at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:130) [com.sonatype.nexus.plugins.nexus-licensing-plugin:3.0.0.SNAPSHOT]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:92) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]  at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]  at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]  at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) [org.eclipse.jetty.servlet:9.2.9.v20150224]  at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) [org.eclipse.jetty.servlet:9.2.9.v20150224]  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.2.9.v20150224]  at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) [org.eclipse.jetty.security:9.2.9.v20150224]  at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) [org.eclipse.jetty.server:9.2.9.v20150224]  at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) [org.eclipse.jetty.server:9.2.9.v20150224]  at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) [org.eclipse.jetty.servlet:9.2.9.v20150224]  at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.2.9.v20150224]  at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) [org.eclipse.jetty.server:9.2.9.v20150224]  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.2.9.v20150224]  at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.9.v20150224]  at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]  at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) [org.eclipse.jetty.server:9.2.9.v20150224]  at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.9.v20150224]  at org.eclipse.jetty.server.Server.handle(Server.java:497) [org.eclipse.jetty.server:9.2.9.v20150224]  at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) [org.eclipse.jetty.server:9.2.9.v20150224]  at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) [org.eclipse.jetty.server:9.2.9.v20150224]  at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [org.eclipse.jetty.io:9.2.9.v20150224]  at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) [org.eclipse.jetty.util:9.2.9.v20150224]  at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) [org.eclipse.jetty.util:9.2.9.v20150224]  at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  {quote}",Bug,Major,Closed,"2015-06-03 17:02:19","2015-06-03 16:02:19",1
"Sonatype Nexus","Release HTTP Test Harness library with fixed OSGi metadata","Release HTTP Test Harness library with fixed OSGi metadata, and then fix it's usage in some ITs like: NugetITSupport, MavenContentValidationIT etc  ",Bug,Major,Closed,"2015-06-03 09:48:52","2015-06-03 08:48:52",1
"Sonatype Nexus","gradle simple-project-staging sample project uses an obsolete version of the nexus-staging-ant-tasks","The build.gradle file in the simple-project-staging project in our trial uses version 1.6.1 of the nexus-staging-ant-tasks:    https://github.com/sonatype/nexus-bundles/blob/nexus-2.11.x/assemblies/nexus-trial/src/main/content/trial-evalguide/gradle/simple-project-staging/build.gradle#L51    This causes the sample project to fail with a pretty unhelpful exception when used with Nexus 2.11.3:    {quote}  * Where:  Build file 'C:\nexus-evalguide\gradle\simple-project-staging\build.gradle' line: 125    * What went wrong:  Execution failed for task ':releaseStagingRepository'.  > java.lang.ArrayIndexOutOfBoundsException: -1    * Try:  Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.  {quote}    I was going to just check in a fix for this, but then I realized there are probably other places in the sample projects using the wrong versions of the staging clients.  So someone who is familiar with these needs to check them over.    ",Bug,Major,Closed,"2015-06-02 23:19:23","2015-06-02 22:19:23",0.5
"Sonatype Nexus","All Configured Users no longer shows external realms","I no longer see users from External Realms (LDAP, Crowd) in Security>Users in the All Configured Users dropdown.  They definately show in NX2 and I'm pretty sure appeared in NX3 (when I filed NEXUS-7996; I can back check if requested).  I am not sure if this is caused by the linked but that's when I noticed it.  This isn't a big deal as everything can be seen in it's respective dropdown, however, it makes for 2 redundant dropdowns (default and all) as well as no way to see everything together.  Since regression however I left major for now.",Bug,Major,Open,"2015-06-02 21:03:30","2015-06-02 20:03:30",2
"Sonatype Nexus","LDAP (verify connection) does not retry","I see no evidence currently that on NX3 LDAP configuration using Verify Connection the retry after and max failed attempts (latter I believe new for NX3) is working.  I noticed this testing NEXUS-8655 after verifying the wait seconds before timeout field was working as I expected.  This appears to work in NX2, but without max failed attempts it basically tries to connect forever (which is probably why the third field was added).  I did not check older NX3 at this time.    On discussion with [~<USER>, he asked if I would close NEXUS-8655 if the first field was working and open a distinct ticket on the second and third fields.  This is that ticket.    Repro steps:  1) Setup a valid LDAP (first page) but make the port an invalid port.  2) Click verify connection.  The connection will try for the number of seconds listed in the first variable then nothing.  I attempted low settings and retries to get this to fire faster (such as 10/2 and 1/5).",Bug,Major,Open,"2015-06-02 15:06:12","2015-06-02 14:06:12",0.5
"Sonatype Nexus","npm database grows unexpectedly large on cache expired requests","On every npm proxy repository cache expiry, when the remote is checked for metadata updates, then the npm Orient DB database file {{default.pcl}} file grows by a large unexpected amount. In theory I would expect no need to store this much new data in the database for something that did not really change.    Reproduce using 2.11.3-01:    1. create npm proxy repo to https://registry.npmjs.org  2. Set all cache settings to 1 minute ( for testing purposes ). Save. These will display as 1,0,0,1 ( UI bug, not the issue )  3. note sonatype-work/nexus/db/npm/default.pcl size: mine is 65k  4. request http://localhost:8081/nexus/content/repositories/npm/express and get 200 response    5. note default.pcl size: mine becomes 449K  6. wait more than 1 minute for cache expiry. Set logger remote.storage.outbound to DEBUG.  7. request express again - verify 304 not modified response from remote, note default.pcl size increase - now size is: 833K  8. repeat - for every cache expiry, default.pcl will grow over 400 k.      ",Bug,Major,Closed,"2015-06-01 19:18:10","2015-06-01 18:18:10",1
"Sonatype Nexus","Creating repos expands all collapsed left nav items","Collapsed IQ Server and Security left nav items to be able to see Tasks and Repos in one screen.  Noticed that creating a Maven Hosted repo auto expanded what I had collapsed.  I tried Raw hosted as well.  No errors in console or log.    I tried creating a task and this did not auto-expand, so as far as I can tell this is a repo creation thing.    I did not check older NX3 or NX2 at this time.  Let me know if you need a vid.",Bug,Trivial,Closed,"2015-05-29 18:58:20","2015-05-29 17:58:20",2
"Sonatype Nexus","Security role can be added to itself","It is currently possible to add a role to itself in the administration user interface. Validation and the UI should make this impossible to prevent downstream problems",Bug,Major,Closed,"2015-05-28 23:29:52","2015-05-28 22:29:52",2
"Sonatype Nexus","improve snapshot remover tasks performance by reducing potential i/o","1. When processing GAV that contains multiple timestamped pom files, and the  remove if released option is true, then make sure we only check for release once, not once per  every timestamp snapshot. This reduces the I/O for the *Remove Snapshots From Repository* task _when the remove if released option is checked ( true )_.    2. Do not include signature or hash files when checking for the oldest accessed snapshot last requested timestamp. Given each artifact can have upwords of 5 total of these (.asc , .asc.sha1, .asc.md5, .sha1 and .md5 ) and typically always two ( .sha1, .md5 ), this can reduce I/O reading attributes files by a minimum of 66%. This is always a benefit to the *Remove Unused Snapshots from Repository* task because this task always tries to calculate the days since any snapshot was last requested. It does this by reading attributes files off disk. Avoiding the above files means attributes for these files does not need to be read off disk.    3. When determining the most recent last requested time for the snapshots in the same build number, avoid iterating over the entire GAV collection of files for each artifact to check. By caching the last requested timestamps in the main processing loop, and determining the most recent last requested date on the fly, we can avoid iterating over the entire collection again for each file, when needing to find the most recent last requested for similar snapshots. This has significant performance benefits for the *Remove Unused Snapshots from Repository* task.  ",Improvement,Major,Closed,"2015-05-28 21:05:07","2015-05-28 20:05:07",0.5
"Sonatype Nexus","Icon missing on search details breadcrumb","Noticed that there's a gap in the breadcrumb when drilling down into search details (search-component-component details).  I asked [~<USER> and he said there should be an icon there.    I am guessing this is recent regression but did not check old NX3 at this time.  NX2 is not affected.",Bug,Trivial,Closed,"2015-05-27 22:09:53","2015-05-27 21:09:53",0.5
"Sonatype Nexus","CLM Verify connection errors","After configuring CLM, I clicked Verify Connection and saw the attached error on screen and the below error in the console.  This is not surprising considering the state of NX3 and CLM however there really isn't a ticket covering this IMO.  I am linking the sister which I think things will be reevaluated but I'm not convinced this will be fixed so ticketing seperately.  This does not affect NX2.  I did not check older versions of NX3 at this time, tho I believe either CLM wasn't integrated or this is new to Dizzam since we stripped legacy (I acknowledge those are someone opposite but just stating what I believe=)).    {quote}  2015-05-27 15:17:26,437-0400 ERROR [qtp756632732-159] admin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: clm_CLM.verifyConnection, java-method: com.sonatype.nexus.clm.internal.ui.ClmComponent.verifyConnection  groovy.lang.MissingMethodException: No signature of method: com.sonatype.nexus.clm.ClmConnector.getRestConfiguration() is applicable for argument types: (java.lang.String, null, null) values: [http://localhost:8070, null, null]  Possible solutions: getRestConfiguration(), getRestConfiguration(java.lang.String, boolean, java.lang.Integer), getRestConfiguration(java.lang.String, boolean, java.lang.Integer, java.lang.String, java.lang.String), getConfiguration()   at org.codehaus.groovy.runtime.ScriptBytecodeAdapter.unwrap(ScriptBytecodeAdapter.java:56) [groovy-all:2.3.7]   at org.codehaus.groovy.runtime.callsite.PojoMetaClassSite.call(PojoMetaClassSite.java:46) [groovy-all:2.3.7]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:124) [groovy-all:2.3.7]   at com.sonatype.nexus.clm.internal.ui.ClmComponent.verifyConnection(ClmComponent.groovy:120) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet$3.invokeMethod(ExtDirectServlet.java:201) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.StandardRequestProcessorBase.dispatchStandardMethod(StandardRequestProcessorBase.java:73) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:502) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequestsInThisThread(JsonRequestProcessor.java:150) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.process(JsonRequestProcessor.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.RequestRouter.processJsonRequest(RequestRouter.java:83) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.processRequest(DirectJNgineServlet.java:617) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.doPost(DirectJNgineServlet.java:580) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet.doPost(ExtDirectServlet.java:121) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:707) [javax.servlet-api:3.1.0]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:70) [com.google.inject:4.0.0]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.3]   at org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.3]   at org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101) [org.sonatype.nexus.security:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:130) [com.sonatype.nexus.plugins.nexus-licensing-plugin:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:63) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:92) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) [org.eclipse.jetty.servlet:9.2.9.v20150224]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) [org.eclipse.jetty.servlet:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) [org.eclipse.jetty.security:9.2.9.v20150224]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) [org.eclipse.jetty.servlet:9.2.9.v20150224]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.9.v20150224]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.Server.handle(Server.java:497) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [org.eclipse.jetty.io:9.2.9.v20150224]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) [org.eclipse.jetty.util:9.2.9.v20150224]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) [org.eclipse.jetty.util:9.2.9.v20150224]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  {quote}",Bug,Major,Closed,"2015-05-27 20:25:01","2015-05-27 19:25:01",0.5
"Sonatype Nexus","Feed paging does not work","As feeds are getting revived, it occurred to me that on UI paging of the feeds does not work.",Bug,Major,Closed,"2015-05-27 16:02:18","2015-05-27 15:02:18",1
"Sonatype Nexus","Default file blob store should be created immediately","Currently, creation of the default blob store is lazy.  This is a problem because (insert problem here).  - Problem was went to look for Blob Store and it wasn't there yet!    A new instance of Nexus should create the default file blob store as it starts up for the first time.",Improvement,Major,Closed,"2015-05-26 20:22:16","2015-05-26 19:22:16",1
"Sonatype Nexus","Raw repo with index.html shows error 400","h4. Acceptance Criteria    Whenever a request ending in slash would otherwise 404, Nexus will check each of the pages, in the order provided.    This only affects raw hosted repositories.  (Proxies can rely on the 'default page' handling of the remote repository.)    h4. RATIONALE    Deploy a site with an index.html to a hosted raw repo e.g. with the Maven site deployment from https://github.com/sonatype/nexus-book-examples/tree/nexus-3.0.x/maven/simple-project    Then navigating to the URL of the repo you see a 400 error in the Nexus UI    http://localhost:8081/repository/site/    Even though http://localhost:8081/repository/site/index.html renders the site in HTML.    Note:  - Make sure we have a longer term plan for how we handle index.html and directory root/etc...",Improvement,Major,Closed,"2015-05-26 19:48:34","2015-05-26 18:48:34",1
"Sonatype Nexus","Using a repository id of .. creates a repository that is now untouchable in the UI","Noticed while testing an unrelated issue that the nexus UI allows you to enter two dots '..' as an id for a repository, doing this renders the repository effectively useless in the UI, ultimately i had to manually remove the repository from my nexus.xml",Bug,Major,Closed,"2015-05-26 17:14:02","2015-05-26 16:14:02",0.5
"Sonatype Nexus","Discrepancy of strictContentTypeValidation between UI created and default DefaultRepositoriesContributor repositories","DefaultRepositoriesContributor creates with {{strictContentTypeValidation=false}} while repositories created via UI have {{strictContentTypeValidation=true}}.    I think we should decide which one is the default and go with that in both cases.    Acceptance Criteria:  - Set strictContentTypeValidation to true when default repos are created",Bug,Minor,Closed,"2015-05-26 11:55:16","2015-05-26 10:55:16",0.5
"Sonatype Nexus","MavenProxyFacet - Could not parse date Last-Modified using system current time as item creation time WARN message","Create a Nexus 3 Maven 2 proxy repository to your Nexus 3 instance Central Proxy repository.    Request abbot/abbot/0.13.0/abbot-0.13.0.pom through this proxy repo. This fails with 404 ( due to {{Declared content type text/xml, but discovered \[text/plain, application/octet-stream\]}}. See NEXUS-8667 I guess? ) - but there also appears to be a problem parsing Last-Modified headers because they were rewritten in a format not expected by our new proxy implementation.    ",Bug,Major,Closed,"2015-05-25 19:57:29","2015-05-25 18:57:29",1
"Sonatype Nexus","newly created scheduled tasks are not enabled by default","Using Nexus 3 ( tested nexus-professional-3.0.0-20150525.080626-1043-bundle ), create a Scheduled task. By default the Task Enabled checkbox is not checked.     When creating any new scheduled task, the default should be that the enabled checkbox is checked. This is a logical default and how it works in Nexus 2.x.    ",Bug,Major,Closed,"2015-05-25 18:12:21","2015-05-25 17:12:21",0.5
"Sonatype Nexus","UI complaining about nexus:healthcheck:read missing for anonymous user","http://take.ms/L1uKq    Load Nexus 3 UI as anonymous user. Lots of messages about {{nexus:healthcheck:read}} priv missing.    Used nexus-professional-3.0.0-20150525.080626-1043-bundle  ",Bug,Major,Closed,"2015-05-25 16:45:36","2015-05-25 15:45:36",0.5
"Sonatype Nexus","create role menu expansion not persisting","See video:  http://take.ms/BEc4f    Note I am not clicking anything other than the Create Role button. Menu is just hiding on it's own before I can click anything.  ",Bug,Major,Closed,"2015-05-25 16:42:12","2015-05-25 15:42:12",0.5
"Sonatype Nexus","New Raw hosted repos should default to 'Allow redeploy'","ACCEPTANCE CRITERIA  An admin user creates a new raw, hosted repository.  Nexus should default the deployment policy to 'Allow redeploy'.    RATIONALE  A single command of 'mvn site:deploy' puts the same file multiple times; if the deployment policy isn't 'allow', it will fail.    When creating a hosted raw repository for Maven site deployment it should be as easy as possible.    1. create repo  2. select raw hosted  3. provide name (e.g. site)    Now mvn site-deploy e.g. with https://github.com/sonatype/nexus-book-examples/blob/nexus-3.0.x/maven/simple-project/    should just work.    However this is not the case since the maven site plugin does repeated deployments of the same files and the default is to disallow redeployments on hosted raw repositories.  ",Improvement,Major,Closed,"2015-05-22 20:38:42","2015-05-22 19:38:42",1
"Sonatype Nexus","mime detection may not cache properly for specific request paths","DefaultMimeSupport has it's own code to extract the extension from a given path. The code doesn't handle certain cases where dots appear multiple times in the path, or when slashes appear after the last dot, which means it can end up extract more of the path than necessary. This can lead to situations where the mime cache is ignored.    DefaultMimeSupport should instead use FilenameUtils.getExtension",Bug,Major,Closed,"2015-05-22 16:38:07","2015-05-22 15:38:07",0.5
"Sonatype Nexus","Maven content validation fails to valid POM","Valid POM is being requested, but Maven Proxy fails to validate it. The POM is not a valid XML but Maven would parse it.    The POM in question:  https://repository.sonatype.org/content/groups/sonatype-grid/org/json/org.json/2.0-NEXUS-3758/org.json-2.0-NEXUS-3758.pom    Excerpt from logs:  ",Bug,Major,Closed,"2015-05-20 12:40:07","2015-05-20 11:40:07",1
"Sonatype Nexus","Group repositories should handle and skip members in case of some exceptions","Spotted while testing, content validation stopped group processing, where the right content was present in two repositories:  - repoA - throw InvalidContentEx, and execution stopped here (and resulting with 500 Internal Error, see NEXUS-8665)  - repoB - did have the good content, but was never asked for.    In this case group handler should neglect (log maybe) that a member reported content validation failure, but *should continue processing* on next member.",Bug,Major,Closed,"2015-05-20 12:13:32","2015-05-20 11:13:32",1
"Sonatype Nexus","Handle content validation failures gracefully","Similar issue to NEXUS-8637, this case also currently results in HTTP 500 Internal Error, but should not. Downstream 404 Not Found is more appropriate, OR, in case of deploy, 400 Bad Request.",Bug,Major,Closed,"2015-05-20 12:11:18","2015-05-20 11:11:18",1
"Sonatype Nexus","After save of LDAP user, Users screen shows non-LDAP users with LDAP filter","Testing LDAP, I saved an LDAP user (giving them permissions) and the behavior returned you to the Users list but showed the non-LDAP users.  The filter however, was still showing LDAP.  This is inconsistant and confusing so ticketing.    One of the reasons for not seeing this elsewhere is this is one of the few (if any) pages in which you save and it changes the screen.  Most of them stay on the page they were on.    This occurred in Dizzam before the found as ticket and was not immediate regression though I did not test older NX3 builds.  This does not impact NX2.",Bug,Trivial,Closed,"2015-05-19 22:24:27","2015-05-19 21:24:27",1
"Sonatype Nexus","non proxy hosts tooltip suggests a misleading syntax","If one is to add non proxy hosts - the tooltip (? icon) suggests regular expression *\.somecompany\.com. Inserting a host with such format does not produce an error, but while having a wildcard '*' at the beginning of a hostname causes an error to show up in the console upon restart of Nexus.  A correct regex patter should be something like:  .+\.somecompany\.com  This correctly validates upon restart.    Acceptance Criteria:  - Change help text to correct pattern",Bug,Minor,Closed,"2015-05-19 21:56:02","2015-05-19 20:56:02",0.5
"Sonatype Nexus","LDAP's Verify Connection times out faster than listed","While testing NEXUS-8606, I went back to a branch before the changes to establish how LDAP was running in NX3 (and NX2) pre-change to review for regression issues.  When testing NEXUS-8606, I noticed that when I set the Connection Rules (via the Connection tab) that it timed out within a 7 count when I clicked Verify Connection regardless of what I put in that field.  In the branch I tested before NEXUS-8606 (109941d), Verify Connection seemed to take longer (or shorter) as I adjusted the values.  Note, in order to see this, you need to do a bad configuration.  If you have a good configuration it works immediately.    Honestly, I am not even sure it's supposed to work this way (or if it was only for actual LDAP timeout).  These fields are new to NX3 (so not NX2 regression).  I did not check older NX3 milestones at this time.",Bug,Major,Closed,"2015-05-19 21:33:58","2015-05-19 20:33:58",1
"Sonatype Nexus","LDAP's Verify Login does nothing","Noticed that in NX3, when configuring LDAP, the Verify Login submission did nothing regardless of configuration setup or data you entered valid or invalid.  There are no errors in the console, log or screen.  As far as I can tell this item does not exist in NX2, so there's nothing to compare against functionally either.  Weirdly, for that reason I am marking this minor because there's no real loss either.  I did not check older milestones of NX3 but this is NOT regression of the ticket discovered by.",Bug,Minor,Closed,"2015-05-19 21:06:20","2015-05-19 20:06:20",0.5
"Sonatype Nexus","LDAP's Verify User Mapping button errors and does nothing","Noticed that in NX3, when configuring LDAP, the Verify User Mapping button gives the attached error and does nothing.  This also appears as a JS error in the console:  Uncaught ReferenceError: me is not defined  nexus-coreui-plugin-prod.js?_v=3.0.0-SNAPSHOT&_dc=1432064146870:1    ADDENDUM: This shows as Uncaught ReferenceError: me is not defined - LdapServers.js?_dc=1432066923264:433 with ?debug on.    This works in NX2.  I did not check older milestones of NX3 but this is not regression of the ticket discovered by.    I am leaving this major because this is a super easy way to make sure this configuration is working before actually working with LDAP stuff.  I am not sure if there's anywhere else that does that in one button click which makes for a poor workaround.",Bug,Major,Closed,"2015-05-19 21:00:16","2015-05-19 20:00:16",0.5
"Sonatype Nexus","Request Timeout field in Crowd appears to do nothing?","While reviewing Crowd, I tried different values for both HTTP and Crowd specific Request Timeout and only the 0 value appeared to affect Crowd (would cause seemingly endless attempts to reconnect on a bad username/password).  I asked the team what this field was supposed to do to clarify I was testing the right thing and it was inferred I should create a ticket for review.    I tried values of 60, 1 and 20000 (in case millseconds regression) in the field.  I tried with Crowd off and valid username/password as well as Crowd on and bad username/password and it immediately gave me a validation no matter what configuration (except in the 0 case).  I tried less combinations on the fallback general HTTP values but my findings were those are not being picked up either.    Investigation appreciated.  If not just me, all the above should probably be (re)tested once a solution is implemented.    I did not check older NX3 or NX2 to see if working/not working at this time.",Bug,Major,Closed,"2015-05-19 14:38:57","2015-05-19 13:38:57",0.5
"Sonatype Nexus","Avoid rebuilding active bundles list each UI poll request",,Improvement,Major,Closed,"2015-05-18 21:31:54","2015-05-18 20:31:54",1
"Sonatype Nexus","On refresh, feature icon and title overlap","Screencast: http://take.ms/v4o3j    Saw this periodically on Nexus 3 Pro, but now seeing on every refresh in Nexus 3 OSS.",Bug,Trivial,Closed,"2015-05-18 10:07:43","2015-05-18 09:07:43",0.5
"Sonatype Nexus","No NX version in describe","While testing the revamped ?describe UI, I noticed that the page no longer has a version at the top.  Instead it says $nexusVersion.  Assuming a variable went awry somewhere?  Since (largely) an internal tool this might be the most trivial thing I've ever filed but I think worth correcting (if not intentional).    Did not check older NX3 at this time, but the screen from [~<USER>'s PR for NEXUS-7711 shows it working, so I'm assuming recent regression, likely because of NEXUS-7711.",Bug,Trivial,Closed,"2015-05-15 23:02:10","2015-05-15 22:02:10",0.5
"Sonatype Nexus","Forbidden redeploy attempt causes HTTP 500 response","While the policy is enforced, the log gets an ugly stack-trace and response code of 500 Internal Error which is not acceptable.        Response should be 400 Bad Request.",Bug,Major,Closed,"2015-05-15 11:59:26","2015-05-15 10:59:26",1
"Sonatype Nexus","Picker widget field labels for disabled are strange","Other fields labels when disabled do not get same treatment.",Improvement,Major,Closed,"2015-05-15 01:18:54","2015-05-15 00:18:54",0.5
"Sonatype Nexus","HTTP Proxy takes 2 clicks to save off","While testing NEXUS-8488, I setup a proxy via System>HTTP, but I saw something weird so went to do it again.  Rather than delete all the settings I had input, I simply unchecked the proxy and saved.  When I did this, I was presented with a screen with HTTP Proxy still checked but both fields validating, despite the fact I had saved with HTTP Proxy unchecked.  If you uncheck again and save this time it turns off.  Similarly if you refresh the page or leave and return, it will be unchecked.    Steps to repro:  1) Load System>HTTP  2) Check HTTP Proxy  3) Enter HTTP Proxy host and HTTP Proxy port  4) Save  5) Uncheck HTTP Proxy  6) Save; BUG: HTTP Proxy rechecks (tho fields are wiped)    I did not check older NX3 or NX2 at this time.",Bug,Trivial,Closed,"2015-05-14 22:18:14","2015-05-14 21:18:14",0.5
"Sonatype Nexus","Switching to System>HTTP auto expands all then collapses","I noticed when I went to System>HTTP, that behind the normal loading screen, every field was expanded.  I could tell this because I saw traces of red where there is none once the field loads in addition to the page contents being longer then loading shorter.    While reproducing I also noticed that intermittantly, I would get a message prompting me to discard/save changes even though I was going to/loading this page.  This may be a distinct issue, however, mentioning here because the video I captured, this happened twice.  The third time (on video) it did not occur and shows the behavior without this.  I left minor in case this is two issues in one, that one is rather perplexing, otherwise this would be trivial.  Let me know if not clear.    I did not check older versions of NX3 or NX2 at this time.",Bug,Minor,Closed,"2015-05-14 22:12:11","2015-05-14 21:12:11",1
"Sonatype Nexus","Stop auto-collapsing side-nav","http://take.ms/6FIqC    Its distracting (ui flickers/twitches on some transitions), doesn't add too much real value.    It also will auto hide even if manually expanded due to status refresh, which is also pretty annoying.    Dont mind if user wants to collapse it, so this isn't about making the side-nav static (collapsable=false) but simply don't automatically hide it anymore.",Improvement,Major,Closed,"2015-05-14 21:50:01","2015-05-14 20:50:01",0.5
"Sonatype Nexus","Add non-browsable warning","We don't yet have repository browse support (e.g. by visiting the repository URL in the browser), which may cause confusion when users follow the repository URLs from the Repo Admin UI.    ACCEPTANCE CRITERIA    For browsable formats (maven, but not nuget - determine which is which), visiting the root of the repository produces a user-friendly explanation that this is meant for clients and is not yet browsable.    Technical comments  - this will require amending the repository recipe(s)",Improvement,Minor,Closed,"2015-05-14 20:16:31","2015-05-14 19:16:31",2
"Sonatype Nexus","Allow fetching of tarballs from incomplete NPM packages","Currently we disallow fetching of tarballs from incomplete NPM packages, where a package is considered as incomplete if it has at least one version which doesn't define a tarball distribution.    We should instead just disallow fetching of tarballs whose specific version is incomplete, rather than ban the whole package whose versions might all be complete except for one incomplete version.    Recreate instructions:    * Install Nexus and add an NPM proxy repository for https://registry.npmjs.org/ and then add it to an NPM group (called npm)  * Accessing chokidar package root should pass:  curl 'http://127.0.0.1:8081/nexus/content/groups/npm/chokidar'  * Now download the registry root:  curl 'http://127.0.0.1:8081/nexus/content/groups/npm/-/all'   (will take a while)  * Accessing chokidar package root should now fail:  curl 'http://127.0.0.1:8081/nexus/content/groups/npm/chokidar'  * Accessing chokidar tarball should also fail:  http://127.0.0.1:8081/nexus/content/groups/npm/chokidar/-/chokidar-0.6.3.tgz    Original cause:  the npmjs registry root declares basic version metadata for all packages, and Nexus distributes this partial metadata across the package roots when the registry root is fetched. If you then request a particular package root (say chokidar) Nexus will overlay the full package metadata with the partial metadata from the registry root. For almost all packages this means that the partial version metadata from the registry root is replaced with full version metadata from the package root. However, the chokidar and phantomjs packages each have a version listed in the registry root that doesn't appear in their package root. This leaves an incomplete version in the merged package root, which then causes nexus to fail to serve any tarballs from that package.    Acceptance test:  with this fix these last two failures are fixed.  ",Bug,Major,Closed,"2015-05-14 01:18:35","2015-05-14 00:18:35",1
"Sonatype Nexus","Replace NPM package root when proxying (instead of merging the content)","At the moment we always merge the downloaded package root with previously cached content. This can end up leaving bad entries in the cache even after they have been removed from the upstream proxy.     The most likely reason package versions were removed from the remote is due to the package author [unpublishing|https://docs.npmjs.com/cli/unpublish] them. End users should examine the associated package SCM repository commit history to look for a note of such an action.    NEXUS-8625 also describes another scenario where Nexus can end up with bad metadata.    Expected: Replace the cached metadata content with the new downloaded content.",Bug,Major,Closed,"2015-05-14 01:12:20","2015-05-14 00:12:20",1
"Sonatype Nexus","Maven Proxy / Hosted repositories cannot be saved","[~<USER> noticed that repositories with version policies cannot be saved.  I checked master and see when I save I get a may not be null message under these.  I checked through the default ones and think it just proxy and hosted maven that are affected.    Alin says this is related to NEXUS-8503 and that is becuase disabling a field will result into those fields to not be submitted and that will not pass repository validation.  I guess when I checked that I only checked by sight, my bad=\    Below also appears in the log:  {quote}  2015-05-13 14:38:42,377-0400 WARN  [qtp789933455-214] admin org.sonatype.nexus.repository.config.ConfigurationFacetImpl - Validation failed; 1 constraints violated:    1) may not be null, type: class org.sonatype.nexus.repository.config.ConfigurationFacetImpl$SectionWrapper, property: attributes[maven].versionPolicy, value: null  {quote}    This does not impact NX2 or older NX3 builds.",Bug,Critical,Closed,"2015-05-13 19:40:04","2015-05-13 18:40:04",1
"Sonatype Nexus","Cannot save changes to an existing LDAP connection","Steps to reproduce:    + Create an LDAP connection  + Edit the connection, and change one of the parameters  + Save the change  + Attempt to navigate to a different feature (notice the “Discard changes” modal)  + If you click “Discard changes”, then navigate back to the LDAP connection, notice how the edited parameter still has its original value.    Screencast:    http://take.ms/1aaBz",Bug,Major,Closed,"2015-05-12 19:13:34","2015-05-12 18:13:34",0.5
"Sonatype Nexus","No such property: valueIfValid while saving LDAP/CLM/Crowd","Cannot create LDAP servers, configure CLM/Crowd due to exception shown in attachment.",Bug,Minor,Closed,"2015-05-12 18:54:06","2015-05-12 17:54:06",1
"Sonatype Nexus","If you change the admin password, auth fails on future login attempts","Steps to reproduce:    + Go to the User feature, and change the password for `admin`.  + Log out, and try to log back in (attempt fails).  + Restart the server, and try to log in (fails).  + Delete the sonatype-work folder, restart the server, and try to log in (fails).  + Rebuild Nexus, start the server, and try to log in (works!)    Example:    http://take.ms/8KZGd    Log output:    ",Bug,Major,Closed,"2015-05-12 18:44:47","2015-05-12 17:44:47",2
"Sonatype Nexus","Misconfigured nuget realm/api key leads to indecipherable warning","In NEXUS-8420, I believed I was unable to push some NuGet packages.  It turns out that my configuration was bad but because the errors were so generic and the fact some packages worked (still a mystery to me) I was unable to tell this.    The front end nuget message is Unable to write data to the transport connection: An existing connection was forcibly closed by the remote host.  The log shows:  {quote}  2015-05-11 17:43:21,120-0400 WARN  [qtp1321231863-47]  org.eclipse.jetty.http.HttpParser - badMessage: java.lang.IllegalStateException: too much data after closed for HttpChannelOverHttp@4fdaf693{r=1,c=false,a=IDLE,uri=-}  {quote}    Neither of these speak to the fact the configuration is bad (realm not enabled, API Key not set for host).  After discussing with [~<USER>, we decided to file and discuss if worth fixing in triage.    This could also be an improvement; leaving bug because of the way the summary is phrased:P  NuGet was revamped for Dizzam so no older NX3 checks were done at this time.  Also did not back check NX2 (which could be impacted).    Acceptance Criteria:  - Provide a human readable message that informs you to turn on the NuGet realm",Bug,Minor,Closed,"2015-05-12 16:06:42","2015-05-12 15:06:42",1
"Sonatype Nexus","UI errors on search load","Loading search I am seeing the attached.  I do not see an error in the logs (standard level) or JS.  I was able to perform a search as well (though having trouble with a second - unsure if related so ticketing seperately) so as far as I can tell this is UI.  My guess is since everything starts null seems it'd conflict with anything not allowed to be null.  This seems recent regression but without the capability to push NuGet repos (NEXUS-8557) I haven't searched for a while.  Search is revamped in Dizzam though so no older NX3 checks done at this time.  This issue does not impact NX2.",Bug,Minor,Closed,"2015-05-11 22:54:51","2015-05-11 21:54:51",2
"Sonatype Nexus","Maven site deployment to Nexus 3 raw repo fails","Create raw hosted repository named site.    Use the project at https://github.com/sonatype/nexus-book-examples/blob/nexus-3.0.x/maven/simple-project/pom.xml    This setup works in Nexus 2.    Create a hosted raw repo with the name site.    run mvn site-deploy    That should work.    Even if you turn of strict content type validation and allow redeploys it doesnt work.",Bug,Major,Closed,"2015-05-11 18:06:56","2015-05-11 17:06:56",1
"Sonatype Nexus","Deploying mulitple releases to Maven repository fails","Use the example project at     https://github.com/sonatype/nexus-book-examples/tree/nexus-3.0.x/maven/simple-project    Update the pom to a release version like 1.0.0    run mvn deploy    This works.    Now update to verison 1.0.1 (or any other release version).    run mvn deploy    This fails although it should work.     This might have to do with the fact that the maven-metadata.xml file is updated during the deployment which violates the deployment policy. The deployment policy should be smart enough to not worry about the metadata files I think (just a guess).",Bug,Major,Closed,"2015-05-11 17:55:45","2015-05-11 16:55:45",1
"Sonatype Nexus","OScriptManager - Cannot find default script language for javascript","Orient supports some scripting features, which we are not using (maybe never will) but its spitting out a warning when it starts up.    Should look into disabling this so it won't complain, or change the default to groovy which is available.",Improvement,Trivial,Closed,"2015-05-11 00:12:39","2015-05-10 23:12:39",0.5
"Sonatype Nexus","Uneditable list leaves whitespace where filter clear was","While writing up NEXUS-8583, I noticed the attached: That there was a weird white space following the greyed out filter space when editing an uneditable role.  When creating a new or editing an editable role, this spot is filled by an X used to clear the filter.  My guess is it's hidden to maximize uneditability but leaves a weird white space in its wake.    I did not check older NX3 or NX2 at this time.",Bug,Trivial,Closed,"2015-05-08 22:20:50","2015-05-08 21:20:50",0.5
"Sonatype Nexus","Unselectable space between field contents and dropdown arrow","I noticed on the repository page when editing/creating a repository with authentication, in the authentication dropdown, there's currently a space between the authentication type contents and the dropdown arrow which pulls down available choices.  This space is unselectable and seems it could be tightened.  See version policy dropdown for expectations.    This seems like recent regression but I did not check older branches at this time.  Revamp is new to Dizzam so no older NX3 checks were performed.  This does not affect NX2 (no dropdown exists).",Bug,Trivial,Closed,"2015-05-08 21:58:32","2015-05-08 20:58:32",0.5
"Sonatype Nexus","repository storage may not be properly deleted","1. Create an npm proxy repository named npm.  2. Request some metadata and package that results in 200 and stored in local cache    3. Delete the repository. Now you have nexus/trash/npm and the packages you downloaded    4. Create an npm hosted repository named npm  5. publish an npm package to it.  6. Delete the repository. This fails ( see example stack trace below ) and the storage/npm directory and contents remain in place. The repository is removed from nexus.xml    7. create an npm proxy repo named npm again. the repo gets created fine.  8. Now the new proxy repo contains the packages from the failed deleted hosted repo directory    Expected:  - delete to trash should not fail in this way and formerly deleted contents should not be available to newly created repos.    ",Bug,Critical,Closed,"2015-05-08 19:24:10","2015-05-08 18:24:10",1
"Sonatype Nexus","Create new user gives error","I went to create a new user and got the attached error on screen and the below error in the log.  This is recent NX3 regression (maybe legacy strip?).  To try and assure that it was not related to a role I gave, I followed up and gave the exact same roles that Anonymous has.  Same issue.  Saving Anonymous works.    {quote}  2015-05-08 14:06:26,487-0400 ERROR [qtp858464260-248] admin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: coreui_User.create, java-method: org.sonatype.nexus.coreui.UserComponent.create  groovy.lang.MissingPropertyException: No such property: valueIfValid for class: java.lang.String   at org.codehaus.groovy.runtime.ScriptBytecodeAdapter.unwrap(ScriptBytecodeAdapter.java:51) [na:na]   at org.codehaus.groovy.runtime.callsite.GetEffectivePojoPropertySite.getProperty(GetEffectivePojoPropertySite.java:63) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callGetProperty(AbstractCallSite.java:227) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callGetPropertySafe(AbstractCallSite.java:333) [na:na]   at org.sonatype.nexus.coreui.UserComponent.create(UserComponent.groovy:141) [na:na]   at org.sonatype.nexus.validation.internal.ValidationInterceptor.invoke(ValidationInterceptor.java:53) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet$3.invokeMethod(ExtDirectServlet.java:204) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.StandardRequestProcessorBase.dispatchStandardMethod(StandardRequestProcessorBase.java:73) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:502) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequestsInThisThread(JsonRequestProcessor.java:150) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.process(JsonRequestProcessor.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.RequestRouter.processJsonRequest(RequestRouter.java:83) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.processRequest(DirectJNgineServlet.java:617) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.doPost(DirectJNgineServlet.java:580) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet.doPost(ExtDirectServlet.java:124) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:707) [javax.servlet-api:3.1.0]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:70) [com.google.inject:4.0.0]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.3]   at org.sonatype.nexus.web.SecurityFilter.executeChain(SecurityFilter.java:87) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.3]   at org.sonatype.nexus.web.SecurityFilter.doFilterInternal(SecurityFilter.java:103) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:134) [com.sonatype.nexus.plugins.nexus-licensing-plugin:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:65) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:92) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) [org.eclipse.jetty.servlet:9.2.9.v20150224]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) [org.eclipse.jetty.servlet:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) [org.eclipse.jetty.security:9.2.9.v20150224]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) [org.eclipse.jetty.servlet:9.2.9.v20150224]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.9.v20150224]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.Server.handle(Server.java:497) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [org.eclipse.jetty.io:9.2.9.v20150224]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) [org.eclipse.jetty.util:9.2.9.v20150224]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) [org.eclipse.jetty.util:9.2.9.v20150224]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  {quote}    I'd make this critical if this wasn't a WIP.  As is, can workaround with default roles, esp since save works.",Bug,Major,Closed,"2015-05-08 19:14:52","2015-05-08 18:14:52",0.5
"Sonatype Nexus","Cannot submit tasks with advanced (cron) filled in","While reviewing NEXUS-7896, I tried to submit a task with advanced cron filled in and got a NPE warning both in browser and in log.  [~<USER> and I checked older Dizzam branches and found this is not related to that change.  I did not check m3 or older (or NX2) at this time.  I am leaving major assuming regression (at least from NX2) or we would have heard something by now.    My crons were:  0 0 0 30 1 1  0 0 12 * * ?    {quote}  2015-05-08 13:30:25,862-0400 ERROR [qtp858464260-222] admin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: coreui_Task.create, java-method: org.sonatype.nexus.coreui.TaskComponent.create  java.lang.NullPointerException: null   at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:210) [com.google.guava:18.0.0]   at org.sonatype.nexus.validation.ValidationMessage.<init>(ValidationMessage.java:36) [org.sonatype.nexus.validation:3.0.0.SNAPSHOT]   at org.sonatype.nexus.validation.ValidationMessage.<init>(ValidationMessage.java:41) [org.sonatype.nexus.validation:3.0.0.SNAPSHOT]   at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) [na:1.8.0_40]   at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) [na:1.8.0_40]   at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) [na:1.8.0_40]   at java.lang.reflect.Constructor.newInstance(Constructor.java:422) [na:1.8.0_40]   at org.codehaus.groovy.reflection.CachedConstructor.invoke(CachedConstructor.java:77) [na:na]   at org.codehaus.groovy.runtime.callsite.ConstructorSite$ConstructorSiteNoUnwrapNoCoerce.callConstructor(ConstructorSite.java:102) [na:na]   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallConstructor(CallSiteArray.java:57) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callConstructor(AbstractCallSite.java:182) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callConstructor(AbstractCallSite.java:194) [na:na]   at org.sonatype.nexus.coreui.TaskComponent.asSchedule(TaskComponent.groovy:351) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite$PogoCachedMethodSiteNoUnwrapNoCoerce.invoke(PogoMetaMethodSite.java:207) [na:na]   at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite.callCurrent(PogoMetaMethodSite.java:56) [na:na]   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141) [na:na]   at org.sonatype.nexus.coreui.TaskComponent.create(TaskComponent.groovy:132) [na:na]   at org.sonatype.nexus.validation.internal.ValidationInterceptor.invoke(ValidationInterceptor.java:53) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.8.0_40]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [na:1.8.0_40]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.8.0_40]   at java.lang.reflect.Method.invoke(Method.java:497) [na:1.8.0_40]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet$3.invokeMethod(ExtDirectServlet.java:204) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.StandardRequestProcessorBase.dispatchStandardMethod(StandardRequestProcessorBase.java:73) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:502) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequestsInThisThread(JsonRequestProcessor.java:150) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.process(JsonRequestProcessor.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.RequestRouter.processJsonRequest(RequestRouter.java:83) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.processRequest(DirectJNgineServlet.java:617) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.doPost(DirectJNgineServlet.java:580) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet.doPost(ExtDirectServlet.java:124) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:707) [javax.servlet-api:3.1.0]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277) [com.google.inject:4.0.0]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:70) [com.google.inject:4.0.0]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.3]   at org.sonatype.nexus.web.SecurityFilter.executeChain(SecurityFilter.java:87) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.3]   at org.sonatype.nexus.web.SecurityFilter.doFilterInternal(SecurityFilter.java:103) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:134) [com.sonatype.nexus.plugins.nexus-licensing-plugin:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:65) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:92) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [com.google.inject:4.0.0]   at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [com.google.inject:4.0.0]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [com.google.inject:4.0.0]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) [org.eclipse.jetty.servlet:9.2.9.v20150224]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) [org.eclipse.jetty.servlet:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) [org.eclipse.jetty.security:9.2.9.v20150224]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) [org.eclipse.jetty.servlet:9.2.9.v20150224]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.9.v20150224]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.Server.handle(Server.java:497) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) [org.eclipse.jetty.server:9.2.9.v20150224]   at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [org.eclipse.jetty.io:9.2.9.v20150224]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) [org.eclipse.jetty.util:9.2.9.v20150224]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) [org.eclipse.jetty.util:9.2.9.v20150224]   at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]  {quote}",Bug,Major,Closed,"2015-05-08 18:42:16","2015-05-08 17:42:16",1
"Sonatype Nexus","'Describe' output not rendering correctly for some values","Looks like we're running into this issue: https://github.com/google/guava/issues/844  Rendering from here is including a micro character that doesn't render properly:  https://github.com/sonatype/nexus-oss/blob/master/plugins/basic/nexus-content-plugin/src/main/resources/org/sonatype/nexus/content/internal/requestDescriptionHtml.vm#L83-83  Noted while reviewing this screenshot in a PR(note the question mark in the Processing Time): https://cloud.githubusercontent.com/assets/186715/7512753/faecffdc-f4a6-11e4-890c-d67da41f21aa.png",Bug,Major,Closed,"2015-05-07 19:16:26","2015-05-07 18:16:26",1
"Sonatype Nexus","improve the experience when npm package files are requested before npm metadata","Our current npm repository behaviour:    1. Request a package tgz through a proxy repository that exists in the remote. 404 not found  2. Request the metadata for that package. 200 response and package url in step 1 says to get it from Nexus  3. Try to get the package again from Nexus - still 404, cached not found.    Expected: Nexus should try to be more forgiving when a package file is requested before metadata.",Improvement,Major,Closed,"2015-05-07 18:01:01","2015-05-07 17:01:01",1
"Sonatype Nexus","prevent OConcurrentModificationException when expiring not found cache and updating package metadata at the same time for a npm repository","The npm database can get in a state where expiring the not found cache on an npm repository can trigger an OConcurrentModificationException if package metadata is updated at the same time by another thread. The other thread would typically be a get or PUT request for an npm package.    {{com.orientechnologies.orient.core.exception.OConcurrentModificationException: Cannot UPDATE the record #9:293 because the version is not the latest. Probably you are updating an old record or it has been modified by another user (db=v6 your=v5)  }}        Expected: do better preventing this commonly reproducible concurrency issue",Bug,Major,Closed,"2015-05-07 17:45:46","2015-05-07 16:45:46",1
"Sonatype Nexus","expire cache task on npm group repositories should not abort when there is a problem processing member repositories","ExpireCacheTask on an npm group repository will abort if there is a problem processing a member repository.    Expected: The task should not abort. The problem should be logged and the task should continue processing as many records/member repositories as possible.    For an example problem, see NEXUS-8568.  ",Bug,Major,Closed,"2015-05-07 17:37:49","2015-05-07 16:37:49",1
"Sonatype Nexus","Support multi-range requests","Currently Nexus only supports HTTP GET requests that contain a single range header. For effective retrieval of large files with tools like zsync (http://zsync.moria.org.uk/) it's important to be able to retrieve multiple parts in a single HTTP request.    We are using this technique extensively with this patch:  https://github.com/<USER>nexus-oss/commit/0cfaea8b4882c335672cae67b6509808713b95dd    Would appreciate if you guys could pull it in. It's low-risk and well-tested.",Improvement,Major,Closed,"2015-05-07 16:41:06","2015-05-07 15:41:06",2
"Sonatype Nexus","Helper text spans 3 lines, could be 1 and save space","I noticed that the Online helper text (seen when creating or editing a repository) spans 3 lines [see attached] and it seems it could be 1 line saving space and consolodating the page a bit.  ADMIN_REPOSITORIES_SETTINGS_ONLINE_HELP in PluginStrings.js seems to be defined as 1 string without breaks, so I assume this is a page issue.  We've specifically spoken about real estate on this page so filing improvement.    This is recent regression to Dizzam and I suspect unintentional fallout (perhaps from http://bamboo.s/browse/NX3-OSS-229/commit ?).    Spoke to [~<USER> about this before filing.",Improvement,Trivial,Closed,"2015-05-07 15:29:39","2015-05-07 14:29:39",0.5
"Sonatype Nexus","support distinct artifactMaxAge and metadataMaxAge settings in NPM","# Create an NPM proxy repository. Leave default values. Save.  # Edit the repository configuration, changing to these values and Save.  ## Not Found Cache TTL = 5  ## Artifact Max Age = 0  ## Metadata Max Age = 0  ## Item Max Age = 1440  # Confirm the values are as you have saved them in nexus.xml and UI.  # Try to change the values back to default values and click Save  # Resulting Values:  ## Not Found Cache TTL = 1440  ## Artifact Max Age = 0  ## Metadata Max Age = 0  ## Item Max Age = 1440      The only way to reset the configuration is     - delete the repository and start over  - edit nexus.xml directly    The UI is sending the correct values, but the backend refuses to save these and responds with:    {noformat:title=response json}  {data:{contentResourceURI:http://localhost:8081/nexus/content/repositories/npmjs,id:npmjs,name:npmjs,provider:npm-proxy,providerRole:org.sonatype.nexus.proxy.repository.Repository,format:npm,repoType:proxy,exposed:true,writePolicy:READ_ONLY,browseable:true,indexable:false,notFoundCacheTTL:1440,repoPolicy:MIXED,checksumPolicy:IGNORE,downloadRemoteIndexes:false,defaultLocalStorageUrl:file:/app/nexus-testing/2.11.2-06/nexus-professional-2.11.2-06-bundle/sonatype-work/nexus/storage/npmjs/,remoteStorage:{remoteStorageUrl:https://registry.npmjs.org/},fileTypeValidation:true,artifactMaxAge:0,metadataMaxAge:0,itemMaxAge:1440,autoBlockActive:true}}  {noformat}  ",Bug,Major,Closed,"2015-05-06 21:51:50","2015-05-06 20:51:50",2
"Sonatype Nexus","Chrome: Cannot use scroll wheel to view some bundles details","I just noticed that I cannot scroll through the bundles details using the scroll wheel of my mouse or the the trackpad of my laptop when in Chrome.  FF works fine and the bundles list also works fine (in Chrome).  Something about the bundles details.  Workaround is to use the scrollbar on the right side or just mousing over it and scrolling.  Copy/highlight mouse dragging also works (tho is an ugly workaround).  Note, keyboard also isn't a workaround but is not part of this issue as it doesn't work on the list or in FF either.  Seems just that keyboard movement through pages is not supported.    The bundles revamp is new to Dizzam.  I did not check older versions of NX3 to see if the same issue affects Plugins.  I did not check NX2 at this time.",Bug,Trivial,Closed,"2015-05-06 21:02:28","2015-05-06 20:02:28",1
"Sonatype Nexus","Search criteria have navigation with no items","I noticed that on the RAW search, if you click More Criteria there's an option for Raw Repositories but it contains no items.  When you drill into, it does open a menu but since there are no items there's a single grey line.  The non-menu type items on this page have a more expected function: you pick them and they disappear from the list.    This issue is not limited to RAW.  You can get this to repro with any menu item that has a second level by adding all the items in that item to the search.    I did not check older versions of NX3 or NX2 at this time.    Steps to repro (this is just the one the attached screen shows):  0) Do not need to login (unless your anonymous is messed up).  1) Click on + to expand Search  2) Click on Raw  3) Click on More Criteria  4) Hover over Raw Repositories.  BUG: Selector is blank.",Bug,Trivial,Closed,"2015-05-06 20:09:06","2015-05-06 19:09:06",0.5
"Sonatype Nexus","Cannot push nuget packages","NEXUS-8419 test essentially involves pushing a package to NuGet hosted and deleting it.  I found that pushing a package was generating an error.  [~<USER> said he noted the same error working on the IT but it was not ticketed yet.  This is that ticket.  This ticket blocks NEXUS-8419 testing so I've marked it a blocker.  This is Dizzam regression and does not occur in NX2.    Here's the error from the log:  {quote}  2015-05-06 12:25:51,850-0400 ERROR [qtp1745283964-51] admin com.sonatype.nexus.r  epository.nuget.internal.NugetPushHandler - Unknown error  java.lang.IllegalStateException: attempted use of temporary document id          at com.google.common.base.Preconditions.checkState(Preconditions.java:17  3) [com.google.guava:18.0.0]          at org.sonatype.nexus.orient.entity.EntityAdapter$AttachedEntityId.getVa  lue(EntityAdapter.java:275) [org.sonatype.nexus.orient:3.0.0.SNAPSHOT]          at org.sonatype.nexus.common.entity.EntityId.toString(EntityId.java:68)  [org.sonatype.nexus.common:3.0.0.SNAPSHOT]          at org.sonatype.nexus.repository.search.SearchFacetImpl.identifier(Searc  hFacetImpl.java:47) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]          at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(Metho  dInvocationAction.java:40) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]          at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGu  ard.java:233) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]          at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(Guarde  dInterceptor.java:53) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]          at org.sonatype.nexus.repository.search.SearchFacetImpl.put(SearchFacetI  mpl.java:53) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]          at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(Metho  dInvocationAction.java:40) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]          at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGu  ard.java:233) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]          at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(Guarde  dInterceptor.java:53) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]          at com.sonatype.nexus.repository.nuget.internal.NugetGalleryFacetImpl.cr  eateOrUpdatePackageAndContents(NugetGalleryFacetImpl.java:425) [na:na]          at com.sonatype.nexus.repository.nuget.internal.NugetGalleryFacetImpl.pu  t(NugetGalleryFacetImpl.java:331) [na:na]          at org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(Metho  dInvocationAction.java:40) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]          at org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGu  ard.java:233) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]          at org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(Guarde  dInterceptor.java:53) [org.sonatype.nexus.common:3.0.0.SNAPSHOT]          at com.sonatype.nexus.repository.nuget.internal.NugetPushHandler.storePa  yload(NugetPushHandler.java:75) [na:na]          at com.sonatype.nexus.repository.nuget.internal.NugetPushHandler.handle(  NugetPushHandler.java:55) [na:na]          at org.sonatype.nexus.repository.view.Context.proceed(Context.java:89) [  org.sonatype.nexus.repository:3.0.0.SNAPSHOT]          at org.sonatype.nexus.repository.security.SecurityHandler.handle(Securit  yHandler.java:46) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]          at org.sonatype.nexus.repository.view.Context.proceed(Context.java:89) [  org.sonatype.nexus.repository:3.0.0.SNAPSHOT]          at org.sonatype.nexus.repository.view.handlers.TimingHandler.handle(Timi  ngHandler.java:46) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]          at org.sonatype.nexus.repository.view.Context.proceed(Context.java:89) [  org.sonatype.nexus.repository:3.0.0.SNAPSHOT]          at org.sonatype.nexus.repository.view.Context.start(Context.java:112) [o  rg.sonatype.nexus.repository:3.0.0.SNAPSHOT]          at org.sonatype.nexus.repository.view.Router.dispatch(Router.java:58) [o  rg.sonatype.nexus.repository:3.0.0.SNAPSHOT]          at org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(Con  figurableViewFacet.java:45) [org.sonatype.nexus.repository:3.0.0.SNAPSHOT]          at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.dispatc  hAndSend(ViewServlet.java:177) [org.sonatype.nexus.plugins.nexus-repository-http  bridge:3.0.0.SNAPSHOT]          at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.doServi  ce(ViewServlet.java:164) [org.sonatype.nexus.plugins.nexus-repository-httpbridge  :3.0.0.SNAPSHOT]          at org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.service  (ViewServlet.java:121) [org.sonatype.nexus.plugins.nexus-repository-httpbridge:3  .0.0.SNAPSHOT]          at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.s  ervlet-api:3.1.0]          at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefi  nition.java:287) [com.google.inject:4.0.0]          at com.google.inject.servlet.ServletDefinition.doService(ServletDefiniti  on.java:277) [com.google.inject:4.0.0]          at com.google.inject.servlet.ServletDefinition.service(ServletDefinition  .java:182) [com.google.inject:4.0.0]          at com.google.inject.servlet.DynamicServletPipeline.service(DynamicServl  etPipeline.java:70) [com.google.inject:4.0.0]          at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainI  nvocation.java:85) [com.google.inject:4.0.0]          at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerReq  uestFilter.java:112) [org.apache.shiro.web:1.2.3]          at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainI  nvocation.java:82) [com.google.inject:4.0.0]          at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilte  rChain.java:61) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.j  ava:108) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilt  er.java:137) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerReq  uestFilter.java:125) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilte  rChain.java:66) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.j  ava:108) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilt  er.java:137) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerReq  uestFilter.java:125) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilte  rChain.java:66) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.j  ava:108) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilt  er.java:137) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerReq  uestFilter.java:125) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilte  rChain.java:66) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(Abstrac  tShiroFilter.java:449) [org.apache.shiro.web:1.2.3]          at org.sonatype.nexus.web.SecurityFilter.executeChain(SecurityFilter.jav  a:87) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]          at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiro  Filter.java:365) [org.apache.shiro.web:1.2.3]          at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallab  le.java:90) [org.apache.shiro.core:1.2.3]          at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable  .java:83) [org.apache.shiro.core:1.2.3]          at org.apache.shiro.subject.support.DelegatingSubject.execute(Delegating  Subject.java:383) [org.apache.shiro.core:1.2.3]          at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(Abs  tractShiroFilter.java:362) [org.apache.shiro.web:1.2.3]          at org.sonatype.nexus.web.SecurityFilter.doFilterInternal(SecurityFilter  .java:103) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]          at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerReq  uestFilter.java:125) [org.apache.shiro.web:1.2.3]          at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainI  nvocation.java:82) [com.google.inject:4.0.0]          at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilte  r(LicensingRedirectFilter.java:134) [com.sonatype.nexus.plugins.nexus-licensing-  plugin:3.0.0.SNAPSHOT]          at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainI  nvocation.java:82) [com.google.inject:4.0.0]          at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(Abst  ractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]          at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainI  nvocation.java:82) [com.google.inject:4.0.0]          at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFil  ter.java:65) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]          at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainI  nvocation.java:82) [com.google.inject:4.0.0]          at org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(Environmen  tFilter.java:92) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]          at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainI  nvocation.java:82) [com.google.inject:4.0.0]          at com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilte  rPipeline.java:104) [com.google.inject:4.0.0]          at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [c  om.google.inject:4.0.0]          at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [c  om.google.inject:4.0.0]          at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:2  03) [com.google.inject:4.0.0]          at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130)  [com.google.inject:4.0.0]          at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(Delegatin  gFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]          at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet  Handler.java:1652) [org.eclipse.jetty.servlet:9.2.9.v20150224]          at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java  :585) [org.eclipse.jetty.servlet:9.2.9.v20150224]          at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j  ava:143) [org.eclipse.jetty.server:9.2.9.v20150224]          at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.jav  a:577) [org.eclipse.jetty.security:9.2.9.v20150224]          at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandl  er.java:223) [org.eclipse.jetty.server:9.2.9.v20150224]          at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandl  er.java:1127) [org.eclipse.jetty.server:9.2.9.v20150224]          at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:  515) [org.eclipse.jetty.servlet:9.2.9.v20150224]          at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandle  r.java:185) [org.eclipse.jetty.server:9.2.9.v20150224]          at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandle  r.java:1061) [org.eclipse.jetty.server:9.2.9.v20150224]          at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j  ava:141) [org.eclipse.jetty.server:9.2.9.v20150224]          at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper  .java:97) [org.eclipse.jetty.server:9.2.9.v20150224]          at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHa  ndler.java:175) [com.codahale.metrics.jetty9:3.0.2]          at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerColl  ection.java:110) [org.eclipse.jetty.server:9.2.9.v20150224]          at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper  .java:97) [org.eclipse.jetty.server:9.2.9.v20150224]          at org.eclipse.jetty.server.Server.handle(Server.java:497) [org.eclipse.  jetty.server:9.2.9.v20150224]          at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) [or  g.eclipse.jetty.server:9.2.9.v20150224]          at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.jav  a:257) [org.eclipse.jetty.server:9.2.9.v20150224]          at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java  :540) [org.eclipse.jetty.io:9.2.9.v20150224]          at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPoo  l.java:635) [org.eclipse.jetty.util:9.2.9.v20150224]          at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool  .java:555) [org.eclipse.jetty.util:9.2.9.v20150224]          at java.lang.Thread.run(Thread.java:745) [na:1.7.0_75]  {quote}    Of note, this error occurs both before and after setting API key, so you should see it pretty fast in the test.  I was testing using the SONATYPE.TEST package and nuget cmd line tool if it matters.",Bug,Blocker,Closed,"2015-05-06 17:38:47","2015-05-06 16:38:47",0.5
"Sonatype Nexus","staging.xml validation can orphan nexus.xml repositories during startup","Under certain startup conditions, Nexus staging configuration validation can orphan staging repositories such that they are no longer visible in the Nexus Staging Repositories UI. The repository storage directory will still exist for the repository, and the orphaned staging repository(s) will still be visible via Repositories -> Nexus Managed Repositories list.    Example log excerpts on startup where staging validation removed a staging repository {{raid_staging-1197}} because it was not yet added to the internal registry of repositories:        h4. Symptoms    After a Nexus restart, some staging repositories are no longer visible in the staging repositories list.    Log messages similar to this will be present in nexus.log:    {quote}  com.sonatype.nexus.staging.internal.persist.DefaultStagingConfiguration - Validation warning:  o repositories - Staging Repository 'raid_staging-1197' is not a valid repository, removing from configuration.  {quote}    h4. Workaround    There is no workaround to prevent this race condition.    h4. How to Recover Orphaned Repositories.    Repositories can be recovered by <USER> Affected users should open a support ticket at https://support.sonatype.com along with a Nexus support bundle.",Bug,Major,Closed,"2015-05-06 16:03:55","2015-05-06 15:03:55",1
"Sonatype Nexus","not found cache should be expired for packages with implied references from updated package metadata","1. Create an npm proxy repository to the official registry  2. Request a known package file in the remote registry, through the proxy repository ( not metadata ). This will result in 404. This is as currently designed as Nexus needs package metadata before getting any related package.  3. request the metadata for the package file in step 2. This is 200 as expected.  4. request the package that was requested in step 2. This is still 404 not found until an expire cache task on the repository is run or the not found cache expires naturally for the package.    Expected: When we update the package metadata, the not found cache should be expired for any package referenced in that metadata. Meaning the 404 not found in step 4 above should not require manually expiring cache or waiting until repository configured cache timeout.",Bug,Major,Closed,"2015-05-06 14:21:24","2015-05-06 13:21:24",0.5
"Sonatype Nexus","(CMA) Repos can become uneditable","While reviewing CMA Repos, I noticed that intermittantly, they were becoming uneditable.  After a lot of permuting through, I found the below reproducable case.  There may be more.  I'm 100% sure, for example, I have seen maven-public uneditable (took a screenshot - which I've attached).  Hopefully this gives enough of a lead to investigate without me permuting through a bunch more items.    If this seems familiar, it may be because of NEXUS-8517.  I am creating a seperate ticket for several reasons.  First, there was some skepticism if that ticket is about granting proper permissions (like a race condition to edit before the repo is editable).  This is with default created repos so there shouldn't be such a race to my knowledge.  Second, totally different set of steps.  You'll note there actually isn't any actions besides view changes being done.  Third, this seems to have nothing to do with timing (NEXUS-8517 goes away if you wait a very small amount of time).  I waited a minute or more between each of the steps below (used a timer) to make sure of this.    CMA repos are new to Dizzam so no previous NX3 testing can be done at this time.  I did not check NX2 at this time.  I did however check both OSS and PRO and this affects both.    Steps:  (from Repository>Repositories)  1) Create - (pick a type, but seems to be any type)  2) Repositories breadcrumb  3) Edit maven-central (looks OK)  4) Repositories breadcrumb  5) Create - (pick a type, but seems to be any type)  6) Repositories breadcrumb  7) Edit maven-central; BUG: normally editable fields remote storage URL, maximum artifact age and NFC TTL are greyed out/uneditable.  No permission to edit message at bottom by save button.",Bug,Minor,Closed,"2015-05-01 22:16:29","2015-05-01 21:16:29",1
"Sonatype Nexus","Format specific config parameter for repositories ","The repo admin has a number of common parameters for all formats as well as format specific parameters.     Ideally the common parameters should always be in the same order and the same location and maybe even visually different.    The format specific parameters should be separate and maybe even highlighted as such.     E.g. Nuget Proxy repo has Query cache size and Query cache age in the middle of other configs.    Maven repo format has Version policy and that is also in between fields.     It would be nice to be able to have this consistent and easily visible somehow.",Bug,Trivial,Closed,"2015-05-01 22:12:55","2015-05-01 21:12:55",1
"Sonatype Nexus","Disable changing version policy on Maven repo","In the new CMA repo I can edit the version policy of a repository after the repository was created. So I can change a release repo to be a snapshot repo afterwards.    I can also change it to mixed even though there might not even be such a repository version policy.    I think it should not be possible to change the version policy after the repo was created (unless I am missing something) and there should be no mixed policy in the drop down.",Bug,Major,Closed,"2015-04-30 22:21:43","2015-04-30 21:21:43",0.5
"Sonatype Nexus","Use paranamer for method validation messages","Presently we have a lot of bean validation annotations on methods which need to specificy message in order to generating meaningful validation responses, due to java < 8 not exposing the parameter names of methods.    We can use paranamer before we require java8 to get the same information:    https://github.com/<USER>hammant/paranamer    ... and remove the need for lots of verbose bean validation annotations.    So that:        Can be simply:    ",Improvement,Minor,Closed,"2015-04-30 20:08:57","2015-04-30 19:08:57",1
"Sonatype Nexus","On repo save NTLM auth fields disappear","I noticed that after saving a repo with auth checked and authentication type Windows NTLM, the Windows NTLM specific auth fields (Windows NTLM hostname and Windows NTLM domain) disappear.  This persists through repo switching but not through refresh/restart or even paging away (outside of CMA repository) and returning to repos.  So those are your workarounds.  This occurs regardless if the fields have values or not.    This is not a problem in NX2 but there's also not two types in NX2, there's just 1 and you use whatever fields you need.  So really this is new to NX3.  Since Admin UI is new to Dizzam no older NX3 checks were done.",Bug,Trivial,Closed,"2015-04-30 14:45:14","2015-04-30 13:45:14",0.5
"Sonatype Nexus","deprecate and disable the download nuget feed scheduled task","As of version 2.10.0, the download nuget feed task is no longer needed for nuget proxy repositories.  We stopped scheduling this automatically in that version, and told people to remove the task in the release notes.  But still, I very often see customer configurations that have this task running.     We're planning a community outreach to get people to remove this task from their instances.  While I was writing up the content for that it occurred to me that the negatives associated with this task for both the end user and nuget.org are very significant:    * It puts a significant load on the nuget.org repository (they are complaining of these queries DOS'ing their server)  * Over time causes size of the nuget h2 database to grow so large that queries [become very slow|https://support.sonatype.com/entries/88909378]    And really, there is almost no benefit to running this task.  I'm thinking we should disable this task in 2.11.3:    # Change the name of the task to Download NuGet Feed (DEPRECATED)  # Change the default implementation to be a no-op              ",Improvement,Major,Closed,"2015-04-29 20:09:45","2015-04-29 19:09:45",1
"Sonatype Nexus","Roles: Filters count as changes to discard","After writing up NEXUS-8520, I clicked log out to continue my testing and noticed I was prompted to discard changes or back.  I hadn't done anything but filter.  This behavior was reproducable on clean login.  Go to roles, edit one, filter on something and try and logout.  I do not believe the filter itself should be included in the changes only the actual changes made to the roles/privlege sections.  Filing for evaluation.    Did not review older versions of NX3 or NX2 at this time.",Bug,Trivial,Closed,"2015-04-29 14:56:08","2015-04-29 13:56:08",0.5
"Sonatype Nexus","Repo uneditable right after creating","Right after creating a maven group, I went to delete it and noticed I could not.  It said I didn't have permission and the delete button (and save button) was greyed out.  I tried another group and it was ok, so I went back to see if there was any errors and it was deletable.  I was able to repro this with maven proxy, maven hosted, nuget proxy and nuget hosted.  Surprisingly I could not with nuget groups (may be a fix hint there).  See attached video example.  This solved itself once (I am not sure how) but I was able to get this behavior to continue by refreshing my browser.  So there may be a complicated workaround but it is not obvious to me.  The easier workaround is to wait a couple seconds to edit.  It seems to be around the same as it takes the repo is created note to fade (maybe 4-5 seconds).    Admin UI is new to CMA for Dizzam so no NX3 backcheck is possible.  I did not check NX2 at this time.",Bug,Minor,Closed,"2015-04-28 22:59:19","2015-04-28 21:59:19",1
"Sonatype Nexus","Category column disappears from Capabilities page","-While reviewing the NX3 documentation for Capabilities, I noticed that there was a section describing a Category column.  I thought this hangover from NX2 but [~<USER> noted he saw it in OSS (I was testing PRO).-  -I double checked and see what he did.  OSS has a Category column in the Capabilities section and PRO does not.-  -I can't think of any reason for this inconsistancy so filing.-    -The category does show when inside the details of the Capability so making trivial.  I did not check older NX3 or NX2 at this time.-    UPDATE: Testing unrelated today, I noticed the Category column missing from OSS. It appears on initial load, but disappears if you leave the page and return. I rechecked PRO and the same thing happens. Sorry for initial misanalysis and titling.",Bug,Trivial,Closed,"2015-04-28 18:29:12","2015-04-28 17:29:12",0.5
"Sonatype Nexus","Authentication password gets overwritten with nothing (does not save?)","While testing NEXUS-8479, I performed the roundabout test listed there to check it and noticed that in the end my authentication password was blank.  I was able to reproduce this somewhat more easily by creating a new proxy repo (minimum fields), editing it to add authentication including username/password, saving, then saving again.  Note, after the first save password shows *** but after the second save it erases.  There are more complex ways to see this as well, but that's the simple one.  I did not check if the password actually saves the first time but the second time it's definately being overwritten by nothing.    The CMA Admin UI is new to Dizzam so no NX3 backcheck was done at this time.  I did not check NX2 at this time.",Bug,Major,Closed,"2015-04-28 18:03:18","2015-04-28 17:03:18",0.5
"Sonatype Nexus","Information copies over from proxy to proxy","While testing NEXUS-8479, I performed the instructions there, entering into a newly created (maven) proxy and entering in authentication and later http request information, and went to another repo.  I picked the Central repo.  When I did this, I noticed that despite the fact that Central has no authentication or http request information that the information from the newly created proxy was copying to Central.  I thought this was the inverse issue of NEXUS-8479 but [~<USER> stated this was a distinct issue from NEXUS-8479 so I'm filing here.  Probably worth rechecking NEXUS-8479 steps when this fix is performed just in case.    No huge harm in this defect (besides lying) except you can inadvertantly copy in information if you save.  Workaround is to delete the info before proceeding to save.    Admin UI (CMA) is new for Dizzam so no back checking at this time.  I did not check NX2 at this time.",Bug,Minor,Closed,"2015-04-28 15:21:11","2015-04-28 14:21:11",0.5
"Sonatype Nexus","Storage facet not using transactions","(Late filing, this is not a new issue) Stuart noticed that now that we've switched from Orient's Graph API to the Document API, transactions aren't automatically started.",Bug,Major,Closed,"2015-04-28 15:20:15","2015-04-28 14:20:15",0.5
"Sonatype Nexus","Maven Version policy uneditable but shows as normal text field would","In NEXUS-8490, [~<USER> resolved the issue such that Version policy was only editable on create and never later.  However, I noticed while testing that on edit, the field appeared white as a normal editable text field would, not grey like the uneditable fields.  Rather than sending back, Alin asked me to file seperately.  This is new to NX3 so older checks are not done at this time.  I did not check NX2 at this time either.",Bug,Trivial,Closed,"2015-04-27 17:36:58","2015-04-27 16:36:58",0.5
"Sonatype Nexus","Authentication Password should always be required","-Noticed that when creating a Maven Proxy when I checked Authentication password did not appear to be required, however, when I submit it was required but via a different message and apparently means as every other field.-  -After talking to [~<USER>, he believes this should not be required so ticketing.-    -This is new to Admin UI so no older NX3 checking is needed.-  -In NX2, password was autofilled in on save attempt rather than it being required.  Because the password was not clearcase I am not sure at this time what was being filled in there.  I assume this could be potentially blank (and appear different) moving forward.  Whether it's actually different, may be a deeper Q.-    UPDATE:  - as per discussion with the team we will no longer support the NX2 behaviour; username and password will always be required and we just need to sort out the details to ensure that the model is consistent across CRUD operations. https://groups.google.com/a/sonatype.com/forum/?hl=en#!topic/sonatype-nexus-dev-group/AWsMoklJY34    Acceptance criteria:  - Password field should be required and styled as such in the UI",Bug,Major,Closed,"2015-04-27 15:59:53","2015-04-27 14:59:53",0.5
"Sonatype Nexus","Disconnect between Admin UI and nuget-hosted config","While testing pushing a NuGet artifact, I noticed that the new Admin UI had Deployment Policy set automatically for the default NuGet hosted repo as read only.  Despite this I was able to push a NuGet artifact.    On further investigation with [~<USER>, we discovered that the initial configuration displayed in the admin UI is not reflected in the database (see attached - row 5).  Further, changes to that repo configuration do not update the DB, despite reflecting in the UI.    Using a newly configured NuGet hosted repo works properly and is the workaround.    This is new to CMA with the addition of the admin UI so no NX3 back checking is possible at this time.  There are no default NuGet repos in NX2 so cannot compare there either.",Bug,Major,Closed,"2015-04-24 17:41:14","2015-04-24 16:41:14",0.5
"Sonatype Nexus","Default repo creation has deployment policy read only","The new CMA default (host) repo creation has deployment policy set as read only.  The NX2 default was dependant upon the release policy (disable redeploy for [maven] release, allow redeploy for [maven] snapshot, etc).  After speaking with [~<USER> and [~<USER> this did not sound intentional so filing.  These policies are new to CMA so no back checking of NX3 can be performed.    Workaround to select what deployment policy is correct manually.    This also affects the default NuGet hosted repo and caused me to find the related (linked) defect.    UPDATE:  - based on discussion during planning today we will leave the default as 'Disable redeploy' and it is already not read-only at this point.",Bug,Minor,Closed,"2015-04-24 17:36:06","2015-04-24 16:36:06",0.5
"Sonatype Nexus","Default nuget proxy has out of bounds value by default","Noticed the default nuget proxy has a value for http request settings outside the bounds of the field (20000, the field allows max of 3600).  Since you subsequently cannot save, it seems likely either the max needs raised or the default needs lowered.  I am marking trivial since you can easily edit to what you want, tho I think this can be improved.    I am wondering if this was supposed to be 2000 and an extra 0 was struck.    This does not occur for default Maven proxy, tho the value is 1500, so no sure guidance there.    There are no default nuget repos in NX2 or older NX3 to compare against.",Bug,Trivial,Closed,"2015-04-24 15:49:34","2015-04-24 14:49:34",0.5
"Sonatype Nexus","Bad repo name validation message missing","Noticed that when you enter in a ? or space on creation of a repository in the Name field you get a validation MISSING_I18N:NAME_VALIDATION_MESSAGE.  Seems the validation message for bad names (vs empty names) is undefined.  I checked all available repo types and it affects them all.    The legacy repo message is    For reference, not saying that should be the new message necessarily (tho it reads fine to me if true).    This is new to CMA and does not affect older versions of NX3. Nor NX2.",Bug,Trivial,Closed,"2015-04-24 15:31:42","2015-04-24 14:31:42",0.5
"Sonatype Nexus","Maven Repository Policy unselectable initially","While testing NEXUS-8486, I noticed that the Central Repository Policy was uneditable despite the fact it should be an editable field.  I created another proxy and it occurs there as well.  The workaround is to enter a repository whose type is NOT Maven Proxy and then the field works.  Until you refresh/restart.  No JS errors.  This is new to NX3 so did not check older versions.  I did not check NX2 at this time.",Bug,Minor,Closed,"2015-04-23 23:03:04","2015-04-23 22:03:04",0.5
"Sonatype Nexus","http proxy settings not working for outbound remote storage requests","Start nx3 for the first time. empty storage.  Add an HTTP proxy to Nexus.  Trust the SSL certificate my proxy serves using the SSL Certificates UI ( this works fine and goes through proxy)    GET http://localhost:8081/repository/maven-central/abbot/abbot/0.13.0/abbot-0.13.0.pom    Request is 200 and works, but request does not go through proxy server    tested nexus-professional-3.0.0-20150423.044744-931-bundle  ",Bug,Major,Closed,"2015-04-23 18:03:46","2015-04-23 17:03:46",1
"Sonatype Nexus","Central shows Repository Policy MIXED","Noticed that NX3 Central repository currently shows Repository Policy MIXED.  This is different from NX2 where it shows Releases.  Releases is an option in the dropdown.  After asking in HipChat filing as regression.    Aside, if this is deemed intentional, I also noticed there's no way to switch back from MIXED, so I'd guess that's a bug and will probably file on it.",Bug,Minor,Closed,"2015-04-23 16:44:12","2015-04-23 15:44:12",0.5
"Sonatype Nexus","Cancel from Verify SMTP connection validates and takes second click","While testing NEXUS-8447, I was on System>Email Server in Verify SMTP Connection popout and clicked to cancel.  Doing so (with no emailed filled in) caused validation to occur.  A second click closes the popout successfully.  Having emailed filled in and clicking cancel also behaves correctly.    I guess this is likely the same fix as NEXUS-8430.  It's definately similar behavior.",Bug,Minor,Closed,"2015-04-22 22:56:02","2015-04-22 21:56:02",0.5
"Sonatype Nexus","It should be apparent you cannot delete a default logger","While reviewing the NEXUS-8377 PR, I noticed that when I tried to delete a default logger nothing happened (page refreshed, logger remained (including on refresh), no error in UI or JS).  I recall talking about this before but I could not find a ticket.  So I am assuming this is a bug because it does not function this way in NX2.  I did not check older versions of NX3 at this time.    If this turns out to be a change in NX3, I think the document should be updated with this fact.    Workaround is to disable (OFF) the logger.",Bug,Trivial,Closed,"2015-04-22 22:04:11","2015-04-22 21:04:11",2
"Sonatype Nexus","EhCache OptionalDataException on unused instance from Shiro session serialization handling","I had NX3 (today's build) running for testing purposes, but left it running for long time (over 5 hrs). At evening, I had zillion of these exceptions in log. UI was showing me that my session has expired, nothing else.    ",Bug,Major,Closed,"2015-04-21 20:32:55","2015-04-21 19:32:55",2
"Sonatype Nexus","Log Viewer shows entire log despite size selection","While testing NEXUS-8442, I was trying to restore my system to the state where I'd had that issue by inputting a large amount of log files (amongst other stuff).  I created the attached ~80mb nexus log, primarily thru turning ROOT onto TRACE.  When I tried to access log viewer in IE I got the below errors (seperate attempts to repro):  SCRIPT14: Not enough storage is available to complete this operation.  File: baseapp-prod.js, Line: 1, Column: 1  SCRIPT14: Not enough storage is available to complete this operation.  File: baseapp-prod.js, Line: 1, Column: 161345  In both cases, the loading swirl stopped swirling but never went away so basically the page did not load.    When I tried to access log viewer in Chrome, I got no JS errors however, the log would load very briefly then white screen.    Note, when I did this with the log at around 16mb there was no issue in either browser, so I all clues point to the size.  BTW, this ticket is especially interesting to me because the log options (in NX2 as well) are to display 25K, 50K and 100K.  It seems shady to me if we're loading an 80mb log in entirity to just get even 100K of data...and no surprise that'd tax resources.    Workaround would be to load the log via console.  I am leaving this major as the workaround may not work for all people (there may be admins without console access) nor do I imagine is it an advisable workaround for marking.    I did not check older versions of NX3 or NX2 at this time.  Note, I don't believe that the issue is related to what I was testing but am filling out the link for completeness (and in case I'm wrong).",Bug,Major,Closed,"2015-04-21 20:24:00","2015-04-21 19:24:00",0.5
"Sonatype Nexus","Cannot scroll in System Information print","While performing UX review, I noticed in System Information the Print window not scrollable (so just shows screen height worth of lines).  This does occur in m3 (checked at <USER>s request) or in NX2.",Bug,Minor,Closed,"2015-04-17 21:58:30","2015-04-17 20:58:30",0.5
"Sonatype Nexus","prefix all jetty specific configuration properties with jetty.","The new jetty xml files in Nexus 3 are copies of those files found in Jetty 9.2.    These files contain system properties to simplify configuration of Jetty without the need to edit the xml files directly.    Some of these properties are prefixed with jetty., some are not:    [https://github.com/sonatype/nexus-oss/blob/master/assemblies/nexus-base-template/src/main/resources/overlay/etc/jetty.xml#L89:L93]     [https://github.com/sonatype/nexus-oss/blob/master/assemblies/nexus-base-template/src/main/resources/overlay/etc/jetty-https.xml#L73:L77]     When prefixed with jetty, it is very clear they are jetty container specific. When not, it is not clear if this applies to Jetty or something internal to Nexus.     There is a chance of conflicts if we don't prefix all jetty properties. It would be more valuable to support when scanning support bundles to see what jetty properties are set when they are grouped alphabetically together as well.    The only downside seems to be that we diverge from shipped default jetty xml files a bit. Personally not a concern with me as our files are bound to diverge in other ways regardless. Nexus jetty xml should be optimized for Nexus, not Jetty living in a vacuum.    Acceptance:     - prefix all container related ( jetty ) system properties with the text 'jetty.', except well established Nexus properties like application-host, etc.",Improvement,Trivial,Closed,"2015-04-17 21:12:57","2015-04-17 20:12:57",2
"Sonatype Nexus","Enable X-Forwarded header handling in NX3","[~<USER> noticed today X-Forwarded header handling is not enabled by default (ref: https://github.com/sonatype/nexus-oss/blob/master/assemblies/nexus-base-template/src/main/resources/overlay/etc/jetty.xml#L55).  He verified uncommenting the lines fixes it but is unsure anything is broken.  He speculates default jetty xml was copied in.    [~<USER> noted this is probably an oversight.  This is a ticket for workflow and safety checks.",Task,Major,Closed,"2015-04-17 19:44:25","2015-04-17 18:44:25",0.5
"Sonatype Nexus","Post-double click to resize a column size, a second resize doesn't work","Noticed while testing NEXUS-8056 in Chrome, on Routing if I double clicked Rule Type, the subsequent double click on Repositories to make it bigger is not working.  If I expand my browsers size it shows the Repositories column already full size so that might be the issue there (I keep my browsers not full screen so I can watch multiple windows easier; it is around the minimum supported 1024 width).    I initially noted this as a comment in NEXUS-8057, curious to see if it'd be fixed there.  <USER>relayed (via HipChat) it would not and asked me to file another ticket.    Here's a video, which also shows me trying to repro the same thing in a Fiddle configured by <USER>for NEXUS-8057.  So, that second part may be irrelavent.    Note, in the course of creating that video, I saw this working once in Nexus, so it's not 100% though 75% is a pretty good repro ratio.  I have not tried other areas of the site at this time, though suspect this would be site wide.  I did not check older versions of NX3 at this time.",Bug,Minor,Closed,"2015-04-17 19:04:34","2015-04-17 18:04:34",1
"Sonatype Nexus","Tasks summary button missing text","During UX review, I noticed that in System>Tasks (on edit) the summary button seems to have lost its text.  Now just shows as a blue box.  This is recent (NX3) regression.  NX2 is not setup this way so is unaffected here.  See attached.",Bug,Minor,Closed,"2015-04-17 15:52:36","2015-04-17 14:52:36",0.5
"Sonatype Nexus","stray null appears on System Information load in IE11","During UX review, I noticed when I load Support>System Information a line null appears in the IE Java Console.  It is not referenced to a page or line of js, it just appears.  I have never seen this before on any page or in any other browser.    Jason has in the past told me that there should be no JS errors and <USER>agreed worth filing for investigation/discussion at least, so here you go.    I did not check older versions of NX3 at this time.  This does not occur in NX2.",Bug,Minor,Closed,"2015-04-17 15:41:09","2015-04-17 14:41:09",0.5
"Sonatype Nexus","Improve System Information mask","During UX review, I noticed when opening Support>System Information the loading mask appeared at the top of the page rather than in the middle.  I'm guessing this is because if in the middle, it'd literally be in the middle which would essentially be unseen 99% of the time because the system information is so long.    I asked <USER>and he replied:  This is actually the feature loading mask, not the form loading mask. Subtle difference. If you click through some of the other menu items, you’ll notice this mask flashing briefly.    I’d file this anyway, since it should mask the entire content window (including breadcrumb), not just the buttons and body. There might also be a way to center the loading indicator, since I agree it’s weird to have it anchored to the top.    Filing as an improvement, though I suppose it could be a bug too.",Improvement,Trivial,Closed,"2015-04-17 15:34:50","2015-04-17 14:34:50",0.5
"Sonatype Nexus","Generating support.zip times out in Windows before it can generate","During UX review, I noticed creating a support.zip in Windows timed out.  This seems OK in Mac.  Nothing shows in log (default levels) besides INFO messages the zip is being generated.  Let me know if those messages would help or if I should try higher/different levels.    I tried this further by removing all the contents except System Information.  This worked albeit slowly (3-4MB file).  My guess thus is either the timeout is too quick or something wrong in Windows (or with my setup).  I did have both options limiters on (the entire time on all systems).",Bug,Major,Closed,"2015-04-17 15:28:36","2015-04-17 14:28:36",2
"Sonatype Nexus","Log Viewer add mark modal has mask inside it","During UX review, I noticed that when you added a mark to the Log (via Support>Logging>Log Viewer) that the modal that you use to add the mark gets a Saving mask.  I had never seen a modal with a mask so asked <USER>and he asked me to file.  He writes: This is a little odd, but the “Add <USER> modal is a bit of an odd-ball itself. Go ahead and file. I’ll probably just move the mask to the log textarea field for consistency.  I do not recall seeing this before but have not checked older versions of NX3 (or NX2) at this time.    Note:  - Just mask the entire UI",Bug,Trivial,Closed,"2015-04-17 15:19:04","2015-04-17 14:19:04",0.5
"Sonatype Nexus","On cancel, window does not return in full view sometimes","During UX review, I noticed that in Windows sometimes I would hit the cancel button and the window would restore to a screen that was not in full view.  See attached for better graphical description.    At first I just noticed in IE but eventually noticed in Chrome.  This issue is intermittant but <USER>asked me to file so he could take a look.  My best luck reproducing was waiting a few seconds (5-10) between test clicks (into view then cancel).  I have been able to break it reliably within 5 attempts by going slower but still does not break every time.    Specifically noticed on:  * Users (on create of new user then cancel) [IE11]  * SSL Certificates (Load Certificate - Paste PEM then cancel) [IE11]  * Logging (Create Logger then cancel) [IE11, Chrome]  * Trusted Keys (Create Key then cancel) [IE11]    I have not yet seen this behavior in any non-Windows browser.  Interestingly, I also haven't yet seen this behavior in OSS but that may have been luck(unluck).  As documented I have also not seen this behavior with breadcrumb clicks.  This may be my lack of doing that or it may be a fix hint there.    If I see more I'll addon.",Bug,Minor,Closed,"2015-04-17 14:46:09","2015-04-17 13:46:09",2
"Sonatype Nexus","Icon missing for Repository View type items","During UX review, I noticed on Security>Priviledges there was no icon for the Repository View type items.  Every other type has an icon.",Bug,Trivial,Closed,"2015-04-17 14:28:46","2015-04-17 13:28:46",0.5
"Sonatype Nexus","+ (expand) icon does not appear in IE11","In the left navigation of IE11, when a main area is collapsed (via the - icon or by default) a + icon does not show to reexpand it.  You can click on the blank area and it will expand.  I left severity major because this is potentially confusing for any who are collapsed by default and/or mistake.  Borderline minor with the workaround.    I've attached a screen of this working in not-IE from <USER> which may be the easiest way to explain (since absence of +s is <USER>to point out, tho can be screened).    I did not check older versions of NX3 at this time.  This does not affect NX2 as there are no +/- icons there.",Bug,Major,Closed,"2015-04-16 22:41:45","2015-04-16 21:41:45",0.5
"Sonatype Nexus","Some pages do not have masks on actions","While doing UX review, I noticed the below pages do not have Saving masks that the rest of the pages do.  After speaking with <USER>we agreed on one ticket.    * Capabilities - Settings (when saving UI:Settings) [noticed FF MacOSX OSS and IE11 Windows 7 PRO)]  * Tasks - Settings (when saving a Task) [noticed FF MacOSX OSS and IE11 Windows 7 PRO]  * Tasks (when running/stopping) [noticed IE11 Windows 7 PRO]  * LDAP (saving to create an LDAP) [noticed IE11 Windows 7, Chrome MacOSX PRO]    I did not check NX2, this perhaps is an improvement but not worrying about that now.",Bug,Trivial,Closed,"2015-04-16 22:31:40","2015-04-16 21:31:40",0.5
"Sonatype Nexus","Some pages/actions have inconsistent masks","Some pages/actions have inconsistant masks re: https://github.com/sonatype/nexus-oss/pull/1162 changes.  Filing one ticket to update after speaking with <USER>    * The Security>SSL Certificates page when Loading PEM, the mask covers the entire page content (but not header or left nav) not just the frame area. [noticed FF MacOSX OSS bundle build]  * Staging Bundle - Upload mask appears to be the whole page not just the area. [noticed Chrome MacOSX PRO bundle build]",Bug,Trivial,Closed,"2015-04-16 22:15:45","2015-04-16 21:15:45",0.5
"Sonatype Nexus","Cancelling out of changing a users password fires validation and requires 2 clicks (sometimes)","While doing the UX overview, I was in Security>Users, edited a user and opened the popout to change their password.  Not wanting to actually do this for a real user, I immediately clicked cancel.  When I did so, validation popped up telling me I needed to enter a user name.  Clicking cancel again closed the popout.  This does not occur if you have the fields filled in and then cancel.  See vid, hopefully clear.",Bug,Trivial,Closed,"2015-04-16 21:52:33","2015-04-16 20:52:33",0.5
"Sonatype Nexus","Reset User Password fires error","While doing the UX review, I noticed that via Security>Users editing a user and resetting their password had the attached screen and linked error: https://gist.github.com/joedragons/6de865fe4725e30f042a    Mulled briefly if this might be related to stripping forgot username/password out but since unsure at least filing for eval.  I did not check older versions of nx3 at this time.",Bug,Major,Closed,"2015-04-16 21:46:53","2015-04-16 20:46:53",1
"Sonatype Nexus","Selecting Format criteria in custom search does nothing sometimes","While doing UX review, I noticed that in Chrome selecting the Format criteria in Custom Search did not load any criteria.  I was able to reproduce this reliably there but not in FF.  In FF, this is reproducable if you go to another search type (NuGet for example) add a criteria, then come back to Custom search type and try adding Format.  Same intermittantly broken behavior in IE11 (Windows7).  Refreshing the page fixes the behavior.",Bug,Major,Closed,"2015-04-16 21:28:22","2015-04-16 20:28:22",1
"Sonatype Nexus","nexus pro log may report nexus as unlicensed on startup even when it is","The 'licenseKey' in AbstractCommercialApplicationStatusSource is only initialized when a LicenseChangedEvent occurred. But this can only happen after NexusInitializedEvent, when the PeriodicLicenseValidator is started.    Anything querying the commercial status before then, like the banner message that appears in the logs at the start of initialization, will assume no license is installed:       Initializing Sonatype Nexus PRO-UNLICENSED 3.0.0-SNAPSHOT    Note: this is only apparent after the recent change to log the edition here instead of the application name (which doesn't include license information). It also looks like this has been an issue for a while because Nx2 also logs the following during initialization:       WARN ... com.sonatype.nexus.licensing.ProfessionalApplicationStatusSource - No license installed    (this state is shortlived, as the PeriodicLicenseValidator is started shortly afterwards.)  ",Bug,Major,Closed,"2015-04-16 18:44:36","2015-04-16 17:44:36",1
"Sonatype Nexus","Possible search index problems on (nuget) delete","While testing NEXUS-8414, I added a NuGet package to a hosted repo then wanting to test again deleted the package from the repo.  On delete, I got the attached warning and errors here: https://gist.github.com/joedragons/6ebca7e16a52c8bbbc35.  Note, despite these, the file did delete correctly.  Speaking with [~<USER>, he said this may be an issue with search index and asked me to file.  Please let me know if I can supply any further detail.  ",Bug,Major,Closed,"2015-04-15 17:58:47","2015-04-15 16:58:47",0.5
"Sonatype Nexus","Realms panel starts uninitialized","Occasionally when I open the Realms page/panel, all of the realms are shown as being 'Available' - this doesn't reflect the actual state, since several are actually active.    Click Save, of course, makes it impossible to use the UI. There aren't any errors reported in the js console.",Bug,Major,Closed,"2015-04-15 15:58:45","2015-04-15 14:58:45",1
"Sonatype Nexus","Edit removing a repository from a group does not take right away","While testing NEXUS-8016, I had added Central to the default nuget group (nuget-group) but later decided I wanted an independant group to test, so removed Central.  Later when I ran the following curl against nuget-group, I was seeing two warnings about incompatable repositories even thought there weren't any.  [~<USER> discovered that there's a problem with removing repositories from CMA such that they will not remove until you restart and then remove them.  He is digging into any other areas/permutations this might affect but asked me to file a ticket.    {quote}  curl -u admin:admin123 -X GET -v http://localhost:8081/repository/nuget-group/Search()/\$count?\$filter=IsLatestVersion&searchTerm=''&targetFramework='net45'&includePrerelease=false  {quote}    I did not check older versions of NX3 at this time.    Steps to reproduce:  1) Login to NX3 as admin  2) Go to Repository>Repositories  3) Edit nuget-group to include Central and save  4) Edit nuget-group to exclude Central (only include the original two nuget repos - proxy and hosted) and save  5) Run the above CURL.  Note there are two WARNs in the log saying Central is included.    NOTE: The first time this broken I noticed loading nuget-group via the UI after step 4, I did not see Central in the configuration (json) however on Nexus restart I did see Central in the configuration (json).  I tried to repro this and it did not occur again.",Bug,Major,Closed,"2015-04-13 22:08:36","2015-04-13 21:08:36",1
"Sonatype Nexus","Cannot create an LDAP connection","This was broken by the recent “unsaved changes” work. The LDAP connection form is being reset when the user drills down to the next screen, which prevents it from being created. Should be a trivial fix.",Bug,Major,Closed,"2015-04-09 17:05:05","2015-04-09 16:05:05",0.5
"Sonatype Nexus","Styling bugs","Nexus design annoyances:    + Menu has thin border at the top (http://take.ms/IFaun)  + Item selector controls have excess padding in the body (http://take.ms/TdU5e)  + Some controls have a permanent scroll bar (http://take.ms/FUgPD and http://take.ms/YfUaI)  + Some controls have inconsistent left alignment (http://take.ms/xKHjD, http://take.ms/Kn2KA, and http://take.ms/M9WdU)  + Bundles toolbar has a grey background (http://take.ms/mth62)  + Bundle detail view needs a wider key column (http://take.ms/LejJt)",Bug,Minor,Closed,"2015-04-09 17:02:06","2015-04-09 16:02:06",2
"Sonatype Nexus","npm plugin does not work with UNC paths","Install Nexus on a path which can be mounted using UNC on Windows.  Start a Powershell console  ( CMD console doesn't like UNC paths ) and change directory to the UNC path when the nexus.bat script lives  Start Nexus with {{./nexus console}}  Notice the Orient database used by the NPM plugin logs some errors on startup, yet the Nexus NPM plugin starts successfully.        Now the NPM plugin is in a bad state. For example, a user can still create npm repositories in Nexus without problem. However simple npm client operations fail in strange ways. Once such way is:    1. Create a npm-proxy repository to https://registry.npmjs.org  2. npm install bower  3. Nexus reports: 404 - Request is serviced by NPM metadata service, remote access not needed from DefaultNpmProxyRepository(id=npm-proxy)    ",Bug,Major,Closed,"2015-04-06 18:20:54","2015-04-06 17:20:54",0.5
"Sonatype Nexus","Port LDAP docs","Added/updated subsections to LDAP connection and auth, user/group mapping & a link to external role mapping",Story,Major,Done,"2015-01-02 23:45:38","2015-01-02 23:45:38",2
"Sonatype Nexus","Use “present” instead of the current year in the copyright notice","So we don’t have to update it every year. Do this:    Copyright © 2008-present, Sonatype Inc. All rights reserved.",Task,Trivial,Closed,"2015-03-31 20:12:06","2015-03-31 19:12:06",1
"Sonatype Nexus","Remove legacy NuGet repo support","Acceptance Criteria  - An admin user can go into NX 3 legacy repo, and won't find any way to add NuGet repositories  - Remove code, tests, references in pro and bundles",Improvement,Major,Closed,"2015-03-31 19:44:24","2015-03-31 18:44:24",1
"Sonatype Nexus","Typo in CLM Server helper text","Noticed that the CLM>Server page helper text says empty a password for the Password field.  Believe this a typo and should be enter a password.  I did not check NX2 or older NX3 versions at this time.",Bug,Trivial,Closed,"2015-03-31 14:33:17","2015-03-31 13:33:17",0.5
"Sonatype Nexus","make it easier to find the nexus software license","The LICENSE.txt file in the Nexus OSS bundle doesn't contain the license Nexus is licensed under, instead it contains the license for the health check plugin.      The EPL software license is actually in the NOTICE.txt file in the bundle.    This is confusing, it seems to me the contents of the files should be reversed.    The github project also doesn't show the license, you need to look at source code headers to figure it out.    ",Improvement,Major,Closed,"2015-03-27 19:45:17","2015-03-27 19:45:17",1
"Sonatype Nexus","Checksum search should be case insensitive","When doing a search for the sha1 hash I was unable to locate the file I was expecting. The tool I was using was generating an upper case hash string which didn't match.    e.g. for http://search.maven.org/#artifactdetails|org.springframework.ws|spring-ws-core|2.2.0.RELEASE|jar  {code:XML}  <dependency>      <groupId>org.springframework.ws</groupId>      <artifactId>spring-ws-core</artifactId>      <version>2.2.0.RELEASE</version>  </dependency>  {code}    The lower case hash works  f5de942e30c3c047a273b5bb42cc5c71d3303fcb  The upper case does not.  F5DE942E30C3C047A273B5BB42CC5C71D3303FCB    Acceptance criteria:    * Make the keyword field case insensitive    Technical notes:    * This will require a reindex",Bug,Major,Closed,"2015-03-24 17:05:27","2015-03-24 17:05:27",2
"Sonatype Nexus","Profile Target Matcher staging rule should not fail on file patterns not uploaded into a staging repository","Setup    - Create a staging ruleset with a Profile Target Matcher Rule  - Create a Repository target that includes these typical patterns:  -- {{^/+com/example/.*}}  -- {{/|/com/|/com/example/.*}}  - Create a staging profile that references the repository target and uses the staging ruleset in the Close and promote set of rulesets to apply    Test  - Stage matching artifacts against this staging profile to create a closed staging repository. This works, as the ruleset patterns match  - Try to release the staging repository. This fails because of the Profile target matcher rule. Nexus created a {{/archetype-catalog.xml}} file on close, and the repository target pattern does not match this.    Expected  - one should not have to add patterns to a repository target for files generated by Nexus in order to apply the Profile Target Matcher rule on a staging repository  - one should still be allowed to apply this rule on Release/Promotion, in case the repository target has changed since the staging repository was closed    ",Bug,Minor,Closed,"2015-03-23 15:17:34","2015-03-23 15:17:34",2
"Sonatype Nexus","Add bean mapping to AttributesMap","In many places we have complex code to read attributes and assign to fields.  It would be nicer to read attributes into a bean.  This would also allow us to use bean-validation framework to implement attribute validation.",Improvement,Minor,Closed,"2015-03-19 17:26:25","2015-03-19 17:26:25",1
"Sonatype Nexus","Nexus RubyGems proxy fails to fetch some gems.","It appears that if a rubygem repository response for a gem is ''Moved Temporarily, nexus fails to follow the url and retrieve this gem.  At the time of writing this text it could be seen for the thread_safe 0.3.5 gem. We are using nexus oss 2.11.2-06 community edition.",Bug,Major,Open,"2015-03-19 11:20:29","2015-03-19 11:20:29",5
"Sonatype Nexus","Investigate and fix failing functional tests","Appears that something has changed in Repository Targets to cause the test to fail. It looks like in most cases the test framework fails to type the expected name completely. And the modal presented for the form definitely has some styling issues.  Failing tests have been quarantined until we sort this out.    http://bamboo.s/chain/result/viewChainResult.action?planKey=NX3-DISTT&buildNumber=43",Bug,Major,Closed,"2015-03-18 15:28:46","2015-03-18 15:28:46",0.5
"Sonatype Nexus","make ?describe optionally return html or json","It would be useful to get ?describe output as JSON in addition to HTML.    - scripting can parse JSON much more easily than html  - when requesting ?describe output from an end user for troubleshooting, asking the user to login to UI, and then using same browser session to request ?describe output is extra work to do and explain. In some cases, the user may not even be able to access the UI due to security restrictions  - it is much simpler to visually grok a JSON response on the cmd line  - a cmd line response as JSON can be more easily piped into JSON parsing tools to isolate specific data    Proposed Criteria:  - if the user agent implies a web browser is being used, return html, otherwise return JSON with the appropriate Content-Type header  - if the request Accept header explicitly requests either JSON or HTML, return it as requested  - the data (model) returned for both content types should be identical  - JSON pretty printed by default is preferable, but not absolutely required initially if it impacts the implementation significantly",Improvement,Minor,Closed,"2015-03-18 15:22:32","2015-03-18 15:22:32",1
"Sonatype Nexus","Validate repository name","Elasticsearch seems to be more finicky that our data model allows right now, and likely spaces in Repository names is something we want to support.      And after removing the space we find we don't allow uppercase letters:      To reproduce just add a new Repository in the UI with a space or capital letter in the name. An unhelpful error is shown in the UI: Failed to start facets    Minimally we should add validation to ensure that we don't allow invalid characters, as right now we end up with configured Repositories that cannot possibly function.    Acceptance criteria:  - names should be validated in the UI, and provide guidance when illegal names are tried  - names should be validated on the server using the same rules as the client(preventing abuse of the ExtDirect api)  - names should only allow (English) alphanumeric and  -_. (dash, underscore, period)  - names should be sanitized for elasticsearch usage in index names; this requires enforcing case-insensitive uniqueness of names as indexes are all lowercase",Bug,Major,Closed,"2015-03-18 01:07:37","2015-03-18 01:07:37",2
"Sonatype Nexus","Add Component/Asset wrappers for OrientVertex","This is a refactoring task to simplify existing format implementations and make it easier to unit test them by adding a Component and Asset wrappers for OrientVertex.    Where it makes sense, these will:  * Be returned by StorageFacet in place of OrientVertex  * Be used by existing format impls in place of direct OrientVertex access  * Take on some of the utility functionality of StorageTx (e.g. getAttributes) and format-specific helpers, if any are found that can be generalized.  * Include getters/setters for format-neutral properties",Task,Minor,Closed,"2015-03-16 14:50:01","2015-03-16 14:50:01",1
"Sonatype Nexus","Add support to set base-url-holder value for scheduled tasks","ATM we only invoke BaseUrlHolder.set() in servlet filter.  We need to have a means to set this in other context, like scheduled tasks.",Improvement,Minor,Closed,"2015-03-12 18:54:03","2015-03-12 18:54:03",1
"Sonatype Nexus","Automatically set last updated date for assets and components","As per March 12th discussion on nexus-cma list.    Acceptance criteria:  * Adding a component or asset record will automatically set the last_updated property to the current time.  * Updating a component or asset record will do the same.  * Works for all types of repositories automatically. Accordingly, this work should also drop the code that manually sets this property today for nuget and raw assets.",Improvement,Minor,Closed,"2015-03-12 18:50:44","2015-03-12 18:50:44",1
"Sonatype Nexus","Capabilities enabled box unchecked during creation","While comparing NX2 and NX3, I discovered that on creation of Capabilities in NX3, the enabled checkbox is automatically unchecked.  In NX2, the enabled checkbox was automatically checked.  I emailed asked if anyone knew if this was intentional and several folks said it was regression, so I am filing.    There was note that some Capabilities we may want not checked to start.  I recently went through and created them all testing something unrelated and am pretty sure they are all functioning this way.  If you'd like me to recheck let me know.    While probably trivial priority (easy workaround to check the box), I am giving minor priority due to regression.  I did not check older versions of NX3 at this time.",Bug,Minor,Closed,"2015-03-10 19:29:48","2015-03-10 19:29:48",0.5
"Sonatype Nexus","Look at enabling strict checksums for our internal maven builds","This might help to catch problems like https://issues.sonatype.org/browse/NEXUS-8221 internally earlier.    [~<USER> brought this up during scrum today, and we'd like to assess the cost/benefit in terms of performance and the possibility to catch Nexus checksum errors sooner. It was also mentioned that checksums from some proxy repos are known to be unreliable, and might lead to false results. ",Task,Major,Closed,"2015-03-09 21:33:57","2015-03-09 21:33:57",1
"Sonatype Nexus","Add authentication guard before allowing template download","Before allowing user to download settings template, ask for authentication, as the template could have sensitive information.",Improvement,Minor,Closed,"2015-03-08 00:32:23","2015-03-08 00:32:23",1
"Sonatype Nexus","Store NuGet package feed metadata at the asset level","To be consistent with other formats (e.g. in terms of how they're displayed in search results), we should store metadata about known-but-not-fetched NuGet packages at the asset level, rather than at the component level.    In other words, when we proxy NuGet metadata, we create a component for each package; underneath we store an asset with no blob.    When/if we fetch the package, we'll update the metadata (as now) and attach the package blob to the asset.",Improvement,Major,Closed,"2015-03-05 20:34:05","2015-03-05 20:34:05",1
"Sonatype Nexus","Certain errors hose the UI","When certain errors (e.g. Ext.Direct errors) occur, the UI will refuse to load features until it is refreshed.    Example: http://take.ms/XG47F    We should change this behavior so failures are localized to features with bad implementations, and don’t affect the web UI globally.",Bug,Major,Closed,"2015-03-05 17:26:13","2015-03-05 17:26:13",0.5
"Sonatype Nexus","Iterate blobs in a blob store","In order to rebuild metadata from blobs (or other disaster recovery type work), we need a way of visiting/walking/iterating the blobs in a blob store.",Story,Major,Done,"2015-03-05 14:56:09","2015-03-05 14:56:09",2
"Sonatype Nexus","Create a task to find and fix bad checksums affected by the extra link detection check","See NEXUS-8221 and NEXUS-8178    The bad checksums are based on the first 8 bytes of the item plus the full content of the item. The task should search the item context and attributes for checksums that match and regenerate them.",Improvement,Critical,Closed,"2015-03-04 17:55:50","2015-03-04 17:55:50",2
"Sonatype Nexus","Update OrientDB from 2.0.2 to 2.0.4","Changes:    https://github.com/orientechnologies/orientdb/issues?q=milestone%3A2.0.4  https://github.com/orientechnologies/orientdb/issues?q=milestone%3A%222.0.3+%28hotfix%29%22  ",Task,Major,Closed,"2015-03-04 13:16:38","2015-03-04 13:16:38",0.5
"Sonatype Nexus","Search indexing appears to miss some components","Steps to replicate:    1. Create a nuget proxy repo (name: 'nugetproxy'), using this configuration:    {    view : {      online : true    },    nugetProxy : { },    proxy : {      remoteUrl : http://www.nuget.org/api/v2/,      artifactMaxAge : 5    },    httpclient : {      connection : {        retries : 2,        timeout : 20000      }    },    storage : { }  }    2. Add some metadata to the proxy. Open a browser to:  http://localhost:8081/repository/nugetproxy/Packages()?$orderby=DownloadCount%20desc&$filter=IsLatestVersion&$skip=0&$top=15&$select=Id,Version,Authors,DownloadCount,VersionDownloadCount,PackageHash,PackageSize,Published&$inlinecount=allpages    Notice that the XML contains 15 entries (15 instances of <entry>), each with different IDs.  (Leave that browser window open.)    3. Do a component search for 'nuget'.  I get only 1 entry, I'm expecting 15.    I notice that the one search result is the last component in the XML feed.    Under some circumstances, when I had a breakpoint set on the indexing (to ensure that the nuget code was actually sending index requests to the search system), I got more search results.    It seems almost as if the index has a buffer that's being overwritten.    4. The component metadata does seem to be intact:    orient:connect plocal:../sonatype-work/nexus/db/component admin admin  orient:select * from component    (I get 15 results.)",Bug,Major,Closed,"2015-03-03 14:53:49","2015-03-03 14:53:49",0.5
"Sonatype Nexus","proxy repository policy strict expects checksums for signature asc files","When releasing with nexus maven staging plugin, we found checksums of pgp signature files were not upload. From our nexus request log      You can see checksum for pom, jar, javadoc and sources are uploaded but not asc files.",Bug,Minor,Open,"2015-03-03 03:34:40","2015-03-03 03:34:40",1
"Sonatype Nexus","Possible to grey out create button","While testing NEXUS-7758, I went to create a task and filtered, but realized I missed something so switched to repositories.  After finding the info I needed, I returned to Tasks but my create button was greyed out/unselectable.  I was able to repro this reliably by filtering on a second level (Tasks) returning to a base level (not even filtering) and then returning.  Steps below.    I went to see if this was an issue in m3 but as far as I can tell there are no second level filters in m3, this is a new concept to Dizzam.  This also does not affect NX2 (same reason but more basic).    Borderline minor as the workaround is to restart/refresh browser.    I do not believe this is related to where I found it but linking in case wrong and for completeness.    Steps:  1) Login to NX3 (Dizzam) as admin  2) Click Tasks (admin section, under System)  3) Click Create  4) Filter by something (like whatever)  5) Click Repositories (left nav item under Repository)  6) Click Tasks again.  BUG: Create is disabled/greyed out.",Bug,Major,Closed,"2015-02-27 17:14:58","2015-02-27 17:14:58",2
"Sonatype Nexus","Cannot save (fake) LDAP connection after creation","Testing NEXUS-7758, I created a fake LDAP connection configuration to make sure the process was still functionally working (as well as graphic changes were made).  I was able to do this however when I went back in to check editing, on save, I got this error.  If I had to guess, I'd say it is checking if my setup is valid on save.  m3 does not do this so if not intentional this is regression.  NOTE: If intentional it is weird to me the initial save works.  I am making an additional assumption that this does not have anything to do with the (fake) variables I entered as I did several several different times, but if you can't repro and want more info about what I put in, let me know.    I did not check NX2 at this time.    {quote}  2015-02-25 16:01:39,947-0500 ERROR [qtp245357559-132] admin com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor - (Controlled) server error: Failed attempt to convert from a json string to java method parameters. Method='ldap_LdapServer.update', Json string='[{order:1,url:ldap://whatever:1/dc=joe,useTrustStore:false,authRealm:null,authUsername:null,authPassword:null,userSubtree:false,userMemberOfAttribute:memberOf,ldapGroupsAsRoles:false,groupType:null,groupBaseDn:null,groupSubtree:false,groupIdAttribute:null,groupMemberAttribute:null,groupMemberFormat:null,groupObjectClass:null,id:cf24ad56-513f-4137-9b9b-99f639bcf55d,name:a,protocol:ldap,host:whatever,port:1,searchBase:dc=joe,authScheme:none,connectionTimeout:30,connectionRetryDelay:300,maxIncidentsCount:3,combo-1569-inputEl:,userBaseDn:,userObjectClass:inetOrgPerson,userLdapFilter:,userIdAttribute:uid,userRealNameAttribute:cn,userEmailAddressAttribute:mail,userPasswordAttribute:userPassword,backupMirrorProtocol:,backupMirrorHost:,backupMirrorPort:,backupMirrorEnabled:false}]', ExpectedTypes='org.sonatype.nexus.ldap.internal.ui.LdapServerXO' for Method 'ldap_LdapServer.update'  com.softwarementors.extjs.djn.gson.JsonException: Failed attempt to convert from a json string to java method parameters. Method='ldap_LdapServer.update', Json string='[{order:1,url:ldap://whatever:1/dc=joe,useTrustStore:false,authRealm:null,authUsername:null,authPassword:null,userSubtree:false,userMemberOfAttribute:memberOf,ldapGroupsAsRoles:false,groupType:null,groupBaseDn:null,groupSubtree:false,groupIdAttribute:null,groupMemberAttribute:null,groupMemberFormat:null,groupObjectClass:null,id:cf24ad56-513f-4137-9b9b-99f639bcf55d,name:a,protocol:ldap,host:whatever,port:1,searchBase:dc=joe,authScheme:none,connectionTimeout:30,connectionRetryDelay:300,maxIncidentsCount:3,combo-1569-inputEl:,userBaseDn:,userObjectClass:inetOrgPerson,userLdapFilter:,userIdAttribute:uid,userRealNameAttribute:cn,userEmailAddressAttribute:mail,userPasswordAttribute:userPassword,backupMirrorProtocol:,backupMirrorHost:,backupMirrorPort:,backupMirrorEnabled:false}]', ExpectedTypes='org.sonatype.nexus.ldap.internal.ui.LdapServerXO'   at com.softwarementors.extjs.djn.gson.JsonException.forFailedConversionFromJsonStringToMethodParameters(JsonException.java:62) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.jsonDataToMethodParameters(JsonRequestProcessor.java:273) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.getIndividualRequestParameters(JsonRequestProcessor.java:255) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:494) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequestsInThisThread(JsonRequestProcessor.java:150) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.process(JsonRequestProcessor.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.RequestRouter.processJsonRequest(RequestRouter.java:83) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.processRequest(DirectJNgineServlet.java:617) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.doPost(DirectJNgineServlet.java:580) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet.doPost(ExtDirectServlet.java:124) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:707) [javax.servlet-api:3.1.0]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:297) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:281) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:186) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.AbstractServletPipeline.service(AbstractServletPipeline.java:65) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [org.sonatype.sisu.guice:3.2.5]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.3]   at org.sonatype.nexus.web.SecurityFilter.executeChain(SecurityFilter.java:87) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:136) [com.sonatype.nexus.plugins.nexus-licensing-plugin:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at org.sonatype.nexus.internal.web.StandardHttpResponseHeadersFilter.doFilter(StandardHttpResponseHeadersFilter.java:80) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:65) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at org.sonatype.nexus.internal.web.BaseUrlHolderFilter.doFilter(BaseUrlHolderFilter.java:68) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.AbstractFilterPipeline.dispatch(AbstractFilterPipeline.java:100) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [org.sonatype.sisu.guice:3.2.5]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) [org.eclipse.jetty.servlet:9.2.7.v20150116]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) [org.eclipse.jetty.servlet:9.2.7.v20150116]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) [org.eclipse.jetty.security:9.2.7.v20150116]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) [org.eclipse.jetty.servlet:9.2.7.v20150116]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.7.v20150116]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.Server.handle(Server.java:497) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:245) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [org.eclipse.jetty.io:9.2.7.v20150116]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) [org.eclipse.jetty.util:9.2.7.v20150116]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) [org.eclipse.jetty.util:9.2.7.v20150116]   at java.lang.Thread.run(Thread.java:745) [na:1.7.0_71]  Caused by: com.google.gson.JsonSyntaxException: java.lang.NumberFormatException: For input string:    at com.google.gson.internal.bind.TypeAdapters$7.read(TypeAdapters.java:232) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.google.gson.internal.bind.TypeAdapters$7.read(TypeAdapters.java:222) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:94) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:178) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.google.gson.Gson.fromJson(Gson.java:791) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.google.gson.Gson.fromJson(Gson.java:855) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.jsonToJavaObject(JsonRequestProcessor.java:365) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.getMethodParameters(JsonRequestProcessor.java:315) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.jsonDataToMethodParameters(JsonRequestProcessor.java:269) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   ... 68 common frames omitted  Caused by: java.lang.NumberFormatException: For input string:    at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) [na:1.7.0_71]   at java.lang.Integer.parseInt(Integer.java:504) [na:1.7.0_71]   at java.lang.Integer.parseInt(Integer.java:527) [na:1.7.0_71]   at com.google.gson.JsonPrimitive.getAsInt(JsonPrimitive.java:255) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.google.gson.internal.bind.JsonTreeReader.nextInt(JsonTreeReader.java:197) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.google.gson.internal.bind.TypeAdapters$7.read(TypeAdapters.java:230) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   ... 76 common frames omitted  {quote}    This is borderline major because of the error however because this only happens (as far as I know) with a fake configuration and optimally users will only ever have legitimate configurations, leaving minor for now.  Workaround would be to use a correct configuration.",Bug,Minor,Closed,"2015-02-26 22:17:27","2015-02-26 22:17:27",1
"Sonatype Nexus","Creating (fake) LDAP errors w/ Map LDAP groups as roles unchecked","While testing NEXUS-7758, I created a fake LDAP just to make sure all the newly formed dialogues were working functionally.  Note, my intention was not to create a real LDAP setup and I don't think that matters in this case.    After filling out Connection information and clicking next, I went to fill out User and group information.  In past iterations, I had picked a configuration template but this time just filled in the required variables.  When I got down to Group Type, I decided to uncheck Map LDAP group as roles (figuring correctly this would hide the required field, thus in essence making it fill).    On creation click, I got the following error in the log as well as a java.lang.IllegalArguementException from the UI.  The UI error struck me the most because almost all of our warnings are defined so you can tell what the error was.    {quote}  2015-02-26 16:00:09,961-0500 ERROR [qtp904481188-171] admin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: ldap_LdapServer.create, java-method: org.sonatype.nexus.ldap.internal.ui.LdapServerComponent.create  java.lang.IllegalArgumentException: null   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.7.0_71]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) [na:1.7.0_71]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.7.0_71]   at java.lang.reflect.Method.invoke(Method.java:606) [na:1.7.0_71]   at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90) [groovy-all:2.3.7]   at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324) [groovy-all:2.3.7]   at groovy.lang.MetaClassImpl.setProperty(MetaClassImpl.java:2662) [groovy-all:2.3.7]   at groovy.lang.MetaClassImpl.setProperty(MetaClassImpl.java:3702) [groovy-all:2.3.7]   at groovy.lang.MetaClassImpl.setProperties(MetaClassImpl.java:1741) [groovy-all:2.3.7]   at org.codehaus.groovy.runtime.callsite.ConstructorSite$NoParamSite.callConstructor(ConstructorSite.java:122) [groovy-all:2.3.7]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callConstructor(AbstractCallSite.java:190) [groovy-all:2.3.7]   at org.sonatype.nexus.ldap.internal.ui.LdapServerComponent.asCLdapServerConfiguration(LdapServerComponent.groovy:362) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.7.0_71]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) [na:1.7.0_71]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.7.0_71]   at java.lang.reflect.Method.invoke(Method.java:606) [na:1.7.0_71]   at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite$PogoCachedMethodSiteNoUnwrapNoCoerce.invoke(PogoMetaMethodSite.java:207) [groovy-all:2.3.7]   at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite.callCurrent(PogoMetaMethodSite.java:56) [groovy-all:2.3.7]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:145) [groovy-all:2.3.7]   at org.sonatype.nexus.ldap.internal.ui.LdapServerComponent.create(LdapServerComponent.groovy:128) [na:na]   at org.sonatype.nexus.extender.modules.ValidationInterceptor.invoke(ValidationInterceptor.java:53) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.7.0_71]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) [na:1.7.0_71]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.7.0_71]   at java.lang.reflect.Method.invoke(Method.java:606) [na:1.7.0_71]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet$3.invokeMethod(ExtDirectServlet.java:204) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.StandardRequestProcessorBase.dispatchStandardMethod(StandardRequestProcessorBase.java:73) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:502) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequestsInThisThread(JsonRequestProcessor.java:150) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.process(JsonRequestProcessor.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.RequestRouter.processJsonRequest(RequestRouter.java:83) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.processRequest(DirectJNgineServlet.java:617) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.doPost(DirectJNgineServlet.java:580) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet.doPost(ExtDirectServlet.java:124) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:707) [javax.servlet-api:3.1.0]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api:3.1.0]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:297) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:281) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:186) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.AbstractServletPipeline.service(AbstractServletPipeline.java:65) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [org.sonatype.sisu.guice:3.2.5]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.3]   at org.sonatype.nexus.web.SecurityFilter.executeChain(SecurityFilter.java:87) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:136) [com.sonatype.nexus.plugins.nexus-licensing-plugin:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at org.sonatype.nexus.internal.web.StandardHttpResponseHeadersFilter.doFilter(StandardHttpResponseHeadersFilter.java:80) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:65) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at org.sonatype.nexus.internal.web.BaseUrlHolderFilter.doFilter(BaseUrlHolderFilter.java:68) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.AbstractFilterPipeline.dispatch(AbstractFilterPipeline.java:100) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [org.sonatype.sisu.guice:3.2.5]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [org.sonatype.sisu.guice:3.2.5]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) [org.eclipse.jetty.servlet:9.2.7.v20150116]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) [org.eclipse.jetty.servlet:9.2.7.v20150116]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) [org.eclipse.jetty.security:9.2.7.v20150116]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) [org.eclipse.jetty.servlet:9.2.7.v20150116]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.7.v20150116]   at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175) [com.codahale.metrics.jetty9:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.Server.handle(Server.java:497) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:245) [org.eclipse.jetty.server:9.2.7.v20150116]   at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) [org.eclipse.jetty.io:9.2.7.v20150116]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) [org.eclipse.jetty.util:9.2.7.v20150116]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) [org.eclipse.jetty.util:9.2.7.v20150116]   at java.lang.Thread.run(Thread.java:745) [na:1.7.0_71]  {quote}    My original test was in Safari but I confirmed in Chrome (both MacOSX).  After doing this, I found that if I left the box checked and filled in the value, everything worked (thus templates were also working).  After realizing that, I checked m3 and it was working there.  This also works in NX2.  This seems new to Dizzam.",Bug,Major,Closed,"2015-02-26 21:45:07","2015-02-26 21:45:07",1
"Sonatype Nexus","Timeout modal dialog does not appear sometimes (related JS error)","While at lunch and shoveling, I timed out NX3 (Dizzam SNAPSHOT) again/as usual.    On return to my session however there was no popout saying it had timed out (as was implemented in m3).  Because of what I was testing, I did have my Javascript Console open and this was there:   POST http://localhost:8081/service/extdirect/poll/rapture_State_get 500 (javax.servlet.ServletException: Filtered request failed.)baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1424962738701:1 Ext.cmd.derive.requestbaseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1424962738701:1 Ext.cmd.derive.runPollbaseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1424962738701:1 Ext.cmd.derive.onTickbaseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1424962738701:1 (anonymous function)    baseapp-prod.js?_v=3.0.0-SNAPSHOT&_dc=1424962738701:1    I'd never seen this fail before so it's intermittent.  However <USER>said he'd seen this before as well, so ticketing so not to lose the (presumably) associated debug.",Bug,Minor,Closed,"2015-02-26 20:26:01","2015-02-26 20:26:01",2
"Sonatype Nexus","Deadlock between yum merge metadata task and yum generate metadata task","Concurrently running yum generate and merge metadata tasks can deadlock.    The generate yum metadata tasks tries to get locks on group metadata:    {quote}      pxpool-1-thread-11 id=181 state=WAITING      - waiting on <0x629c279d> (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)      - locked <0x629c279d> (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)      owned by qtp2025967620-804 id=804      at sun.misc.Unsafe.park(Native Method)      at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:867)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1197)      at java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.lock(ReentrantReadWriteLock.java:945)      at org.sonatype.nexus.yum.internal.YumGroupImpl.markDirty(YumGroupImpl.java:109)      at org.sonatype.nexus.yum.internal.task.GenerateMetadataTask.regenerateMetadataForGroups(GenerateMetadataTask.java:267)      at org.sonatype.nexus.yum.internal.task.GenerateMetadataTask.doRun(GenerateMetadataTask.java:183)      at org.sonatype.nexus.yum.internal.task.GenerateMetadataTask.doRun(GenerateMetadataTask.java:69)      at org.sonatype.nexus.scheduling.AbstractNexusTask.call(AbstractNexusTask.java:151)      at org.sonatype.scheduling.DefaultScheduledTask.call(DefaultScheduledTask.java:418)      at org.sonatype.nexus.threads.MDCAwareCallable.call(MDCAwareCallable.java:44)      at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)      at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)      at java.util.concurrent.FutureTask.run(FutureTask.java:262)      at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)      at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)      at java.lang.Thread.run(Thread.java:745)  {quote}    And the merge metadata tasks tries to get UID locks on the group repositories children, who (presumably) are not giving it to them because they're running generate metadata:    {quote}      pxpool-1-thread-4 id=157 state=WAITING      - waiting on <0x4a6f1c78> (a java.util.concurrent.Semaphore$FairSync)      - locked <0x4a6f1c78> (a java.util.concurrent.Semaphore$FairSync)      at sun.misc.Unsafe.park(Native Method)      at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireShared(AbstractQueuedSynchronizer.java:964)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireShared(AbstractQueuedSynchronizer.java:1282)      at java.util.concurrent.Semaphore.acquireUninterruptibly(Semaphore.java:500)      at org.sonatype.sisu.locks.LocalResourceLock.acquire(LocalResourceLockFactory.java:83)      at org.sonatype.sisu.locks.AbstractSemaphoreResourceLock.lockShared(AbstractSemaphoreResourceLock.java:50)      at org.sonatype.nexus.proxy.item.SisuLockResource.lockShared(SisuLockResource.java:38)      at org.sonatype.nexus.proxy.item.DefaultRepositoryItemUidLock.lock(DefaultRepositoryItemUidLock.java:35)      at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:757)      at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:592)      at org.sonatype.nexus.yum.internal.task.MergeMetadataTask.getBaseDirsOfMemberRepositories(MergeMetadataTask.java:142)      at org.sonatype.nexus.yum.internal.task.MergeMetadataTask.doRun(MergeMetadataTask.java:102)      at org.sonatype.nexus.yum.internal.task.MergeMetadataTask.doRun(MergeMetadataTask.java:61)      at org.sonatype.nexus.scheduling.AbstractNexusTask.call(AbstractNexusTask.java:151)      at org.sonatype.scheduling.DefaultScheduledTask.call(DefaultScheduledTask.java:418)      at org.sonatype.nexus.threads.MDCAwareCallable.call(MDCAwareCallable.java:44)      at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)      at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)      at java.util.concurrent.FutureTask.run(FutureTask.java:262)      at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)      at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)      at java.lang.Thread.run(Thread.java:745)  {quote}",Bug,Major,Closed,"2015-02-26 19:32:54","2015-02-26 19:32:54",0.5
"Sonatype Nexus","Upgrade to Jetty 9.2.9 or greater","There is a vulnerability to avoid so we need to upgrade.    https://github.com/eclipse/jetty.project/blob/jetty-9.2.x/advisories/2015-02-24-httpparser-error-buffer-bleed.md    ",Task,Major,Closed,"2015-02-26 14:46:10","2015-02-26 14:46:10",0.5
"Sonatype Nexus","Subheader text contains redundancy with content","In NEXUS-7758, the capability details were merged from 4 areas to 2.  One of the things that moved was the Notes (About) section.  However, in the post-deploy, I noticed that the details area has a header Notes but the old details also have Notes:.  I checked with [~<USER> and we agree it's redundancy and can be removed.  Because so much of NEXUS-7758 is working, filing a separate ticket to avoid failing the parent over something so small.  See attached for how it is now (one example), if you need more or old screens let me know.  Because of recent adjustment this is not an issue in NX2 or NX3-m3 (or earlier).",Bug,Trivial,Closed,"2015-02-25 22:52:04","2015-02-25 22:52:04",0.5
"Sonatype Nexus","RubyGems repository - error fetching gem from internal gem server ","I can't install gem locally that is stored in internal gem server    I followed the instructions in chapter 18 in the Repository Management with Nexus manual: http://books.sonatype.com/nexus-book/2.11/pdf/nxbook-pdf.pdf    I am using nexus-2.11.2-03    I can install gems that are found on RubyGems.org but I can't install gems that are in my internal gem server. I am able to install the nexus gem and push my internal gem to the internal gem repository. Everything documented in chapter 18 works for me except for the fetching (installing) of gem that is in my internal repository.     I tried to install it using gem as well as bundler and both failed. Attached are the logs, the first test was using gem to install:    gem install amt_modules -v 1.0.3  jvm 1    | 2015-02-25 15:12:40,714+0000 WARN  [qtp1997550262-52] deployment org.sonatype.nexus.proxy.storage.local.fs.DefaultFSPeer - Could not delete file: C:\nexus\sonatype-work\nexus\storage\gems-internal\specs.4.8.gz  jvm 1    | java.nio.file.FileSystemException: C:\nexus\sonatype-work\nexus\storage\gems-internal\specs.4.8.gz: The process cannot access the file because it is being used by another process.    second test was to setup bundler and once run I got an different exception:    bundle install  jvm 1    | 2015-02-25 15:18:43,261+0000 WARN  [qtp1997550262-55] anonymous org.sonatype.nexus.plugins.ruby.proxy.DefaultProxyRubyRepository - Failed URL retrieve/cache: https://rubygems.org  jvm 1    | java.nio.file.InvalidPathException: Illegal char <?> at index 69: C:\nexus\sonatype-work\nexus\storage\rubygems-org\api\v1\dependencies?gems=amt_modules  jvm 1    |  at sun.nio.fs.WindowsPathParser.normalize(Unknown Source) ~[na:1.8.0_25]  ",Bug,Major,Closed,"2015-02-25 15:33:27","2015-02-25 15:33:27",1
"Sonatype Nexus","verbose WARN on NuGet proxy RemoteItemNotFoundException should be logged similar to other repository types","When a request for a remote NuGet package is made and the result is 404 not found, Nexus should not print a full WARN stack trace.        Expected: Log in a manner consistent with other proxy repository types on remote item not found.",Bug,Major,Closed,"2015-02-18 13:57:42","2015-02-18 13:57:42",0.5
"Sonatype Nexus","Both timeout and server disconnect messages can be shown","Talking to <USER>last week, he mentioned that Jason had noticed both timeout and server shutdown popouts before (see screen).  Today at lunch, my NX3 (Dizzam SNAPSHOT) timed out so I went ahead and shut down the server and was able to reproduce this behavior.  The only difference in my experience was my timeout message was first (thus grey not focused/white) rather than server, probably because it was the first to occur.  Since disconnected and needing action on both events, once you receive one popout, do not believe there is value in having the other so logging a bug for evaluation.",Bug,Minor,Closed,"2015-02-17 18:19:23","2015-02-17 18:19:23",0.5
"Sonatype Nexus","Add scheduled tasks list filter when creating tasks","In Nexus 3, when creating a new scheduled task, add a filter to help you find named tasks easier.    ",Improvement,Major,Closed,"2015-02-13 15:07:29","2015-02-13 15:07:29",0.5
"Sonatype Nexus","Regression: Yum enabled staging repositories can't be released if target release repository contains yum metadata","# Configure a hosted repository to allow yum metadata generation.  # Deploy an rpm into the hosted repository  # Configure a staging profile to allow yum metadata generation, and to release into the hosted repository used in step 1  # Stage an rpm, then try to release it    This will fail with a message like this:    {quote}  Artifact updating: Repository ='releases:Releases' does not allow updating artifact='/repodata/repomd.xml'  {quote}    This is a regression, in 2.10.0 the above scenario works without any problems.    In Nexus 2.11.1 if you try to release a staging repository that has yum metadata generation enabled it will fail if the target repository has a repodata/repomd.xml file in it already.",Bug,Major,Closed,"2015-02-09 19:09:34","2015-02-09 19:09:34",2
"Sonatype Nexus","Store state of grid columns and sorting","As a user, if I add columns to a results page, I would like them to remain that way at least for the duration of my session.    ---    While testing CLM, I searched and then added Security Issues and License Threat columns to see the results.  Unsatisfied I did another search and noticed that those added columns were removed.    I realized we just talked about this in a semi-recent meeting but did not see a ticket.  I also assume this is behaving as desired and is not a bug.  If I am wrong, please feel free to adjust the issue type.    While my example was for search, I think this use case would be good for all pages.  There was discussion about making this longer than a session, which would solve the minimal case I mentioned above.    I did not test NX3 at this time because I believe search (specifically) is in flux.    Note:  - Could be a mixin that handles this (http://docs-origin.sencha.com/extjs/4.2.3/#!/api/Ext.state.Stateful)    Tech Direction:  - Configure grids to be stateful",Improvement,Minor,Closed,"2015-02-09 16:08:25","2015-02-09 16:08:25",0.5
"Sonatype Nexus","On Login, Password appears filled in IE11","While reviewing my Windows 7 VM, on Nexus 3 login, I noticed that the password field already had *s in it.  I think they were a lighter grey (same color as the guide text) but I'm not 100% sure.  This does not occur in MacOSX or CentOS.  I am pretty sure it does not occur in NX2 (W7) either but I did not double check due to it being NX2 UI and us not reviewing that right now.    I felt this confusing and worth making the same as others Password if possible.",Bug,Trivial,Closed,"2015-02-05 21:58:59","2015-02-05 21:58:59",0.5
"Sonatype Nexus"," Connection leak in Browse Remote when content encoding is gzip","There is a connection leak triggered when using the Browse Remote feature.    h4. Symptoms    Logs contain these types of messages:    bq. 2015-02-23 08:57:27 WARN  [850148762-12088] - org.sonatype.nexus.plugins.rrb.MavenRepositoryReader - Failed to get directory listing content   bq. org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool    h4. Cause    Under normal circumstances the leak is handled gracefully by GC and HttpClient. Still, in case when remote uses Content-Encoding: gzip and/or chunked transfer encoding, the connections are NOT reused even after longer period, leading to connection pool depletion.    h5. Original reporter's description:    {quote}  When I'm browsing a remote maven repository in 2.11.1-01, after maybe ~20 steps through the remote repository tree, I get an infinitly spinning cirle. Refresh doesn't work either. The only way to continue browsing the repository is to restart Nexus.     This seems to impede all communication with the remote repository. Downloading a file that has not yet been cached locally doesn't work either in this state.  {quote}    h4. Workaround    For immediate mitigation a Nexus restart is required to free the leaking connections.    For temporary mitigation until you upgrade to a fixed Nexus version, install the version specific patched jars attached to this issue.      ",Bug,Major,Closed,"2015-02-04 10:22:31","2015-02-04 10:22:31",1
"Sonatype Nexus","concurrent request paths cause ItemNotFoundException during population of not found cache","Create a Maven 2 proxy repository to https://download.newrelic.com called `Yum-Newrelic`    **While** a request at this path is executing ( and ultimately returns with 302 or 404 ):        before this request ends, a request at these paths at the same time fail or throw errors:                  ",Bug,Major,Closed,"2015-02-03 19:54:23","2015-02-03 19:54:23",1
"Sonatype Nexus","OFF log level for Loggers visible as TRACE in the UI","Add a new Logger or change an existing logger level to {{OFF}}.    Upon Saving this logger, the level is displayed as TRACE in the UI. In reality the logger is in fact OFF in logback-overrides.xml",Bug,Minor,Closed,"2015-02-03 17:07:37","2015-02-03 17:07:37",1
"Sonatype Nexus","support zip generation fails if system has mounted clearcase volumes","Support zip generation can fail when processing clearcase volumes:    {quote}  2015-02-03 16:11:20 ERROR [qtp1900065549-63898] admin org.sonatype.nexus.atlas.internal.SupportZipGeneratorImpl - Failed to create support ZIP  java.nio.file.NoSuchFileException: /vobs/tag/pvob_orc  at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[na:1.7.0_07]  at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[na:1.7.0_07]  at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[na:1.7.0_07]  at sun.nio.fs.UnixFileStore.readAttributes(UnixFileStore.java:111) ~[na:1.7.0_07]  at sun.nio.fs.UnixFileStore.getTotalSpace(UnixFileStore.java:118) ~[na:1.7.0_07]    {quote}    We should catch and log this exception, and then keep going.",Bug,Minor,Closed,"2015-02-03 16:56:09","2015-02-03 16:56:09",0.5
"Sonatype Nexus","forgot password feature performs badly with external realms","The forgot username/password feature rest resource ( /service/local/users_forgotid ) of Nexus can cause performance issues against an external realm.    We should consider options such as:    - optimizing the generic queries that the resource performs for external users   - provide a configurable way to disable the feature  - consider removing the feature entirely if that is easier  - removing the Forgot Username and Forgot Password resource privs from the built in anonymous role.    Acceptance Criteria:  - Remove Forgot Password/Username feature from UI (just remove the js code)    ",Bug,Major,Closed,"2015-02-02 17:07:37","2015-02-02 17:07:37",2
"Sonatype Nexus","Apache HttpClient 4.4 is out","Apache HttpClient 4.4 is out, is worth to consider updating to it sometime soon.",Improvement,Minor,Closed,"2015-02-02 13:59:00","2015-02-02 13:59:00",1
"Sonatype Nexus","Rapture should not depend on any legacy REST endpoints","Looks like we have dependency on:    /service/local/authentication/login    and /service/local/nuget/*     (could be others)    These need to be removed and replaced by siesta endpoints.",Bug,Critical,Closed,"2015-01-31 01:23:49","2015-01-31 01:23:49",2
"Sonatype Nexus","impossible to delete stale hosted npm repository metadata","Create a npm hosted repo with id 'npm-hosted'.  Publish one package into it.  Hit the /-/all resource for this repo. Verify the published package metadata.  Delete the entire npm hosted repo using the repository Delete button.  Create another npm hosted repo with the same id.  Hit the /-/all resource for this repo again - you still get metadata about the first repo even though the new repo contains nothing.    Similar:  delete all the content from a hosted npm repo but leave the repo itself. Nexus still serves metadata about packages which do not exist. Expire cache on the hosted repo does not help.  ",Bug,Major,Closed,"2015-01-30 21:56:22","2015-01-30 21:56:22",2
"Sonatype Nexus","Double click resize column does not show full column contents sometimes","In NEXUS-7959 it was revealed (#3) that you can double click column headers to expand contents to full width, giving this column priority.  I noticed when you do this with columns with shorter content (like Status) part of the words remain cutoff.  I suspect this is because the column width includes the filter dropdown but the space for the contents does not (not sure tho, but that is how it appears).    I did not check NX2 at this time.    Acceptance Criteria:  * If I double click to see contents of a column, I want to see full contents, not ellipsed contents.",Bug,Trivial,Closed,"2015-01-29 23:09:04","2015-01-29 23:09:04",2
"Sonatype Nexus","Hiding and restoring columns resizes weirdly","While reviewing NEXUS-7959 (#1), from Repositories (Admin>Repository>Repositories) I removed the type column then added it back (having the original columns there) and noticed that many of the columns, including the lengthy name column were super small.    I am not sure if this was because of NEXUS-7959 but I definitely think the resizing could be better.  On refresh, everything resizes correctly, but on refresh all the hidden columns are restored as well, so that doesn't really mean much.  Waffled between Improvement and Bug; feel free to swap it if you want.    If unclear/you prefer a movie let me know.    I did not check NX2 at this time; I suspect NX3 specific.",Bug,Trivial,Closed,"2015-01-29 22:55:36","2015-01-29 22:55:36",2
"Sonatype Nexus","Common asset hashing","Acceptance criteria:  * There is a service to generate hashes for assets in one or more standard algorithms  * There's a standard spot in asset metadata for storing these hashes  * Wire it up so that Raw and Simple assets record these actual hashes (as opposed to format-specific ways of obtaining the expected hashes, which should also eventually be stored)  ",Story,Major,Done,"2015-01-28 22:34:43","2015-01-28 22:34:43",1
"Sonatype Nexus","rebuild hosted npm metadata task metadata parsing errors","Tried to run rebuild hosted npm metadata task ( new in 2.11.2 ) against about 500MB of tgz packages from the strongloop registry.    https://drive.google.com/file/d/0B2wPMwl-8cOXdmMtYlUyWjJ4STQ/view?usp=sharing    Had several messages of concern - unsure as to the overall seriousness of each of these:          ",Bug,Major,Closed,"2015-01-28 19:39:10","2015-01-28 19:39:10",1
"Sonatype Nexus","performance advice in logs when querying npm all resource","Create an npm group repo with the following members:    npm-hosted ( hosted npm repo )  npm-proxy ( https://registry.npmjs.org )  npm-strongloop ( http://npm.strongloop.com/ )  npm-nodejitsu ( https://registry.nodejitsu.com )    make a query to:        Some performance related advice prints in logs. Is this advice we need to follow?    ",Improvement,Major,Closed,"2015-01-27 20:43:58","2015-01-27 20:43:58",1
"Sonatype Nexus","Improve task helper text by clarifying acronym","Last week I noticed in the Remove Releases From Repository task there was helper text for the Number to Keep field: The number of versions for each GA to keep.    What GA was was unclear to me.  [~<USER> clarified it was the first two portions of GAV - GroupIdArtifactId but suggested it could be clarified to The number of versions for each artifact identifier to keep.    I was going to leave this alone and chalk to my newness but other team members thought clarify valuable as well.    The message is the same in NX2 (though I expect the change will just be NX3).",Improvement,Trivial,Closed,"2015-01-27 19:46:49","2015-01-27 19:46:49",0.5
"Sonatype Nexus","User Token Protect Content feature should return 401 with message","Enable User Token and the Protect Content feature.    When a request is made to a /content path with valid credentials that are not Nexus user token credentials, Nexus responds with 401, but no entity explaining why.     Problems:   - the end user is confused, because they know they have entered technically valid organization credentials.  - the Nexus admin is confused because they either have forgotten about or were not the ones who setup the Protect Content feature, or just assume protecting content is a good idea, so leave the box enabled.  - the Protect Content feature is valuable, but it is a rather odd special case that affects all realms in Nexus because of the special Token it creates internally, so an administrator is not reminded it may be in play because it is not near where all the other realms are configured  - a Nexus admin must enable DEBUG and TRACE logs to see why there was a 401, assuming they can even understand what loggers to enable and what to look for        Improvement: Simple continue to respond with 401, but include a simple message body explaining the reasoning - that user token credentials are being enforced in Nexus. In this way a simple test using curl that gets 401 response will help the admin, end user or <USER>in quickly identifying the problem.    ",Improvement,Minor,Closed,"2015-01-27 15:51:18","2015-01-27 15:51:18",0.5
"Sonatype Nexus","Clarify Yum Capability helper text","Reviewing Capabilities I noticed that in Yum: Generate Metadata and Yum: Staging Generate Metadata that the Aliases field had helper text Format: =[,=].    I had no idea what this meant and after reviewing the book at [~<USER>'s prompting, I found that it means that the Aliases field is comma delineated (i.e. production=1.2,testing=2.0).    Even knowing this, I feel this is unclear.  Suggest we replace with that fact or just put an example (either in helper text or in greytext in the field itself).    I did not check older versions of NX3 at this time.",Improvement,Trivial,Closed,"2015-01-26 19:10:59","2015-01-26 19:10:59",0.5
"Sonatype Nexus","failed content integrity validation message when remote returns 404","https://github.com/sonatype/nexus-oss/blob/nexus-2.11.x/components/nexus-core/src/main/java/org/sonatype/nexus/proxy/repository/AbstractProxyRepository.java#L1510-1510    https://github.com/sonatype/nexus-oss/blob/nexus-2.11.x/components/nexus-core/src/main/java/org/sonatype/nexus/proxy/repository/AbstractProxyRepository.java#L1259-1259    Prints a concerning log message stating failed content integrity validation when in actual fact, the remote may have responded with 404 or other implied 'not found' status code.    Instead, print a log message indicating the status code and more exact reason the file was detected as not valid.    To reproduce:  # Change logging level of ROOT to DEBUG  # Request a file through a Maven proxy repository that the remote will return 404 for.  # examine the logs for the message failed content integrity validation        ",Bug,Major,Closed,"2015-01-23 21:27:19","2015-01-23 21:27:19",1
"Sonatype Nexus","Security handler: missing credentials causes 500, not 403","When you leave off the credentials while trying to GET/PUT (etc.) to a secured repository, Nexus returns status 500 - I presume we eventually need to return status 403.    2015-01-23 11:08:05,761-0500 WARN  [qtp1001492536-389] anonymous org.sonatype.nexus.repository.httpbridge.internal.ViewServlet - Service failure  org.apache.shiro.authz.AuthorizationException: User is not permitted: nexus:repository-admin:simplehosted1:read          at org.sonatype.security.authorization.ExceptionCatchingModularRealmAuthorizer.checkPermission(ExceptionCatchingModularRealmAuthorizer.java:66) [na:na]          at org.sonatype.security.authorization.ExceptionCatchingModularRealmAuthorizer.checkPermissions(ExceptionCatchingModularRealmAuthorizer.java:84) [na:na]          at org.apache.shiro.mgt.AuthorizingSecurityManager.checkPermissions(AuthorizingSecurityManager.java:145) [na:na]          at org.apache.shiro.subject.support.DelegatingSubject.checkPermissions(DelegatingSubject.java:215) [org.apache.shiro.core:1.2.3]          at org.sonatype.nexus.repository.security.SecurityHelper.ensurePermitted(SecurityHelper.java:60) [na:na]          at org.sonatype.nexus.repository.security.SecurityHelper.ensurePermitted(SecurityHelper.java:67) [na:na]          at org.sonatype.nexus.repository.manager.RepositoryManagerImpl.get(RepositoryManagerImpl.java:224) [na:na]",Bug,Major,Closed,"2015-01-23 16:27:36","2015-01-23 16:27:36",0.5
"Sonatype Nexus","Accessing a repository root causes 'repo not found' 404","Create a repository  (of any sort), then issue a GET request to its root.    [karaf console]  orient:connect plocal:../sonatype-work/nexus/db/config admin admin  orient:insert 'into repository_configuration SET repository_name=rawhosted, recipe_name=raw-hosted'     [shell]  curl -v --user 'admin:admin123' -X GET http://localhost:8081/repository/rawhosted/    => Notice the 404 reason is ERROR 404 Repository not found    This will prevent repositories from handling the root path, which is bad.",Bug,Major,Closed,"2015-01-23 16:13:36","2015-01-23 16:13:36",1
"Sonatype Nexus","Users: Changing dropdown does not show list until refresh","In NX3 Cowbell SNAPSHOT, I noticed that on the users page, when I changed from Default to All Configured Users the 2nd list was empty.  After review, I found that the list would show contents if I refreshed (via the button on the page, not the browser).  I checked NX2 and the same behavior seems to occur except that the dropdown defaults to All Configured Users but shows no contents when switching to All Users (for example).    Attaching screen (of server with all 3 default users; NX3), let me know if unclear, and I can do a movie.    Acceptance Criteria:  * When changing dropdown, refresh and display all users who are in results of the new dropdown selected.",Bug,Minor,Closed,"2015-01-23 15:03:05","2015-01-23 15:03:05",2
"Sonatype Nexus","Update HttpClient dependencies","Update HttpClient and HttpCore to:  * HttpClient 4.3.6, release notes https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310360&version=12327489  * HttpCore 4.3.3, release notes https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310340&version=12326260",Improvement,Major,Closed,"2015-01-23 08:32:21","2015-01-23 08:32:21",1
"Sonatype Nexus","Remove deprecated Task from NX3","While reviewing https://issues.sonatype.org/browse/NEXUS-7895 I loaded the Download Nuget Feed task and noticed some text weirdness however [~<USER> pointed out this had been depreciated in NX2 (.9) and should probably be removed from NX3.    Creating a task for evaluation/doing.  If this is WONTFIXed, the text could use some work (ref: 1/22/2015 email).  I did not check older versions of NX3 at this time.    Acceptance Criteria:  * Remove Download Nuget Feed task",Task,Minor,Closed,"2015-01-22 18:51:10","2015-01-22 18:51:10",0.5
"Sonatype Nexus","Tasks: Improve helper text by removing and rebuilding title text","While reviewing NEXUS-7895, I noticed that the helper text for Evict Unused Proxied Items From Repository Caches task for the Evict items older than (days) was as attached but I felt grammatically wrong.    After discussion with [~<USER> and [~<USER>, we decided to remove that helper text and instead change the title to Evict unused proxy items older than (days) (so it would encompass the elements of the helper text that were removed).    I did not check NX2 at this time as I have been told to expect no UI changes for that.  I did not check older versions of NX3 either.    Acceptance Criteria:  * Remove helper text from Evict Unused Proxy Items task  * The title of Evict Unused Proxy Items will be Evict unused proxy items older than (days)",Improvement,Trivial,Closed,"2015-01-22 17:21:25","2015-01-22 17:21:25",0.5
"Sonatype Nexus","NX3 feeds have the same name unhelpfully","Two feeds in NX3 are named New File and are distinct items.  While this text is cleaner than NX2 (long descriptions) there is a distinction in NX2 beyond just the path.    Requesting this be differentiated somehow.    Filing as a bug since this was different (not a bug) in NX2.  I've attached NX3 and NX2 screens.  Will also reach out to <USER>Manfred to see if they have any suggestions.  I am too verbose to make suggestions for this one=)",Bug,Trivial,Closed,"2015-01-21 21:37:23","2015-01-21 21:37:23",0.5
"Sonatype Nexus","Capabilities update failure","Trying to update a Capability results in an exception and failure to transition back to the list view. Appears related to the recent change to drilldown pattern in the UI.  ",Bug,Major,Closed,"2015-01-21 18:14:37","2015-01-21 18:14:37",1
"Sonatype Nexus","Staging repository detail view throws Exception on load","- detail view won't load, hits an undefined method here: https://github.com/sonatype/nexus-pro/blob/master/plugins/internal/nexus-proui-plugin/src/main/resources/static/rapture/NX/proui/controller/StagingRepositories.js#L263-263  - reproduction:   -- Add a Staging profile (content is irrelevant)  -- Upload an artifact to staging; UI upload is sufficient  -- Navigate to the newly created Staging repository and click it in the list view  -- Observe error thrown: TypeError: me.getFeature(...).setDescriptionIconName is not a function StagingRepositories.js:263  ",Bug,Major,Closed,"2015-01-21 17:46:00","2015-01-21 17:46:00",1
"Sonatype Nexus","User Creation does not transition back to list view after saving","Record is saved as expected, but the UI does not transition back to the list view as other drilldown views do.  Leads to failure with present code at https://github.com/sonatype/nexus-bundles/blob/master/testsuite/functional-testsuite/src/test/ft-resources/testsuite/security/310_security_user.t.js#L85",Bug,Major,Closed,"2015-01-21 17:43:02","2015-01-21 17:43:02",1
"Sonatype Nexus","Saving shows a validator briefly when condition is fulfilled (sometimes/some fields)","While reviewing NEXUS-7901, I created a task and edited it and noticed that a validator was appearing despite the fact the field was filled in.  This occurs on both save and discard.  If this can be prevented, I see no point in having this appear.  See attached movie (shows save only).",Bug,Trivial,Closed,"2015-01-21 16:31:04","2015-01-21 16:31:04",0.5
"Sonatype Nexus","Invalid email now allowed w/ typo & errors","In NX3 on System>Email Server, when Verifying SMTP Connection you can verify with a blank submission (not allowed in NX2).  I noticed that the resultant message Invalida e-mail address: <> has a typo (Invalid).  There is also an error in the log, that was not present in NX2, likely because this was not allowed:  {quote}  2015-01-21 10:23:40,467-0500 ERROR [qtp414557038-235] admin org.sonatype.nexus.extdirect.internal.ExtDirectServlet - Failed to invoke action method: coreui_SmtpSettings.verifyConnection, java-method: org.sonatype.nexus.coreui.SmtpSettingsComponent.verifyConnection  java.lang.IllegalArgumentException: Invalida e-mail address: <>   at org.sonatype.micromailer.Address.validateAddress(Address.java:115) [na:na]   at org.sonatype.micromailer.Address.<init>(Address.java:44) [na:na]   at org.sonatype.micromailer.Address.<init>(Address.java:36) [na:na]   at org.sonatype.nexus.internal.email.DefaultSmtpSettingsValidator.sendSmtpConfigurationTest(DefaultSmtpSettingsValidator.java:72) [na:na]   at org.sonatype.nexus.email.SmtpSettingsValidator$sendSmtpConfigurationTest.call(Unknown Source) [na:na]   at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:45) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:108) [na:na]   at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:120) [na:na]   at org.sonatype.nexus.coreui.SmtpSettingsComponent.verifyConnection(SmtpSettingsComponent.groovy:132) [na:na]   at org.sonatype.nexus.extender.modules.ValidationInterceptor.invoke(ValidationInterceptor.java:53) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInvocationAdapter.proceed(AopAllianceMethodInvocationAdapter.java:49) [na:na]   at org.apache.shiro.authz.aop.AuthorizingAnnotationMethodInterceptor.invoke(AuthorizingAnnotationMethodInterceptor.java:68) [na:na]   at org.apache.shiro.guice.aop.AopAllianceMethodInterceptorAdapter.invoke(AopAllianceMethodInterceptorAdapter.java:36) [na:na]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.7.0_71]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) [na:1.7.0_71]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.7.0_71]   at java.lang.reflect.Method.invoke(Method.java:606) [na:1.7.0_71]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeJavaMethod(DispatcherBase.java:142) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.invokeMethod(DispatcherBase.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet$3.invokeMethod(ExtDirectServlet.java:208) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.dispatcher.DispatcherBase.dispatch(DispatcherBase.java:63) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.StandardRequestProcessorBase.dispatchStandardMethod(StandardRequestProcessorBase.java:73) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequest(JsonRequestProcessor.java:502) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.processIndividualRequestsInThisThread(JsonRequestProcessor.java:150) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.processor.standard.json.JsonRequestProcessor.process(JsonRequestProcessor.java:133) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.router.RequestRouter.processJsonRequest(RequestRouter.java:83) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.processRequest(DirectJNgineServlet.java:617) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at com.softwarementors.extjs.djn.servlet.DirectJNgineServlet.doPost(DirectJNgineServlet.java:580) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at org.sonatype.nexus.extdirect.internal.ExtDirectServlet.doPost(ExtDirectServlet.java:128) [org.sonatype.nexus.plugins.nexus-extdirect-plugin:3.0.0.SNAPSHOT]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:755) [javax.servlet:3.0.0.v201112011016]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet:3.0.0.v201112011016]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:298) [org.sonatype.sisu.guice:3.2.4]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:282) [org.sonatype.sisu.guice:3.2.4]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:187) [org.sonatype.sisu.guice:3.2.4]   at com.google.inject.servlet.AbstractServletPipeline.service(AbstractServletPipeline.java:59) [org.sonatype.sisu.guice:3.2.4]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [org.sonatype.sisu.guice:3.2.4]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.4]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [org.apache.shiro.web:1.2.3]   at org.sonatype.nexus.web.SecurityFilter.executeChain(SecurityFilter.java:87) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [org.apache.shiro.core:1.2.3]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [org.apache.shiro.web:1.2.3]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [org.apache.shiro.web:1.2.3]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.4]   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:136) [com.sonatype.nexus.plugins.nexus-licensing-plugin:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.4]   at com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97) [com.codahale.metrics.servlet:3.0.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.4]   at org.sonatype.nexus.web.internal.StandardHttpResponseHeadersFilter.doFilter(StandardHttpResponseHeadersFilter.java:80) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.4]   at org.sonatype.nexus.web.internal.ErrorPageFilter.doFilter(ErrorPageFilter.java:66) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.4]   at org.sonatype.nexus.web.internal.BaseUrlHolderFilter.doFilter(BaseUrlHolderFilter.java:68) [org.sonatype.nexus.core:3.0.0.SNAPSHOT]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [org.sonatype.sisu.guice:3.2.4]   at com.google.inject.servlet.AbstractFilterPipeline.dispatch(AbstractFilterPipeline.java:94) [org.sonatype.sisu.guice:3.2.4]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133) [org.sonatype.sisu.guice:3.2.4]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130) [org.sonatype.sisu.guice:3.2.4]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203) [org.sonatype.sisu.guice:3.2.4]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130) [org.sonatype.sisu.guice:3.2.4]   at org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73) [org.sonatype.nexus.bootstrap:3.0.0.SNAPSHOT]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:455) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1075) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:384) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1009) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at com.codahale.metrics.jetty8.InstrumentedHandler.handle(InstrumentedHandler.java:192) [com.codahale.metrics.jetty8:3.0.2]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:154) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.Server.handle(Server.java:370) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:489) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.AbstractHttpConnection.content(AbstractHttpConnection.java:960) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:1021) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:865) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:240) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543) [org.eclipse.jetty.aggregate.jetty-all-server:8.1.11.v20130520]   at java.lang.Thread.run(Thread.java:745) [na:1.7.0_71]  Caused by: javax.mail.internet.AddressException: Empty address   at javax.mail.internet.InternetAddress.checkAddress(InternetAddress.java:1149) [na:na]   at javax.mail.internet.InternetAddress.validate(InternetAddress.java:1129) [na:na]   at org.sonatype.micromailer.Address.getInternetAddress(Address.java:61) [na:na]   at org.sonatype.micromailer.Address.validateAddress(Address.java:111) [na:na]   ... 100 common frames omitted  {quote}    Interestingly, if you start to actually type an invalid email, it blocks it and validates.  I am not sure the gain of allowing this blank mail, so cannot suggest to revert to NX2 not allowing which would presumably fix this or if these need patched.",Bug,Minor,Closed,"2015-01-21 15:32:02","2015-01-21 15:32:02",1
"Sonatype Nexus","Update NPM plugin to use OrientDB 2.0","Note: databases created by OrientDB 1.7 are compatible with OrientDB 2.0    http://www.orientechnologies.com/docs/last/orientdb.wiki/Migration-from-1.7.x-to-2.0.x.html",Task,Major,Closed,"2015-01-21 11:26:35","2015-01-21 11:26:35",0.5
"Sonatype Nexus","Finish conversion to NX.I18n string ","A few places still not using NX.I18n.    * -Review all usage of NX.Messages API-  * -Review all usage of NX.Dialogs API-  * -Review all usage of NX.Security API-  * -Review all usage of 'waitMsg:' specifications    Classes in nexus-rapture-plugin:  * -NX.view.AboutWindow-  * -NX.view.Authenticate-  * -NX.view.ExpireSession-  * -NX.view.UnsupportedBrowser-  * -NX.view.header.AdminMode-  * -NX.view.header.BrowseMode-  * -NX.view.header.UserMode-  * -NX.view.header.Help-  * -NX.view.header.Messages-  * -NX.view.feature.NotFound-    Classes in nexus-coreui-plugin:  * -NX.coreui.controller.Metrics-  * -NX.coreui.controller.NuGetRepositorySettings-    -Pending further investigation fore coreui and proui modules.-",Story,Minor,Done,"2015-01-21 00:15:42","2015-01-21 00:15:42",3
"Sonatype Nexus","Make StorageFacet blob methods transactional","If you call storageFacet.createBlob(), or storageFacet.deleteBlob() but then roll back the transaction, the changes occur anyways. This can lead to orient and the blob store getting out of sync.    A simple pattern for handling this was built into some older CMA work where it was called BlobTx - it just accumulated new and to-be-deleted blobs in separate lists, and when the transaction was rolled back or committed, the corresponding list of blobs all get soft-deleted.    This isn't bulletproof transactionality, but it's much better than the current approach which completely ignores transactions for blob operations, and will err on the side of stray blobs rather than over-eagerly deleted blobs.",Story,Major,Done,"2015-01-20 20:33:56","2015-01-20 20:33:56",2
"Sonatype Nexus","Add Security to Raw Repositories","Following the pattern established by the Simple repository format, add permissions and permission-checking to the raw repositories.",Story,Major,Done,"2015-01-20 20:06:45","2015-01-20 20:06:45",2
"Sonatype Nexus","Header mode buttons look like toggles, not navigation links.","To a first-time user, it’s unclear what the mode buttons are supposed to do. They look like toggles. We need to tie them to the page better, make them look like navigation.    !Welcome - Sonatype Nexus 2015-01-20 10-35-44.png|thumbnail!",Improvement,Minor,Closed,"2015-01-20 18:37:21","2015-01-20 18:37:21",0.5
"Sonatype Nexus","Typos in Smart Proxy: File Event Sink capability About","While testing NEXUS-7854 yesterday, I noticed 3 typoes in the Smart Proxy: File Event Sink capability's About section.  I checked and these exist in NX2 as well.  Bug for cleanup.    1) in the flush/publih window. - 'publish' is missing an s.  2) blank lines are ingored - 'ignored' is missing an n.  3) for the event or addional - 'additional' misspelled.",Bug,Trivial,Closed,"2015-01-20 15:09:48","2015-01-20 15:09:48",0.5
"Sonatype Nexus","Some tabs have missing borders",,Bug,Minor,Closed,"2015-01-20 01:19:27","2015-01-20 01:19:27",0.5
"Sonatype Nexus","Single pill shows, should be hidden to avoid confusion","While reviewing NEXUS-7660, I loaded repository which only had one element so I clicked it.  I noticed the resultant item had a blue Info button and info below it.  I tried clicking the button and nothing happened.  After discussion with [~<USER> he relayed this was part of NEXUS-7709 and that items with a single pill should be hidden to avoid confusion.  I reviewed the rest of the site and saw no others, I believe this is the only place with this going on.  Ticketing as requested.",Bug,Trivial,Closed,"2015-01-19 23:00:04","2015-01-19 23:00:04",0.5
"Sonatype Nexus","Grid view is broken (column hide, reorder, and resize)","When you hide a column, the web UI navigates away from the current page: http://take.ms/3Svy5    When you reorder the columns, the data aren’t rendered appropriately: http://take.ms/pbERY    When you double-click the resize bar for a column, the grid doesn’t perform any overflow checking: http://take.ms/6T3Sr",Bug,Major,Closed,"2015-01-19 22:48:55","2015-01-19 22:48:55",3
"Sonatype Nexus","Failed to Load warnings in JS Console","While reviewing NEXUS-7760, I noticed I kept getting the attached warnings in my Safari Web Console once per browser session.  I thought it might be search related but noticed that I also got it when I signed in and clicked Feeds and also when I clicked Standard (Repository; clicking Repositories was fine).  The messages are the same each time.    I do not notice anything errant on the pages but filing for investigation.    Note:  Do awful things to browser size to replicate this    Acceptance Criteria:  - Current missing assets will not show up in js console any longer when scrolling tabs",Bug,Minor,Closed,"2015-01-19 21:51:09","2015-01-19 21:51:09",0.5
"Sonatype Nexus","(Re)Clarify Analytics text","Last week, I noticed that the text to enable the sending of analytics (Support>Analytics) information to Sonatype had changed in NX3 from:  Enable automatic analytics event submission  to  Send anonymized analytics to Sonatype    I raised a concern that the latter read like a single function whereas the checkbox was doing more than that.  We hashed out better text:  Enable anonymized analytics submission to Sonatype    Some concern was raised that some of the words in this suggestion were unnecessary and/or redundant.",Bug,Trivial,Closed,"2015-01-19 19:58:24","2015-01-19 19:58:24",0.5
"Sonatype Nexus","Privilege add validates with incorrect message?","While testing https://issues.sonatype.org/browse/NEXUS-7911, I added a privilege with the same (attached below) configuration and now I am getting the validation listed below which I believe is incorrect since there is a value.  I asked [~<USER>, and he said this was uncovered by his fix and not caused by it.  He speculated it may be a UI issue.  Because of that filing separately.",Bug,Minor,Closed,"2015-01-15 22:25:32","2015-01-15 22:25:32",1
"Sonatype Nexus","In drilldown panels, focus doesn’t automatically move to the current panel.","When I click a drilldown panel, I expect the focus to move to the first field in the new panel. This is not currently the case.    Also, it’s possible to tab to a previous or subsequent drilldown panel, which messes up the view. This also needs fixing. Example: http://take.ms/UFZkR",Bug,Major,Closed,"2015-01-15 18:57:47","2015-01-15 18:57:47",1
"Sonatype Nexus","Cannot delete a logger (easily)","I created a logger with a typo and went to delete it but found that I could not get the Delete Logger button to enable.  I tried clicking away from the logger and back and I tried clicking away from the section and back.  I also tried right click.  I was able to delete by resetting all to default levels but that also wipes out any other changes you may have made (both loggers added and special configurations).    This appears to be an NX3 specific issue; I did not have this issue in NX2.  I only tested the SNAPSHOT (Cowbell) at this time, not older versions of NX3.",Bug,Major,Closed,"2015-01-15 18:37:39","2015-01-15 18:37:39",0.5
"Sonatype Nexus","maven site deployments with .. in paths fail","Since Nexus 2.11.1 I have a problem deploying sites of maven modules via dav protocol which have a parent and where I do not want the site to deployed at a path below the parent site.    Maven site plugin generates links relative to the site of the parent project. Nexus does not accept these relative links anymore.    See (the edited) log excerpt below for an example.    Do you have an idea what I can do other than requesting / implementing a change in the site plugin, changing my site deployment structure? I'd also rather not change the transport protocol (if that would be a solution) because that probably would be difficult to organize.    {quote}  [INFO] --- maven-site-plugin:3.4:deploy (default-cli) @ simple-child ---  [INFO] Parent project loaded from repository: org.example.nexus.deployment.problem:simple-parent:pom:0.1.0-SNAPSHOT  http://localhost:8081/nexus/content/sites/local-maven-sites/simple-parent/0.1.0-SNAPSHOT/ - Session: Opened  [INFO] Pushing c:\Users\me\Development\eclipse-workspace\simple-child\target\site  [INFO]    >>> to http://localhost:8081/nexus/content/sites/local-maven-sites/simple-parent/0.1.0-SNAPSHOT/../../simple-child  Uploading: ../../simple-child/css/maven-base.css to http://localhost:8081/nexus/content/sites/local-maven-sites/simple-parent/0.1.0-SNAPSHOT/    #http://localhost/nexus/content/sites/local-maven-sites/simple-parent/0.1.0-SNAPSHOT/../../simple-child/css/maven-base.css - Status code:  400   Transfer error: org.apache.maven.wagon.TransferFailedException: Failed to transfer file:  http://localhost:8081/nexus/content/sites/local-maven-sites/simple-parent/0.1.0-SNAPSHOT/../../simple-child/css/maven-base.css. Return code is: 400  http://localhost:8081/nexus/content/sites/local-maven-sites/simple-parent/0.1.0-SNAPSHOT/ - Session: Disconnecting  http://localhost:8081/nexus/content/sites/local-maven-sites/simple-parent/0.1.0-SNAPSHOT/ - Session: Disconnected  [INFO] ------------------------------------------------------------------------  [INFO] BUILD FAILURE  [INFO] ------------------------------------------------------------------------  {quote}",Bug,Major,Closed,"2015-01-15 09:56:36","2015-01-15 09:56:36",1
"Sonatype Nexus","Publish storage events","Make sure appropriate events get pushed to the EventHub when changes occur via StorageFacet.    This includes creation, updates, and deletes of assets and components, and creation and deletion of blobs.    These events should be published only if the graph transaction on which they occurred is successfully committed.",Task,Major,Closed,"2015-01-14 16:40:53","2015-01-14 16:40:53",2
"Sonatype Nexus","Improve one button management method on sub-UI pages","As a user, I want to get what I want quickly and with as few clicks as possible from the navigation menus.  I prefer none of the options to be hidden unless essential to avoid clutter/confusion.    ---    In NX3 (Cowbell SNAPSHOT), I noticed on the Privileges page there was a Create button with a dropdown which resulted in just one item.  This took me aback because I am not sure the purpose of having a dropdown with just 1 item, seems like extra clicks to me.    On internal review, <USER>suggested With the new drilldown panels, we can show a list of types when a user clicks “Create privilege” instead of having a bunch of buttons up front.  Of course, if there’s only one privilege type, we just won’t show that panel.  And decided to ticket.    Areas affected that could be improved (on review yesterday):  * Templates  * Privileges  * Staging profiles  * Roles  * SSL Certificates (http://localhost:8081/#admin/security/sslcertificates - has a create button with 2 options in the drop.)  * Respository ('(user/non-admin) have 2 drops in their More (for Standard).')  * Capabilities (capability type dropdown should be modeled as a drilldown panel)  * Tasks (same as above)    I did not check NX2 at this time since we are not planning to improve the UI on that unless pressed.  I strongly suspect some of these are there however (some may not be, a result from the move from tabs).",Improvement,Trivial,Closed,"2015-01-14 15:36:01","2015-01-14 15:36:01",2
"Sonatype Nexus","content validation fails for valid rar file","Create a proxy repo to https://repository.jboss.org/nexus/content/groups/public-jboss/    Request the following file:     http://localhost:8081/nexus/content/repositories/jboss/org/jboss/genericjms/generic-jms-ra/1.0.7.Final/generic-jms-ra-1.0.7.Final.rar    Nexus blocks this apparently valid rar file and should not.    ",Bug,Minor,Closed,"2015-01-14 13:45:50","2015-01-14 13:45:50",3
"Sonatype Nexus","support proxying maven.oracle.com","Oracle has started to publish a Maven repo with weblogic related artifacts. I expect that to become pretty popular with Oracle users since it saves TONS of time in terms of deploying the artifacts to an internal Nexus instance alternatively. We should make sure we know how to configure this so we can show customers and potentially work with Oracle to get any problems removed.    https://blogs.oracle.com/WebLogicServer/entry/weblogic_server_and_the_oracle    More info:  http://docs.oracle.com/middleware/1213/core/MAVEN/config_maven_repo.htm#MAVEN9012    E.g. there might be no index.     This could also be done as a blog post related investigation if there is no engineering budget.. ",Improvement,Minor,Closed,"2015-01-13 21:00:12","2015-01-13 21:00:12",1
"Sonatype Nexus","Remove old releases task does not rebuild maven-metadata.xml files","The remove releases from repository scheduled task does not rebuild maven-metadata.xml files, removed releases still show as available in these files.    ",Bug,Major,Open,"2015-01-12 23:10:57","2015-01-12 23:10:57",2
"Sonatype Nexus","resuming downloads for unsatisfiable Range should respond with 416 or 200 instead of 206","Hi there, we noticed when using wget with the --continue flag set that it will hang indefinitely when trying to download a file which we've already downloaded.    Looking closer we can see:    {code}  ubuntu@agent-00-00:/vagrant$ wget  -S -c -d  https://maven.atlassian.com/public/com/atlassian/bamboo/atlassian-bamboo-agent-elastic-installer/5.7.2/atlassian-bamboo-agent-elastic-installer-5.7.2-jar-with-dependencies.jar  DEBUG output created by Wget 1.13.4 on linux-gnu.    URI encoding = `UTF-8'  --2015-01-12 04:00:03--  https://maven.atlassian.com/public/com/atlassian/bamboo/atlassian-bamboo-agent-elastic-installer/5.7.2/atlassian-bamboo-agent-elastic-installer-5.7.2-jar-with-dependencies.jar  Resolving maven.atlassian.com (maven.atlassian.com)... 172.24.36.3  Caching maven.atlassian.com => 172.24.36.3  Connecting to maven.atlassian.com (maven.atlassian.com)|172.24.36.3|:443... connected.  Created socket 3.  Releasing 0x000000000176ad40 (new refcount 1).  Initiating SSL handshake.  Handshake successful; connected socket 3 to SSL handle 0x000000000176b350  certificate:    subject: /C=AU/ST=New South Wales/L=Sydney/O=<USER>Pty Ltd/CN=*.atlassian.com    issuer:  /C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert SHA2 High Assurance Server CA  X509 certificate successfully verified and matches host maven.atlassian.com    ---request begin---  GET /public/com/atlassian/bamboo/atlassian-bamboo-agent-elastic-installer/5.7.2/atlassian-bamboo-agent-elastic-installer-5.7.2-jar-with-dependencies.jar HTTP/1.1  Range: bytes=22299663-  User-Agent: Wget/1.13.4 (linux-gnu)  Accept: */*  Host: maven.atlassian.com  Connection: Keep-Alive    ---request end---  HTTP request sent, awaiting response...  ---response begin---  HTTP/1.1 206 Partial Content  Server: nginx  Date: Mon, 12 Jan 2015 04:00:03 GMT  Content-Type: application/java-archive  Content-Length: 0  Connection: keep-alive  X-Frame-Options: SAMEORIGIN  X-Content-Type-Options: nosniff  Accept-Ranges: bytes  ETag: {SHA1{642389d24532277bb5d2b779055c1fc338092a75}}  Last-Modified: Tue, 02 Dec 2014 08:08:34 GMT  Content-Range: 22299663-22299663/22299663  Set-Cookie: rememberMe=deleteMe; Path=/; Max-Age=0; Expires=Sun, 11-Jan-2015 04:00:03 GMT  Strict-Transport-Security: max-age=31536000    ---response end---      HTTP/1.1 206 Partial Content    Server: nginx    Date: Mon, 12 Jan 2015 04:00:03 GMT    Content-Type: application/java-archive    Content-Length: 0    Connection: keep-alive    X-Frame-Options: SAMEORIGIN    X-Content-Type-Options: nosniff    Accept-Ranges: bytes    ETag: {SHA1{642389d24532277bb5d2b779055c1fc338092a75}}    Last-Modified: Tue, 02 Dec 2014 08:08:34 GMT    Content-Range: 22299663-22299663/22299663    Set-Cookie: rememberMe=deleteMe; Path=/; Max-Age=0; Expires=Sun, 11-Jan-2015 04:00:03 GMT    Strict-Transport-Security: max-age=31536000  Registered socket 3 for persistent reuse.  Length: 22299664 (21M), 1 remaining [application/java-archive]  Saving to: `atlassian-bamboo-agent-elastic-installer-5.7.2-jar-with-dependencies.jar'    99% [++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ] 22,299,663  --.-K/s  {code}    The request will hang there and ultimately timeout.     Looking into the RFC for range: http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html    We see the interesting point        Testing wget against other servers we see the behaviour as described in the RFC (a 416 or 200). However against nexus we get a 206, even when the range really is out of bounds. The content length is set to 0 and the content-range header seems to be adjusted accordingly, but it still seems it's not the correct behaviour given the request.    Any chance we can get a hand here?",Bug,Major,Closed,"2015-01-12 04:06:22","2015-01-12 04:06:22",1
"Sonatype Nexus","Upgrade Groovy version","Update to more recent Groovy version. Groovy 2.3.7 appears to be the latest available version with a corresponding groovy-eclipse compiler, with 2.3.9 being the last release published at this time.    Java 8 interoperability is only official since 2.3.x so hopefully this will head off any compatibility issues    Acceptance Criteria:  - Nexus 3 OSS and Pro will use Groovy 2.3.7",Story,Major,Done,"2015-01-10 23:47:15","2015-01-10 23:47:15",1
"Sonatype Nexus","Tasks: Replace removed Cron helper text","While testing NEXUS-7705, I noticed that when creating a new task when scheduling Advanced (Cron) the long guidance text describing Cron examples was gone.  I asked in email if this was intentional and it was decided that rather than having long examples, there would be an entry in the help content that we could link our helper text to.    I waffled between making this a task or a bug, but since the text is removed, I went with bug.  This is NX3 only as the text is present in NX2.    I believe this cannot be done until the link is added so added dependancy.    Acceptance Criteria:  - Have minimal helper text listing the columns and meaning of * and ? for cron syntax easily accessible via the UI. (Does not need to be shown constantly)  - Have a cron link to the Nexus Book documentation/search for more elaborate explanation and examples which is expected to be needed infrequently.",Bug,Minor,Closed,"2015-01-09 15:14:50","2015-01-09 15:14:50",0.5
"Sonatype Nexus","Empty Trash Task helper grammar is off","While reviewing https://issues.sonatype.org/browse/NEXUS-7705, I noticed that on an Empty Trash tasks the repository field had the helper text Select the repository to empty the trash..  This read grammatically weird to me so I checked with [~<USER> and [~<USER> and they suggested:    * Select the repository whose trash will be emptied  * Select the repository trash to be emptied  * The trash for the selected repository (below) will be emptied    Note, they had periods at the ends of some of their suggestions (as does the original text) but I removed them per the Design principles document attached with NEXUS-7705.    This is an NX3 issue only; NX2 does not have any helper text (which could be another solution).",Bug,Trivial,Closed,"2015-01-08 23:07:03","2015-01-08 23:07:03",0.5
"Sonatype Nexus","Text clarify timeout field","While scanning text after NEXUS-7705 was closed, I noticed that on Administration>HTTP the Timeout field had no descriptor.  Recommend adding one telling what the # indicates (seconds, minutes, hours).  I do not know which it is, so cannot recommend text at this time.    Did not see this page in NX2, so only checked NX3 at this time.",Improvement,Trivial,Closed,"2015-01-08 22:40:00","2015-01-08 22:40:00",0.5
"Sonatype Nexus","No Kenai Capability About causing warning in log","While testing NEXUS-7768 I noticed that when I clicked on the Capabilities left nav item I was getting this in the log:  {quote}  2015-01-08 12:15:51,353-0500 WARN  [pool-7-thread-7] joedragons org.sonatype.sisu.goodies.template.internal.VelocityTemplateEngine - Missing resource for template: kenai-about.vm; for owner: org.sonatype.security.realms.kenai.internal.capability.KenaiCapabilityDescriptor  {quote}    I suspect this is because no About is defined for the Kenai capability.  I checked all the other capabilities that are default added and all have an About defined even if just basically a repetition the name.  I did not check all the capabilties in the list however.    I did not notice this error before I added the capbility so I am guessing it only checks the ones listed.    I did notice when I went to create though and selected the dropdown (before picking a capability) I got the same error.    This became a capability in NX3 so not surprisingly no error in NX2.    Unsure epic or component, so guidance appreciated.",Bug,Minor,Closed,"2015-01-08 18:32:07","2015-01-08 18:32:07",0.5
"Sonatype Nexus","RUT Auth does not work for /content URL's","Disable anonymous access in Nexus, and configure RUT auth.  This works for /service/local URL's:        It does not work for /content URLs:        ",Bug,Major,Closed,"2015-01-08 15:09:21","2015-01-08 15:09:21",3
"Sonatype Nexus","Role ordering now case sensitive","As a user, I do not want to worry about using case to have my values show.    ---    Adding a role, I created test and thought it was not appearing.  After evaluating, I found that it sorted below the default ones provided in Nexus.  I changed it to Test and found it sorted in.  This is a bug rather than an improvement type because in NX2, the sort is case insensitive.  I did not see any tickets indicating this was intentional or a known issue.",Bug,Trivial,Closed,"2015-01-06 22:08:44","2015-01-06 22:08:44",0.5
"Sonatype Nexus","/service/local/authentication/logout should ask the user-agent to delete the session cookie","Currently a request to logout with a valid session cookie, will delete the server side session in Nexus, so that the originally sent session cookie value is no longer valid in the browser.    However the response that comes back should ( but does not ) ask the user-agent to delete/expire the existing session cookie, so that it does not bother trying to send it again.    We should make logout return a Set-Cookie header as expected that forces delete/expiry of the session cookie.  ",Bug,Major,Closed,"2015-01-06 19:14:10","2015-01-06 19:14:10",1
"Sonatype Nexus","allow nexus 2.x to load outreach content by version,edition and user","NX3 loads outreach iframe with version/edition/user parameters to allow the outreach bundle to template.  NX2 should get this.    Example in NX3 of the params:  https://github.com/sonatype/nexus-oss/blob/master/plugins/rapture/nexus-coreui-plugin/src/main/resources/static/rapture/NX/coreui/controller/Outreach.js#L85",Improvement,Major,Closed,"2015-01-06 18:54:55","2015-01-06 18:54:55",2
"Sonatype Nexus","change the default Nexus session cookie name","The Nexus Session cookie name is currently JSESSIONID.    This is a default Java webapp default session cookie name.    When Nexus is running on a host where another java webapp is located, sometimes conflicts can occur with this cookie name where one webapp overwrites the cookie of the other.    To help avoid such conflicts, we should given the Nexus session cookie a non-default name. In case this presents unforeseen problems in some environments, make the cookie name configurable by a Nexus administrator.  ",Improvement,Major,Closed,"2015-01-06 18:53:27","2015-01-06 18:53:27",1
"Sonatype Nexus","generate dynamic Secure parameterized cookies based on HttpServletRequest.isSecure()","Secure flag should be set on Set-Cookie values dynamically based on if the inbound request is reported as secure by the container hosting Nexus, instead of using the configurable option provided by NEXUS-7800  ",Improvement,Major,Closed,"2015-01-06 18:47:13","2015-01-06 18:47:13",2
"Sonatype Nexus","prevent restlet resources from sending duplicate Date and Server headers","When a Nexus Restlet resource is requested ( service/local/* ), restlet sends back duplicate Date and Server headers.    There should be only one Date header, and Jetty provides this for all responses:    http://download.eclipse.org/jetty/stable-8/xref/org/eclipse/jetty/http/HttpGenerator.html#482    There should only be one Server header, with each product/version joined in the header value by a single space.    http://pretty-rfc.herokuapp.com/RFC2616#header.server  http://pretty-rfc.herokuapp.com/RFC2616#product.tokens    < HTTP/1.1 200 OK  < Date: Sat, 03 Jan 2015 16:16:33 GMT  < Server: Nexus/2.11.1-01  < X-Frame-Options: SAMEORIGIN  < X-Content-Type-Options: nosniff  < Set-Cookie: JSESSIONID=2f781ca7-d955-45c7-99e4-a84cdcfa6d4a; Path=/nexus; HttpOnly  < Set-Cookie: rememberMe=deleteMe; Path=/nexus; Max-Age=0; Expires=Fri, 02-Jan-2015 16:16:33 GMT  < Content-Type: application/xml; charset=UTF-8  < Date: Sat, 03 Jan 2015 16:16:33 GMT  < Vary: Accept-Charset, Accept-Encoding, Accept-Language, Accept  < Server: Noelios-Restlet-Engine/1.1.6-SONATYPE-5348-V8  < Content-Length: 10320  ",Improvement,Minor,Closed,"2015-01-06 18:42:58","2015-01-06 18:42:58",1
"Sonatype Nexus","NuGet Package upload strings missing or so","Seems like there are some missing or broken strings related to NuGet package upload. ",Bug,Major,Closed,"2015-01-05 22:48:01","2015-01-05 22:48:01",0.5
"Sonatype Nexus","org.jacoco:org.jacoco.report:0.6.2.201302030002 produces OBR metadata which cannot be parsed by felix 4.4.1","Create a virtual OBR repository against the default central proxy repository in Nexus.  Request this artifact through the central proxy:    http://localhost:8081/nexus/content/repositories/central/org/jacoco/org.jacoco.report/0.6.2.201302030002/org.jacoco.report-0.6.2.201302030002.jar      Now fire up felix 4.4.1 and add the virtual obr repository to it.  This fails due to a missing trailing parenthesis in this declaration:    {code}  (mandatory:<*bundle-version)): (&(package=org.jacoco.core)(bundle-version=[0.6.2,0.6.3))(mandatory:<*bundle-version))  {code}    I don't know if this is because the artifact has invalid metadata, or if there is a bug in the obr.xml file generation.    ",Bug,Major,Closed,"2015-01-05 20:43:00","2015-01-05 20:43:00",0.5
"Sonatype Nexus","Update the example email address","The System Email Address in Administration - System - Email Server is currently <EMAIL>. This is a valid domain name that is not under Sonatype control. It should probably be changed to the dedicated example.com domain. Maybe <EMAIL> or so.",Improvement,Trivial,Closed,"2014-12-31 00:39:31","2014-12-31 00:39:31",0.5
"Sonatype Nexus","request.log does not include authenticated userid for certain requests","Configure repos:    nuget-group   -- nuget-proxy ( https://www.nuget.org/api/v2/ )    Delete the Nexus anonymous user. Do not configure Nuget API key realm.    Make the following request with Nexus 2.11.1    wget --debug --http-user admin --http-password=admin123 -S http://localhost:8081/nexus/service/local/nuget/nuget-group/Microsoft.AspNet.WebApi.Client/5.2.2    by design, wget does not use pre-emptive auth and makes two requests, the first responds with 401 and WWW-Authenticate headers and the second sends your credentials in response.    request.log does not print the authenticated user on the second request.    127.0.0.1 - - [30/Dec/2014:12:40:37 -0400] GET /nexus/service/local/nuget/nuget-group/Microsoft.AspNet.WebApi.Client/5.2.2 HTTP/1.1 401 0  127.0.0.1 - - [30/Dec/2014:12:40:45 -0400] GET /nexus/service/local/nuget/nuget-group/Microsoft.AspNet.WebApi.Client/5.2.2 HTTP/1.1 404 388    Note: the 404 in this case was because I had an http proxy server configured in Nexus returning 404 for the outbound request. This should normally return 200 and not related to this problem.    Seems like the security filter change in NEXUS-7785 where the logging was added is not being picked up for some reason.",Bug,Minor,Closed,"2014-12-30 17:43:09","2014-12-30 17:43:09",1
"Sonatype Nexus","Shell quoting is interfering with orient comment quoting","I'd expect this to work:        ... but it does not.    This however does work:        ",Bug,Major,Closed,"2014-12-25 00:53:23","2014-12-25 00:53:23",1
"Sonatype Nexus","Capability About section blank on new","Jason noticed that the About section when creating a new Capability was blank.  I subsequently noticed that this is filled in once you create the capability in the About tab of the subsequent screen; believe this is a bug with the creation section since the text is defined.    I only checked NX3 (SNAPSHOT) at this time.",Bug,Trivial,Closed,"2014-12-24 19:35:14","2014-12-24 19:35:14",0.5
"Sonatype Nexus","Ban content which could be interpreted as a link to be uploaded or downloaded","To prevent malicious abuse of the NX2 framework, we should inspect content which is uploaded (deployed to hosted) or downloaded (fetched from remote) to ensure that the NX2 framework would not interpret the content as a link.    This should be separate from content-validation checking and always checked.    Only direct use of the NX2 framework api to store a [Default]StorageLinkItem should be allowed to make content that is to be interpreted as a link.",Improvement,Critical,Closed,"2014-12-24 03:12:16","2014-12-24 03:12:16",1
"Sonatype Nexus","Flesh out first StorageFacet interface and impl","To support the initial raw content format, take an initial hack at the StorageFacet interface as roughly described here:  https://docs.sonatype.com/display/Nexus/Nexus+3+Storage+Facet#Nexus3StorageFacet-Facet    ...and provide an initial implementation    This is expected to be reworked at some point. In order to provide something that basically works, the interface will provide direct access to OrientDB primitives (e.g. Vertices, Edges, and possibly the Graph) rather than trying to hide them behind other objects, where practical.",Task,Major,Closed,"2014-12-23 20:20:09","2014-12-23 20:20:09",1
"Sonatype Nexus","Solicit graph data model feedback from OrientDB team","Compose and send a proposed OrientDB graph data model for Nexus 3 to the OrientDB folks.    Purpose: Get expert advice on the direction we're pursuing for persistence of Component/Asset information, to inform the design.",Task,Major,Closed,"2014-12-23 20:14:20","2014-12-23 20:14:20",1
"Sonatype Nexus","Implement Raw Format Proxy Repository For New CMA","Implement a repository which proxies a remote HTTP site and stores any files (of any format) in the CMA repository storage facet. Only GET requests are honored (others are rejected). Configuration parameters include the remote URL being proxied, the not-found and stored-item expiry times.    This will serve as a reference implementation for more complex formats' proxy repositories.",Story,Major,Done,"2014-12-22 20:51:14","2014-12-22 20:51:14",1
"Sonatype Nexus","Implement Raw Format For Hosted Under New CMA Architecture","Implement a simple bucket of files that allows for any file to be shared, so that they appear to be a repository while preserving the path. This is the simplest of the repo formats in Nexus.     Equivalant of Site Repository from Nexus 2. We did this because Maven uploaded files such as HTML to describe your repo. This allows for documentation/etc... to be shared. ",Story,Major,Done,"2014-12-22 20:09:48","2014-12-22 20:09:48",1
"Sonatype Nexus","provide a scheduled task to rebuild the npm metadata from storage data for hosted repositories","As a Nexus administrator I want a supported procedure to rebuild the npm metadata from existing npm repository storage, particularly from hosted repositories.    This is useful for rebuilding metadata from rsynced npm storage in a failover instance and as a database corruption recovery tool.    Notes:  - Look into OrientDB backup, export as potential options if we can't rebuild    ",Improvement,Major,Closed,"2014-12-18 15:10:16","2014-12-18 15:10:16",1
"Sonatype Nexus","Nexus allows direct access to trash directory through content URL's.","Nexus allows direct access to trash directory contents through /content URL's.    Directory browsing does not work:    https://oss.sonatype.org/content/repositories/releases/.nexus/trash    But direct access does (note, this file might not be there anymore at some point, but right now the download works).    https://oss.sonatype.org/content/repositories/releases/.nexus/trash/br/com/address/archetypes/strtus2-archetype/maven-metadata.xml    This is a security concern, some of our customers have artifacts which are are only accessible to a small set of developers, and are protected via repository target privileges.  Access through /.nexus/trash will likely bypass these restrictions.",Bug,Major,Closed,"2014-12-17 21:36:01","2014-12-17 21:36:01",1
"Sonatype Nexus","Show persistent message on idle time out","As a user, it'd be nice to have a persistent message when I come back to a session and am logged out.    ---    Two times today, I've been idling on NX3 and on return to the screen have had a pause then realized I am logged out presumably due to idling.  One benefit of NEXUS-7755 was that there was a history including that you were logged out.  Right now, you can potentially just click anonymously before realizing what happened.  Suggesting a message on the screen relaying you have been logged out that persists until the user clicks it off (or otherwise notes it as being seen).  If NEXUS-7755 or like history is restored, then this could likely be OBE.    Acceptance Criteria:  - When a user is logged out due to timeout, show the user a dialog that indicates to them they have been logged out",Improvement,Minor,Closed,"2014-12-16 18:57:18","2014-12-16 18:57:18",1
"Sonatype Nexus","Unselecting icon does nothing?","Demonstration of the bug: http://monosnap.com/file/s3Dm8abWmAmgUdm4R3xp4ZERUwhorv    Currently in NX when you have the box icon at the top of the screen selected (or the gear if logged in as admin), if you click to unselect it, it removes the blue indicating that the item is selected but nothing else changes.  This was confusing to me as a new NX3 user.  For example, if logged in as an admin with the gear selected, if you unselect the gear you remain on the administration section.  The only thing that changes is the fact the gear icon is no longer blue.  When I posed this to the team, it was requested I file a ticket.    My expectation was that there be some behavior when the icons are not selected or suggest that they not be able to be unselected if no behavior is going to occur.    Going with bug for now; please change to improvement if you believe it's better.    Buttons not present in NX2.",Bug,Minor,Closed,"2014-12-15 19:53:08","2014-12-15 19:53:08",2
"Sonatype Nexus","Second frame on welcome screen sometimes appears repeating milestone resources","While discussing NEXUS-7811, Jason noticed the screen I took had a second frame repeating the milestone resources available for admin on the welcome page.  I was able to reproduce this but not consistently by logging in and out of the system as admin (deployment and anonymous do not have these resources at this time).    Since I was able to repro several times despite not every time I am filing.  If I see further tidbits about this I will add.    I am making this minor because once this frame shows up, it remains even on logout, exposing these resources to a non-admin.  I also have noticed less frequently while testing this that the resources sometimes stay on the page on logout (but on the non-second framed screen).  I mulled filing a second ticket but was unable to repro this behavior in FF or Chrome, so I'm holding off for now, semi-hopeful this ticket fix may cleanup that as well.    I did not specifically check NX2 for this at this time, however, I've never seen this there before.",Bug,Trivial,Closed,"2014-12-15 17:55:07","2014-12-15 17:55:07",3
"Sonatype Nexus","Add straight forward (console/log) start notification","As a tester/administrator, it'd be good to have a clean indicator that the server is started in the console.  ---  In training, it is mentioned that you can see Nexus has started by looking at Started InstrumentedSelectChannelConnector@0.0.0.0:8081”.  Usability suggestion, add a line after the system processes are done “Nexus has started.” or something akin.  This is not unlike the “Initializing” message currently present (and I personally feel would be more useful).    This is just for nexus console.  Nexus start has a clean(ish) message.    This affects both NX3 m2 and SNAPSHOT.  I had seen this a while ago but had not checked SNAPSHOT til today, thus the delay in filing.",Improvement,Trivial,Closed,"2014-12-12 23:58:15","2014-12-12 23:58:15",1
"Sonatype Nexus","Refine button text for server disconnected dialog","As a user, I do not want error/warnings I cannot get rid of (however useful).    ---    While testing NX3 SNAPSHOT I shutdown my server but forgot to close NX in my browser.  I noticed NX3 has a cool warning now that tells you there is a disconnect.  However, following this warning if you try and do anything you get a message popout on the screen There is a problem communicating with server.  This is similar to the NX2 message which I believe says timeout, however, the NX3 message will not go away on close (OK) - instead it reopens the popout and adds another warning window on the right side.    I don't feel this is good usability but if intentional, there's no point I see to having the OK button as is.  It might as well be a close tab button.    This is not an issue in NX2, tho I do believe NX3 performance is better besides this aspect.    I believe I noticed this in the milestone build as well but wanted to check the snapshot.  I did not see this in my notes however nor did I (re)recheck at this time.  I can if you like and it helps.",Improvement,Trivial,Closed,"2014-12-12 23:37:28","2014-12-12 23:37:28",0.5
"Sonatype Nexus","Kenai Settings UI","Implement settings UI for Kenai (similar to Crowd UI)",Story,Minor,Done,"2014-12-12 10:51:06","2014-12-12 10:51:06",1
"Sonatype Nexus","non-snapshot versions containing SNAPSHOT can bypass a release repository Deployment Policy","We have a nexus server:    Sonatype Nexus™ Open Source Edition, Version: 2.0.6    (sure - kinda old)     But we are able to redeploy a version of an artifact with a version string of:    1.0.0-SNAPSHOT-FOO-999    We have our release repo set up to deny redeploy, but we were able to redeploy this to this release repo over and over.",Bug,Major,Closed,"2014-12-12 02:09:50","2014-12-12 02:09:50",2
"Sonatype Nexus","Upgrade to Jetty 9.2.x",,Story,Major,Done,"2014-12-11 20:09:52","2014-12-11 20:09:52",1
"Sonatype Nexus","npm groups should merge versions of the same package in different members","Start with this repository setup:        Configure your registry for **gets** to point at npm-group with proper permissions.    Using {{npm publish}} and a proper publishConfig url in package.json  deploy package X version 0.0.1 to npm-hosted1   deploy package X version 0.0.2 to npm-hosted2    Execute {{npm view X versions}}    This returns one version {{0.0.1}}.    Reorder the group members:        Execute {{npm view X versions}}    This returns one version ( {{0.0.2}} ).    Expected  - {{npm view X versions}} should list all versions of the same package in all group members    Notes:  - NPM groups do not exactly match up with Maven groups  -- NPM packages are flat, there is no hierarchy    Because of this, should we treat NPM groups like Maven groups?  We have a concern that we could merge packages together due to the flat nature of NPM that weren't meant to be merged  Scoped packages was invented to circumvent this problem    Potentially do:  - Allow for capability for specific groups to do merge, and instruct the users on how to add hosted/proxy repos to the group",Improvement,Major,Closed,"2014-12-11 16:03:28","2014-12-11 16:03:28",0.5
"Sonatype Nexus","Revisit tasks logging","Before NX3 Scheduler (legacy scheduler) there was a lot (was maybe even noisy) logging about tasks started, stoppped ,etc...    With new scheduler we got to the opposite end of the horse, silence. Scheduler uses INFO logging very sparingly.    Tinker about, do we need at least some INFO logs about tasks, and if yes what? State transition?    Note: This is about logging only, as feeds are preserved and should be available with full content as before.",Improvement,Major,Closed,"2014-12-10 20:41:34","2014-12-10 20:41:34",0.5
"Sonatype Nexus","request.log should be able to print the Nexus authenticated userid","You can configure %u in the request log via logback access layout pattern.    However this always prints - despite requests being authenticated by Nexus.    Nexus should implement a way to print the authenticated user id in the request.log    This is a useful diagnostic tool and helps avoid requiring 2 log lines in nexus.log proper as described in this article:    https://support.sonatype.com/entries/24056287",Improvement,Minor,Closed,"2014-12-03 20:57:24","2014-12-03 20:57:24",1
"Sonatype Nexus","NullPointerException in pom validator staging rule","The updates to the POM validation rule are lacking some sanity checks for nulls.    {quote}  2014-12-01 10:53:47,412-0600 INFO  [qtp1153766106-75721] <USER>com.sonatype.nexus.staging.internal.DefaultStagingManager - Closing staging repositories [comgithubthe-alchemist-1001]  2014-12-01 10:53:47,916-0600 INFO  [pxpool-1-thread-16] <USER>com.sonatype.nexus.staging.internal.task.StagingBackgroundTask - STARTED Closing staging repositories: [comgithubthe-alchemist-1001]  2014-12-01 10:53:48,166-0600 INFO  [pxpool-1-thread-16] <USER>org.sonatype.nexus.configuration.ModelUtils - Saving model /data/nexus/sonatype-work/nexus/conf/staging.xml  2014-12-01 10:53:48,614-0600 INFO  [pxpool-1-thread-16] <USER>org.sonatype.nexus.configuration.ModelUtils - Saving model /data/nexus/sonatype-work/nexus/conf/staging.xml  2014-12-01 10:53:48,997-0600 INFO  [pxpool-1-thread-16] <USER>org.sonatype.nexus.configuration.ModelUtils - Saving model /data/nexus/sonatype-work/nexus/conf/staging.xml  2014-12-01 10:53:49,438-0600 WARN  [pxpool-1-thread-16] <USER>org.sonatype.nexus.proxy.walker.DefaultWalker - Aborted walking on repository comgithubthe-alchemist-1001 (staging: open) [id=comgithubthe-alchemist-1001] from path /, cause: null  java.lang.NullPointerException: null  at com.sonatype.nexus.staging.internal.rules.POMStagingRuleEvaluator$POMStagingRuleWalkerProcessor.validateDependency(POMStagingRuleEvaluator.java:140) ~[nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.rules.POMStagingRuleEvaluator$POMStagingRuleWalkerProcessor.validateDependencies(POMStagingRuleEvaluator.java:123) ~[nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.rules.POMStagingRuleEvaluator$POMStagingRuleWalkerProcessor.validatePOM(POMStagingRuleEvaluator.java:95) ~[nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.rules.POMStagingRuleEvaluator$POMStagingRuleWalkerProcessor.processFileItem(POMStagingRuleEvaluator.java:64) ~[nexus-staging-plugin-2.11.0-01/:na]  at org.sonatype.nexus.proxy.walker.AbstractFileWalkerProcessor.processItem(AbstractFileWalkerProcessor.java:26) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.processItem(DefaultWalker.java:292) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkItem(DefaultWalker.java:244) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkRecursive(DefaultWalker.java:200) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkRecursive(DefaultWalker.java:209) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkRecursive(DefaultWalker.java:209) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkRecursive(DefaultWalker.java:209) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkRecursive(DefaultWalker.java:209) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkRecursive(DefaultWalker.java:209) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walk(DefaultWalker.java:89) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at com.sonatype.nexus.staging.rule.AbstractStagingRuleEvaluator.evaluate(AbstractStagingRuleEvaluator.java:46) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.rule.StagingRule.evaluate(StagingRule.java:63) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.StagingRulesHelper.evaluateRules(StagingRulesHelper.java:271) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.StagingRulesHelper.evaluateRuleSet(StagingRulesHelper.java:238) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.StagingRulesHelper.evaluateProfileRuleSets(StagingRulesHelper.java:131) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.StagingRulesHelper.evaluate(StagingRulesHelper.java:102) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.RepositoryCloseTask$CloseOperation.verifyItem(RepositoryCloseTask.java:89) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.RepositoryCloseTask$CloseOperation.verifyItem(RepositoryCloseTask.java:1) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.OperationTaskSupport$OperationSupport.verify(OperationTaskSupport.java:294) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.OperationTaskSupport.executeOperations(OperationTaskSupport.java:425) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.OperationTaskSupport.doCall(OperationTaskSupport.java:415) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.TaskSupport.call(TaskSupport.java:37) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.StagingTaskSupport.call(StagingTaskSupport.java:133) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.StagingBackgroundTask.execute(StagingBackgroundTask.java:67) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.NexusTaskSupport.doRun(NexusTaskSupport.java:52) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.NexusTaskSupport.doRun(NexusTaskSupport.java:1) [nexus-staging-plugin-2.11.0-01/:na]  at org.sonatype.nexus.scheduling.AbstractNexusTask.call(AbstractNexusTask.java:151) [nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.scheduling.DefaultScheduledTask.call(DefaultScheduledTask.java:418) [nexus-scheduler-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.threads.MDCAwareCallable.call(MDCAwareCallable.java:44) [nexus-core-2.11.0-01.jar:2.11.0-01]  at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [shiro-core-1.2.3.jar:1.2.3]  at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [shiro-core-1.2.3.jar:1.2.3]  at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) [na:1.7.0_21]  at java.util.concurrent.FutureTask.run(FutureTask.java:166) [na:1.7.0_21]  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178) [na:1.7.0_21]  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292) [na:1.7.0_21]  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_21]  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_21]  at java.lang.Thread.run(Thread.java:722) [na:1.7.0_21]  2014-12-01 10:53:49,439-0600 WARN  [pxpool-1-thread-16] <USER>com.sonatype.nexus.staging.internal.StagingRulesHelper - Rule 'pom-staging' evaluation unexpectedly failed  org.sonatype.nexus.proxy.walker.WalkerException: Aborted walking on repository ID='comgithubthe-alchemist-1001' from path='/'.  at org.sonatype.nexus.proxy.walker.DefaultWalker.reportWalkEnd(DefaultWalker.java:152) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walk(DefaultWalker.java:118) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at com.sonatype.nexus.staging.rule.AbstractStagingRuleEvaluator.evaluate(AbstractStagingRuleEvaluator.java:46) ~[nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.rule.StagingRule.evaluate(StagingRule.java:63) ~[nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.StagingRulesHelper.evaluateRules(StagingRulesHelper.java:271) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.StagingRulesHelper.evaluateRuleSet(StagingRulesHelper.java:238) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.StagingRulesHelper.evaluateProfileRuleSets(StagingRulesHelper.java:131) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.StagingRulesHelper.evaluate(StagingRulesHelper.java:102) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.RepositoryCloseTask$CloseOperation.verifyItem(RepositoryCloseTask.java:89) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.RepositoryCloseTask$CloseOperation.verifyItem(RepositoryCloseTask.java:1) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.OperationTaskSupport$OperationSupport.verify(OperationTaskSupport.java:294) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.OperationTaskSupport.executeOperations(OperationTaskSupport.java:425) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.OperationTaskSupport.doCall(OperationTaskSupport.java:415) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.TaskSupport.call(TaskSupport.java:37) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.StagingTaskSupport.call(StagingTaskSupport.java:133) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.StagingBackgroundTask.execute(StagingBackgroundTask.java:67) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.NexusTaskSupport.doRun(NexusTaskSupport.java:52) [nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.task.NexusTaskSupport.doRun(NexusTaskSupport.java:1) [nexus-staging-plugin-2.11.0-01/:na]  at org.sonatype.nexus.scheduling.AbstractNexusTask.call(AbstractNexusTask.java:151) [nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.scheduling.DefaultScheduledTask.call(DefaultScheduledTask.java:418) [nexus-scheduler-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.threads.MDCAwareCallable.call(MDCAwareCallable.java:44) [nexus-core-2.11.0-01.jar:2.11.0-01]  at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [shiro-core-1.2.3.jar:1.2.3]  at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [shiro-core-1.2.3.jar:1.2.3]  at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) [na:1.7.0_21]  at java.util.concurrent.FutureTask.run(FutureTask.java:166) [na:1.7.0_21]  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178) [na:1.7.0_21]  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292) [na:1.7.0_21]  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_21]  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_21]  at java.lang.Thread.run(Thread.java:722) [na:1.7.0_21]  Caused by: java.lang.NullPointerException: null  at com.sonatype.nexus.staging.internal.rules.POMStagingRuleEvaluator$POMStagingRuleWalkerProcessor.validateDependency(POMStagingRuleEvaluator.java:140) ~[nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.rules.POMStagingRuleEvaluator$POMStagingRuleWalkerProcessor.validateDependencies(POMStagingRuleEvaluator.java:123) ~[nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.rules.POMStagingRuleEvaluator$POMStagingRuleWalkerProcessor.validatePOM(POMStagingRuleEvaluator.java:95) ~[nexus-staging-plugin-2.11.0-01/:na]  at com.sonatype.nexus.staging.internal.rules.POMStagingRuleEvaluator$POMStagingRuleWalkerProcessor.processFileItem(POMStagingRuleEvaluator.java:64) ~[nexus-staging-plugin-2.11.0-01/:na]  at org.sonatype.nexus.proxy.walker.AbstractFileWalkerProcessor.processItem(AbstractFileWalkerProcessor.java:26) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.processItem(DefaultWalker.java:292) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkItem(DefaultWalker.java:244) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkRecursive(DefaultWalker.java:200) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkRecursive(DefaultWalker.java:209) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkRecursive(DefaultWalker.java:209) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkRecursive(DefaultWalker.java:209) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkRecursive(DefaultWalker.java:209) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walkRecursive(DefaultWalker.java:209) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  at org.sonatype.nexus.proxy.walker.DefaultWalker.walk(DefaultWalker.java:89) ~[nexus-core-2.11.0-01.jar:2.11.0-01]  ... 28 common frames omitted  {quote}",Bug,Critical,Closed,"2014-12-01 21:26:40","2014-12-01 21:26:40",0.5
"Sonatype Nexus","deadlock trying to read .meta/obr.xml after running task to merge metadata","It is possible more than one thread can attempt to merge obr group metadata at the same time.    This causes a virtual deadlock situation and prevents other threads trying to read the metadata.    Example thread stacks that can be seen on dumps when in this situation:        ----    Example blocked thread:        ----    Competing threads:            Waiting threads:    ",Bug,Major,Closed,"2014-11-28 15:12:24","2014-11-28 15:12:24",0
"Sonatype Nexus","Remove legacy Staging modello configuration","Staging has already been moved to orient db but old modello based config classes are still in place and used to upgrade from staging.xml.    Lets remove the modello classes and take care of upgrade during NX2->NX3 migration.    Note: Removing modello will mean that quite a bunch of staging legacy ITs will have to be rewritten as they are copying over a staging.xml",Story,Minor,Done,"2014-11-28 08:38:40","2014-11-28 08:38:40",5
"Sonatype Nexus","Remove legacy PGP modello configuration","PGP configuration has already been moved to a capability but old modello based config classes are still in place and used to upgrade from pgp.xml.    Lets remove the modello classes and take care of upgrade during NX2->NX3 migration    Note: Removing modello will mean that a bunch of staging/pgp legacy ITs will have to be rewritten as they are copying over a pgp.xml",Story,Minor,Done,"2014-11-28 08:34:58","2014-11-28 08:34:58",2
"Sonatype Nexus","Remove legacy Crowd modello configuration","Crowd configuration has already been moved to a capability but old modello based config classes are still in place and used to upgrade from crowd-plugin.xml.    Lets remove the modello classes and take care of upgrade during NX2->NX3 migration",Story,Minor,Done,"2014-11-28 08:27:41","2014-11-28 08:27:41",0.5
"Sonatype Nexus","Replace LDAP configuration","Replace modello based LDAP configuration with orient db    Acceptance Criteria:  - Make LDAP plugin stop use Modello (and have dropped use of it alltogether), and have it tied into config OrientDB instance. (/)  - Module tests related changes as needed (as many of those stuff ldap.xml under tests), true for nexus-ldap-plugin module UTs as for nexus-ldap-plugin module ITs (/)  - Remove use of Plexus from module UTs and ITs (as current tests were unmaintable, this was a desperate step of mine -- <USER> (/)  - Update nexus-ldap-testsupport, remove Plexus (as use of the ldap testsupport module implied use of Plexus in dependant module, which is unwanted) (/)  - Introduce nexus-ldap-client (needed to be able to manipulate LDAP configuration from real ITs, as copying ldap.xml does not work anymore) (/)  - Update OSS legacy and modern ITs as needed (replace copied ldap.xml's with LDAP Rest Client use) (/)  - Update Pro legacy and modern ITs as needed (replace copied ldap.xml's with LDAP Rest Client use) (/)",Story,Major,Done,"2014-11-28 08:09:30","2014-11-28 08:09:30",1
"Sonatype Nexus","Replace Kenai configuration","Replace modello based Kenai configuration with a capability",Story,Major,Done,"2014-11-28 08:07:12","2014-11-28 08:07:12",1
"Sonatype Nexus","Gems repositories show Smart Proxy tab","The proxy and hosted Gem repositories show the Smart Proxy tab even though there is no related functionality.    Found in 2.11.0-01",Bug,Minor,Closed,"2014-11-27 21:40:02","2014-11-27 21:40:02",0.5
"Sonatype Nexus","RUT Auth Realm does not authenticate in Nexus 3","Add Rut Auth to the top of the active realms list in Nexus 3, above both XML realms.  Add the RUT Auth capability with the header value of username.  Send the following request:        Note the User is not permitted message.    Debug Logs from this request show RUT auth is not even consulted:      ",Bug,Major,Closed,"2014-11-27 17:37:10","2014-11-27 17:37:10",3
"Sonatype Nexus","Enable browse storage for ruby gems repositories","I've checked all issues filed against ruby in both the github project, jira, and support tickets.  I found no problems reported with the browse storage tab.    I don't see any reason for us to have disabled it, it seems like its been working well enough for most people for years now.  If there were widespread issues we would likely have heard of them.    ",Improvement,Major,Closed,"2014-11-20 17:31:10","2014-11-20 17:31:10",0.5
"Sonatype Nexus","capture generation time in analytics event-zip header.json as reference","Think we should add a 'created' attribute in the header (or a format property) to be used as a hint as when the file was generated.",Improvement,Minor,Closed,"2014-11-15 01:27:01","2014-11-15 01:27:01",1
"Sonatype Nexus","Expiring item cache in Nuget proxy repositories causes them to auto-block frequently","The default item max age in NuGet proxy repositories is set to 1440 minutes (I'm not sure why, artifacts should be immutable).    When it expires for a a path Nexus issues a request to the remote to check for updates.  Unfortunately, it uses the full path of the artifact, e.g.:     http://localhost:8081/nexus/service/local/nuget/nuget-repo/Extended.Wpf.Toolkit/2.2.0/Extended.Wpf.Toolkit-2.2.0.nupkg    This doesn't work for NuGet feeds, it results in a 400 response.  This 400 response causes the repository to auto-block.    Note that the initial download of an artifact doesn't do this (even if the full path is requested through the proxies /content URL), it uses the right path for NuGet:    http://localhost:8081/nexus/service/local/nuget/nuget-repo/Extended.Wpf.Toolkit/2.2.0/        ",Bug,Major,Closed,"2014-11-14 21:51:14","2014-11-14 21:51:14",2
"Sonatype Nexus","limit size of analytics event zip files at creation and submission","Large event-zip files can cause timeouts resulting in error recovery kicking in and resulting in the event-zip getting stuck and resending over and over.",Bug,Major,Closed,"2014-11-14 21:25:00","2014-11-14 21:25:00",3
"Sonatype Nexus","Adjust header size of message notification windows","Should be smaller height and font size, these are not as important as modal dialogs but presently the sizes are the same.",Improvement,Major,Closed,"2014-11-14 00:54:14","2014-11-14 00:54:14",0.5
"Sonatype Nexus","Paging toolbar looks disabled when its not disabled","Should probably adjust to use darker style like used for button glyphs.",Improvement,Major,Closed,"2014-11-14 00:50:13","2014-11-14 00:50:13",0.5
"Sonatype Nexus","Feeds view still using dark header style",,Improvement,Major,Closed,"2014-11-14 00:41:22","2014-11-14 00:41:22",1
"Sonatype Nexus","Accept license dialog refinements","Feels a bit ugly... not sure we care too much, but maybe a few adjustments can make this not look like ass?",Improvement,Trivial,Closed,"2014-11-14 00:37:16","2014-11-14 00:37:16",1
"Sonatype Nexus","Search criteria field layout won't scale has issues with textbox size","The design of the search criteria fields should be improve so this can scale better.  ATM these will push off the screen if more are added.  Also some fields are simply too small for realistic user input we'd expect.",Improvement,Minor,Closed,"2014-11-14 00:34:21","2014-11-14 00:34:21",3
"Sonatype Nexus","Change password dialog is too wide","This has someting to do with re-using settingsforms bits which have this preset width.    Acceptance Criteria:  - Bring Change Password Dialog into being a consistent width with Login Dialog",Improvement,Minor,Closed,"2014-11-14 00:31:42","2014-11-14 00:31:42",1
"Sonatype Nexus","Artifact upload layout/style refinements","The upload views are bulky and do not scale well when adding more file types.    Should refine this design and consider options to make this work better over all.",Improvement,Major,Closed,"2014-11-14 00:29:31","2014-11-14 00:29:31",3
"Sonatype Nexus","Adjust style of master detail warning messages ",,Improvement,Major,Closed,"2014-11-14 00:25:21","2014-11-14 00:25:21",1
"Sonatype Nexus","make multi-valued cache choices explicit","Instead of numeric spinners for cache TTL and max ages, these should be drop down single select options.    Possible values for Artifact Max Age are currently -1 / 0 / n where n is some number of minutes.    This is represented on the UI with a number spinner.    Instead a single drop down list that said something like:    Infinite  Finite  Never    When Finite is select, provide a text input or spinner that lets them input a positive integer only.    The numeric spinners can also change values unknowingly when you are using a mouse wheel to scroll the settings page before saving. This can result in the wrong values being used.    The meaning of -1 is too cryptic - use words for humans.  ",Improvement,Minor,Closed,"2014-11-13 19:30:36","2014-11-13 19:30:36",3
"Sonatype Nexus","Not Found Cache TTL set to any negative value caches not found artifacts for 2 minutes","Set Not Found Cache TTL to 0 - this caches not found request infinitely    Set not Found Cache TTL to -1 - this caches NFC for 2 minutes.    Expected: Anecdotally -1 has been used in the past to disable the not found cache for a repo.    Has something changed?    ",Bug,Minor,Closed,"2014-11-13 19:25:00","2014-11-13 19:25:00",1
"Sonatype Nexus","downloading specific versions of NuGet packages via Visual Studio package manager console fails","Download of older versions of NuGet packages using the Visual studio NuGet package manager console doesn't work unless the packages are already cached in Nexus.    {quote}  PM> Install-Package -Id Google.ProtocolBuffers -Version 2.3.0.277  Install-Package : Unable to find version '2.3.0.277' of package 'Google.ProtocolBuffers'.  At line:1 char:16  + Install-Package <<<<  -Id Google.ProtocolBuffers -Version 2.3.0.277      + CategoryInfo          : NotSpecified: (:) [Install-Package], InvalidOperationException      + FullyQualifiedErrorId : NuGetCmdletUnhandledException,NuGet.PowerShell.Commands.InstallPackageCommand   {quote}    This fails.  But then download it directly into Nexus via GET request:    {quote}  curl http://localhost:8081/nexus/service/local/nuget/nugroup/Google.ProtocolBuffers/2.3.0.277 > /dev/null  {quote}    After this the download from PM works:    {quote}  PM> Install-Package -Id Google.ProtocolBuffers -Version 2.3.0.277  Installing 'Google.ProtocolBuffers 2.3.0.277'.  Successfully installed 'Google.ProtocolBuffers 2.3.0.277'.  Adding 'Google.ProtocolBuffers 2.3.0.277' to SonatypeNexusCSharp.  Successfully added 'Google.ProtocolBuffers 2.3.0.277' to SonatypeNexusCSharp.  {quote}    The query which fails (and then succeeds) is:    {quote}  http://localhost:8081/nexus/service/local/nuget/nugroup/Packages%28Id=%27Google.ProtocolBuffers%27,Version=%272.3.0.277%27%29  {quote}        ",Bug,Major,Closed,"2014-11-12 21:39:59","2014-11-12 21:39:59",3
"Sonatype Nexus","Logs (read) privilege doesn't give access to /service/siesta/logging/log","The Logs (read) privilege maps to the nexus:logs privilege.  But access to /service/siesta/logging/log requires nexus:log.    This means that granting access to logs (read) doesn't let a user see the log in the UI.",Bug,Minor,Closed,"2014-11-12 16:19:14","2014-11-12 16:19:14",0.5
"Sonatype Nexus","Inconsistency in handling of repository targets for NuGet","If you send a delete request to a NuGet repository the path used to resolve the repository target permissions does not include the leading /.  This is inconsistent with other repositories in Nexus.    For instance, this command:    {quote}  NuGet.exe delete SonatypeNexusCSharp 1.0.0 -ApiKey 3fa626ae-e597-3840-96fe-caa35a7f7bed -Source http://192.168.1.50:8081/nexus/service/local/nuget/nnn  {quote}    Results in a path of SonatypeNexusCSharp/1.0.0 being used:    {quote}  2014-11-12 09:33:43 DEBUG [qtp327533081-125] rich org.sonatype.nexus.proxy.targets.DefaultTargetRegistry - Resolving targets for repository='nugroup' for path='SonatypeNexusCSharp/1.0.0'  {quote}    This means a standard target of /SonatypeNexusCSharp/.* used in a repository target permission will not match.    If you try the same delete through the UI the request will go through /service/local/repositories/<repo-id>/content, and the target starting with / will work.    *Workaround*    Change the regular expression in the target to indicate the leading / is optional.  For example:               ",Bug,Minor,Closed,"2014-11-12 15:42:17","2014-11-12 15:42:17",0.5
"Sonatype Nexus","Update location of shell user state from ~/.karaf to ~/.nexus","Don't want to clobber other karaf-based services.",Improvement,Minor,Closed,"2014-11-11 23:05:48","2014-11-11 23:05:48",1
"Sonatype Nexus","Convert the metrics frames to the light panel treatment","Current treatment:    !Screen Shot 2014-11-11 at 2.01.16 PM.png|thumbnail!    Light panels (for reference):    !Screen Shot 2014-11-11 at 2.02.53 PM.png|thumbnail!",Task,Major,Closed,"2014-11-11 22:03:26","2014-11-11 22:03:26",1
"Sonatype Nexus","disable SSLv3 for outbound requests by default","bq. Oracle recommends that users and developers disable use of the SSLv3 protocol.     http://www.oracle.com/technetwork/java/javase/documentation/cve-2014-3566-2342133.html    Referenced from release notes:    http://www.oracle.com/technetwork/java/javase/7u71-relnotes-2296187.html  http://www.oracle.com/technetwork/java/javase/8u25-relnotes-2296185.html    At the bottom of the article is a suggested approach in code to use to disable SSLv3 explicitly by default. Nexus should do this as well by default for outbound requests.    Only apply this default exclusion in case where https.protocols system property is not set. ( per NEXUS-7594 )  ",Improvement,Major,Closed,"2014-11-05 16:11:35","2014-11-05 16:11:35",2
"Sonatype Nexus","Karaf status and stop commands depend on the shutdown port","We either need to re-enable the random shutdown port (but disable it for any tests, as it causes issues wrt. port allocation) or preferably enhance the status and stop commands to work with a PID file like in Nx2.",Bug,Major,Closed,"2014-11-04 14:30:27","2014-11-04 14:30:27",1
"Sonatype Nexus","SSL certificates added using load from server option only use direct socket connection","Configure Nexus to use proxy server which can write it's own SSL certificate in place of the actual remote certificate. ( ie. Charles proxy ). For example, configure it to SSL proxy https://nvd.nist.gov    In Nexus, Go to SSL Certificates and click Add... Load From Server...  Enter nvd.nist.gov and click Load Certificate button.  Nexus UI sends a request similar to:    bq. 'http://localhost:8081/nexus/service/siesta/ssl/certificates?_dc=1415038245066&host=nvd.nist.gov&port=443'    Nexus certificates resource tries to make a direct socket connection to the remote instead of https connection. This is by design.    Now enter https://nvd.nist.gov and click Load Certificate button. Nexus *still* tries to make a direct socket connection.    Notice the url sent to Nexus backend is still:    bq. 'http://localhost:8081/nexus/service/siesta/ssl/certificates?_dc=1415038245066&host=nvd.nist.gov&port=443'    It seems to be missing the 'protocolHint' parameter.    https://github.com/sonatype/nexus-pro/blob/nexus-2.10.x/plugins/security/nexus-ssl-plugin/src/main/java/com/sonatype/nexus/ssl/plugin/internal/rest/CertificatesResource.java#L91-91    Nexus 2.8.0 does the same thing.    The problem this creates is it is very common proxy servers overwrite remote certs. Without using https instead of direct socket, it is easy to trust the wrong cert. or not be able to trust the correct cert unless you manually get the pem file externally and upload it.    Expected: When http or https is specified, the internal http client with correct proxy settings should be used to get the remote cert and present that to the end user.    ",Bug,Major,Closed,"2014-11-03 18:33:41","2014-11-03 18:33:41",0.5
"Sonatype Nexus","Upgrade to Apache Tika 1.7 for better mime detection","As proper fix for issue NEXUS-7603 is implemented in it, see  https://issues.apache.org/jira/browse/TIKA-1461    Current circumvention is bad, as proper fix requires mime XML database changes (not doable via custom-mimetypes), so we could only do a patch release to properly fix it. Once 1.7 is out, we should integrate it,","Technical Debt",Minor,Closed,"2014-10-31 11:55:58","2014-10-31 11:55:58",1
"Sonatype Nexus","Content detection/validation for proxy repositories","Content from sources needs to be able to detect the type, by asking Tika and recoding this in metadata.  Additional logic will also be needed to layer ontop to validate that content we get is what we think, to cope with issues like asking for a .jar file and getting a .html error page.    Acceptance Criteria:  - You will be able to deploy a Maven site to a hosted raw repo and when viewing it in the browser it will display properly due to content types being returned",Story,Major,Done,"2014-10-29 21:06:41","2014-10-29 21:06:41",1
"Sonatype Nexus","CLM server password is not removed from support tool zip configuration","The clm server password is not removed from the capabilities.xml file in a generated support zip:    {code:XML}      <capability>        <version>1</version>        <id>149589872f8674</id>        <typeId>clm</typeId>        <properties>          <property>            <key>username</key>            <value>nexus</value>          </property>          <property>            <key>properties</key>            <value></value>          </property>          <property>            <key>password</key>            <value>{ytt7g/xp2PUHBzzEd+hCgEjDcBtg/VJvBy0ODZD5AAA=}</value>          </property>          <property>            <key>url</key>            <value>http://localhost:8070</value>          </property>        </properties>      </capability>  {code}",Bug,Major,Closed,"2014-10-29 18:26:20","2014-10-29 18:26:20",1
"Sonatype Nexus","Change quick search clear icon to grayscale","The light-blue hover/focus/click states look wrong against that dark gray background. Consider switching to grayscale or a stronger blue.",Task,Major,Closed,"2014-10-28 20:29:28","2014-10-28 20:29:28",1
"Sonatype Nexus","Live style guide","Implement the 8shapes visual index as a tab in the developer console.    Reference:    https://www.dropbox.com/sh/hh02tj5th6dsh2q/AABNgGt8ZNk41i-ZlzvSZSLsa/visual%20index?dl=0#lh:null-Sonatype%20Nexus%20Visual%20Index.psd    Out of scope items:    - Icons (we aren’t using all the icons represented in the style guide)",Story,Major,Done,"2014-10-28 18:39:41","2014-10-28 18:39:41",5
"Sonatype Nexus","NuGet Proxy Repository","As a .NET developer, so that I can get quicker and more reliable access to remote packages, I want the ability to have NuGet repos cached locally     Acceptance Criteria:  - Implement handlers for the various read-only NuGet gallery protocol endpoints (ODATA queries, downloading, etc.).   - Implement the caching of remotely-fetched components in component storage.  - If a user requests a package we don't have by URL we should send a request to fetch the metadata from the remote proxy  - Feed counts should reflect what the upstream repo reports  -- Search results will be slightly different due to the algorithms we use versus NuGet.org  - If the remote repo goes down, a user should be able to still use the proxy repo with locally available metadata and packages  - Locally cached NuGet metadata should be visible in Nexus ElasticSearch results (regardless of whether we have the packages yet)  - Nexus Admins will be able to configure the cache duration/size for queries to remote repos so that we don't overload the remote repo  - If a user Searches on the NuGet Feed search results are capped at 40 entries  - Supported clients are Visual Studio 2013's package manager, the VS package manager powershell utility, the standalone Nuget.exe command-line client, and the Nuget Package Manager.",Story,Major,Done,"2014-10-28 18:04:11","2014-10-28 18:04:11",1
"Sonatype Nexus","NuGet Component Metadata/Asset Storage","Implement storage for NuGet metadata and content.",Story,Major,Done,"2014-10-28 18:00:42","2014-10-28 18:00:42",5
"Sonatype Nexus","Cached Components Lifecycle","Placeholder story.    Determine when cached components should be deleted (seems likely in response to the originating Source being deleted). Consider soft deletion of the source, the component metadata, the blobs.",Story,Major,Done,"2014-10-28 17:58:52","2014-10-28 17:58:52",3
"Sonatype Nexus","NuGet ComponentSource","Implement a NuGet ComponentSource.    Create the source, the domain object for the metadata/asset (as appropriate), config/factory.    Support all of the read-only aspects of the NuGet gallery protocol (e.g. fetching content, ODATA queries such as feeds, counts, etc.).",Story,Major,Done,"2014-10-28 17:57:05","2014-10-28 17:57:05",8
"Sonatype Nexus","Nexus BUG in rubygems-proxy ItemNotFoundException during cache","Found in logs during performing test scenarios (see NEXUS-7607).    jvm 1    | 2014-10-28 14:21:44,922+0100 WARN  [qtp1187179057-85] anonymous org.sonatype.nexus.plugins.ruby.proxy.DefaultProxyRubyRepository - Nexus BUG in rubygems-proxy [id=rubygems-proxy], ItemNotFoundException during cache! Please report this issue along with the stack trace below!  jvm 1    | org.sonatype.nexus.proxy.ItemNotFoundException: Path /api/v1/dependencies?gems=pattern-match, not found in local storage of repository rubygems-proxy [id=rubygems-proxy]  jvm 1    |  at org.sonatype.nexus.proxy.storage.local.fs.DefaultFSLocalRepositoryStorage.retrieveItemFromFile(DefaultFSLocalRepositoryStorage.java:267) ~[nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.proxy.storage.local.fs.DefaultFSLocalRepositoryStorage.retrieveItem(DefaultFSLocalRepositoryStorage.java:292) ~[nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.proxy.repository.AbstractRepository.doRetrieveLocalItem(AbstractRepository.java:1238) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.proxy.repository.AbstractProxyRepository.doCacheItem(AbstractProxyRepository.java:910) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.plugins.ruby.proxy.DefaultProxyRubyRepository.doCacheItem(DefaultProxyRubyRepository.java:180) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.proxy.repository.AbstractProxyRepository.doRetrieveRemoteItem(AbstractProxyRepository.java:1413) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.plugins.ruby.proxy.DefaultProxyRubyRepository.doRetrieveRemoteItem(DefaultProxyRubyRepository.java:193) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.proxy.repository.AbstractProxyRepository.doRetrieveItem0(AbstractProxyRepository.java:1147) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.proxy.repository.AbstractProxyRepository.doRetrieveItem(AbstractProxyRepository.java:1030) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:758) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.plugins.ruby.proxy.DefaultProxyRubyRepository.retrieveDirectItem(DefaultProxyRubyRepository.java:219) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.plugins.ruby.proxy.ProxyNexusStorage.retrieve(ProxyNexusStorage.java:48) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.layout.ProxiedGETLayout.retrieveAll(ProxiedGETLayout.java:59) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.layout.GETLayout.bundlerApiFile(GETLayout.java:114) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.api.ApiV1DependenciesCuba.on(ApiV1DependenciesCuba.java:50) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.State.nested(State.java:55) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.api.ApiV1Cuba.on(ApiV1Cuba.java:46) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.State.nested(State.java:61) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.api.ApiCuba.on(ApiCuba.java:49) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.State.nested(State.java:61) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.RootCuba.on(RootCuba.java:66) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.State.nested(State.java:61) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.RubygemsFileSystem.visit(RubygemsFileSystem.java:84) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.RubygemsFileSystem.get(RubygemsFileSystem.java:60) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.plugins.ruby.NexusRubygemsFacade.get(NexusRubygemsFacade.java:60) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.plugins.ruby.proxy.DefaultProxyRubyRepository.retrieveItem(DefaultProxyRubyRepository.java:241) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.proxy.repository.AbstractGroupRepository.doRetrieveItems(AbstractGroupRepository.java:451) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.plugins.ruby.group.GroupNexusStorage.retrieve(GroupNexusStorage.java:193) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.layout.ProxiedGETLayout.retrieveAll(ProxiedGETLayout.java:59) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.layout.GETLayout.bundlerApiFile(GETLayout.java:114) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.api.ApiV1DependenciesCuba.on(ApiV1DependenciesCuba.java:50) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.State.nested(State.java:55) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.api.ApiV1Cuba.on(ApiV1Cuba.java:46) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.State.nested(State.java:61) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.api.ApiCuba.on(ApiCuba.java:49) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.State.nested(State.java:61) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.RootCuba.on(RootCuba.java:66) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.State.nested(State.java:61) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.RubygemsFileSystem.visit(RubygemsFileSystem.java:84) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.ruby.cuba.RubygemsFileSystem.get(RubygemsFileSystem.java:60) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.plugins.ruby.NexusRubygemsFacade.get(NexusRubygemsFacade.java:60) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.plugins.ruby.group.DefaultRubyGroupRepository.retrieveItem(DefaultRubyGroupRepository.java:128) [nexus-ruby-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:590) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.proxy.router.DefaultRepositoryRouter.retrieveItem(DefaultRepositoryRouter.java:155) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.content.internal.ContentServlet.doGet(ContentServlet.java:387) [nexus-content-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at org.sonatype.nexus.content.internal.ContentServlet.service(ContentServlet.java:353) [nexus-content-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]  jvm 1    |  at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:288) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:278) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:93) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.sonatype.nexus.web.internal.SecurityFilter.executeChain(SecurityFilter.java:73) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [shiro-core-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [shiro-core-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [shiro-core-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.2.3.jar:1.2.3]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:135) [nexus-licensing-plugin-2.11.0-SNAPSHOT/:na]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.yammer.metrics.web.WebappMetricsFilter.doFilter(WebappMetricsFilter.java:76) [metrics-web-2.2.0.jar:na]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at org.sonatype.nexus.web.internal.CommonHeadersFilter.doFilter(CommonHeadersFilter.java:69) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at org.sonatype.nexus.web.internal.ErrorPageFilter.doFilter(ErrorPageFilter.java:71) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at org.sonatype.nexus.web.internal.BaseUrlHolderFilter.doFilter(BaseUrlHolderFilter.java:70) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterPipeline.dispatch(NexusGuiceFilter.java:56) [nexus-core-2.11.0-SNAPSHOT.jar:2.11.0-SNAPSHOT]  jvm 1    |  at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:132) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:129) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:206) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:129) [guice-servlet-3.1.10.jar:3.1.10]  jvm 1    |  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419) [jetty-servlet-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:455) [jetty-servlet-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557) [jetty-security-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1075) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:384) [jetty-servlet-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1009) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at com.yammer.metrics.jetty.InstrumentedHandler.handle(InstrumentedHandler.java:200) [metrics-jetty-2.2.0.jar:na]  jvm 1    |  at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:154) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.Server.handle(Server.java:370) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:489) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:949) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1011) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644) [jetty-http-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235) [jetty-http-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668) [jetty-io-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52) [jetty-io-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608) [jetty-util-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543) [jetty-util-8.1.11.v20130520.jar:8.1.11.v20130520]  jvm 1    |  at java.lang.Thread.run(Thread.java:745) [na:1.7.0_71]  jvm 1    | 2014-10-28 14:23:08,834+0100 WARN  [qtp1187179057-83] anonymous org.sonatype.nexus.content.internal.ContentServlet - org.eclipse.jetty.io.EofException, caused by: java.io.IOException: Broken pipe [client=127.0.0.1,ua=Ruby, RubyGems/2.1.9 universal-java-1.7 Ruby/1.9.3 (2014-09-25 patchlevel 392) jruby,req=GET http://localhost:8081/nexus/content/repositories/rubygems-group/gems/jruby-jars-1.7.16.gem]  ",Bug,Major,Closed,"2014-10-28 15:53:52","2014-10-28 15:53:52",1
"Sonatype Nexus","View content storage policy","View config includes a content storage policy: the view either to uses the default blob store, or one which writes to a location specified in the view config. (Well, really it's a sort of inline blob store config.)",Story,Major,Done,"2014-10-23 18:41:39","2014-10-23 17:41:39",1
"Sonatype Nexus","add support for npm deprecate","Acceptance Criteria:  - Add and test support for the ability to use the npm deprecate command to deprecate a package  - Add and test support for the ability to use the npm deprecate command to UNdeprecate a package  - Visually show that the package has been deprecated in Search and Browse    This is the alternative for npm unpublish ( NEXUS-6892 )",Story,Major,Done,"2014-10-23 12:05:47","2014-10-23 11:05:47",1
"Sonatype Nexus","npm install cmd can trigger nexus NPE and 500 status when remote returns non-standard fields and stub attachments","Hi guys,    After solving problems with the environment (apparently HTTP Proxy), we are now with another behavior: the server returns a NullPointerException while I use npm install... For instance, npm client tried to install an app and here's the output collected in the Nexus logs.    Have you seen this before?    2014-10-22 17:51:57 WARN  [p933859241-1983] - org.sonatype.nexus.content.internal.ContentServlet - null [client=172.18.51.2,ua=npm/1.4.9 node/v0.10.32 linux x64,req=GET http://pprfirmas302.corp.intuit.net:8081/nexus/content/groups/npm-all/gulp-jshint]  java.lang.NullPointerException: null   at com.bolyuba.nexus.plugin.npm.service.internal.MetadataParser.parsePackageAttachment(MetadataParser.java:241) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.MetadataParser.parsePackageAttachments(MetadataParser.java:211) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.MetadataParser.parsePackageRoot(MetadataParser.java:155) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.MetadataParser.parsePackageRoot(MetadataParser.java:100) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.proxy.HttpProxyMetadataTransport.fetchPackageRoot(HttpProxyMetadataTransport.java:147) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.ProxyMetadataServiceImpl.mayUpdatePackageRoot(ProxyMetadataServiceImpl.java:203) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.ProxyMetadataServiceImpl.doGeneratePackageRoot(ProxyMetadataServiceImpl.java:189) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.GeneratorSupport.generatePackageRoot(GeneratorSupport.java:108) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.GroupMetadataServiceImpl.doGeneratePackageRoot(GroupMetadataServiceImpl.java:68) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.GeneratorSupport.generatePackageRoot(GeneratorSupport.java:108) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.GeneratorSupport.producePackageRoot(GeneratorSupport.java:77) ~[na:na]   at com.bolyuba.nexus.plugin.npm.group.DefaultNpmGroupRepository.doRetrieveLocalItem(DefaultNpmGroupRepository.java:136) ~[na:na]   at org.sonatype.nexus.proxy.repository.AbstractRepository.doRetrieveItem(AbstractRepository.java:1230) ~[nexus-core-2.10.0-02.jar:2.10.0-02]   at org.sonatype.nexus.proxy.repository.AbstractGroupRepository.doRetrieveItem(AbstractGroupRepository.java:237) ~[nexus-core-2.10.0-02.jar:2.10.0-02]   at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:758) ~[nexus-core-2.10.0-02.jar:2.10.0-02]   at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:590) ~[nexus-core-2.10.0-02.jar:2.10.0-02]   at org.sonatype.nexus.proxy.router.DefaultRepositoryRouter.retrieveItem(DefaultRepositoryRouter.java:155) ~[nexus-core-2.10.0-02.jar:2.10.0-02]   at org.sonatype.nexus.content.internal.ContentServlet.doGet(ContentServlet.java:387) [nexus-content-plugin-2.10.0-02/:na]   at org.sonatype.nexus.content.internal.ContentServlet.service(ContentServlet.java:353) [nexus-content-plugin-2.10.0-02/:na]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:288) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:278) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:93) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [guice-servlet-3.1.10.jar:3.1.10]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [shiro-web-1.2.2.jar:1.2.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [shiro-web-1.2.2.jar:1.2.2]   at org.sonatype.nexus.web.internal.SecurityFilter.executeChain(SecurityFilter.java:73) [nexus-core-2.10.0-02.jar:2.10.0-02]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [shiro-core-1.2.2.jar:1.2.2]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [shiro-core-1.2.2.jar:1.2.2]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [shiro-core-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.2.2.jar:1.2.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:135) [nexus-licensing-plugin-2.10.0-02/:na]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]   at com.yammer.metrics.web.WebappMetricsFilter.doFilter(WebappMetricsFilter.java:76) [metrics-web-2.2.0.jar:na]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.CommonHeadersFilter.doFilter(CommonHeadersFilter.java:69) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.ErrorPageFilter.doFilter(ErrorPageFilter.java:71) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.BaseUrlHolderFilter.doFilter(BaseUrlHolderFilter.java:70) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterPipeline.dispatch(NexusGuiceFilter.java:56) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:132) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:129) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:206) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:129) [guice-servlet-3.1.10.jar:3.1.10]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419) [jetty-servlet-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:455) [jetty-servlet-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557) [jetty-security-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1075) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:384) [jetty-servlet-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1009) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at com.yammer.metrics.jetty.InstrumentedHandler.handle(InstrumentedHandler.java:200) [metrics-jetty-2.2.0.jar:na]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:154) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.Server.handle(Server.java:370) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:489) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:949) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1011) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644) [jetty-http-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235) [jetty-http-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668) [jetty-io-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52) [jetty-io-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608) [jetty-util-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543) [jetty-util-8.1.11.v20130520.jar:8.1.11.v20130520]   at java.lang.Thread.run(Thread.java:745) [na:1.7.0_72]  2014-10-22 17:51:57 WARN  [p933859241-1982] - org.sonatype.nexus.content.internal.ContentServlet - null [client=172.18.51.2,ua=npm/1.4.9 node/v0.10.32 linux x64,req=GET http://pprfirmas302.corp.intuit.net:8081/nexus/content/groups/npm-all/gulp-shell]  java.lang.NullPointerException: null   at com.bolyuba.nexus.plugin.npm.service.internal.MetadataParser.parsePackageAttachment(MetadataParser.java:241) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.MetadataParser.parsePackageAttachments(MetadataParser.java:211) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.MetadataParser.parsePackageRoot(MetadataParser.java:155) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.MetadataParser.parsePackageRoot(MetadataParser.java:100) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.proxy.HttpProxyMetadataTransport.fetchPackageRoot(HttpProxyMetadataTransport.java:147) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.ProxyMetadataServiceImpl.mayUpdatePackageRoot(ProxyMetadataServiceImpl.java:203) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.ProxyMetadataServiceImpl.doGeneratePackageRoot(ProxyMetadataServiceImpl.java:189) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.GeneratorSupport.generatePackageRoot(GeneratorSupport.java:108) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.GroupMetadataServiceImpl.doGeneratePackageRoot(GroupMetadataServiceImpl.java:68) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.GeneratorSupport.generatePackageRoot(GeneratorSupport.java:108) ~[na:na]   at com.bolyuba.nexus.plugin.npm.service.internal.GeneratorSupport.producePackageRoot(GeneratorSupport.java:77) ~[na:na]   at com.bolyuba.nexus.plugin.npm.group.DefaultNpmGroupRepository.doRetrieveLocalItem(DefaultNpmGroupRepository.java:136) ~[na:na]   at org.sonatype.nexus.proxy.repository.AbstractRepository.doRetrieveItem(AbstractRepository.java:1230) ~[nexus-core-2.10.0-02.jar:2.10.0-02]   at org.sonatype.nexus.proxy.repository.AbstractGroupRepository.doRetrieveItem(AbstractGroupRepository.java:237) ~[nexus-core-2.10.0-02.jar:2.10.0-02]   at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:758) ~[nexus-core-2.10.0-02.jar:2.10.0-02]   at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:590) ~[nexus-core-2.10.0-02.jar:2.10.0-02]   at org.sonatype.nexus.proxy.router.DefaultRepositoryRouter.retrieveItem(DefaultRepositoryRouter.java:155) ~[nexus-core-2.10.0-02.jar:2.10.0-02]   at org.sonatype.nexus.content.internal.ContentServlet.doGet(ContentServlet.java:387) [nexus-content-plugin-2.10.0-02/:na]   at org.sonatype.nexus.content.internal.ContentServlet.service(ContentServlet.java:353) [nexus-content-plugin-2.10.0-02/:na]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:288) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:278) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:93) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) [guice-servlet-3.1.10.jar:3.1.10]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) [shiro-web-1.2.2.jar:1.2.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) [shiro-web-1.2.2.jar:1.2.2]   at org.sonatype.nexus.web.internal.SecurityFilter.executeChain(SecurityFilter.java:73) [nexus-core-2.10.0-02.jar:2.10.0-02]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [shiro-core-1.2.2.jar:1.2.2]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [shiro-core-1.2.2.jar:1.2.2]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) [shiro-core-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) [shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) [shiro-web-1.2.2.jar:1.2.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:135) [nexus-licensing-plugin-2.10.0-02/:na]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) [guice-servlet-3.1.10.jar:3.1.10]   at com.yammer.metrics.web.WebappMetricsFilter.doFilter(WebappMetricsFilter.java:76) [metrics-web-2.2.0.jar:na]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.CommonHeadersFilter.doFilter(CommonHeadersFilter.java:69) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.ErrorPageFilter.doFilter(ErrorPageFilter.java:71) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.BaseUrlHolderFilter.doFilter(BaseUrlHolderFilter.java:70) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) [nexus-core-2.10.0-02.jar:2.10.0-02]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterPipeline.dispatch(NexusGuiceFilter.java:56) [nexus-core-2.10.0-02.jar:2.10.0-02]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:132) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:129) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:206) [guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:129) [guice-servlet-3.1.10.jar:3.1.10]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419) [jetty-servlet-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:455) [jetty-servlet-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557) [jetty-security-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1075) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:384) [jetty-servlet-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1009) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at com.yammer.metrics.jetty.InstrumentedHandler.handle(InstrumentedHandler.java:200) [metrics-jetty-2.2.0.jar:na]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:154) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.Server.handle(Server.java:370) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:489) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:949) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1011) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644) [jetty-http-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235) [jetty-http-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82) [jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668) [jetty-io-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52) [jetty-io-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608) [jetty-util-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543) [jetty-util-8.1.11.v20130520.jar:8.1.11.v20130520]   at java.lang.Thread.run(Thread.java:745) [na:1.7.0_72]  ",Bug,Major,Closed,"2014-10-23 01:55:12","2014-10-23 00:55:12",1
"Sonatype Nexus","npm attribute storage corruption can lead to http 500 responses","Configure proxy to http://registry.npmjs.org  Configure proxy server in nexus.  Make these requests:     curl -s -v -4 http://localhost:8081/nexus/content/repositories/npmjs/bower/-/bower-1.3.12.tgz    gets 404    curl -s -v -4 http://localhost:8081/nexus/content/repositories/npmjs/bower    gets 200 but nexus sends TWO requests to remote - see NEXUS-7616    ( this creates a file at nexus/storage/npmjs/.nexus/attributes/bower )    {noformat:title=bower contents}  > cat bower   {storageItem-created:1414012676202,storageItem-checkedRemotely:9223372036854775807,storageItem-generation:2,proxyRepository-invalidationToken:1414012362178478000,storageItem-lastRequested:1414012676203,storageItem-modified:1414012676202,storageItem-readable:true,storageItem-expired:true,storageItem-repositoryId:npmjs,storageItem-writable:true,storageItem-path:/bower}  {noformat}    Then request:    curl -s -v -4 http://localhost:8081/nexus/content/repositories/npmjs/bower/-/bower-1.3.12.tgz    Nexus returns 500 response.    {quote}  jvm 1    | 2014-10-22 18:08:44,370-0300 INFO  [qtp991699868-92] admin org.sonatype.nexus.configuration.application.DefaultNexusConfiguration - Applying Nexus Configuration due to changes in [npmjs] made by admin...  jvm 1    | 2014-10-22 18:08:44,390-0300 INFO  [esh-1-thread-7] admin org.sonatype.nexus.events.RepositoryConfigurationUpdatedEventInspector - The Remote URL of repository npmjs (id=npmjs) has been changed, expiring its caches.  jvm 1    | 2014-10-22 18:08:44,897-0300 INFO  [pxpool-1-thread-1] admin org.sonatype.nexus.tasks.ExpireCacheTask - Scheduled task (ExpireCacheTask) started :: Expiring caches for repository npmjs from path null and below.  jvm 1    | 2014-10-22 18:08:44,922-0300 INFO  [pxpool-1-thread-1] admin org.sonatype.nexus.tasks.ExpireCacheTask - Scheduled task (ExpireCacheTask) finished :: Expiring caches for repository npmjs from path null and below. (started 2014-10-22T18:08:44-03:00, runtime 0:00:00.023)  jvm 1    | 2014-10-22 18:08:44,930-0300 INFO  [pxpool-1-thread-1] admin org.sonatype.nexus.configuration.application.DefaultNexusConfiguration - Applying Nexus Configuration due to changes in [Scheduled Tasks] made by *TASK...  jvm 1    | 2014-10-22 18:09:29,872-0300 INFO  [qtp991699868-89] admin org.sonatype.nexus.configuration.ModelUtils - Loading model /Users/<USER>Documents/qe-support/zen-6621/nexus-professional-2.10.0-02-bundle/sonatype-work/nexus/conf/pgp.xml  jvm 1    | 2014-10-22 18:12:41,661-0300 INFO  [qtp991699868-88] admin org.sonatype.nexus.configuration.application.DefaultNexusConfiguration - Applying Nexus Configuration due to changes in [npmjs] made by admin...  jvm 1    | 2014-10-22 18:12:41,667-0300 INFO  [esh-1-thread-10] admin org.sonatype.nexus.events.RepositoryConfigurationUpdatedEventInspector - The Remote URL of repository npmjs (id=npmjs) has been changed, expiring its caches.  jvm 1    | 2014-10-22 18:12:42,171-0300 INFO  [pxpool-1-thread-1] admin org.sonatype.nexus.tasks.ExpireCacheTask - Scheduled task (ExpireCacheTask) started :: Expiring caches for repository npmjs from path null and below.  jvm 1    | 2014-10-22 18:12:42,180-0300 INFO  [pxpool-1-thread-1] admin org.sonatype.nexus.tasks.ExpireCacheTask - Scheduled task (ExpireCacheTask) finished :: Expiring caches for repository npmjs from path null and below. (started 2014-10-22T18:12:42-03:00, runtime 0:00:00.009)  jvm 1    | 2014-10-22 18:12:42,246-0300 INFO  [pxpool-1-thread-1] admin org.sonatype.nexus.configuration.application.DefaultNexusConfiguration - Applying Nexus Configuration due to changes in [Scheduled Tasks] made by *TASK...  jvm 1    | 2014-10-22 18:12:54,305-0300 INFO  [qtp991699868-88] admin org.sonatype.nexus.configuration.application.DefaultNexusConfiguration - Applying Nexus Configuration due to changes in [SMTP Client, Notification Manager, Global Remote Connection Settings, Global Rest Api Settings, Global HTTP Proxy] made by admin...  jvm 1    | 2014-10-22 18:12:54,412-0300 INFO  [qtp991699868-92] admin org.sonatype.nexus.configuration.ModelUtils - Saving model /Users/<USER>Documents/qe-support/zen-6621/nexus-professional-2.10.0-02-bundle/sonatype-work/nexus/conf/pgp.xml  jvm 1    | 2014-10-22 18:12:54,431-0300 INFO  [qtp991699868-89] admin org.sonatype.nexus.configuration.ModelUtils - Saving model /Users/<USER>Documents/qe-support/zen-6621/nexus-professional-2.10.0-02-bundle/sonatype-work/nexus/conf/lvo-plugin.xml  jvm 1    | 2014-10-22 18:17:55,776-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: ignoreCookies  jvm 1    | 2014-10-22 18:17:55,777-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.client.protocol.RequestAuthCache - Auth cache not set in the context  jvm 1    | 2014-10-22 18:17:55,778-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.impl.execchain.MainClientExec - Opening connection {}->http://localhost:8888->http://registry.npmjs.org:80  jvm 1    | 2014-10-22 18:17:55,779-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.impl.conn.HttpClientConnectionOperator - Connecting to localhost/127.0.0.1:8888  jvm 1    | 2014-10-22 18:17:55,780-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.impl.conn.HttpClientConnectionOperator - Connection established 127.0.0.1:51843<->127.0.0.1:8888  jvm 1    | 2014-10-22 18:17:55,780-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.impl.execchain.MainClientExec - Executing request GET http://registry.npmjs.org/bower HTTP/1.1  jvm 1    | 2014-10-22 18:17:55,780-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.impl.execchain.MainClientExec - Target auth state: UNCHALLENGED  jvm 1    | 2014-10-22 18:17:55,780-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.impl.execchain.MainClientExec - Proxy auth state: UNCHALLENGED  jvm 1    | 2014-10-22 18:17:55,781-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> GET http://registry.npmjs.org/bower HTTP/1.1  jvm 1    | 2014-10-22 18:17:55,781-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> accept: application/json  jvm 1    | 2014-10-22 18:17:55,781-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> Host: registry.npmjs.org  jvm 1    | 2014-10-22 18:17:55,781-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> Proxy-Connection: Keep-Alive  jvm 1    | 2014-10-22 18:17:55,781-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> User-Agent: Nexus/2.10.0-02 (PRO; Mac OS X; 10.10; x86_64; 1.7.0_71) apacheHttpClient4x/2.10.0-02  jvm 1    | 2014-10-22 18:17:55,781-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> Accept-Encoding: gzip,deflate  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << HTTP/1.1 200 OK  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Server: CouchDB/1.5.0 (Erlang OTP/R16B03)  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Etag: 5IH3YVKIZ3VMGKRZP2FHQWVQM  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Content-Type: application/json  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Cache-Control: max-age=60  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Content-Length: 105338  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Accept-Ranges: bytes  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Date: Wed, 22 Oct 2014 21:17:55 GMT  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Via: 1.1 varnish  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Age: 18  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << X-Served-By: cache-jfk1025-JFK  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << X-Cache: HIT  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << X-Cache-Hits: 1  jvm 1    | 2014-10-22 18:17:55,909-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << X-Timer: S1414012675.831864,VS0,VE0  jvm 1    | 2014-10-22 18:17:55,910-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Vary: Accept  jvm 1    | 2014-10-22 18:17:55,910-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Proxy-Connection: Keep-alive  jvm 1    | 2014-10-22 18:17:55,910-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.impl.execchain.MainClientExec - Connection can be kept alive for 30000 MILLISECONDS  jvm 1    | 2014-10-22 18:17:56,130-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: ignoreCookies  jvm 1    | 2014-10-22 18:17:56,130-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.client.protocol.RequestAuthCache - Auth cache not set in the context  jvm 1    | 2014-10-22 18:17:56,130-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.impl.execchain.MainClientExec - Executing request GET http://registry.npmjs.org/bower HTTP/1.1  jvm 1    | 2014-10-22 18:17:56,130-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.impl.execchain.MainClientExec - Target auth state: UNCHALLENGED  jvm 1    | 2014-10-22 18:17:56,130-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.impl.execchain.MainClientExec - Proxy auth state: UNCHALLENGED  jvm 1    | 2014-10-22 18:17:56,131-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> GET http://registry.npmjs.org/bower HTTP/1.1  jvm 1    | 2014-10-22 18:17:56,131-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> accept: application/json  jvm 1    | 2014-10-22 18:17:56,131-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> if-none-match: 5IH3YVKIZ3VMGKRZP2FHQWVQM  jvm 1    | 2014-10-22 18:17:56,131-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> Host: registry.npmjs.org  jvm 1    | 2014-10-22 18:17:56,131-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> Proxy-Connection: Keep-Alive  jvm 1    | 2014-10-22 18:17:56,131-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> User-Agent: Nexus/2.10.0-02 (PRO; Mac OS X; 10.10; x86_64; 1.7.0_71) apacheHttpClient4x/2.10.0-02  jvm 1    | 2014-10-22 18:17:56,131-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 >> Accept-Encoding: gzip,deflate  jvm 1    | 2014-10-22 18:17:56,161-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << HTTP/1.1 304 Not Modified  jvm 1    | 2014-10-22 18:17:56,161-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Date: Wed, 22 Oct 2014 21:17:56 GMT  jvm 1    | 2014-10-22 18:17:56,161-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Via: 1.1 varnish  jvm 1    | 2014-10-22 18:17:56,161-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Last-Modified: Wed, 22 Oct 2014 21:17:55 GMT  jvm 1    | 2014-10-22 18:17:56,161-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Cache-Control: max-age=60  jvm 1    | 2014-10-22 18:17:56,161-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << ETag: 5IH3YVKIZ3VMGKRZP2FHQWVQM  jvm 1    | 2014-10-22 18:17:56,162-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Age: 18  jvm 1    | 2014-10-22 18:17:56,162-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << X-Served-By: cache-jfk1025-JFK  jvm 1    | 2014-10-22 18:17:56,162-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << X-Cache: HIT  jvm 1    | 2014-10-22 18:17:56,162-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << X-Cache-Hits: 2  jvm 1    | 2014-10-22 18:17:56,162-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << X-Timer: S1414012676.085727,VS0,VE0  jvm 1    | 2014-10-22 18:17:56,162-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Vary: Accept  jvm 1    | 2014-10-22 18:17:56,162-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.headers - http-outgoing-12 << Proxy-Connection: Keep-alive  jvm 1    | 2014-10-22 18:17:56,162-0300 DEBUG [qtp991699868-91] anonymous org.apache.http.impl.execchain.MainClientExec - Connection can be kept alive for 30000 MILLISECONDS  jvm 1    | 2014-10-22 18:18:27,769-0300 DEBUG [HC4x-EvictingThread] *SYSTEM org.apache.http.impl.conn.CPool - Connection [id:12][route:{}->http://localhost:8888->http://registry.npmjs.org:80][state:null] expired @ Wed Oct 22 18:18:26 ADT 2014  jvm 1    | 2014-10-22 18:18:27,769-0300 DEBUG [HC4x-EvictingThread] *SYSTEM org.apache.http.impl.conn.DefaultManagedHttpClientConnection - http-outgoing-12: Close connection                jvm 1    | 2014-10-22 18:23:33,581-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: ignoreCookies  jvm 1    | 2014-10-22 18:23:33,581-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.client.protocol.RequestAuthCache - Auth cache not set in the context  jvm 1    | 2014-10-22 18:23:33,581-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.impl.execchain.MainClientExec - Opening connection {}->http://localhost:8888->http://registry.npmjs.org:80  jvm 1    | 2014-10-22 18:23:33,582-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.impl.conn.HttpClientConnectionOperator - Connecting to localhost/127.0.0.1:8888  jvm 1    | 2014-10-22 18:23:33,582-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.impl.conn.HttpClientConnectionOperator - Connection established 127.0.0.1:51884<->127.0.0.1:8888  jvm 1    | 2014-10-22 18:23:33,582-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.impl.execchain.MainClientExec - Executing request GET http://registry.npmjs.org/bower/-/bower-1.3.12.tgz HTTP/1.1  jvm 1    | 2014-10-22 18:23:33,582-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.impl.execchain.MainClientExec - Target auth state: UNCHALLENGED  jvm 1    | 2014-10-22 18:23:33,583-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.impl.execchain.MainClientExec - Proxy auth state: UNCHALLENGED  jvm 1    | 2014-10-22 18:23:33,583-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 >> GET http://registry.npmjs.org/bower/-/bower-1.3.12.tgz HTTP/1.1  jvm 1    | 2014-10-22 18:23:33,583-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 >> Accept: application/x-gzip  jvm 1    | 2014-10-22 18:23:33,583-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 >> Host: registry.npmjs.org  jvm 1    | 2014-10-22 18:23:33,583-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 >> Proxy-Connection: Keep-Alive  jvm 1    | 2014-10-22 18:23:33,583-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 >> User-Agent: Nexus/2.10.0-02 (PRO; Mac OS X; 10.10; x86_64; 1.7.0_71)  jvm 1    | 2014-10-22 18:23:33,583-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 >> Accept-Encoding: gzip,deflate  jvm 1    | 2014-10-22 18:23:33,725-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << HTTP/1.1 200 OK  jvm 1    | 2014-10-22 18:23:33,725-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Server: nginx/1.4.6 (Ubuntu)  jvm 1    | 2014-10-22 18:23:33,725-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Content-Type: application/octet-stream  jvm 1    | 2014-10-22 18:23:33,725-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Last-Modified: Sun, 28 Sep 2014 16:41:33 GMT  jvm 1    | 2014-10-22 18:23:33,725-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << ETag: 54283a3d-1ca45  jvm 1    | 2014-10-22 18:23:33,725-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Expires: Thu, 23 Oct 2014 00:11:37 GMT  jvm 1    | 2014-10-22 18:23:33,725-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Access-Control-Allow-Origin: *  jvm 1    | 2014-10-22 18:23:33,725-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Access-Control-Allow-Methods: GET  jvm 1    | 2014-10-22 18:23:33,725-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Cache-Control: max-age=21600  jvm 1    | 2014-10-22 18:23:33,725-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Content-Length: 117317  jvm 1    | 2014-10-22 18:23:33,726-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Accept-Ranges: bytes  jvm 1    | 2014-10-22 18:23:33,726-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Date: Wed, 22 Oct 2014 21:23:33 GMT  jvm 1    | 2014-10-22 18:23:33,726-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Via: 1.1 varnish  jvm 1    | 2014-10-22 18:23:33,726-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Age: 11665  jvm 1    | 2014-10-22 18:23:33,726-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << X-Served-By: cache-atl6227-ATL  jvm 1    | 2014-10-22 18:23:33,726-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << X-Cache: HIT  jvm 1    | 2014-10-22 18:23:33,726-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << X-Cache-Hits: 1  jvm 1    | 2014-10-22 18:23:33,726-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << X-Timer: S1414013013.621243,VS0,VE17  jvm 1    | 2014-10-22 18:23:33,726-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.headers - http-outgoing-13 << Proxy-Connection: Keep-alive  jvm 1    | 2014-10-22 18:23:33,726-0300 DEBUG [qtp991699868-89] anonymous org.apache.http.impl.execchain.MainClientExec - Connection can be kept alive for 30000 MILLISECONDS  jvm 1    | 2014-10-22 18:23:33,912-0300 INFO  [qtp991699868-89] anonymous org.sonatype.nexus.proxy.storage.remote.httpclient.HttpClientRemoteStorage - Updating remote transport for proxy repository npmjs [id=npmjs]...  jvm 1    | 2014-10-22 18:23:33,913-0300 WARN  [qtp991699868-89] anonymous com.bolyuba.nexus.plugin.npm.proxy.DefaultNpmProxyRepository - Remote peer of proxy repository npmjs [id=npmjs] threw a org.sonatype.nexus.proxy.RemoteStorageException exception. Connection/transport problems occured while connecting to remote peer of the repository. Auto-blocking this repository to prevent further connection-leaks and known-to-fail outbound connections until administrator fixes the problems, or Nexus detects remote repository as healthy. - Cause(s): NPM service error > Cannot store attributes! > Could not create the directory hierarchy in repository npmjs [id=npmjs] to write /Users/<USER>Documents/qe-support/zen-6621/nexus-professional-2.10.0-02-bundle/sonatype-work/nexus/storage/npmjs/.nexus/attributes/bower/- > /Users/<USER>Documents/qe-support/zen-6621/nexus-professional-2.10.0-02-bundle/sonatype-work/nexus/storage/npmjs/.nexus/attributes/bower/-: Not a directory  jvm 1    | 2014-10-22 18:23:33,914-0300 INFO  [RepositoryStatusChecker-npmjs] admin com.bolyuba.nexus.plugin.npm.proxy.DefaultNpmProxyRepository-npmjs - Next attempt to auto-unblock the npmjs (id=npmjs) repository by checking its remote peer health will occur in 40 seconds.  jvm 1    | 2014-10-22 18:23:33,921-0300 WARN  [qtp991699868-89] anonymous org.sonatype.nexus.content.internal.ContentServlet - org.sonatype.nexus.proxy.LocalStorageException: Exception during reading up an item from FS storage!, caused by: org.sonatype.nexus.proxy.LocalStorageException: Could not create the directory hierarchy in repository npmjs [id=npmjs] to write /Users/<USER>Documents/qe-support/zen-6621/nexus-professional-2.10.0-02-bundle/sonatype-work/nexus/storage/npmjs/.nexus/attributes/bower/-, caused by: java.nio.file.FileSystemException: /Users/<USER>Documents/qe-support/zen-6621/nexus-professional-2.10.0-02-bundle/sonatype-work/nexus/storage/npmjs/.nexus/attributes/bower/-: Not a directory [client=127.0.0.1,ua=curl/7.37.0,req=GET http://localhost:8081/nexus/content/repositories/npmjs/bower/-/bower-1.3.12.tgz]  jvm 1    | 2014-10-22 18:24:08,002-0300 DEBUG [HC4x-EvictingThread] *SYSTEM org.apache.http.impl.conn.CPool - Connection [id:13][route:{}->http://localhost:8888->http://registry.npmjs.org:80][state:null] expired @ Wed Oct 22 18:24:03 ADT 2014  jvm 1    | 2014-10-22 18:24:08,003-0300 DEBUG [HC4x-EvictingThread] *SYSTEM org.apache.http.impl.conn.DefaultManagedHttpClientConnection - http-outgoing-13: Close connection  jvm 1    | 2014-10-22 18:24:13,918-0300 INFO  [RepositoryStatusChecker-npmjs] admin com.bolyuba.nexus.plugin.npm.proxy.DefaultNpmProxyRepository-npmjs - Next attempt to auto-unblock the npmjs (id=npmjs) repository by checking its remote peer health will occur in 1 minute 20 seconds.  jvm 1    | 2014-10-22 18:24:13,919-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: ignoreCookies  jvm 1    | 2014-10-22 18:24:13,919-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.client.protocol.RequestAuthCache - Auth cache not set in the context  jvm 1    | 2014-10-22 18:24:13,920-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.impl.execchain.MainClientExec - Opening connection {}->http://localhost:8888->http://registry.npmjs.org:80  jvm 1    | 2014-10-22 18:24:13,921-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.impl.conn.HttpClientConnectionOperator - Connecting to localhost/127.0.0.1:8888  jvm 1    | 2014-10-22 18:24:13,921-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.impl.conn.HttpClientConnectionOperator - Connection established 127.0.0.1:51896<->127.0.0.1:8888  jvm 1    | 2014-10-22 18:24:13,921-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.impl.execchain.MainClientExec - Executing request HEAD http://registry.npmjs.org/ HTTP/1.1  jvm 1    | 2014-10-22 18:24:13,921-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.impl.execchain.MainClientExec - Target auth state: UNCHALLENGED  jvm 1    | 2014-10-22 18:24:13,921-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.impl.execchain.MainClientExec - Proxy auth state: UNCHALLENGED  jvm 1    | 2014-10-22 18:24:13,922-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 >> HEAD http://registry.npmjs.org/ HTTP/1.1  jvm 1    | 2014-10-22 18:24:13,922-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 >> Accept: */*  jvm 1    | 2014-10-22 18:24:13,922-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 >> Accept-Language: en-us  jvm 1    | 2014-10-22 18:24:13,922-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 >> Accept-Encoding: gzip,deflate,identity  jvm 1    | 2014-10-22 18:24:13,922-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 >> Cache-Control: no-cache  jvm 1    | 2014-10-22 18:24:13,922-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 >> Host: registry.npmjs.org  jvm 1    | 2014-10-22 18:24:13,922-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 >> Proxy-Connection: Keep-Alive  jvm 1    | 2014-10-22 18:24:13,922-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 >> User-Agent: Nexus/2.10.0-02 (PRO; Mac OS X; 10.10; x86_64; 1.7.0_71) apacheHttpClient4x/2.10.0-02  jvm 1    | 2014-10-22 18:24:14,363-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << HTTP/1.1 200 OK  jvm 1    | 2014-10-22 18:24:14,363-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << Server: CouchDB/1.5.0 (Erlang OTP/R16B03)  jvm 1    | 2014-10-22 18:24:14,363-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << Content-Type: text/plain; charset=utf-8  jvm 1    | 2014-10-22 18:24:14,363-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << Cache-Control: max-age=60  jvm 1    | 2014-10-22 18:24:14,363-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << Content-Length: 259  jvm 1    | 2014-10-22 18:24:14,363-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << Accept-Ranges: bytes  jvm 1    | 2014-10-22 18:24:14,363-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << Date: Wed, 22 Oct 2014 21:24:14 GMT  jvm 1    | 2014-10-22 18:24:14,363-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << Via: 1.1 varnish  jvm 1    | 2014-10-22 18:24:14,363-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << Age: 0  jvm 1    | 2014-10-22 18:24:14,363-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << X-Served-By: cache-jfk1024-JFK  jvm 1    | 2014-10-22 18:24:14,364-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << X-Cache: MISS  jvm 1    | 2014-10-22 18:24:14,364-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << X-Cache-Hits: 0  jvm 1    | 2014-10-22 18:24:14,364-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << X-Timer: S1414013053.934079,VS0,VE349  jvm 1    | 2014-10-22 18:24:14,364-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.headers - http-outgoing-14 << Proxy-Connection: Keep-alive  jvm 1    | 2014-10-22 18:24:14,364-0300 DEBUG [proxy-3-thread-8] admin org.apache.http.impl.execchain.MainClientExec - Connection can be kept alive for 30000 MILLISECONDS  jvm 1    | 2014-10-22 18:24:14,365-0300 WARN  [proxy-3-thread-8] admin com.bolyuba.nexus.plugin.npm.proxy.DefaultNpmProxyRepository - Remote peer of proxy repository npmjs [id=npmjs] detected as healthy, un-blocking the proxy repository (it was AutoBlocked by Nexus).  jvm 1    | 2014-10-22 18:24:48,036-0300 DEBUG [HC4x-EvictingThread] *SYSTEM org.apache.http.impl.conn.CPool - Connection [id:14][route:{}->http://localhost:8888->http://registry.npmjs.org:80][state:null] expired @ Wed Oct 22 18:24:44 ADT 2014  jvm 1    | 2014-10-22 18:24:48,037-0300 DEBUG [HC4x-EvictingThread] *SYSTEM org.apache.http.impl.conn.DefaultManagedHttpClientConnection - http-outgoing-14: Close connection    {quote}      ",Bug,Critical,Closed,"2014-10-22 22:30:06","2014-10-22 21:30:06",1
"Sonatype Nexus","file content validation fails for application/x-msdownload jar files","Create a Maven 2 release proxy repo to https://maven.atlassian.com/content/groups/public/  Set file content validation to true.    Request http://localhost:8081/nexus/content/repositories/atlassian/com/atlassian/support/healthcheck/support-healthcheck-plugin/1.0.3/support-healthcheck-plugin-1.0.3.jar    This returns 404. The reason is content validation fails.        Turns out this jar is correctly parsed by Apache Tika ( MIME lib Nexus uses ) as application/x-msdownload.    https://github.com/apache/tika/blob/trunk/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml#L3039    Nexus thinks this should be application/java-archive    Expected:  - Nexus should treat this jar as the proper expected type and not fail content validation.    Perhaps similar fix as we did in NEXUS-6271 for empty zip    ",Bug,Major,Closed,"2014-10-22 13:46:32","2014-10-22 12:46:32",2
"Sonatype Nexus","programatically enforce minimum requirements for yum configuration including debug messages","Currently it is possible to enable YUM support (and in fact it is enabled by default in pro) even if no createrepo command is found.    This can lead you down the track of configuring stuff for yum support and filling up the logs with exceptions that no createrepo command was found.    It would be better to simply disable the capability if no command is found and not allow enabling it either, and instead presenting a useful error message in the UI that says you need to have createrepo and mergerepo on the path (and probably therefore run on Linux..)    It should probably look for the mergerepo command as well. ",Improvement,Major,Closed,"2014-10-18 00:52:54","2014-10-17 23:52:54",1
"Sonatype Nexus","disable insecure SSL protocols by default in jetty HTTPS sample configuration","As a best practice and in response to poodle.io, Nexus jetty-https.xml config files should disableinsecure protocols by default going forward.    This effectively means disabling SSLv* protocols at present.    Jetty 9.3 proper is doing this going forward.    https://bugs.eclipse.org/bugs/show_bug.cgi?id=447381            ",Improvement,Major,Closed,"2014-10-17 20:35:42","2014-10-17 19:35:42",0.5
"Sonatype Nexus","allow configuring https.protocols and https.cipherSuites on Nexus outbound HTTP client connections","In NEXUS-5526, a change was made to allow javax.net.* system properties to be set on the HTTP Client embedded within Nexus.    https://github.com/sonatype/nexus-oss/commit/a7eb959b98b769cdfef190348f61e94b385ed32a#diff-35540aaccce768f70470408e7d8a0470    We have since regressed back to not allowing this:    https://github.com/sonatype/nexus-oss/commit/6c6507c8daf1cf6110d5f1d63c4d28a25b62c563#diff-35540aaccce768f70470408e7d8a0470    And the attempt to backout changes did not restore use of the System connection factory method:    https://github.com/sonatype/nexus-oss/commit/0ab135701ad42b169d8283fb8bddb110a3bd3bf7#diff-35540aaccce768f70470408e7d8a0470    In Nexus 2.8.0-05 we started including httpclient 4.3.x into Nexus. [httpclient 4.3.x system SSLSocketFactory started honouring https.protocols and https.ciphersuites|https://issues.apache.org/jira/browse/HTTPCLIENT-1343] - however in 2.8 our regression prevents setting protocols and ciphers on outbound connections from being an option for end users.    So two problems:  - it seems [we have regressed|https://github.com/sonatype/nexus-oss/commit/0ab135701ad42b169d8283fb8bddb110a3bd3bf7#diff-35540aaccce768f70470408e7d8a0470] honouring system properties that influence the outbound http connections  - we don't expose a way to set https protocols and ciphers preferences on Nexus outbound connections ( https.protocols / https.ciphersuites )    Expected  - make Nexus use the system socket factories provided by http client, so that standard javax.net system properties can influence outbound connections    http://hc.apache.org/httpcomponents-client-4.3.x/httpclient/xref/org/apache/http/conn/ssl/SSLConnectionSocketFactory.html#162   ",Improvement,Major,Closed,"2014-10-17 16:53:58","2014-10-17 15:53:58",2
"Sonatype Nexus","CMA component administration UI","Need UI for administration of various CMA components like:    * sources  * views  * blobstores",Story,Major,Done,"2014-10-16 18:17:10","2014-10-16 17:17:10",8
"Sonatype Nexus","Component Source Availability/Lifecycle","Elaborate on the concept of source availability. In both config and instantiated sources, handle state tracking for:    * auto-blocking on communication errors with escalating retry times  * manual blocking  * correct view behavior when sources are removed entirely",Story,Major,Done,"2014-10-14 18:27:20","2014-10-14 17:27:20",2
"Sonatype Nexus","No DEBUG log from staging plugin","When executing maven build using {{-X}} parameter that includes nexus-staging-maven-plugin, there is no DEBUG output (coming from relevant components, not from the Mojo itself)., while the components does log important things at DEBUG level.     This makes nearly impossible (or just overly <USER> to properly diagnose what happens during staging...",Bug,Major,Closed,"2014-10-14 12:25:58","2014-10-14 11:25:58",1
"Sonatype Nexus","Update apache shiro to 1.2.3","master is already updated ( https://github.com/sonatype/nexus-oss/commit/98b532220a852d52331fc4318f5ae9585c160093 ), should bump this up on 2.10 and 2.11 branches to avoid CLM complaining (though its complaining about non-issues)",Improvement,Major,Closed,"2014-10-12 21:45:13","2014-10-12 20:45:13",0.5
"Sonatype Nexus","Component View/Source Name-Generation","Create the simple name-generating methods for ComponentOriginId types, so that (eventually) the UI can request ViewIDs and ComponentSourceIDs for new views/sources as users define them.",Improvement,Major,Closed,"2014-10-10 22:15:07","2014-10-10 21:15:07",1
"Sonatype Nexus","Configurable HTTP pools for Component Sources","Component sources need configurable HTTP connection parameters, including:    thread/connection pool sizes  authentication credentials  redirection-following policy  schema downgrade policy    Expose a standard way of configuring HTTP connection parameters for connection sources (presumably written into ComponentSourceConfig's Map), and a framework for instantiating those pools and serving connections to HTTP-based component sources.    Consider SSLSocketFactory functionality described in NEXUS-7594",Story,Major,Done,"2014-10-10 22:10:37","2014-10-10 21:10:37",3
"Sonatype Nexus","Show Browse Storage, Browse Remote, Mirrors, <dependencyManagement/> in Summary tab based on repository type","h3. Browse Remote     Browse Remote parses remote HTML directory lists. Unless the remote publishes a parseable HTML directory listing, Browse Remote cannot work.    Browse Remote should only be visible for Maven 1, Maven 2, P2, OBR repository types. ( although as stated, if remote is not publishing something parseable, still may not work )    h3. Browse Storage  Show Browse Storage only for 'maven1', 'maven2', 'nugett', 'obr', 'p2', 'site'    In the case of P2 proxy repo, the UI may timeout requesting the local storage contents, as the local storage triggers generating of a large content.xml which can take greater than the 60 second default UI timeout to render.    h3. Mirror    Show for hosted repos only for maven1 and maven2.    h3. Summary Tab <distributionManagement>    maven1, maven2, site      ",Bug,Major,Closed,"2014-10-08 14:11:54","2014-10-08 13:11:54",1
"Sonatype Nexus","configuring staging profile to release to npm hosted repo should not be allowed","Create an npm hosted repo.  Create a staging profile. You can select the npm hosted repo as the Release Repository.  Stage an artifact. Try to release the staging repo. Release fails with 500 error.        Expected:    - do not allow npm hosted repos to be a release repository for a staging profile",Bug,Major,Closed,"2014-10-07 18:51:34","2014-10-07 17:51:34",1
"Sonatype Nexus","Officially support Java 8 as runtime for Nexus","We are currently unofficially supporting Java 8 - we would like to officially support it. The only way to do that is run all Nexus tests using CI Java 8 on release branches.    This task is about setting this up permanently.    In addition any further work required to officially support Java 8 should be done.",Story,Major,Done,"2014-06-26 20:03:54","2014-06-26 19:03:54",1
"Sonatype Nexus","Deleting nuget repo leaves scheduled tasks behind","1. Create a NuGet proxy repo  2. Notice the scheduled task is automatically created  3. Restart Nexus  4. Delete the proxy repo  5. Notice the scheduled task is still there (it's deleted if you skip step 3.)    Separately:    1. Create a Nuget proxy repo  2. Create several scheduled tasks to download its feed  3. Delete the proxy repo  4. Notice that at most one scheduled task was deleted; the others linger",Bug,Major,Closed,"2014-07-09 14:55:04","2014-07-09 13:55:04",1
"Sonatype Nexus","Nexus OSS support bundle does not include ldap.xml file","A support zip generated from Nexus OSS does not include the ldap.xml file.",Bug,Major,Closed,"2014-09-30 19:19:20","2014-09-30 18:19:20",1
"Sonatype Nexus","The yum versions REST resource is only updated at startup","As documented [here|https://github.com/sonatype/nexus-oss/tree/master/plugins/yum/nexus-yum-repository-plugin] the yum plugin supports versioned views of repositories, as in:    http://your.nexus/nexus/service/local/yum/repos/releases/1.2.3/    Unfortunately, the internal cache of version numbers is only populated at at startup time, it is not updated when new artifacts are deployed.  This makes the feature non-functional for most use cases.  ",Bug,Minor,Closed,"2014-09-30 17:24:35","2014-09-30 16:24:35",1
"Sonatype Nexus","npm hosted repository should maintain time field on deploys","NPM hosted repository should maintain time field on deploys. Basically this algorithm (from npm couchdb server) needs to be ported to hosted repositories:    https://github.com/npm/npm-registry-couchapp/blob/master/registry/updates.js#L79    Due to lack of this, the only known downside (or bug if you like) is that commands listing package metadata (like {{npm search}} is) will mark the package as prehistoric. Example {{npm search}} output (packages deployed by user deployment user are locally published ones):    ",Bug,Minor,Closed,"2014-09-30 10:47:01","2014-09-30 09:47:01",1
"Sonatype Nexus","NPM metadata requested over HTTPS tells me to get the tarball over HTTP","If I am a savvy user and am using registry.npmjs.org over HTTPS, and issue a metadata request like this one:  https://registry.npmjs.org/commonjs    It will tell me to get the tarball over HTTP. What is the point of HTTPS then?    As I checked, both HTTP and HTTPS URLs works for tarball.    NPM registry issue  https://github.com/npm/npm-www/issues/915    was told to close it, then we filed  https://github.com/npm/newww/issues/390    was told to close it, then we filed...  https://github.com/npm/npm-registry-couchapp/issues/218    ...hopefully to get some traction.",Bug,Major,Open,"2014-09-25 20:47:56","2014-09-25 19:47:56",2
"Sonatype Nexus","If all user tokens are cleared this should be logged at INFO","Currently, we only log at DEBUG if all user tokens are cleared. This should be logged at INFO:    {quote}  2014-09-24 17:12:29 DEBUG [qtp680480074-130] admin com.sonatype.nexus.usertoken.plugin.internal.UserTokenServiceImpl - Removing all records  {quote}",Bug,Minor,Closed,"2014-09-24 23:17:49","2014-09-24 22:17:49",0.5
"Sonatype Nexus","Support indirection URLs","As per registry spec, version descriptor objects are not mandatory, and a URL where to find them is allowed too (see registry root description or Package Root Object's version field).    NX should aggregate these into one document (either before storing or on serving, it depends). Currently, this feature is not used by registry.npmjs.org, but it might be used in future (or dropped, as the spec is much more a draft really).    Links:  http://wiki.commonjs.org/wiki/Packages/Registry#registry_root_url  http://wiki.commonjs.org/wiki/Packages/Registry#Package_Root_Object    https://github.com/<USER>nexus-npm-repository-plugin/issues/13",Improvement,Major,Closed,"2014-08-07 21:31:36","2014-08-07 20:31:36",8
"Sonatype Nexus","comma in group membership attribute value breaks static LDAP group mapping","If you have an LDAP group mapping where the user's CN has a comma in it then static group mapping in Nexus will not work.    So if your user's common names are entered as Lastname,Firstname and distinguished names are used in the group membership attribute you end up with a query like this one being issued by Nexus:        This doesn't work because the backslash needs to be escaped:          The following code change seems to resolve this issue:        ",Bug,Minor,Closed,"2014-09-22 20:53:53","2014-09-22 19:53:53",1
"Sonatype Nexus","Add link to participate/mailing-list/whatever to help menu","Folks seem to not be able to find http://www.sonatype.org/nexus/participate lets put this into the Help menu for NX 3.",Improvement,Trivial,Closed,"2014-09-19 18:44:13","2014-09-19 17:44:13",0.5
"Sonatype Nexus","trial bundle uses wrong default temp dir","nexus.vmoptions contains        This should include setting the java tmp dir    Noticed this in one customer's trial bundle log:        That is a very bad temporary directory location...if two nexuses are running on the same host especially.    https://issues.sonatype.org/browse/NEXUS-6352        ",Bug,Major,Closed,"2014-09-19 18:29:44","2014-09-19 17:29:44",1
"Sonatype Nexus","trial bundle config includes procurement.xml","procurement features are no longer trialed in the trial eval guide    https://github.com/sonatype/nexus-bundles/blob/nexus-2.9.x/assemblies/nexus-trial/src/main/content/trial-config/conf/procurement.xml    Including procurement.xml causes scary WARN logging on startup:      ",Bug,Major,Closed,"2014-09-19 18:07:10","2014-09-19 17:07:10",0.5
"Sonatype Nexus","trial bundle does not have central repo in public group","https://github.com/sonatype/nexus-bundles/blob/nexus-2.9.x/assemblies/nexus-trial/src/main/content/trial-config/conf/nexus.xml#L231    This means all the trial examples which require download of remote artifacts fail.  ",Bug,Critical,Closed,"2014-09-19 18:03:38","2014-09-19 17:03:38",0.5
"Sonatype Nexus","do not add enabled secure central capability by default on installations without legacy secure central url","There is no need to add this capability, enabled at least, anymore. The default URLs of central have changed to the free URL, so this capability does a needless authtoken fetch on boot and periodically checks every few minutes if it fails. When it does fail, it usually always fails.    It is common for this to fail all the time in corporate env due to firewalls.    If someone is upgrading with secure.central.sonatype.com already configured, then yeah, enabling it makes sense.      ",Bug,Minor,Closed,"2014-09-18 19:10:26","2014-09-18 18:10:26",0.5
"Sonatype Nexus","npm search fails with JsonParseException: Unexpected end-of-input","Configure a group repo in Nexus with npmhosted and npmproxy.    Execute {{npm search}} on the cli.      After a long wait, Nexus prints:        However the cmd seems to display a reasonable list of packages without error.  ",Improvement,Major,Closed,"2014-09-17 21:20:23","2014-09-17 20:20:23",2
"Sonatype Nexus","add complete default NPM repository roles","Using 935774f6d36757f677dd4cb48008af81f6cf84ab of the npm plugin, I noticed only the following Roles installed:    Repo: All NPM repositories (View)    It seems Full Control and Read are missing for starters.    ",Improvement,Major,Closed,"2014-09-17 20:37:05","2014-09-17 19:37:05",1
"Sonatype Nexus","disable Browse Storage tab for npm repositories","-  hide the Browse Storage tab  - park the code to enable Browse Storage in case we revisit the scalability issues    We already have Browse Storage working in latest SNAPSHOT. However we are concerned given the flat structure of npm repositories, that the 2.x UI will not scale well in some situations viewing Browse Storage.    ",Improvement,Major,Closed,"2014-09-17 20:04:24","2014-09-17 19:04:24",0.5
"Sonatype Nexus","disable Smart Proxy support for npm repositories","- hide the Smart Proxy tab for each npm repository  - prevent Smart Proxy subscription and publisher capabilities for npm repos    Initial release should not support Smart Proxy   ",Improvement,Major,Closed,"2014-09-17 20:01:46","2014-09-17 19:01:46",0.5
"Sonatype Nexus","Investigate feasibility of expected NPM JSON error messages for better user experience","Investigate feasibility of expected NPM JSON error messages for better user experience.    Currently, npm does the right job (behaves based on HTTP response code), but spits the raw HTML error page on console.",Bug,Minor,Closed,"2014-09-16 20:28:10","2014-09-16 19:28:10",2
"Sonatype Nexus","Support for npm scoped packages","Add support for scoped packages. This is new feature of npm 2.0.0 release, and targets users using private registries, by adding a scope to package namespace, basically solving the problem of name clashes between public and private packages.    More info  https://github.com/npm/npm/issues/5239  http://blog.nodejitsu.com/a-summary-of-scoped-modules-in-npm/",Improvement,Major,Closed,"2014-09-16 12:19:25","2014-09-16 11:19:25",5
"Sonatype Nexus","NuGet $count queries can lead to excessive caching","The new passthrough code maps a $count query to a remote Packages query and pre-fetches all matching feed entries. IIRC this is to ensure a stable count with local hosted packages in the case of duplicates.    For queries that match a lot of packages this can lead to excessive caching whereas we only really need to combine the remote count with local counts. (This assumes no duplication between remote and hosted feeds, if there is duplication then this could lead to over-counting.)",Bug,Major,Closed,"2014-09-14 17:42:18","2014-09-14 16:42:18",2
"Sonatype Nexus","Querying NuGet proxy with no $top parameter causes excessive caching","I noticed this when manually testing NuGet with curl.    The code that runs the new pass-through queries against the NuGet proxy will automatically page through all results that match the query rather than stop at the first page. This means that if you get the Packages feed using curl with no query parameters it will attempt to page through the entire NuGet proxy feed and not come back for several minutes.    This could explain the longer query times occasionally observed in the field, because we'll be fetching all matching entries rather than stopping at the first page of results. However, the next time the query is run it would be faster because we've pre-fetched all subsequent pages.    If possible we should take exactly what's returned from the NuGet upstream feed and not follow next page references. This should just be a matter of tweaking the feed scraper.",Bug,Major,Closed,"2014-09-10 01:16:17","2014-09-10 00:16:17",3
"Sonatype Nexus","Deleting a repository in the UI doesn't fully delete it on the server","Using Nexus 3.0-SNAPSHOT:  * Create a new repository (any type) with id of Test  * Delete the Test repository  * Attempt to create a new repository (any type) with id of Test  * UI will not allow this and reports Test already exists  Refreshing the UI and logging out and back in have no affect, but restarting Nexus makes the Test repository re-appear in the UI. Similarly deleting the Test repository and then restarting Nexus appears to resurrect it.",Bug,Major,Closed,"2014-09-12 16:35:06","2014-09-12 15:35:06",0.5
"Sonatype Nexus","Some NuGet UI elements are missing in the OSS distribution","When I use the latest nexus-3.0.0-SNAPSHOT-bundle.zip OSS distribution I can create NuGet repositories, but their configuration only shows a single tab: Settings, the token tab is not visible. Similarly the new NuGet upload option never appears even after a NuGet hosted repository is created.    Using the nexus-professional-3.0.0-SNAPSHOT-bundle.zip from the same build (with exactly the same NuGet plugin) all NuGet UI elements appear as expected.",Bug,Major,Closed,"2014-09-12 16:25:00","2014-09-12 15:25:00",0.5
"Sonatype Nexus","Exception deleting user when User-token feature is not enabled","Unpack and start Nexus  * Create an internal user  * Delete the internal user  * Exception will appear in log:      ",Bug,Minor,Closed,"2014-09-11 18:42:17","2014-09-11 17:42:17",0.5
"Sonatype Nexus","mergerepo should run via asynchronous event handler","Currently if mergerepo needs to run it runs synchronously during processing of GET requests for group level repodata/repomd.xml  files.    The mergerepo command can take a while to run if large data sets are involved, this can lead to client side timeouts.  It would be better if it ran on an asynchronous event handler.  This should include a configurable delayed start similar to the current generate yum metadata's delete delay.    ",Improvement,Major,Closed,"2014-09-11 16:41:49","2014-09-11 15:41:49",3
"Sonatype Nexus","make a durable Server Name Indication SNI fix that does not rely on specific sun classes","Current fix for Server Name Indication (SNI), while works, is fragile as it uses {{sun.*}} classes:  https://github.com/sonatype/nexus-oss/commit/b581a1be6ab5b289f44eb7575570589d66bc40c1    The related HttpClient issue contains comments explaining how to properly implement this (and the code is in place since 4.3.2), so on the long term that is where we should go. Still, it would require some rework of the NexusSSLConnectionSocketFactory we implemented and use with HC4.    https://issues.apache.org/jira/browse/HTTPCLIENT-1119",Bug,Major,Closed,"2014-09-10 19:54:03","2014-09-10 18:54:03",2
"Sonatype Nexus","Add option for delay in generate yum metadata capability","Currently a yum: generate metadata task is kicked off asynchronously every time an RPM is deployed.  This runs createrepo, which can take a considerable amount of time.  We should add an option to the capability to delay kicking off this task to account for workflows that publish multiple RPM files in a short period of time.    This could be called generate metadata delay.",Improvement,Minor,Open,"2014-09-10 13:45:50","2014-09-10 12:45:50",3
"Sonatype Nexus","maven staging plugin ArrayIndexOutOfBoundsException: -1 on release using Java 8","I am using 1.6.3 and get this exception when calling mvn nexus-staging:release -e        Migrated from  https://github.com/sonatype/nexus-maven-plugins/issues/71",Bug,Major,Closed,"2014-09-09 12:14:15","2014-09-09 11:14:15",1
"Sonatype Nexus","Update extjs-maven-plugin use of omit flags","ATM our maven-plugin and //<if flag> is inverted in configuration from standard sencha cmd.  Ie. you flip on a flag to cause the section to be omitted, instead of flipping on the flag to have the section be *not* omitted.    Should clean this up so that its consistent for sanity.",Improvement,Trivial,Closed,"2014-09-06 20:36:24","2014-09-06 19:36:24",2
"Sonatype Nexus","Guard logging with //<if debug>","To further optimize the prod build of js, guard all logging.",Improvement,Trivial,Closed,"2014-09-06 20:28:43","2014-09-06 19:28:43",3
"Sonatype Nexus","Testsuite executes tests with previous session","Testsuite execution seems to be polluting tests with previous test state, need to resolve how to get each test isolated for its own session.",Bug,Critical,Closed,"2014-09-06 00:17:14","2014-09-05 23:17:14",3
"Sonatype Nexus","Feature href renders as a link (also non-functional in group selection)",,Bug,Minor,Closed,"2014-09-05 20:39:52","2014-09-05 19:39:52",1
"Sonatype Nexus","Unable to disable CLM from settings page","Have to disable the capability, which isn't very friendly.  Should add a [_] Enable checkbox to the CLM server config view.",Bug,Minor,Closed,"2014-09-05 20:42:53","2014-09-05 19:42:53",0.5
"Sonatype Nexus","External users should be read only","One should not be possible to delete/update an external user",Bug,Major,Closed,"2014-09-05 17:32:35","2014-09-05 16:32:35",0.5
"Sonatype Nexus","Increase default heap size for oss, keep in sync with pro","2.9, 2.10 and master branches have been updated    A note that we are justifying this change because the NuGet features have moved into OSS recently  We expect the host resources available to OSS users to be similar to pro users now as well.    Specifically the heap sizes are changed as follows in wrapper.conf:    wrapper.java.initmemory=256  wrapper.java.maxmemory=768    ",Improvement,Minor,Closed,"2014-09-04 20:10:00","2014-09-04 19:10:00",0.5
"Sonatype Nexus","Improve sorting of NuGet results when no order is specified","Unlike the Nuget Package Explorer, Visual Studio's NuGet plugin doesn't seem to specify a sort order with its queries by default    Nexus defaults to alphabetical by package name, which generally means the results are not very useful  for VS users, who are likely the majority.    Using Download Count as a default sort order would make the results much more useful.  (Which may or may not be what nuget.org is doing - apparently result ordering is under active development.)",Bug,Major,Closed,"2014-09-04 18:46:12","2014-09-04 17:46:12",2
"Sonatype Nexus","Virtual repo detail panel missing tabs","Should probably always show tabs, even if its just the one Settings tab, to keep the UI consistent.",Improvement,Major,Closed,"2014-09-04 02:40:40","2014-09-04 01:40:40",0.5
"Sonatype Nexus","Sign-in dialog appears even when user is logged in","Started up nexus, logged in, navigated to account/user:    http://localhost:8081/?debug#user/account    Then CTRL-R to reload the browser.  The UI shows that I'm logged in, but still prompts me to sign-in?",Bug,Major,Closed,"2014-09-04 02:33:14","2014-09-04 01:33:14",1
"Sonatype Nexus","Upgrade ExtJS 4.2.3","http://www.sencha.com/forum/showthread.php?291239-Ext-JS-4.2.3-is-Now-Available    Will need to verify style changes and rebuild baseapp.",Improvement,Major,Closed,"2014-09-03 22:56:59","2014-09-03 21:56:59",2
"Sonatype Nexus","Inconsistent use of Name in component search","In the search results component detail header and list Name is used for the artifactId and for the filename.     These should be differentiated. Also the Name in the header conflicts with the Component list where a ID/Name is created by using groupId:artifact ID.    This naming should be made more meaningful and consistent somehow. ",Bug,Major,Closed,"2014-09-03 20:25:36","2014-09-03 19:25:36",0.5
"Sonatype Nexus","sourcing ldap users in the UI does not scale","Configure ldap config to a valid server with 5000 users.  Open users management.  Change the source to LDAP.  Nexus now makes 5000+ group member queries and tries to load 5000 records into the Nexus UI. More than likely Nexus UI will timeout and not render anything - meanwhile the queries are happily proceeding as requested in the backend.    This will either crash LDAP, crash Nexus or crash the browser.   ",Bug,Major,Closed,"2014-09-03 18:50:54","2014-09-03 17:50:54",3
"Sonatype Nexus","creating a user with id that already exists fails without any reason why","Create a user with id fake.  Create another user with id fake  Clicking Add for the second user leaves the dialog and provides no feedback about why the user could not be created.",Bug,Major,Closed,"2014-09-03 17:56:58","2014-09-03 16:56:58",0.5
"Sonatype Nexus","adding a new user is allowed despite form validation failures","Login as admin.  #/admin/security/users  Click New.  Add a new user by pasting in an email address of  @foo.com ( content inside quotes) and Save.  A message is displayed about Invalid Email Address  Press Save again n times. Looks like nothing is happening. No error messages or red messages.  Click X on top right of dialog to close it.  Refresh User list. Your user is created with a bad email address.  ",Bug,Major,Closed,"2014-09-03 17:52:25","2014-09-03 16:52:25",0.5
"Sonatype Nexus","ldap server view certificate button is enabled before valid values are entered","Login as admin.  Open http://localhost:8081/nexus/#admin/security/ldap  Click New.  Change protocol to ldaps.  Click View Certificate. A bunch of strange exception messages get thrown in the message console. I do not see these messages logged in the nexus log file.  ",Bug,Major,Closed,"2014-09-03 15:51:56","2014-09-03 14:51:56",0.5
"Sonatype Nexus","prevent createrepo/mergerepo from creating sqlite rpm metadata","According to all accounts I could find, the sqllite databases created using the --database ( defaults to true since 2010, createrepo-0.9.9) option to createrepo/mergerepo is an **client optimization only**.    Where access to Nexus is highly concurrent, and all yum clients seem to support the basic mode without sqlite files on the server just fine, we should therefore stop asking createrepo.mergerepo to create the sqllite databases.     This in theory should improve metadata creation performance(TBD), increase locking throughput and avoid the possibility of having xml based metadata out of sync from sqllite data.     Since 2010, createrepo and mergerepo have added the --no-database option to prevent creation of the sqlite metadata. Before 0.9.9 version, no sqlite data was being created unless specifically asked.    These commits changed the default createrepo/mergerepo behavior from not creating sqlite databases to creating them.    http://createrepo.baseurl.org/gitweb?p=createrepo.git;a=commit;h=1891306b9f4dc98567bcd9507708d8e089e2c69c    http://createrepo.baseurl.org/gitweb?p=createrepo.git;a=commit;h=bc3df9bece50098d9dc1c82f0addac36cc1db67a    Further, YUM documentation ( and code if you look <USER>enough) clarifies that if sqlite files are not found, YUM falls back to getting the XML files instead.    http://yum.baseurl.org/gitweb?p=yum.git;a=blob;f=docs/yum.conf.5;h=97acbe43eb63660a86beb4c1ea5b322bdf1303ad;hb=HEAD#l676    ----    Our code uses --database option, thereby always creating sqlite databases on the server.    [GenerateMetadataTask --database option|https://github.com/sonatype/nexus-oss/blob/master/plugins/yum/nexus-yum-repository-plugin/src/main/java/org/sonatype/nexus/yum/internal/task/GenerateMetadataTask.java#L344-344]    [MergeMetadataTask -d option|https://github.com/sonatype/nexus-oss/blob/master/plugins/yum/nexus-yum-repository-plugin/src/main/java/org/sonatype/nexus/yum/internal/task/MergeMetadataTask.java#L227-227]      In summary:  - our commands should remove -d, --database and add --no-database  - we should clearly specify we require createrepo 0.9.9 or greater to be used OR provide some override to not pass the --no-database option to createrepo/mergerepo in case the local version does not recognize this option  - if implemented, YUM clients can call [yum clean dbcache|http://yum.baseurl.org/wiki/YumCommands] locally to clean up any previously downloaded from Nexus sqlite databases and from then on generate their own sqlite files from the xml data only  - YUM clients could configure 'mddownloadpolicy' in yum.conf to be xml, as a very slight optimization when known to be talking to Nexus, but not required  - on upgrade after this change, delete any sqlite files in Nexus repos to avoid clients from downloading them in the future and getting even more confused, or something more slightly confusing, always responding 404 even if they exist        ",Improvement,Major,Closed,"2014-09-03 02:55:03","2014-09-03 01:55:03",2
"Sonatype Nexus","Inconsistent placement of Save/Discard buttons","When editing a user as admin the Save and Discard buttons on the bottom of the editing section are always visible even if there are more fields and so on to edit below.     On the other hand the editing section for Settings of a repository has the buttons placed within the list of items at the very bottom and is therefore not always visible.     I am not sure which style I prefer but we should select one and stick to it.",Bug,Minor,Closed,"2014-09-02 21:05:50","2014-09-02 20:05:50",0.5
"Sonatype Nexus","LDAP verify connection button is disabled until all configuration is filled in","In Nexus 3.0 it is no longer possible to verify your LDAP connection settings right after filling them in, you have to go to the user & group tab and fill in all of that information first.        ",Bug,Minor,Closed,"2014-09-02 19:24:17","2014-09-02 18:24:17",1
"Sonatype Nexus","Avoid proliferation of artifacts checked into scm for testing","ATM there are a non-trivial number of places where we have test artifacts in scm, such as:        We should look into alternative means to have artifacts available for testing.  Not suggesting we go to maven to download these though, but perhaps a module that has all of these test resources and the testsuite can simply extract that archive if it needs them or something along those lines.",Improvement,Minor,Closed,"2014-09-01 23:24:20","2014-09-01 22:24:20",2
"Sonatype Nexus","Update all code references to use sign-in/out terminology ","ATM we have code using log-in/out, but we want these to be sign-in/out to be consistent with the displayed content for coherence.",Improvement,Trivial,Closed,"2014-09-01 21:11:57","2014-09-01 20:11:57",1
"Sonatype Nexus","Provide our own implementation of Karaf's startup Lock",,Improvement,Minor,Closed,"2014-08-29 18:12:34","2014-08-29 17:12:34",2
"Sonatype Nexus","Child group repository with only one yum enabled member breaks yum metadata merge","Create a set of yum enabled repositories:    {code}        Because GroupB only has one member mergerepo is never run against it.  Consequentially it contains no yum metadata.  This breaks running mergerepo against GroupA, it will fail every time with error:    {quote}  Could not merge repos: Could not setup merge repo pkgsack: Cannot retrieve repository metadata (repomd.xml) for repository: repo1. Please verify its path and try again  {quote}        I think the simplest fix for this would be:    # Implement NEXUS-6801 (prevent generation of sqlite metadata)  # If a group only contains one member copy that member's metadata and rewrite the URL in the primary.xml.gz file",Task,Major,Closed,"2014-08-29 17:42:04","2014-08-29 16:42:04",3
"Sonatype Nexus","Missing option to set/reset user password from user admin",,Bug,Major,Closed,"2014-08-28 21:23:04","2014-08-28 20:23:04",1
"Sonatype Nexus","provide method to exclude specific User-Agent values from browser detection ","https://support.sonatype.com/entries/98305496-How-do-I-enable-WWW-Authenticate-headers-for-content-401-responses    NEXUS-6189 introduced not returning WWW-Authenticate headers for 401 web browser content responses.    This is non-standard behaviour. A customer wants to upgrade to latest Nexus, and when they did, this broke some internal tooling that relied on WWW-Authenticate. Disabling the browser detector is not a good long term solution for them because their internal tool is already deployed to production.    The request is to add some way to specify a user agent string that can always be treated as a non-browser, and therefore return the default authenticate headers.",Improvement,Major,Closed,"2014-08-26 16:18:09","2014-08-26 15:18:09",1
"Sonatype Nexus","Update maven-bridge to use eclipse-aether (instead sonatype-aether)","Unsure why we are still using the old version of aether, suggest we update this component to use the latest bits from eclipse.","Technical Debt",Minor,Closed,"2014-08-21 19:51:54","2014-08-21 18:51:54",3
"Sonatype Nexus","Yum plugin can clobber temp files not belonging to the current process","https://github.com/sonatype/nexus-oss/blob/nexus-2.9.x/plugins/yum/nexus-yum-repository-plugin/src/main/java/org/sonatype/nexus/yum/internal/task/MergeMetadataTask.java#L89-89    This call seems to blindly try to delete all /var/tmp/yum-<nexususername>* files.    If two Nexuses on the same host share the same tmp dir, it is possible one Nexus will clobber the files from another Nexus.",Bug,Major,Closed,"2014-08-21 17:10:12","2014-08-21 16:10:12",1
"Sonatype Nexus","correct inconsistencies of tmp dir usage between Nexus and Yum related forked processes","Summary:     - TMPDIR environment variable should be set to java.io.tmpdir absolute value when YUM command line is forked*  - Yum plugin should make better assumptions about where the tmp directory is    ----    The assumption is the correct way to specify the temp dir for all nexus activity is the java.io.tmpdir system property.    Yum related tasks currently fork processes which inherit the Nexus java process *environment*.    Yum createrepo and mergerepo tools seem to respect the TMPDIR environment variable.    Launch Nexus with TMPDIR environment variable not set but java.io.tmpdir system property set in wrapper.conf java.additional property.    When a YUM metadata task is forked, the forked yum tooling can potentially choose a different tmp dir than what java.io.tmpdir is set as. In one case this caused a no space left on device error when metadata was being generated for a large yum repo because /var/tmp was filling up.    Additionally, our YUM code makes assumptions about the tmp dir being used by YUM, which could conflict with the tmp dir specified by TMPDIR env variable.    https://github.com/sonatype/nexus-oss/blob/nexus-2.9.x/plugins/yum/nexus-yum-repository-plugin/src/main/java/org/sonatype/nexus/yum/internal/task/MergeMetadataTask.java#L159-159    ",Bug,Major,Closed,"2014-08-21 17:04:34","2014-08-21 16:04:34",3
"Sonatype Nexus","When jetty is unable to start properly, shutdown the entire container","This is the behavior we had in NX 2, but in NX 3 presently if Jetty fails to start (ie. bind exception) the container is left running.    Since in this case the server is non-functional, the process should be shutdown gracefully.",Bug,Major,Closed,"2014-08-20 23:13:40","2014-08-20 22:13:40",2
"Sonatype Nexus","Search allows adding duplicate critirias",,Bug,Major,Closed,"2014-08-20 01:41:16","2014-08-20 00:41:16",1
"Sonatype Nexus","Initial selection of admin/repository doesn't show settings","Selecting another repo shows settings, and then selecting original repo shows settings.",Bug,Major,Closed,"2014-08-18 01:46:35","2014-08-18 00:46:35",1
"Sonatype Nexus","Fresh loading of UI sometimes does not show the proper menu","When this happens, reloading the browser resets to the proper menu.",Bug,Major,Closed,"2014-08-18 01:44:10","2014-08-18 00:44:10",1
"Sonatype Nexus","Replace delete_() and export_() names","... with something that jslint doesn't complain about.    May want to revisit the entire naming scheme for these methods?",Bug,Trivial,Closed,"2014-08-17 00:24:32","2014-08-16 23:24:32",1
"Sonatype Nexus","LDAP configuration dialog sized incorrectly in IE10","The fields in the LDAP configuration dialog extend past the edge of the dialog in IE10.    ",Bug,Trivial,Closed,"2014-08-07 17:15:48","2014-08-07 16:15:48",1
"Sonatype Nexus","repository path does not display ( sometimes? )","Repository path column values are missing for me.    I was running Nexus on port 3000 if that matters. Tried Chrome and Firefox.    Using Nexus OSS  nexus-3.0.0-20140806.235753-371-bundle  ",Bug,Major,Closed,"2014-08-07 16:42:59","2014-08-07 15:42:59",1
"Sonatype Nexus","RHC analyze popup goes away too quickly","I can't finish reading it before it goes away automatically. And sometimes mousing over it is <USER>",Bug,Major,Closed,"2014-08-07 16:37:07","2014-08-07 15:37:07",0.5
"Sonatype Nexus","icon column is missing text in column selection dropdown","icon column is missing text in drop down, so I don't know what the checkbox does",Bug,Minor,Closed,"2014-08-07 16:34:10","2014-08-07 15:34:10",1
"Sonatype Nexus","On stopping Nexus, ERROR Could not dispatch NexusStoppedEvent to capabilities NexusIsActiveCondition","./nexus console  Enter  CTRL-D  Nexus begins to stop  See an ERROR message in the stop logging    2014-08-07 07:56:01,130-0700 ERROR [FelixStartLevel] *SYSTEM com.google.common.eventbus.EventBus.default - Could not dispatch event: Nexus is active to public void org.sonatype.nexus.plugins.capabilit  ies.internal.condition.NexusIsActiveCondition.handle(org.sonatype.nexus.proxy.events.NexusStoppedEvent)    confusing at best - what does this mean and can we prevent it?    ",Bug,Minor,Closed,"2014-08-07 16:01:36","2014-08-07 15:01:36",1
"Sonatype Nexus","running ./start n times, starts the container n times","./start  (no output to console - did it start?)  ./start  (no output to console about already running container)  now you have two containers running and no feedback about this  ./stop  (no output anything was stopped)  You still have one container running.  Continue stopping by running ./stop - sometimes the script does detect the other containers running, sometimes it prints     Can't connect to the container. The container is not running.    ..even when one is running...    Same thing happens using ./nexus script directly.    Expected:   - prevent starting multiple containers  - properly detect running containers  - always provide feedback to console about what we thought happened  - do we even need all these individual control scripts exposed to user? what about just having nexus/nexus.bat like before    ",Bug,Major,Closed,"2014-08-07 14:50:07","2014-08-07 13:50:07",2
"Sonatype Nexus","Yum metadata for proxy repositories should refer to the URL of the source Nexus instance","As a result of the fix for NEXUS-5829 yum proxy repositories are no longer directly usable, the proxied metadata contains the URL's of the originating repository, so yum request to download artifacts end up bypassing Nexus, and go to the originating repository.    This is inconsistent with all other types of proxy repositories in Nexus.  The URL's in the proxied metadata should be rewritten to use the URL of the proxy repository.",Bug,Major,Closed,"2014-07-17 17:05:16","2014-07-17 16:05:16",5
"Sonatype Nexus","Remove use of OSchema.save()","This is a nop, but should be removed for clarity.",Bug,Trivial,Closed,"2014-07-15 20:14:58","2014-07-15 19:14:58",0.5
"Sonatype Nexus","add more robust proxy repository URL validation","The core does validate the remoteUrl of a proxy repository, but the current validation is too lax. HttpClient but also some other components uses URIs, but validation is done using URL. This causes various problems, like endless loops in remoteState discovery for example (as HC4 IAExes on bad URL).    If NX validation fixed, it will not allow for a proxy to have a bad remote URL, either by refusing to boot, or on proxy addition/modification to refuse to save the configuration.",Bug,Major,Closed,"2014-07-12 11:13:51","2014-07-12 10:13:51",1
"Sonatype Nexus","Analytics EventData.timestamp field not really timestamp","A field timestamp is set in analytics data. This is set using System.nanoTIme(), which is useless as a timestamp field.    We need to see the year/month/day/hour/minute/second that something happened.    Can we please change this from System.nanoTime() to System.currentTimeInMillis() ?    ",Bug,Major,Closed,"2014-07-10 19:53:19","2014-07-10 18:53:19",1
"Sonatype Nexus","Add full rebuild option to generate yum scheduled task","The generate yum metadata task caches information in two places:    # A checksum cache in $TMPDIR/nexus-yum-repository-plugin/.cache-releases/releases  # A list of rpm's to be processed in $TMPDIR/tmp/nexus-yum-repository-plugin/.cache-releases/.packageFiles/<repo-id>.txt    If either of these has invalid data it can prevent the metadata from regenerating properly.  We should provide an option to the generate yum metadata task (clear caches) which clears these before running createrepo.  This would give end users a way to recover from situations where a previous run had malfunctioned.    ",Improvement,Minor,Closed,"2014-07-07 19:12:50","2014-07-07 18:12:50",1
"Sonatype Nexus","Staging repository listing log spam when repository is not found","OSSRH logs are filled with junk like this:    {quote}  2014-06-30 12:12:27 WARN  [qtp1936214235-377168] knutster com.sonatype.nexus.staging.rest.repository.RepositoryListResource - Failed to convert repository item: id = 'comlicel-1002'; ignoring  org.sonatype.nexus.proxy.NoSuchRepositoryException: Repository with ID=comlicel-1002 not found          at org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.getRepository(DefaultRepositoryRegistry.java:124) ~[nexus-core-2.8.1-01.jar:2.8.1-01]          at org.sonatype.nexus.rest.ProtectedRepositoryRegistry.getRepository(ProtectedRepositoryRegistry.java:71) ~[nexus-restlet1x-plugin-2.8.1-01/:na]          at com.sonatype.nexus.staging.rest.repository.RepositoryResourceSupport.convert(RepositoryResourceSupport.java:49) ~[nexus-staging-plugin-2.8.1-01/:na]          at com.sonatype.nexus.staging.rest.repository.RepositoryListResource$1.doApply(RepositoryListResource.java:94) ~[nexus-staging-plugin-2.8.1-01/:na]          at com.sonatype.nexus.staging.internal.persist.ConfigurationFunctionSupport.apply(ConfigurationFunctionSupport.java:48) [nexus-staging-plugin-2.8.1-01/:na]          at com.sonatype.nexus.staging.internal.persist.DefaultStagingConfiguration.browsex(DefaultStagingConfiguration.java:603) [nexus-staging-plugin-2.8.1-01/:na]          at com.sonatype.nexus.staging.internal.persist.DefaultStagingConfiguration.browse(DefaultStagingConfiguration.java:588) [nexus-staging-plugin-2.8.1-01/:na]          at com.sonatype.nexus.staging.rest.repository.RepositoryListResource.get(RepositoryListResource.java:79) [nexus-staging-plugin-2.8.1-01/:na]          at com.sonatype.nexus.staging.rest.repository.RepositoryListResource.get(RepositoryListResource.java:69) [nexus-staging-plugin-2.8.1-01/:na]          at org.sonatype.plexus.rest.resource.RestletResource.represent(RestletResource.java:233) [nexus-restlet1x-plugin-2.8.1-01/:na]          at org.sonatype.nexus.rest.NexusRestletResource.represent(NexusRestletResource.java:39) [nexus-restlet1x-plugin-2.8.1-01/:na]  {quote}  ",Improvement,Minor,Closed,"2014-06-30 18:17:07","2014-06-30 17:17:07",0.5
"Sonatype Nexus","Profile ID is showing up in staging role names","The staging profile ID is showing up in generated staging roles.  They should be showing the profile name.    ",Bug,Minor,Closed,"2014-06-26 22:47:45","2014-06-26 21:47:45",1
"Sonatype Nexus","include all referenced jetty configuration files in support zip","we currently include jetty.xml in support zip.    Nexus 2.8.x allows more than one wrapper.app.parameter and therefore more than one jetty config file.    Suggest we either include each jetty file now, or one effective jetty.xml if that is easier.",Improvement,Minor,Closed,"2014-06-26 14:16:59","2014-06-26 13:16:59",1
"Sonatype Nexus","Download indexes task should not process out of service repositories","If a repository is out of service it is still processed by the download indexes scheduled task.  It should not be.    Interestingly, update indexes task does not have this problem.    ",Bug,Minor,Closed,"2014-06-23 18:16:32","2014-06-23 17:16:32",1
"Sonatype Nexus","upgrade from previously upgraded 2.8 OSS to Pro ldap configuration can fail subsequent upgrades","On LDAP configuration for post 2.8 versions of Nexus.",Bug,Major,Closed,"2014-06-23 16:14:43","2014-06-23 15:14:43",1
"Sonatype Nexus","Add a mode to staging which allows explicit profile selection, and also enforces repository targets","Currently explicit staging profile selection bypasses any repository target set in a staging profile.  This is OK for some use cases, but for others it gives end users the ability to deploy artifacts with group ID's that they should not have access to.    Disabling explicit profile selection as a workaround isn't always an option, because some nexus-staging-maven-plugin goals require it.  An example of this is deploy-staged-repository.    We should consider adding a mode to staging that allows explicit staging profile selection, and yet still enforces the staging profile's repository target.  ",Improvement,Major,Closed,"2014-06-19 16:56:03","2014-06-19 15:56:03",3
"Sonatype Nexus","LDAP OSS to Pro upgrade bug, multiple configuration fields are not migrated","Discovered while adapting OSS ITs to now merged Pro LDAP (issue is NEXUS-6591). On upgrade of OSS config to Pro config, the flag introduced for NXCM-370 is lost (userBaseDn is optional, when subtree search is used) and some others too.    This should be fixed in 2.9.  In master, the work/changes done as part of NEXUS-6591 fixes the problem.    OSS ITs that now run against Pro LDAP plugin caught this.",Bug,Major,Closed,"2014-06-18 15:23:20","2014-06-18 14:23:20",0.5
"Sonatype Nexus","allow direct request for NuGet artifact through proxy repository if artifact is not already cached in the local feed","Request this URL through a NuGet proxy repository of https://www.nuget.org/api/v2:    http://localhost:8081/nexus/service/local/nuget/nuget-proxy/Extended.Wpf.Toolkit/1.8.0    The outbound request made is this:    https://www.nuget.org/api/v2/Packages(Id='Extended.Wpf.Toolkit',Version='1.8.0')    A 200 response is received with XML describing the artifact, but then no request is made for this:    https://www.nuget.org/api/v2/package/Extended.Wpf.Toolkit/1.8.0    If you then enable fetch all versions in the download nuget feed and make the original request again it will work.  I'm not sure why this is necessary since the path is the same, and Nexus knows that the artifact exists due to the first request's return value.    ",Improvement,Major,Closed,"2014-06-16 18:51:38","2014-06-16 17:51:38",1
"Sonatype Nexus","Nuget: return 403 with reason instead of 404 when redirection fails through a proxy server","Given an org configures an http proxy server to access certain hosts only  And Nexus is configured with this http proxy server  And GET requests to a nuget proxy repository hosted in Nexus have to follow a redirect to a different host than the host they proxy in order to download an artifact  When the artifact is downloaded through Nexus  and the http proxy server responds with 403 because access to that host is not allowed  Then Nexus should respond to the original request with 403  And the response should include the possible reason of the 403 ( source proxy server was used, the redirected to host used and that the routing through it failed with 403)    Nexus currently responds with 404 and no reason to the NuGet client. This leads a Nexus admin to turn on Nexus DEBUG logging to see redirection failure instead of client user knowing they need to configure the Nexus HTTP proxy server to allow certain hosts.    PULL REQUESTS:  https://github.com/sonatype/nexus-oss/pull/601 (2.9.x)  https://github.com/sonatype/nexus-oss/pull/606 (master)",Improvement,Major,Closed,"2014-06-13 16:12:01","2014-06-13 15:12:01",1
"Sonatype Nexus","Crowd plugin that is not configured logs IllegalStateException when viewing security roles","If you log in as admin, and go this screen below:    http://localhost:8081/nexus/#admin/security/roles    Nexus log will get multiple lines of Crowd Errors, like these:        Note: I just started NX fresh, did not configure _anything_ (so not even touched Crowd), and just started clicking around on UI",Bug,Major,Closed,"2014-06-12 13:49:01","2014-06-12 12:49:01",1
"Sonatype Nexus","CLM application treatment is confusing","CLM application drop down when editing a staging profile has some confusing items.    - it asks to choose (none) when it is not even an option if CLM is not configured.  - it asks to select an application when one can't be selected since CLM is not configured, OR the license prevents display of an app OR CLM user does not have permissions to the app.    ",Improvement,Minor,Closed,"2014-06-10 22:16:17","2014-06-10 21:16:17",1
"Sonatype Nexus","Request timeout in Crowd configuration should be in seconds","The request timeout in the Crowd configuration screen is in milliseconds.      I don't see a good use case for this level of granularity, and other timeouts in Nexus are in seconds.  We should make this one use seconds also.",Improvement,Minor,Closed,"2014-06-10 20:04:32","2014-06-10 19:04:32",1
"Sonatype Nexus","goodies/litmus TestUtil.createTempDir() does not return canonical references","This can cause some tests to fail if the base directory of the tests change.    Specifically ApplicationDirectoriesImplTest.ensureWorkDir fails if setUp directory references (created by util.createTempDir) are not canonical.",Bug,Trivial,Closed,"2014-06-08 20:58:21","2014-06-08 19:58:21",0.5
"Sonatype Nexus","upgrade to HTTP client 4.3.4","See RelNotes  https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310360&version=12326286",Task,Major,Closed,"2014-06-06 10:44:05","2014-06-06 09:44:05",0.5
"Sonatype Nexus","include request.log in support bundle","request.log should be included in support bundles from Nexus.",Improvement,Major,Closed,"2014-06-03 14:50:39","2014-06-03 13:50:39",0.5
"Sonatype Nexus","Include staging database details into support-zip","With the move to nosql db for staging, we have lost the ability to include the staging.xml in support-zip.    Example of same thing done with Capabilities:  https://github.com/sonatype/nexus-oss/blob/master/plugins/capabilities/nexus-capabilities-plugin/src/main/java/org/sonatype/nexus/plugins/capabilities/internal/SupportBundleCustomizerImpl.java",Bug,Major,Closed,"2014-05-30 22:42:27","2014-05-30 21:42:27",1
"Sonatype Nexus","Support Bundle can include unprotected HTTP proxy server password","When Nexus is configured with an HTTP proxy server that has username and password, then the system properties `http.proxyPassword` and `https.proxyPassword` get set to the plain text proxy server password.    The sysinfo report included in the support bundle can include these plain text system property values. Suggest these values be replaced with some known text instead to protect the password from being transmitted in the support bundle.    ",Bug,Major,Closed,"2014-05-29 15:02:51","2014-05-29 14:02:51",0.5
"Sonatype Nexus","KZ Timeline partitioning strategy","On master branch, the Timeline rework from Lucene to KZ is mostly done, but one element slipped: partition strategy.    Originally, with lucene, Timeline had no notion of partitions, but purge did use lingo of days (purge, but keep last N days).    Today, with KZ need to (manually, until related issue https://github.com/kazukidb/kazuki/issues/26 is sorted out) manage partitions on APPEND ops, and hence, purge implementation would become trivial.",Improvement,Major,Closed,"2014-05-29 11:05:30","2014-05-29 10:05:30",1
"Sonatype Nexus","Port licensing REST resources to siesta",,Improvement,Major,Closed,"2014-05-20 21:22:17","2014-05-20 20:22:17",3
"Sonatype Nexus","Port outreach REST resources to siesta",,Bug,Major,Closed,"2014-05-20 17:15:53","2014-05-20 16:15:53",2
"Sonatype Nexus","Update fontawesome","Latest version ATM is 4.1.0 (we are currently using 4.0.3).",Task,Major,Closed,"2014-05-16 23:05:42","2014-05-16 22:05:42",0.5
"Sonatype Nexus","Open source PRO LDAP plugin","Nexus has 2 LDAP plugins one for OSS and one for PRO.  We should remove the OSS plugin and move the PRO plugin to OSS.  Including all of the tests, etc.    Can probably leave the packagenames asis, unless we feel its better to rename those to org.sonatype.nexus.ldap at this time?    This will also include opensourcing the SSL plugin.",Task,Major,Closed,"2014-05-16 19:54:38","2014-05-16 18:54:38",3
"Sonatype Nexus","Bring back boot report of REST endpoints and components","This was removed from siesta 2.x upgrade, but it was a nice feature we should bring it back.",Improvement,Trivial,Closed,"2014-05-14 18:03:04","2014-05-14 17:03:04",2
"Sonatype Nexus","Yum Generate Metadata only allows a single RPM per Directory","Some of our legacy build processes require uploading RPMs directly to the file system.  It currently adds more than one RPM to a directory but the Yum Generate Metadata task only allows a single RPM per directory.    I can work around this by manually updating the xml config to change the property 'singleRpmPerDirectory' with a value of 'False'    This will allow multiple RPMs per directory.    It would be useful to have this option available in the Yum Generate Metadata configuration screen.",Bug,Major,Closed,"2014-05-14 14:25:37","2014-05-14 13:25:37",0.5
"Sonatype Nexus","Yum Generate Metadata does not detect new rpms added on filesystem","Some of our legacy build processes require uploading RPMs directly to the file system.  The Yum Generate Metadata task is unable to pick up these new RPMs.    Once a Yum Generate Metadata task has completed it produces a rpm list file.  After this any RPMs added directly to the filesystem will not get picked up as the Generate Metadata task will reuse the existing rpm list file.    I can work around this by manually updating the xml config to add the property 'forceFullScan' with a value of 'True'    This will force a Full Scan and will not reuse the old rpm list file.    It would be useful to have this option available in the Yum Generate Metadata configuration screen.",Bug,Major,Closed,"2014-05-14 14:22:21","2014-05-14 13:22:21",0.5
"Sonatype Nexus","Smart Proxy download immediately option for checksum updates sends duplicate download requests for main artifact","Set up a two nexus instances, one proxying the other with smart proxy + preemptive fetch.  Artifacts deployed to the remote are downloaded 3 times.    Retrieval:    {quote}  2014-05-06 13:23:41 DEBUG [esh-1-thread-5] *SYSTEM remote.storage.outbound - [abc] GET http://192.168.1.155:8081/nexus/content/repositories/releases/com/foo/project/1.0/project-1.0.jar - 30.51 ms  2014-05-06 13:23:41 DEBUG [esh-1-thread-6] *SYSTEM remote.storage.outbound - [abc] GET http://192.168.1.155:8081/nexus/content/repositories/releases/com/foo/project/1.0/project-1.0.jar - 38.24 ms  2014-05-06 13:23:42 DEBUG [esh-1-thread-7] *SYSTEM remote.storage.outbound - [abc] GET http://192.168.1.155:8081/nexus/content/repositories/releases/com/foo/project/1.0/project-1.0.jar - 39.46 ms  {quote}    Storage:    {quote}  2014-05-06 13:23:41 DEBUG [esh-1-thread-5] *SYSTEM org.sonatype.nexus.proxy.storage.local.fs.DefaultFSPeer - Storing file to /Users/<USER>Nexii/nexus-272/foo/sonatype-work/nexus/storage/abc/com/foo/project/1.0/project-1.0.jar 2014-05-06 13:23:41 DEBUG [esh-1-thread-6] *SYSTEM org.sonatype.nexus.proxy.storage.local.fs.DefaultFSPeer - Storing file to /Users/<USER>Nexii/nexus-272/foo/sonatype-work/nexus/storage/abc/com/foo/project/1.0/project-1.0.jar 2014-05-06 13:23:42 DEBUG [esh-1-thread-7] *SYSTEM org.sonatype.nexus.proxy.storage.local.fs.DefaultFSPeer - Storing file to /Users/<USER>Nexii/nexus-272/foo/sonatype-work/nexus/storage/abc/com/foo/project/1.0/project-1.0.jar  {quote}",Bug,Major,Closed,"2014-05-06 19:31:55","2014-05-06 18:31:55",2
"Sonatype Nexus","Add X-Frame-Options header to avoid clickjacking","https://developer.mozilla.org/en-US/docs/Web/HTTP/X-Frame-Options    Unsure if this needs to be just on the index.html or on more content responses too?",Improvement,Major,Closed,"2014-05-05 22:51:36","2014-05-05 21:51:36",1
"Sonatype Nexus","Remove use of ApplicationStatusSource","Remove ApplictaionStatusSource and related AbstractSystemStatusSource.    Use Provider<SystemStatus> instead.    Resolve use, purpose and meaning of ApplicationStatusSource.setState as well as SystemState ingeneral.  ",Improvement,Minor,Closed,"2014-05-05 01:42:05","2014-05-05 00:42:05",2
"Sonatype Nexus","OBR virtual repository metadata update fails when triggered by smart proxy download immediately","A virtual OBR repository shadowing a maven release proxy repository is not able to update it's metadata in response to a smart proxy preemptive fetch due to lack of privileges.    {quote}  2014-05-01 13:07:19,745-0500 WARN  [esh-1-thread-19] *SYSTEM org.sonatype.nexus.obr.shadow.ObrShadowRepository - Could not sync shadow ObrShadowRepository(id=obv) for event RepositoryItemEventCacheUpdate(sender=abc [id=abc], abc:/com/osgiknowhow/sandbox/pig-latin-client/1.0.1/pig-latin-client-1.0.1.jar)  org.sonatype.nexus.proxy.StorageException: A storage exception occured!   at org.sonatype.nexus.obr.util.ObrUtils.updateObr(ObrUtils.java:323) ~[na:na]   at org.sonatype.nexus.obr.shadow.ObrShadowRepository.updateLink(ObrShadowRepository.java:145) ~[na:na]   at org.sonatype.nexus.obr.shadow.ObrShadowRepository.createLink(ObrShadowRepository.java:124) ~[na:na]   at org.sonatype.nexus.proxy.repository.AbstractShadowRepository.onRepositoryItemEvent(AbstractShadowRepository.java:113) ~[nexus-core-2.8.0-05.jar:2.8.0-05]   at sun.reflect.GeneratedMethodAccessor37.invoke(Unknown Source) ~[na:na]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_55]   at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_55]   at org.sonatype.sisu.goodies.eventbus.internal.guava.EventHandler.handleEvent(EventHandler.java:80) [goodies-eventbus-1.9.jar:1.9]   at org.sonatype.sisu.goodies.eventbus.internal.guava.EventBus.dispatch(EventBus.java:329) [goodies-eventbus-1.9.jar:1.9]   at org.sonatype.sisu.goodies.eventbus.internal.DefaultGuavaEventBus.dispatch(DefaultGuavaEventBus.java:34) [goodies-eventbus-1.9.jar:1.9]   at org.sonatype.sisu.goodies.eventbus.internal.ReentrantGuavaEventBus.dispatchQueuedEvents(ReentrantGuavaEventBus.java:57) [goodies-eventbus-1.9.jar:1.9]   at org.sonatype.sisu.goodies.eventbus.internal.guava.EventBus.post(EventBus.java:281) [goodies-eventbus-1.9.jar:1.9]   at org.sonatype.sisu.goodies.eventbus.internal.DefaultEventBus.post(DefaultEventBus.java:78) [goodies-eventbus-1.9.jar:1.9]   at org.sonatype.nexus.proxy.repository.AbstractProxyRepository.doCacheItem(AbstractProxyRepository.java:879) [nexus-core-2.8.0-05.jar:2.8.0-05]   at org.sonatype.nexus.proxy.maven.AbstractMavenRepository.doCacheItem(AbstractMavenRepository.java:482) [nexus-core-2.8.0-05.jar:2.8.0-05]   at org.sonatype.nexus.proxy.maven.maven2.M2Repository.doCacheItem(M2Repository.java:231) [nexus-core-2.8.0-05.jar:2.8.0-05]   at org.sonatype.nexus.proxy.repository.AbstractProxyRepository.doRetrieveRemoteItem(AbstractProxyRepository.java:1364) [nexus-core-2.8.0-05.jar:2.8.0-05]   at org.sonatype.nexus.proxy.repository.AbstractProxyRepository.doRetrieveItem0(AbstractProxyRepository.java:1103) [nexus-core-2.8.0-05.jar:2.8.0-05]   at org.sonatype.nexus.proxy.repository.AbstractProxyRepository.doRetrieveItem(AbstractProxyRepository.java:986) [nexus-core-2.8.0-05.jar:2.8.0-05]   at org.sonatype.nexus.proxy.maven.AbstractMavenRepository.doRetrieveArtifactItem(AbstractMavenRepository.java:408) [nexus-core-2.8.0-05.jar:2.8.0-05]   at org.sonatype.nexus.proxy.maven.AbstractMavenRepository.doRetrieveItem(AbstractMavenRepository.java:391) [nexus-core-2.8.0-05.jar:2.8.0-05]   at org.sonatype.nexus.proxy.maven.maven2.M2Repository.doRetrieveItem(M2Repository.java:395) [nexus-core-2.8.0-05.jar:2.8.0-05]   at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:757) [nexus-core-2.8.0-05.jar:2.8.0-05]   at com.sonatype.nexus.plugins.smartproxy.event.internal.handler.ItemHandlerSupport.fetchItem(ItemHandlerSupport.java:190) [nexus-smartproxy-plugin-2.8.0-05/:na]   at com.sonatype.nexus.plugins.smartproxy.event.internal.handler.ItemHandlerSupport.doFetchItem(ItemHandlerSupport.java:205) [nexus-smartproxy-plugin-2.8.0-05/:na]   at com.sonatype.nexus.plugins.smartproxy.event.internal.handler.ItemHandlerSupport.access$000(ItemHandlerSupport.java:48) [nexus-smartproxy-plugin-2.8.0-05/:na]   at com.sonatype.nexus.plugins.smartproxy.event.internal.handler.ItemHandlerSupport$PreemptiveFetchItemEvent.perform(ItemHandlerSupport.java:254) [nexus-smartproxy-plugin-2.8.0-05/:na]   at com.sonatype.nexus.plugins.smartproxy.event.internal.handler.ItemHandlerSupport$PreemptiveFetchItemEventInspector.inspect(ItemHandlerSupport.java:270) [nexus-smartproxy-plugin-2.8.0-05/:na]   at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source) ~[na:na]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_55]   at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_55]   at com.google.common.eventbus.EventSubscriber.handleEvent(EventSubscriber.java:74) [guava-16.0.1.jar:na]   at com.google.common.eventbus.EventBus.dispatch(EventBus.java:322) [guava-16.0.1.jar:na]   at com.google.common.eventbus.AsyncEventBus.access$001(AsyncEventBus.java:34) [guava-16.0.1.jar:na]   at com.google.common.eventbus.AsyncEventBus$1.run(AsyncEventBus.java:117) [guava-16.0.1.jar:na]   at org.sonatype.nexus.threads.MDCAwareRunnable.run(MDCAwareRunnable.java:41) [nexus-core-2.8.0-05.jar:2.8.0-05]   at org.apache.shiro.subject.support.SubjectRunnable.doRun(SubjectRunnable.java:120) [shiro-core-1.2.2.jar:1.2.2]   at org.apache.shiro.subject.support.SubjectRunnable.run(SubjectRunnable.java:108) [shiro-core-1.2.2.jar:1.2.2]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_55]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_55]   at java.lang.Thread.run(Thread.java:745) [na:1.7.0_55]  Caused by: org.sonatype.nexus.proxy.StorageException: A storage exception occured!   at org.sonatype.nexus.obr.util.ObrUtils.retrieveObrItem(ObrUtils.java:178) ~[na:na]   at org.sonatype.nexus.obr.util.ObrUtils.updateObr(ObrUtils.java:301) ~[na:na]   ... 40 common frames omitted  Caused by: org.sonatype.nexus.proxy.AccessDeniedException: Access denied on repository ID='obv', path='/.meta/obr.xml', action='read'!   at org.sonatype.nexus.proxy.access.DefaultAccessManager.decide(DefaultAccessManager.java:48) ~[nexus-core-2.8.0-05.jar:2.8.0-05]   at org.sonatype.nexus.proxy.repository.AbstractRepository.checkConditions(AbstractRepository.java:1174) [nexus-core-2.8.0-05.jar:2.8.0-05]   at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:587) [nexus-core-2.8.0-05.jar:2.8.0-05]   at org.sonatype.nexus.obr.util.ObrUtils.retrieveObrItem(ObrUtils.java:166) ~[na:na]   ... 41 common frames omitted  {quote}",Bug,Major,Closed,"2014-05-01 19:15:49","2014-05-01 18:15:49",3
"Sonatype Nexus","Regression: File content validation still enabled for procurement, no way to disable","This was supposed to have been fixed in 2.8:  NEXUS-6234    It seems it wasn't, I'm still seeing this issue.",Bug,Minor,Closed,"2014-05-01 16:47:31","2014-05-01 15:47:31",1
"Sonatype Nexus","uncompressed archives with HTML file as an entry can be rejected by file content validation","Fire up Nexus 2.7.2, and retrieve this URL:    http://localhost:8081/nexus/content/groups/public/com/intellij/annotations/7.0.3/annotations-7.0.3.jar    This works.    Now try the same with Nexus 2.8.0.  This will fail, the artifact is rejected by file content validation.  I'm not sure why, the magic number is correct, and various zip programs I tried (including jar) unpack it without complaint.      {quote}  jvm 1 | 2014-04-29 09:15:15,818-0500 INFO [qtp128766849-84] admin org.sonatype.nexus.proxy.maven.maven2.M2Repository - Proxied item central:/com/intellij/annotations/7.0.3/annotations-7.0.3.jar evaluated as INVALID during content validation (validator=filetypevalidator, sourceUrl=https://secure.central.sonatype.com/maven2/com/intellij/annotations/7.0.3/annotations-7.0.3.jar)  {quote}",Bug,Minor,Closed,"2014-04-29 15:32:03","2014-04-29 14:32:03",2
"Sonatype Nexus","File deletion does a copy/delete to trash rather than a move","Not sure why we are doing a copy/delete here:    https://github.com/sonatype/nexus-oss/blob/master/components/nexus-core/src/main/java/org/sonatype/nexus/util/file/DirSupport.java#L325    I seem to recall that a file move in Java will do a move if possible, and fall back to copy/delete if it isn't.  If this is the case we should consider changing this implementation.",Task,Minor,Closed,"2014-04-14 16:32:52","2014-04-14 15:32:52",1
"Sonatype Nexus","Replace N and TN security ids with meaningful identifiers","Get rid of confusing security entity identifiers.  13 or T9 is meaningless, use meaningful names instead[","Technical Debt",Major,Closed,"2014-04-13 04:30:44","2014-04-13 03:30:44",5
"Sonatype Nexus","Archive browser doesn't work for NuGet .nupkg packages","The archive browser doesn't work for NuGet packages.  Adding an override into the nexus.mimetypes file in WEB-INF/classes fixes this, so it seems to be just a case of a missing default value.    We should add nupkg: application/zip into our default mime types.  ",Improvement,Minor,Closed,"2014-04-09 22:39:42","2014-04-09 21:39:42",0.5
"Sonatype Nexus","Remove plexusldaptestsuite","Similar to NEXUS-6511, this one is also an aged plexus component.    https://github.com/sonatype/sisu-ldap-testsuite    Use case in UTs/ITs:  - load a LDIF file  - start up a LDAP server  - use of ldap/ldaps protocols  - using LDAP server from LDAP Realm of Security    We might update the existing tooling, or replace it with something like this  (is WIP but looks nice), or just roll a very thing wrapper around ApacheDS/OpenDS/whatever    https://github.com/trevershick/ldap-test-utils","Technical Debt",Major,Closed,"2014-04-09 11:57:52","2014-04-09 10:57:52",2
"Sonatype Nexus","Replace PGP modello configuration with a capability","Acceptance Criteria:  On upgrade, latest pgp configuration will be converted to a capability  Users will have to first upgrade to 2.8 to get on latest pgp configuration",Improvement,Major,Closed,"2014-04-08 01:38:38","2014-04-08 00:38:38",3
"Sonatype Nexus","Remove plexusjettytestsuite","Replace plexus-jetty-testsuite with HTH",Improvement,Major,Closed,"2014-04-02 20:23:49","2014-04-02 19:23:49",5
"Sonatype Nexus","ERROR log message from M2Repository - LocalStorageException FileAlreadyExistsException does not include root cause throwable","Nexus logs may contain an ERROR log message similar to the following ( not specific to this particular artifact ):    {quote}  2014-04-01 14:36:02 ERROR [qtp608010191-4349] anonymous org.sonatype.nexus.proxy.maven.maven2.M2Repository - Got LocalStorageException in proxy repository <USER> [id=atlassian] while caching retrieved artifact ResourceStoreRequest\{...\} got from URL https://maven.atlassian.com/public/, will attempt next mirror, cause: java.nio.file.FileAlreadyExistsException: /home/nexus/nexus/sonatype-work/nexus/storage/atlassian/com/atlassian/jira/jira-func-tests/4.4.1  {quote}    Cause:    {quote}  java.nio.file.FileAlreadyExistsException: /home/nexus/nexus/sonatype-work/nexus/storage/atlassian/com/atlassian/jira/jira-func-tests/4.4.1  {quote}    Expected:    This log message should include a stack trace to better understand what led to this problem.",Bug,Minor,Closed,"2014-04-01 20:48:32","2014-04-01 19:48:32",0.5
"Sonatype Nexus","Yum metadata generation can block download of repomd.xml file for long periods of time.","The generation of yum metadata can block downloads of the repomd.xml file for a long time.    Nexus should not hold the lock on this file for a long period of time.  One possible solution to this would be to generate the metadata in a temporary location, and then acquire the lock only to move it into place.",Bug,Major,Closed,"2014-04-01 19:43:32","2014-04-01 18:43:32",3
"Sonatype Nexus","inbound request URL syntax validity should be checked and fail fast","Inbound request URLs that contain certain invalid characters may bypass basic syntax checking and cause Nexus to perform more internal work then necessary. This can also cause Nexus to report noisy WARN messages in the logs.     Expected:  Nexus should perform URL syntax validation as early as possible and fail with simple log messages instead of verbose WARN when a URL is syntactically invalid. The HTTP response should return a 400 status in this case.    ",Bug,Major,Closed,"2014-03-31 22:59:49","2014-03-31 21:59:49",1
"Sonatype Nexus","Unable to install a license after a non-trial license expires","If a non-trial license expires you cannot install a new license through the UI.    {quote}  2016-04-30 16:43:56,265-0500 DEBUG [qtp30070137-72]  org.apache.shiro.session.mgt.DefaultSessionManager - Unable to resolve session ID from SessionKey [org.apache.shiro.web.session.mgt.WebSessionKey@411147].  Returning null to indicate a session could not be found.  2016-04-30 16:43:56,265-0500 DEBUG [qtp30070137-72] *UNKNOWN org.sonatype.nexus.restlet1x.internal.RestletServlet - Processing: POST /nexus/service/local/licensing/upload (http://localhost:8081/nexus/service/local/licensing/upload)  2016-04-30 16:43:56,437-0500 INFO  [qtp30070137-72] *UNKNOWN /nexus - nexus: [Noelios Restlet Engine] - Attaching application: org.sonatype.nexus.rest.NexusApplication@1da2473 to URI: /nexus/service/local  2016-04-30 16:43:56,546-0500 DEBUG [qtp30070137-72] *UNKNOWN com.sonatype.nexus.licensing.api.LicenseInstallPlexusResource - Error installing license, returning status: Forbidden (403) - Subject is unauthorized to install a license.  org.sonatype.plexus.rest.resource.PlexusResourceException: Subject is unauthorized to install a license.   at com.sonatype.nexus.licensing.api.LicenseInstallPlexusResource.checkPermission(LicenseInstallPlexusResource.java:297) [nexus-licensing-plugin-2.8.0-01/:na]   at com.sonatype.nexus.licensing.api.LicenseInstallPlexusResource.upload(LicenseInstallPlexusResource.java:256) [nexus-licensing-plugin-2.8.0-01/:na]   at com.sonatype.nexus.licensing.api.LicenseInstallPlexusResource.upload(LicenseInstallPlexusResource.java:219) [nexus-licensing-plugin-2.8.0-01/:na]   at org.sonatype.plexus.rest.resource.RestletResource.upload(RestletResource.java:350) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.sonatype.plexus.rest.resource.RestletResource.acceptRepresentation(RestletResource.java:250) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.sonatype.nexus.rest.NexusRestletResource.acceptRepresentation(NexusRestletResource.java:70) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.resource.Resource.post(Resource.java:688) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.resource.Resource.handlePost(Resource.java:537) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Finder.handle(Finder.java:357) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.doHandle(Filter.java:150) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.handle(Filter.java:195) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Router.handle(Router.java:504) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.doHandle(Filter.java:150) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.handle(Filter.java:195) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.doHandle(Filter.java:150) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.sonatype.plexus.rest.RetargetableRestlet.doHandle(RetargetableRestlet.java:36) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.handle(Filter.java:195) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.doHandle(Filter.java:150) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.handle(Filter.java:195) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.doHandle(Filter.java:150) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.handle(Filter.java:195) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.doHandle(Filter.java:150) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at com.noelios.restlet.StatusFilter.doHandle(StatusFilter.java:130) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.handle(Filter.java:195) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.doHandle(Filter.java:150) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.handle(Filter.java:195) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at com.noelios.restlet.ChainHelper.handle(ChainHelper.java:124) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at com.noelios.restlet.application.ApplicationHelper.handle(ApplicationHelper.java:112) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Application.handle(Application.java:341) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.doHandle(Filter.java:150) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.handle(Filter.java:195) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Router.handle(Router.java:504) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.doHandle(Filter.java:150) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Filter.handle(Filter.java:195) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Router.handle(Router.java:504) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at com.noelios.restlet.ChainHelper.handle(ChainHelper.java:124) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Component.handle(Component.java:676) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.restlet.Server.handle(Server.java:331) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at com.noelios.restlet.ServerHelper.handle(ServerHelper.java:68) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at com.noelios.restlet.http.HttpServerHelper.handle(HttpServerHelper.java:147) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at com.noelios.restlet.ext.servlet.ServerServlet.service(ServerServlet.java:881) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at org.sonatype.nexus.restlet1x.internal.RestletServlet.service(RestletServlet.java:90) ~[nexus-restlet1x-plugin-2.8.0-01/:na]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) ~[javax.servlet-3.0.0.v201112011016.jar:na]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:288) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:278) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:93) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85) ~[guice-servlet-3.1.10.jar:3.1.10]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) ~[shiro-web-1.2.2.jar:1.2.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) ~[guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) ~[nexus-core-2.8.0-01.jar:2.8.0-01]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) ~[guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) ~[nexus-core-2.8.0-01.jar:2.8.0-01]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) ~[guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) ~[nexus-core-2.8.0-01.jar:2.8.0-01]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.sonatype.nexus.analytics.internal.RestRequestCollector.doFilter(RestRequestCollector.java:82) ~[na:na]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) ~[guice-servlet-3.1.10.jar:3.1.10]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) ~[shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) ~[shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) ~[shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) ~[shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) ~[shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) ~[shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) ~[shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) ~[shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) ~[shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) ~[shiro-web-1.2.2.jar:1.2.2]   at org.sonatype.nexus.web.internal.SecurityFilter.executeChain(SecurityFilter.java:73) ~[nexus-core-2.8.0-01.jar:2.8.0-01]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) ~[shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) ~[shiro-core-1.2.2.jar:1.2.2]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) ~[shiro-core-1.2.2.jar:1.2.2]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) ~[shiro-core-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) ~[shiro-web-1.2.2.jar:1.2.2]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) ~[shiro-web-1.2.2.jar:1.2.2]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) ~[guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) ~[nexus-core-2.8.0-01.jar:2.8.0-01]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:135) ~[nexus-licensing-plugin-2.8.0-01/:na]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) ~[guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) ~[nexus-core-2.8.0-01.jar:2.8.0-01]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.yammer.metrics.web.WebappMetricsFilter.doFilter(WebappMetricsFilter.java:76) ~[metrics-web-2.2.0.jar:na]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) ~[guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.CommonHeadersFilter.doFilter(CommonHeadersFilter.java:67) ~[nexus-core-2.8.0-01.jar:2.8.0-01]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) ~[guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.ErrorPageFilter.doFilter(ErrorPageFilter.java:71) ~[nexus-core-2.8.0-01.jar:2.8.0-01]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) ~[guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.BaseUrlHolderFilter.doFilter(BaseUrlHolderFilter.java:70) ~[nexus-core-2.8.0-01.jar:2.8.0-01]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) ~[guice-servlet-3.1.10.jar:3.1.10]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:82) ~[nexus-core-2.8.0-01.jar:2.8.0-01]   at org.sonatype.nexus.web.internal.NexusGuiceFilter$MultiFilterPipeline.dispatch(NexusGuiceFilter.java:56) ~[nexus-core-2.8.0-01.jar:2.8.0-01]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:132) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:129) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:206) ~[guice-servlet-3.1.10.jar:3.1.10]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:129) ~[guice-servlet-3.1.10.jar:3.1.10]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419) ~[jetty-servlet-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:455) ~[jetty-servlet-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557) ~[jetty-security-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1075) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:384) ~[jetty-servlet-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1009) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at com.yammer.metrics.jetty.InstrumentedHandler.handle(InstrumentedHandler.java:200) ~[metrics-jetty-2.2.0.jar:na]   at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:154) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.Server.handle(Server.java:370) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:489) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.AbstractHttpConnection.content(AbstractHttpConnection.java:960) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:1021) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:865) ~[jetty-http-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:240) ~[jetty-http-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82) ~[jetty-server-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668) ~[jetty-io-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52) ~[jetty-io-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608) ~[jetty-util-8.1.11.v20130520.jar:8.1.11.v20130520]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543) ~[jetty-util-8.1.11.v20130520.jar:8.1.11.v20130520]   at java.lang.Thread.run(Unknown Source) ~[na:1.7.0_25]    {quote}",Bug,Major,Closed,"2014-03-31 22:45:18","2014-03-31 21:45:18",2
"Sonatype Nexus","Remove Releases From Repository task should not remove non maven standard versioned artifacts","According to Rich ( and makes sense ) the remove releases from repository task should not process any artifacts except Maven 2 artifacts with A.b.c-buildnumber standard Maven versions    From https://docs.sonatype.com/display/ProdMgmt/Scheduled+Task+to+Clean+Up+Release+Artifacts    {quote}  We would require that version numbers for the artifacts be comparable, this means that they will need to conform to Maven conventions. I think the fallback of string comparison would be too risky, so if parsing a version number doesn't result in an ArtifactVersion object with populated major, minor, and incremental versions then we will not remove the associated artifact.  {quote}      In 2.7 and 2.8, it does seem to process any non-standard version strings as string and prunes release artifacts in alpha order.    1. Deploy artifacts in a hosted repo at same GA with versions,  - deploy them in this order: 'theta', '<USER>, 'alpha'.  2. Run a remove releases task against the release repo, with number to keep as 2, repository target as any.  3. Notice when task completes, alpha is removed, <USER>and theta remain.    Expected: all to remain since version is non-standard.        ",Bug,Major,Open,"2014-03-31 19:48:14","2014-03-31 18:48:14",0
"Sonatype Nexus","Add support class for capabilities without configuration","There are a bunch of capabilities that do not have any configuration, all of them using similar class as configuration. Create a support class WithoutConfiguration and reuse it all over the place.",Improvement,Minor,Closed,"2014-03-27 06:48:25","2014-03-27 06:48:25",1
"Sonatype Nexus","Better warnings when license is going to expire","Consider much more prominent warnings when a license is going to expire. Consider:  * A purple banner  * A health check that goes into metrics  * Sending an email  * Log entries  * Randomly return HTTP 402 :P",Bug,Minor,Open,"2012-02-08 18:09:26","2012-02-08 18:09:26",2
"Sonatype Nexus","Staging promotions puts the staging group into target group but does not remove previously put members of staging group from target group","Started off from NEXUS-4845    The reason why we have cycle, is a bug in staging plugin: when a staging repository is closed, apparently it is put into target group. But, if you promote it -- it is implemented as a group internally in nexus -- the group is put also into target group.    Hence, the initial staging repository is put twice into target group.    Proposed fix: either remove initially put staging repository from target group before putting in promoted group, or simply do not put the promotion group into target group, since all the members are already put into target group.",Bug,Major,Closed,"2012-02-08 16:23:13","2012-02-08 16:23:13",2
"Sonatype Nexus","Releasing a staging repository doesn't take target repository deployment policy into account","Just noticed while testing staging for 1.8.0.1 release, that if i have GAV foo:artifact:1.0 deployed to a release repository, and then i stage that same artifact, and release it to the same target repository, i get no errors, even though the target repository has Deployment Policy of Disable Redeploy",Bug,Major,Closed,"2010-10-20 21:38:33","2010-10-20 20:38:33",2
"Sonatype Nexus","Regression: Error dialog for bad metadata search value is formatted poorly and has bad link","Enter         as the search term for the key and value fields in metadata search.    You get an ugly error dialog in 2.0    In 1.9.2.4, the error dialog is less ugly although the error message could be improved to be less technical.    The 'home page'  link in the error dialog is broken. ( 404)  ",Bug,Minor,Closed,"2012-02-07 13:21:00","2012-02-07 13:21:00",1
"Sonatype Nexus","LDAP servers are sorted in alphabetical order in the UI, so you can't see what the real order is.","The list of LDAP servers in the enterprise ldap UI is being sorted alphabetically in the UI.  This means it is not possible to see the real order that Nexus will use when consulting the servers.    Note that the order is stored correctly in the ldap.xml file.",Bug,Major,Closed,"2011-08-30 17:11:32","2011-08-30 16:11:32",1
"Sonatype Nexus","Nexus Cookies do not specify port, resulting in cookies from myhostname:8081 are sent to myhostname:8082","I tracked this down to cookies do not typically set the port.  So per RFC can be sent to a different server as long as the host name is the same.  http://stackoverflow.com/questions/1612177/are-http-cookies-port-specific      Setting the port in the cookie may cause other issues with browsers (and how does this play with firewalls and proxies)    One simple solution is to make the cookie name configurable.  If we ever switch to shiro-guice (which will remove a bunch of other code) we could easily inject/configure the cookie name.    Or if we are going to keep our boiler plate code, we could configure the cookie name in org.sonatype.nexus.security.NexusWebRealmSecurityManager.init() to call webSessionManager.setSessionIdCookie(...)      Original Setup:  {quote}  I started two nexus pro instances locally.    Nexus A - http://lcaolhost:8081/nexus - publisher  Nexus B - http://localhost:8082/nexus - subscriber    Established a Smart Proxy trust between A and B.    Created apache-snapshots-proxy repo on Nexus B proxied to Nexus A http://localhost:8081/nexus/content/repositories/apache-snapshots    Besides logging into the UI only a few times I noticed the following after a short while in the Nexus B logs:    {quote}  jvm 1    | 2012-01-19 15:45:22 INFO  [Thread-25      ] - org.apache.shiro.session.mgt.AbstractValidatingSessionManager - Validating all active sessions...  jvm 1    | 2012-01-19 15:45:22 INFO  [Thread-25      ] - org.apache.shiro.session.mgt.AbstractValidatingSessionManager - Finished session validation.  [274] sessions were stopped.  {quote}      Nexus A seemed to have 169 sessions cleaned up.    How is it that 274 sessions were created? Are these being created by smart proxy?  {quote}",Bug,Major,Closed,"2012-01-19 19:42:57","2012-01-19 19:42:57",2
"Sonatype Nexus","Allow configuring Crowd HTTP client with specific HTTP connection retry count","Crowd connection may have its own retry characteristics, similar to how proxy repos may have.    The Crowd configuration should expose customizing this value, like it does connection timeout. Otherwise it will pick up the global server retry value default of 3.",Improvement,Minor,Closed,"2013-08-30 17:26:30","2013-08-30 16:26:30",2
"Sonatype Nexus","Enhancement: Tie OData to Lucene index (for performance)",,Improvement,Minor,Closed,"2011-11-28 20:49:52","2011-11-28 20:49:52",10
"Sonatype Nexus","Enhancement: add NuGet Information tab that is analogous to Maven Information tab exposing NuGet metadata",,Improvement,Minor,Closed,"2011-11-30 19:37:45","2011-11-30 19:37:45",6
"Sonatype Nexus","Expire Repository Caches scheduled task not available for NuGet Group Repos","# Create a Nuget Repo Group containing one each of Nuget Proxy, hosted, virtual repos.  # Create an Expire Repository Caches task. Notice that the NuGet proxy and Nuget Hosted Repos are available to select in the task configuration, however NuGet Group is not.    Compare this with the fact a Maven 2 Group Repo can be selected for this task.   ",Bug,Trivial,Closed,"2011-12-09 17:14:13","2011-12-09 17:14:13",1
"Sonatype Nexus","Code housekeeping: make sure all NuGet DB problems are logged","Not all operations are logged on failure",Improvement,Trivial,Closed,"2012-06-20 13:52:28","2012-06-20 12:52:28",1
"Sonatype Nexus","Enhancement: Browse Index tab for NuGet repos","Given that a user can browse an Index of Maven artifacts via the Browse Index tab, and given oData information may be made indexable with lucene in Nexus UI, it may be suitable to support a Browse Index view of nupkg artifacts from within the Nexus UI.    The usefulness of this may be in question for NuGet repos however since developers will typically use NuGet Package Explorer to 'explore' nupkg artifacts.",Improvement,Minor,Closed,"2011-12-01 04:21:51","2011-12-01 04:21:51",3
"Sonatype Nexus","Create UI/privilege so admin can list users who have active (NuGet) API keys and revoke them if necessary",,Improvement,Minor,Closed,"2012-01-17 12:54:11","2012-01-17 12:54:11",1
"Sonatype Nexus","Clarify Promote Repository Notification Settings for Staging Profile","When creating a staging profile, there is a section Promote Repository Notification Settings. But for artifacts for a staging profile can only be dropped or released, not promoted. I think the text in the UI should be changed to Release Repository Notification Settings.  (If the UI template is shared for Build Promotion Profile, it could be changed into Promote/Release Repository Notification Settings.)",Improvement,Minor,Closed,"2011-09-05 13:19:09","2011-09-05 12:19:09",1
"Sonatype Nexus","Crowd: excessive requests to crowd server when listing crowd users","Configure Crowd Server. Open Users tab of Nexus. Select Realm list drop down on Users tab toolbar. Click Magnifying glass icon without any search criteria.    Nexus then sends one request to Crowd server to list *all* crowd users ( max results is http://localhost:8095/crowd/rest/usermanagement/1/search?entity-type=user&start-index=0&max-results=2147483647&expand=user. Once this response comes back, for each user in the response a request is sent to get that user's roles.    This could have a large performance impact where the remote crowd server maps lots of users.    We should improve performance impact here. Examples:    - limit the max number of users returned to the initial query - maybe 500?  - do not request each user's roles ( to display in role column ) until the user is selected in the list.      ",Bug,Critical,Closed,"2013-09-07 15:48:42","2013-09-07 14:48:42",3
"Sonatype Nexus","Welcome/outreach content does not scroll",,Bug,Minor,Closed,"2014-03-24 18:37:18","2014-03-24 18:37:18",1
"Sonatype Nexus","Replace Crowd modello configuration with a capability","Acceptance Criteria:  On upgrade, latest crowd configuration will be converted to a capability  Users will have to first upgrade to 2.8 to get on latest crowd configuration",Improvement,Major,Closed,"2014-03-15 01:14:28","2014-03-15 01:14:28",3
"Sonatype Nexus","Replace plexus-cipher",,Improvement,Minor,Closed,"2014-03-10 17:24:38","2014-03-10 17:24:38",2
"Sonatype Nexus","Update Shiro dependency to 1.2.3","As Shiro 1.2.3 is out, we should bump Nexus Shiro dependency to it. Nexus currently uses 1.2.2",Task,Major,Closed,"2014-03-05 08:42:24","2014-03-05 08:42:24",0.5
"Sonatype Nexus","Upgrade to Tika 1.6","Once it is released, probably around end of April 2014.    And then remove the custom mime types fix added in issue NEXUS-6271, like the custom mime XML.","Technical Debt",Major,Closed,"2014-02-27 20:36:30","2014-02-27 20:36:30",1
"Sonatype Nexus","Print message in log if high-strength JCE is installed","Not having JCE *may* cause problems with some installation configurations.    We should detect if it is installed, and if it is installed, log the fact at INFO.    Apparently calling this will work for this purpose:    Cipher.getMaxAllowedKeyLength(AES);    It will return 128 if no JCE is installed, 2147483647 if it is.",Improvement,Minor,Closed,"2014-02-26 20:04:24","2014-02-26 20:04:24",1
"Sonatype Nexus","strip out invalid addressees out of staging emails before send attempt","Staging emails can be sent to users identified by roles, specific email addresses, and the creator of the staging repo. If any one of these collected addresses is invalid syntactically, the entire email sending fails. The message logged:        Some client side validation should be performed on the collected addresses before sending. If there are any addresses left after striping out the bad ones, continue the send attempt to these 'good ones'. Log at WARN all stripped addresses so an admin has a chance to correct this.  ",Bug,Major,Closed,"2014-02-25 21:13:42","2014-02-25 21:13:42",1
"Sonatype Nexus","poorly named caches","See attached image.    The part after . is driven by Shiro - there should always be one authenticatingCache and one authorizationCache for any realm, *if enabled - otherwise it should not even be present/visible.    The part before . is driven by Nexus impl. Keep it simple:  Prefix names like this should be used:    XML  LDAP  Crowd  kenai    enterprise-ldap cache should be deleted as is legacy junk and replaced with LDAP.authenticationCache and LDAP.autorizationCache proper.    path-cache of what? Suggestions for better name here? Like Nexus.contentPathCache    shiro-activeSessionCache - should probably remove the name shiro here and mention it as Nexus.sessionCache or similar.              ",Improvement,Minor,Closed,"2014-02-25 14:49:50","2014-02-25 14:49:50",3
"Sonatype Nexus","timeline can leave index files in deleted state","Similar to NEXUS-6172, the Timeline indexer can apparently also leave index related files in deleted state.    Example:       ",Bug,Minor,Closed,"2014-02-21 18:31:10","2014-02-21 18:31:10",1
"Sonatype Nexus","Upgrade to siesta 2.x (based on JAX-RS 2.0 w/RESTEasy)",,Improvement,Major,Closed,"2014-02-17 21:36:40","2014-02-17 21:36:40",5
"Sonatype Nexus","prevent scheduling a new YUM GenerateMetadataTask when one is already blocked","We are concerned that more one YUM GenerateMetadataTask can be blocked while waiting for one to complete that is running already.    Given One YUM GenerateMetadataTask (A) against repo (X) is already running  and Given One YUM GenerateMetadataTask (B) against repo (X) is already blocked waiting for A to complete  Then do not queue another YUM GenerateMetadataTask (C) against repo (X)    This is to help avoid depleting the scheduled task queue if many rpms are being added and deleted from the same repo.    Such a condition should be noticeable using INFO level logging to help detect when this happens.  ",Bug,Minor,Closed,"2014-02-07 18:16:35","2014-02-07 18:16:35",3
"Sonatype Nexus","If yum metadata generation fails the output of the createrepo/mergerepo command should always be logged","If yum metadata creation fails all we see is this:    {quote}  2014-02-03 11:17:08 WARN  [ool-1-thread-14] - org.sonatype.nexus.yum.internal.task.GenerateMetadataTask - Scheduled task (GenerateMetadataTask) failed :: Generate Yum metadata of repository 'snapshots' (started 2014-02-03T11:17:08+00:00, runtime 0:00:00.391)  java.io.IOException: Yum metadata generation failed   at org.sonatype.nexus.yum.internal.task.GenerateMetadataTask.doRun(GenerateMetadataTask.java:177) ~[na:na]   at org.sonatype.nexus.yum.internal.task.GenerateMetadataTask.doRun(GenerateMetadataTask.java:72) ~[na:na]   at org.sonatype.nexus.scheduling.AbstractNexusTask.call(AbstractNexusTask.java:157) ~[nexus-core-2.7.1-01.jar:2.7.1-01]   at org.sonatype.scheduling.DefaultScheduledTask.call(DefaultScheduledTask.java:419) [nexus-scheduler-2.7.1-01.jar:2.7.1-01]   at org.sonatype.nexus.threads.MDCAwareCallable.call(MDCAwareCallable.java:45) [nexus-core-2.7.1-01.jar:2.7.1-01]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [shiro-core-1.2.2.jar:1.2.2]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [shiro-core-1.2.2.jar:1.2.2]   at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) [na:1.7.0_10]   at java.util.concurrent.FutureTask.run(FutureTask.java:166) [na:1.7.0_10]   at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178) [na:1.7.0_10]   at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292) [na:1.7.0_10]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) [na:1.7.0_10]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) [na:1.7.0_10]   at java.lang.Thread.run(Thread.java:722) [na:1.7.0_10]  Caused by: org.apache.commons.exec.ExecuteException: Process exited with an error: 1 (Exit value: 1)   at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:377) ~[na:na]   at org.apache.commons.exec.DefaultExecutor.execute(DefaultExecutor.java:160) ~[na:na]   at org.apache.commons.exec.DefaultExecutor.execute(DefaultExecutor.java:147) ~[na:na]   at org.sonatype.nexus.yum.internal.task.CommandLineExecutor.exec(CommandLineExecutor.java:46) ~[na:na]   at org.sonatype.nexus.yum.internal.task.GenerateMetadataTask.doRun(GenerateMetadataTask.java:168) ~[na:na]   ... 13 common frames omitted    {quote}    This makes it pretty much impossible to figure out what happened.  We need to record the command output in case of failure.",Improvement,Major,Closed,"2014-02-05 16:54:33","2014-02-05 16:54:33",1
"Sonatype Nexus","Checksum search fails after repair index task is run","Start up nexus, enable index download for central.  When the task completes search for: dc6a73fdbd1fa3f0944e8497c6c872fa21dca37e    This will work.    Now right click on the central proxy, and run repair index.  When the task completes repeat the above search.  This fails.    I'm not sure what is going on here... is this due to a difference between the full and incremental indexes published on central?    ",Bug,Major,Closed,"2014-02-04 22:21:26","2014-02-04 22:21:26",2
"Sonatype Nexus","Add end-user instructions for support ticket creation in Support Tools UI","The support tools tab does not show how to contact support.  The *Nexus Professional* edition should have a link to the create ticket link in the support site (https://support.sonatype.com/anonymous_requests/new).        ",Improvement,Minor,Closed,"2014-01-31 16:39:06","2014-01-31 16:39:06",1
"Sonatype Nexus","provide option to set or not set rpm metadata baseurl per metadata updates","Scenario:  - yum does not work with authentication + https urls  - yum does work in a limited fashion for authentication + http by putting the username + password as part of the url  - nexus requires base url to be always set in the metadata  - createrepo tool makes setting the baseurl in the metadata optional  - would generally like all requests to Nexus to use https, which typically requires one to force it and enter a nexus base url of https://... ,   - forcing the nexus base url to https:// puts https:// in the metadata, forcing yum to try and use https:// urls  - last item breaks yum    request: provide option to set or not set rpm metadata baseurl per each repository metadata modification          ",Improvement,Major,Closed,"2014-01-30 17:40:08","2014-01-30 17:40:08",1
"Sonatype Nexus","Repository health check fails when using an HTTP proxy server with NTLM authentication.","I'm not sure when this regression occurred yet, but RHC no longer works with NTLM http proxy servers.    I tested with 2.6.4 and 2.7.0, and in both cases it fails with 407 response.    When testing with 2.0.6 it works fine (I tested with this version because we originally fixed this in 2.0.1).",Bug,Major,Closed,"2014-01-13 23:33:50","2014-01-13 23:33:50",2
"Sonatype Nexus","Inconsistencies in file item checksum handling","Seems like issue NEXUS-5418 introduced even more inconsistencies as known, and it made Rebuild Maven Metadata defunct (unverified, as reported by user on HC).    It caused a known inconsistency, that proxy repositories response on file retrieval of SHA1 (and MD5) files basically redirected response to main file (the file that asked checksum belongs to) and served the response generated for main item corresponding attribute. This does not happen in hosted or group repositories, but should.    The problem reported by user probably stems from same change, as Rebuild Maven Metadata, once you end up with wrong checksums, does not recalculates them, but restores the bad ones from attributes.",Bug,Major,Closed,"2013-12-18 09:40:13","2013-12-18 09:40:13",5
"Sonatype Nexus","Timestamped M2 Snapshots should be consumable over M1 shadow","Because of NEXUS-3963 and how shadowed artifact file name is constructed here  https://github.com/sonatype/nexus-oss/blob/nexus-2.7.x/components/nexus-core/src/main/java/org/sonatype/nexus/proxy/maven/LayoutConverterShadowRepository.java#L421    the timestamped M2 artifacts are not consumable by Maven1 from M1 shadow repositories.    Suggested fix: the code on referenced line(s) should be something like this (pseudo code):      Point is in use of {{gav.getBaseVersion()}} that will make shadowed file use {{X-SNAPSHOT}} instead of the timestamped file name.    Note that this change will pose a (neglectable) limitation: Maven1 will see and be able to consume only _latest deployed snapshots_. Also, on removal of any snapshot in master repository, the link is shadow will get removed and _not redirected to another timestamped snapshot_. But these issues will not happen, if usual configuration is used, where you deploy constantly newer and never snapshots, while having remote old snapshots task running regularly. The link will get fixed on new subsequent deploy.",Improvement,Major,Closed,"2013-12-17 10:31:17","2013-12-17 10:31:17",1
"Sonatype Nexus","Requesting a folder which does not exist in a proxy repository's local storage causes a file to be created in storage.","Start a clean 2.7 instance.    Add a proxy for https://repository.sonatype.org/content/groups/forge, add it into the public group.    Now request:    http://localhost:8081/nexus/content/groups/public/com    A file named com will be downloaded to the proxy repository's local cache (attached).  This file contains the HTML directory listing of the remote.    All attempts to download artifacts that start with com will now fail. ",Bug,Blocker,Closed,"2013-12-13 17:05:48","2013-12-13 17:05:48",3
"Sonatype Nexus","?asExpired flag for incoming item request should be forwarded to proxied target","?asExpired flag for incoming item request should be forwarded to proxied target.    This way, in case of chained nexuses, the GET would propagate updates across all participating nexuses, and deliver the really latest to client.",Bug,Major,Closed,"2013-12-13 11:24:14","2013-12-13 11:24:14",1
"Sonatype Nexus","The ?asExpired flag does not invalidate NFC","The ?asExpired flag is meant to invalidate local cache and force a remote check for requested item. Still, it is getting blocked by NFC, if the item is not locally cached, but is in NFC.",Bug,Major,Closed,"2013-12-13 11:13:24","2013-12-13 11:13:24",1
"Sonatype Nexus","New describe page lost the group's not found reasoning.","New describe page lost the group's not found reasoning.",Bug,Major,Closed,"2013-12-12 12:01:21","2013-12-12 12:01:21",3
"Sonatype Nexus","Drop opensearch integration",,Improvement,Minor,Closed,"2013-12-11 20:17:18","2013-12-11 20:17:18",1
"Sonatype Nexus","Nexus 2.7 now returns 501 instead of 405 for MKCOL, possibly breaking some wagons","Nexus 2.7 is returning 501 for MKCOL now, previous versions returned 405.    Update:  Seems the issue here is monitoring software looking for 50x responses.  This change causes a steady stream of false alarms for some setups.    Update 2: This is causing build slowdowns, since the builds are attempting to create each parent directory individually in response to 501 rather than just giving up as it did with the 405 response.",Bug,Major,Closed,"2013-12-10 20:39:23","2013-12-10 20:39:23",1
"Sonatype Nexus","Add ability to disable SSL certificate checks to nexus maven plugins","It's not uncommon for end users to run Nexus with self signed SSL certificates.  In general they can make Maven play nicely with these by using [system properties|http://maven.apache.org/wagon/wagon-providers/wagon-http/].    It would be nice if the nexus maven plugins had a mechanism to do the same. Having them respect the same system properties referenced above is probably best, since an end user would need to set these anyhow.    ",Improvement,Minor,Closed,"2013-12-06 21:48:56","2013-12-06 21:48:56",3
"Sonatype Nexus","different metadata values in search results NuGet proxy repo compared to Nuget hosted repo","1) Download http://www.nuget.org/packages/Microsoft.AspNet.WebApi.Client/5.0.0  2) Examine the metadata inside the nuspec file.    {noformat:title=Microsoft.AspNet.WebApi.Client.nuspec}  <?xml version=1.0?>  <package xmlns=http://schemas.microsoft.com/packaging/2012/06/nuspec.xsd>    <metadata>      <id>Microsoft.AspNet.WebApi.Client</id>      <version>5.0.0</version>      <title>Microsoft ASP.NET Web API 2 Client</title>      <authors>Microsoft</authors>      <owners>Microsoft</owners>      <licenseUrl>http://www.microsoft.com/web/webpi/eula/aspnetcomponent_rtw_ENU.htm</licenseUrl>      <projectUrl>http://www.asp.net/web-api</projectUrl>      <requireLicenseAcceptance>true</requireLicenseAcceptance>      <description>This package adds support for formatting and content negotiation to System.Net.Http. It includes support for JSON, XML, and form URL encoded data.</description>      <summary>This package adds support for formatting and content negotiation to System.Net.Http.</summary>      <releaseNotes>Please go here to view the release notes: http://go.microsoft.com/fwlink/?LinkID=320753&amp;clcid=0x409</releaseNotes>      <copyright>© Microsoft Corporation. All rights reserved.</copyright>      <language>en-US</language>      <tags>Microsoft AspNet WebApi AspNetWebApi HttpClient</tags>      <dependencies>        <group targetFramework=.NETFramework4.5>          <dependency id=Newtonsoft.Json version=4.5.11 />        </group>        <group targetFramework=.NETPortable0.0-wp8+netcore45+net45>          <dependency id=Newtonsoft.Json version=4.5.11 />          <dependency id=Microsoft.Net.Http version=2.2.13 />        </group>      </dependencies>      <frameworkAssemblies>        <frameworkAssembly assemblyName=System.Net.Http targetFramework=.NETFramework4.5 />      </frameworkAssemblies>    </metadata>  </package>    curl -v https://www.nuget.org/api/v2/Search%28%29?\$filter=IsLatestVersion&\$skip=0&\$top=30&searchTerm=%27microsoft.aspnet.webapi.client%27&targetFramework=%27net45%27&includePrerelease=false -o nuget.org.xml    curl -v http://localhost:8081/nexus/service/local/nuget/nuget-local/Search%28%29?\$filter=IsLatestVersion&\$skip=0&\$top=30&searchTerm=%27microsoft.aspnet.webapi.client%27&targetFramework=%27net45%27&includePrerelease=false -o nexus-local.xml -u admin:admin123          <d:Language m:null=true></d:Language>        <d:ReportAbuseUrl m:null=true></d:ReportAbuseUrl>        <d:ReleaseNotes m:null=true></d:ReleaseNotes>    <d:Language>en-US</d:Language>  <d:ReportAbuseUrl>https://www.nuget.org/package/ReportAbuse/Microsoft.AspNet.WebApi.Client/5.0.0</d:ReportAbuseUrl>        <d:ReleaseNotes>Please go here to view the release notes: http://go.microsoft.com/fwlink/?LinkID=320753&amp;clcid=0x409</d:ReleaseNotes>          <d:Title>Microsoft ASP.NET Web API Client Libraries</d:Title>          <d:Title>Microsoft ASP.NET Web API 2 Client</d:Title>    <d:PackageHash>yvcCEHUckwmGe8MziCBYrFEvpdE6xIrWVWn3ST8ZWFNAZXMjz0VXOz1erm2MmhXAy/ZcwPje3MJLLP4UnBbVQg==</d:PackageHash>        <d:PackageHashAlgorithm>SHA512</d:PackageHashAlgorithm>        <d:PackageSize m:type=Edm.Int64>179537</d:PackageSize>    <d:PackageHash>+UEMZXby0QvVYVh8yHen2Qm5cX/yr2lP6qNWhxhacJIQWUo+5p5Vb6ToRrxjukcZmPuoVhwKMBdyNGNDWXFiDA==</d:PackageHash>        <d:PackageHashAlgorithm>SHA512</d:PackageHashAlgorithm>        <d:PackageSize m:type=Edm.Int64>179605</d:PackageSize>  {noformat}    ----    Note the differences for <d:Dependencies> has already been reported as NEXUS-6158 since that is a more critical item.            ",Bug,Medium,Open,"2013-12-03 15:09:57","2013-12-03 15:09:57",0
"Sonatype Nexus","nuget local repos feeds should support nuspec dependency optional targetFramework attribute","Nuspec defines an optional targetFramework attribute as of version 2.0    http://docs.nuget.org/docs/reference/nuspec-reference#Specifying_Dependencies_in_version_2.0_and_above    When uploading a nupkg with a nuspec containing this attribute, Nexus does not expose the framework bits in the feed <p:dependencies> element, therefore *installing these artifacts from a local nuget repo using visual studio does not work*.    In contrast, *downloading a nupkg from a __proxy__ repository feed WILL work because these dependency details include targetFramework details*.    ----    Example:    1) Download a nupkg which specifies dependencies with targetFramework  https://www.nuget.org/api/v2/package/Microsoft.AspNet.WebApi.Client/5.0.0     Results in a file called microsoft.aspnet.webapi.client.5.0.0.nupkg    ----    1) Boot nexus Pro  2) Add a local repo of Nuget type  3) Using the artifact upload tab, upload the nuget artifact into the local nuget repo.  4) Perform a search against that local nuget repo for the uploaded artifact. The feed entry returned will not contain the targetFramework string inside the dependency element.        ----    Compare this with a proxy Nuget repo of the official feed:  1) in nexus, add a proxy repo against https://www.nuget.org/api/v2  2) wait for the download nuget index task to complete ( approx 5-6 minutes )  3) Perform a search against that proxy nuget repo for the same artifact. The feed entry returned will contain the targetFramework string inside the dependency element.           ----    Attached files contain the detailed differences:    {noformat:title=nexus-local.xml feed from local nuget repo}  curl -v http://localhost:8081/nexus/service/local/nuget/nuget-local/Search%28%29?\$filter=IsLatestVersion&\$skip=0&\$top=30&searchTerm=%27microsoft.aspnet.webapi.client%27&targetFramework=%27net45%27&includePrerelease=false -o nexus-local.xml -u admin:admin123      {noformat:title=nuget.org.xml feed direct from nuget.org}  curl -v https://www.nuget.org/api/v2/Search%28%29?\$filter=IsLatestVersion&\$skip=0&\$top=30&searchTerm=%27microsoft.aspnet.webapi.client%27&targetFramework=%27net45%27&includePrerelease=false -o nuget.org.xml  {noformat}              ",Bug,Major,Closed,"2013-12-03 14:03:51","2013-12-03 14:03:51",2
"Sonatype Nexus","Support apk, apklib and aar as mime type for Android developers and users","It would be nice if the archive browser and other mime related features work for the Android related archive formats apklib and aar.    The apk mime type should allow Android applications to be served from nexus for installation on devices as well. ",Improvement,Major,Closed,"2013-11-18 19:18:08","2013-11-18 19:18:08",1
"Sonatype Nexus","Still some verbose EofExceptions being logged with verbose stack details",,Bug,Minor,Closed,"2013-11-08 18:43:50","2013-11-08 18:43:50",1
"Sonatype Nexus","nexus-core-client uses Java7 API","Seems nexus-client-core uses Java7 API and classes. Offended classes:  org.sonatype.nexus.client.internal.rest.jersey.subsystem.JerseyUtilities  org.sonatype.nexus.client.internal.rest.jersey.subsystem.JerseyContent    Most notably java.nio.files.Files class and File.toPath method.    Seems animal sniffer is not running on these? How got 2.7.0-01 build released otherwise?",Bug,Critical,Closed,"2013-11-08 16:20:37","2013-11-08 16:20:37",1
"Sonatype Nexus","user token authenticate dialog error messages cut off in IE10","happens for both Reset User Token and Access User Token dialogs.",Bug,Minor,Closed,"2013-11-07 06:02:01","2013-11-07 06:02:01",1
"Sonatype Nexus","Remove support for upgrades previous to 2.0","Starting in Nexus 2.8, automatic upgrade of versions of Nexus older than 2.0 are no longer supported.    Upgrades to Nexus 2.8 or newer must first upgrade to the latest 2.7.x version first, then upgrade to the latest version.  ",Improvement,Major,Closed,"2013-11-06 22:40:43","2013-11-06 22:40:43",3
"Sonatype Nexus","Move /content handling to its own plugin","ATM this is in the nexus-web-utils module, and probably should have been moved to its own plugin instead.",Improvement,Minor,Closed,"2013-11-05 19:52:29","2013-11-05 19:52:29",2
"Sonatype Nexus","RequestContext Java8 incompatibility","Basically, similar (if not same) fix should be applied to it as was done here:  https://github.com/sonatype/nexus-oss/pull/89    Also, it similarly breaks Map contract as AppContext does.",Bug,Major,Closed,"2013-11-05 18:46:25","2013-11-05 18:46:25",1
"Sonatype Nexus","Two Velocity instances exists in Nexus, no reason to not have them shared","It seems two instances of Velocity (and those are quite memory hungry) exists in Nexus, and as I talked to JD, there actually no reason to not unify them.    Related classes:  SharedTemplateEngineProvider    and Velocity setting from it should be moved to  NexusVelocityConfigurator",Bug,Major,Closed,"2013-11-05 18:44:40","2013-11-05 18:44:40",1
"Sonatype Nexus","ui dialogs display literal <br/> html tags","make a UI request to Nexus that will timeout. the simplest is start nexus, login, shutdown nexus and make another ui request.    You see a dialog that states the request timed out ( as expected ) but the message starts with '<br/><br>'    This is just one example. Other dialogs have the same escaping problem.",Bug,Major,Closed,"2013-11-01 20:25:30","2013-11-01 20:25:30",1
"Sonatype Nexus","Should be possible to reset configured loggers","Add a button to logging UI that will remove all loggers persisted in logback-overrides.xml ",Improvement,Trivial,Closed,"2013-10-31 17:33:05","2013-10-31 17:33:05",1
"Sonatype Nexus","Capability repository local status condition becomes satisfied before repository status is changed","RepositoryLocalStatusCondition watches RepositoryEventLocalStatusChanged, event which is (wrongly) sent before repository configuration is saved, meaning that doing any operation with repository will end up in exceptions like for example: org.sonatype.nexus.proxy.RepositoryNotAvailableException: Repository 3rd party [id=thirdparty] is not available!    We should use ",Bug,Minor,Closed,"2013-10-31 08:52:07","2013-10-31 08:52:07",1
"Sonatype Nexus","Maven Archetype plugin wrong use of RepositoryEventLocalStatusChanged","Or better, Nx Core fires RepositoryEventLocalStatusChanged event at wrong moment, when the configuration is not yet applied, and MAC plugin attempts to install the catalog while repository is still Out of Service (configuration change is not committed yet), causing log spam such as:    {quote}  jvm 1    | 2013-10-31 09:33:19 INFO  [qtp1111344480-85] admin org.sonatype.nexus.plugins.mac.MacPluginEventInspector - Unable to install the generated archetype catalog, repository releases is out of service  {quote}    Still, the MAC plugin successfully handles the local status change of the repository, as the subsequent event (fired when configuration change is committed) redoes the work and succeeds.",Bug,Minor,Closed,"2013-10-31 08:40:04","2013-10-31 08:40:04",1
"Sonatype Nexus","Update to xstream 1.4.5","Supports ignoring unknown xml:    Allow unknown XML elements to be ignored using new method XStream.ignoreUnknownElements",Improvement,Major,Closed,"2013-10-30 23:50:13","2013-10-30 23:50:13",1
"Sonatype Nexus","Failure during capability load prevents the rest of capabilities to be loaded","An exception thrown during capability.load will result in the rest of them to not be loaded (capabilities not yet loaded).    ",Improvement,Critical,Closed,"2013-10-30 20:07:22","2013-10-30 20:07:22",1
"Sonatype Nexus","Smart Proxy secure connector capability should validate fields","Port should be validated as a positive integer  Advertise Uri should be validated as URI",Improvement,Trivial,Closed,"2013-10-30 19:49:08","2013-10-30 19:49:08",1
"Sonatype Nexus","update Nexus and components to use httpclient 4.2.6 to pick up SSL and NTLM related fixes","Important SSL and NTLM related fixes    https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310360&version=12324353    These seems less risky than upgrading to 4.3.x of httpclient at this stage.( 2.7 )",Improvement,Major,Closed,"2013-10-30 12:09:38","2013-10-30 12:09:38",1
"Sonatype Nexus","update httpclient dependencies in nexus-ant-tasks and nexus-maven-plugins","Noticed nexus-ant-tanks still depend on httpclient 4.2.2 - this version has known bugs and should be updated to match what the recent version of nexus-staging-maven-plugin is using at the very least.",Improvement,Major,Closed,"2013-10-30 12:05:29","2013-10-30 12:05:29",1
"Sonatype Nexus","CLM failure on Staging Close rendering seems broken","Followed the Staging Profile Fail on Close Repository from CLM testing scenario. Everything when fine, and happened as expected, except the Activity rendering seems broken. Instead of the rendering shown in video, I got raw data it seems. While following the x.appScan.url did lead me to report.",Bug,Minor,Closed,"2013-10-30 11:19:42","2013-10-30 11:19:42",1
"Sonatype Nexus","CLM App Management link of profile editor leads to wrong URL","See attached video.    In short, with CLM configured, at Staging profile south panel, the CLM Application Management link is shown, but it leads to wrong URL (having CLM Brain responding with 404):    http://localhost:8070//assets/index.html#/management/application/0001/policies    Note the double slash ({{//assets}}). Manually removing one slash leads to page okay.    When no application selected, the CLM Dashboard is correct, leads to proper page on Brain.",Bug,Major,Closed,"2013-10-30 11:09:26","2013-10-30 11:09:26",1
"Sonatype Nexus","Yum merge metadata capability cause Stack Overflow when repository is put Out of Service","The test scenario contains a step, that a capability that depend on a repository should get passivated.    I tried this with Yum Generate Metadata using Releases repository.    Then Releases put out of service, UI got Server Error 500 response and Nexus log had a stack overflow exception:    {quote}  jvm 1    | java.lang.StackOverflowError: null  jvm 1    |  at java.util.regex.Pattern$GroupTail.match(Pattern.java:4615) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$CharProperty.match(Pattern.java:3694) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$GroupHead.match(Pattern.java:4556) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$Branch.match(Pattern.java:4500) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$Branch.match(Pattern.java:4500) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$Branch.match(Pattern.java:4500) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$BranchConn.match(Pattern.java:4466) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$GroupTail.match(Pattern.java:4615) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$Curly.match0(Pattern.java:4177) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$Curly.match(Pattern.java:4132) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$GroupHead.match(Pattern.java:4556) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$Branch.match(Pattern.java:4502) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$Branch.match(Pattern.java:4500) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$BmpCharProperty.match(Pattern.java:3715) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Pattern$Start.match(Pattern.java:3408) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Matcher.search(Matcher.java:1199) ~[na:1.7.0_45]  jvm 1    |  at java.util.regex.Matcher.find(Matcher.java:618) ~[na:1.7.0_45]  jvm 1    |  at java.util.Formatter.parse(Formatter.java:2517) ~[na:1.7.0_45]  jvm 1    |  at java.util.Formatter.format(Formatter.java:2469) ~[na:1.7.0_45]  jvm 1    |  at java.util.Formatter.format(Formatter.java:2423) ~[na:1.7.0_45]  jvm 1    |  at java.lang.String.format(String.java:2797) ~[na:1.7.0_45]  jvm 1    |  at org.sonatype.nexus.proxy.utils.RepositoryStringUtils.getHumanizedNameString(RepositoryStringUtils.java:25) ~[nexus-core-2.7.0-SNAPSHOT.jar:2.7.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.proxy.RepositoryNotAvailableException.<init>(RepositoryNotAvailableException.java:32) ~[nexus-core-2.7.0-SNAPSHOT.jar:2.7.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.proxy.repository.AbstractRepository.checkConditions(AbstractRepository.java:1155) ~[nexus-core-2.7.0-SNAPSHOT.jar:2.7.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(AbstractRepository.java:590) ~[nexus-core-2.7.0-SNAPSHOT.jar:2.7.0-SNAPSHOT]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:138) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  jvm 1    |  at org.sonatype.nexus.yum.internal.capabilities.MetadataCapabilitySupport.renderStatus(MetadataCapabilitySupport.java:157) ~[na:na]  jvm 1    |  at org.sonatype.nexus.capability.support.CapabilitySupport.status(CapabilitySupport.java:78) ~[na:na]  ...  {quote}",Bug,Major,Closed,"2013-10-30 09:12:29","2013-10-30 09:12:29",1
"Sonatype Nexus","Use of FormDataBodyPart results in failure to discover resource","I'm converting my plug-in to use the new siesta/jersey based framework. One of the resources has a POST method that consumes multipart/form-data. Declaring a parameter like this:  {code:none}  @FormDataParam(value) FormDataBodyPart value  {code}  results in that the resource fails to be discovered (it doesn't show up in the log under org.sonatype.nexus.plugins.siesta.SiestaModule - Resources: during boot). If I change the FormDataBodyPart into a String, then the resource shows up and can be called. Using a String results in a value that contains the full raw content of the part so it's not really an option.    I'm currently using 2.7.0.m4",Bug,Minor,Closed,"2013-10-28 22:52:24","2013-10-28 22:52:24",2
"Sonatype Nexus","Automatic routing warnings should include repository ID","We need to include the repository ID in automatic routing log messages.  Without this it is very difficult to track the cause down.    {quote}  2013-10-28 07:52:58 WARN [ar-4-thread-3] Task-User org.sonatype.nexus.proxy.maven.routing.internal.RemoteContentDiscovererImpl - Remote strategy prefix-file error: RemoteAccessDeniedException   {quote}",Bug,Minor,Closed,"2013-10-28 15:05:28","2013-10-28 15:05:28",1
"Sonatype Nexus","improve Remove Releases from Repository task performance","As said in summary. When first scheduled, we had an oom exception. So we increased the max memory to 1 GiB. After that we had no more oom issues. The task ran for 147h 43m 57s and finished successfully. During this time he cleaned up 8270 releases (as derived from the log entries Recreating Maven2 metadata in repository ID='releases' from path=.... Disk space went from 134GiB down to 75GiB. While it was successfull I think this is incredibly slow. The fix might be similar to the one from issue NEXUS-4640.    Fix: A new task option is added to make the task perform better. [Refer to comment|https://issues.sonatype.org/browse/NEXUS-6048?focusedCommentId=301151&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-301151]",Improvement,Major,Closed,"2013-10-28 13:53:27","2013-10-28 13:53:27",3
"Sonatype Nexus","Move handling of /static resources outside of restlet1x plugin","Probably should handle this with a simple servlet similar to content impl.    Should also add detection of overlapping static resources, we already have a few of these, we should know about these early so we can fix them as they could cause inconsistent behavior.",Improvement,Minor,Closed,"2013-10-25 18:43:47","2013-10-25 17:43:47",2
"Sonatype Nexus","Merge classes ItemPathUtils and PathUtils","As they are both almost about the same: repository item paths. But, their names and the fact there are two of these is very misleading.    References:  org.sonatype.nexus.util.ItemPathUtils  org.sonatype.nexus.util.PathUtils",Improvement,Minor,Closed,"2013-10-25 13:06:32","2013-10-25 12:06:32",1
"Sonatype Nexus","Impossible to disable CLM from UI","It is not possible to disable CLM (ie. unset the hostname) from the UI.    The only way to disable CLM is to rm the xml file and restart the server.",Bug,Major,Closed,"2013-10-25 00:11:35","2013-10-24 23:11:35",1
"Sonatype Nexus","Template processing error: IO Error rendering template '/templates/repositoryContentHtml.vm' when connection reset","Seeing this a lot in customer logs. Can we prevent this huge stack? Looks like request was ending in 4xx error and failed to write the template. Hopefully it cleans up after itself...    ",Bug,Major,Closed,"2013-10-24 20:49:00","2013-10-24 19:49:00",1
"Sonatype Nexus","Repository auto-block can trigger a deadlock in smart proxy.","See the attached jstack.out file.  Smart proxy is attempting to shut down the jms connection because repository is being auto-blocked.  This is causing request threads to pile up on the UID lock.",Bug,Major,Closed,"2013-10-24 18:05:40","2013-10-24 17:05:40",5
"Sonatype Nexus","Nexus serving insecure content: add.png, delete.png","See attached from loading RSO.    This prevents a Green lock icon when browsing nexus securely using https.        ",Bug,Minor,Closed,"2013-10-22 17:04:15","2013-10-22 16:04:15",1
"Sonatype Nexus","Browse remote tab is visible for Nuget repos but should not be","Browse Remote tab for NuGet proxy repos is visible.    This is a regression. Not sure which version it first regressed but original issue to hide it was https://issues.sonatype.org/browse/NXCM-3543",Bug,Minor,Closed,"2013-10-22 14:27:31","2013-10-22 13:27:31",1
"Sonatype Nexus","Remove deprecated classes and api","In 2.7 we deprecated a lot (mainly util) classes. This is just a reminder for next iteration to drop them.",Task,Major,Closed,"2013-10-22 10:52:39","2013-10-22 09:52:39",5
"Sonatype Nexus","The undeployArtifact in DefaultMetadataUpdater attempts to add version instead of removing","The method org.sonatype.nexus.proxy.maven.DefaultMetadataUpdater.undeployArtifact(ArtifactStoreRequest) uses an AddVersionOperator where it probably should use a RemoveVersionOperator. At present, it performs the same task as the deployArtifact method.",Bug,Minor,Closed,"2013-10-19 08:45:26","2013-10-19 07:45:26",1
"Sonatype Nexus","Review File and stream utility usage in Nexus","While doing issues like NEXUS-5993, I noticed we are not consistent at all what libraries we use for java.io.File and java.io.*Stream manipulations. Libraries in use are (in no particular order):  * plexus-util  * commons-io  * guava  * some in-nexus breed code (FileUtils, IOUtils, etc)    All these uses should be reviewed, and probably aligned with one of the selected libraries.",Task,Major,Closed,"2013-10-17 16:00:45","2013-10-17 15:00:45",3
"Sonatype Nexus","Nexus should respect X-Forwarded headers by default","To minimize any potential problems fronting nexus with Apache mod_proxy or other reverse proxies using the X-Forwarded-* headers, we should configure Jetty to acknowledge and respect any X-Forwarded headers by default.    See Jetty Logic here:  http://download.eclipse.org/jetty/stable-8/xref/org/eclipse/jetty/server/AbstractConnector.html#432    See Jetty Docs describing how to front Jetty with reverse proxy SSL:  http://wiki.eclipse.org/Jetty/Howto/Configure_mod_proxy    Related forum post:  http://wiki.eclipse.org/Jetty/Howto/Configure_mod_proxy    We should also update the book to mention how to set the X-Forwarded-Proto header in httpd as well.    http://books.sonatype.com/nexus-book/reference/install-sect-proxy.html    ",Improvement,Major,Closed,"2013-10-17 15:24:58","2013-10-17 14:24:58",1
"Sonatype Nexus","Improvement: CompositeException should print stack traces of it's contained exceptions","Way too often customer log files contain entries like the one below, and it turns out the contained exceptions were logged at DEBUG.    So there's a failure, and no way to know what happened.    We should log at least some of the stack traces from the contained exceptions.  Maybe up to a limit of 10 or something?    {quote}  2013-10-14 14:28:40 WARN [pxpool-1-thread-18] n0158588 org.sonatype.nexus.tasks.OptimizeIndexTask - Scheduled task (Optimize _a_ repository) failed :: Optimizing repository Hosting index. (started 2013-10-14T14:24:51-04:00, runtime 0:03:49.174)  java.io.IOException: Exception(s) happened during reindexAllRepositories()  at org.sonatype.nexus.index.DefaultIndexerManager.optimizeIndex(DefaultIndexerManager.java:1792) ~[na:na]  at org.sonatype.nexus.index.DefaultIndexerManager.optimizeRepositoryIndex(DefaultIndexerManager.java:1766) ~[na:na]  at org.sonatype.nexus.tasks.OptimizeIndexTask.doRun(OptimizeIndexTask.java:56) ~[na:na]  at org.sonatype.nexus.scheduling.AbstractNexusTask.call(AbstractNexusTask.java:177) ~[nexus-core-2.6.0-05.jar:2.6.0-05]  at org.sonatype.scheduling.DefaultScheduledTask.call(DefaultScheduledTask.java:483) ~[nexus-scheduler-2.6.0-05.jar:2.6.0-05]  at org.sonatype.nexus.threads.MDCAwareCallable.call(MDCAwareCallable.java:44) ~[nexus-core-2.6.0-05.jar:2.6.0-05]  at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) ~[shiro-core-1.2.2.jar:1.2.2]  at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) ~[shiro-core-1.2.2.jar:1.2.2]  at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) ~[na:1.7.0_25]  at java.util.concurrent.FutureTask.run(FutureTask.java:166) ~[na:1.7.0_25]  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178) ~[na:1.7.0_25]  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292) ~[na:1.7.0_25]  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_25]  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_25]  at java.lang.Thread.run(Thread.java:724) ~[na:1.7.0_25]  Caused by: org.sonatype.nexus.util.CompositeException: Multiple exceptions happened, please see prior log messages for details.  ... 15 common frames omitted  2013-10-14 14:28:40 WARN [pxpool-1-thread-18] n0158588 org.sonatype.scheduling.DefaultScheduledTask - Exception in call method of scheduled task Optimize _a_ repository  java.io.IOException: Exception(s) happened during reindexAllRepositories()  at org.sonatype.nexus.index.DefaultIndexerManager.optimizeIndex(DefaultIndexerManager.java:1792) ~[na:na]  at org.sonatype.nexus.index.DefaultIndexerManager.optimizeRepositoryIndex(DefaultIndexerManager.java:1766) ~[na:na]  at org.sonatype.nexus.tasks.OptimizeIndexTask.doRun(OptimizeIndexTask.java:56) ~[na:na]  at org.sonatype.nexus.scheduling.AbstractNexusTask.call(AbstractNexusTask.java:177) ~[nexus-core-2.6.0-05.jar:2.6.0-05]  at org.sonatype.scheduling.DefaultScheduledTask.call(DefaultScheduledTask.java:483) ~[nexus-scheduler-2.6.0-05.jar:2.6.0-05]  at org.sonatype.nexus.threads.MDCAwareCallable.call(MDCAwareCallable.java:44) ~[nexus-core-2.6.0-05.jar:2.6.0-05]  at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) ~[shiro-core-1.2.2.jar:1.2.2]  at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) ~[shiro-core-1.2.2.jar:1.2.2]  at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) ~[na:1.7.0_25]  at java.util.concurrent.FutureTask.run(FutureTask.java:166) ~[na:1.7.0_25]  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178) ~[na:1.7.0_25]  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292) ~[na:1.7.0_25]  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_25]  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_25]  at java.lang.Thread.run(Thread.java:724) ~[na:1.7.0_25]  Caused by: org.sonatype.nexus.util.CompositeException: Multiple exceptions happened, please see prior log messages for details.  ... 15 common frames omitted  {quote}",Improvement,Minor,Closed,"2013-10-15 15:43:55","2013-10-15 14:43:55",2
"Sonatype Nexus","PGP key server information configuration on settings page click links to configured URL","When a user goes to _remove_ a pgp server, they have to go to administration/server to the pgp key server information section and *click* an entry in the key server urls list and then click remove, then save to remove the entry.    The problem here is that the first *click* opens up the configured URL in another browser window, which is very confusing and disorienting.",Bug,Trivial,Closed,"2013-10-11 18:22:24","2013-10-11 17:22:24",1
"Sonatype Nexus","xml:base URL embedded in yum metadata breaks proxy repositories","In fixing NEXUS-5806 we started to embed the server base URL into the xml:base of the yum primary.xml.gz file.    This causes proxy's of yum enabled group repositories to fail, requests to download artifacts from yum are made to the proxy's remote instead of the proxy itself.",Bug,Major,Closed,"2013-10-10 19:30:39","2013-10-10 18:30:39",3
"Sonatype Nexus","review File.mkdirs() usage, replace with Files.createDirectory(file.toPath()); to not hide IOExceptions","see summary - we don't want to hide low level IOExceptions anymore in buggy code",Improvement,Major,Closed,"2013-10-09 19:06:40","2013-10-09 18:06:40",3
"Sonatype Nexus","If application server settings (optional) is not checked than administration/server page can't be saved.","Uncheck application server settings (optional), under administration/server and save.    Now make another change on the page and attempt to save.  This fails.    Why this section is optional anyhow?",Task,Major,Closed,"2013-10-08 20:36:16","2013-10-08 19:36:16",1
"Sonatype Nexus","No task will clean up snapshots from a procurement repository","There is no way to clean up cached artifacts from a procurement repository.     This isn't usually a problem, but in the case of snapshots it definitely is, since these will accumulate over time, and old versions generally aren't needed.    It seems to me the Evict unused proxied items task should work for this use case, since procurement repositories are essentially proxy repositories with rules.    The snapshot removal task is definitely not appropriate, it rewrites the metadata files, and the procurement repository should be serving the metadata from the remote.  ",Task,Major,Closed,"2013-10-08 19:58:26","2013-10-08 18:58:26",2
"Sonatype Nexus","nexus-staging-maven-plugin should record ID of build promotion repository, then use this during release","The nexus-staging-maven-plugin:promote goal currently does not record the build promotion repository.    This makes it difficult to automate a stage->close->promote->release workflow.    If a staging repository has been promoted we should record the ID, and then use this during a subsequent release goal.",Improvement,Minor,Closed,"2013-10-08 15:00:56","2013-10-08 14:00:56",1
"Sonatype Nexus","Staging finish privilege is confusing","The description of the staging finish privilege is confusing.  It appears that this allows a user to close a staging repository associated with a profile?    If so, we should change the description to use the word close.",Bug,Trivial,Closed,"2013-10-07 14:58:44","2013-10-07 13:58:44",1
"Sonatype Nexus","Remove pgp.mit.edu from list of uses SKS Keyservers","nexus-pgp-plugin uses a list of SKS servers to perform signature validation (used by Staging and Procurement plugins).    The default entries are:  * http://pool.sks-keyservers.net:11371/  * http://pgp.mit.edu:11371/    While the first itself is a _SKS server pool_, the latter is a simple standalone one. Moreover, the latter one _was removed from the former's pool_ as it's not maintained. It uses SKS Server version 1.1.1 while the pool is on version 1.1.3, 1.1.4 and above (1.1.4+).    With latest changes (NEXUS-5969 for example), the MIT SKS server will just create log pollution, as for example GPG subkey search is added and works only in SKS Server version 1.1.3 and above    https://bitbucket.org/skskeyserver/sks-keyserver/src/4069c369eaaa718c6d4f19427f8f164fb9a1e1f0/CHANGELOG?at=default#cl-65    Hence, even if the check will succeed, log will contain spam if MIT server is tried first (and we randomly choose servers from the list AFAIK).    Proposed solution: remove MIT from default configuration    More about this: The hostname pool.sks-keyservers.net will be resolved to an actual server based on requester location and other factors. Problem with retries (ie. you got assigned a server that is 0xdeadbeef, unlikely but still possible), is that OS and Java will cache DNS resolution result. A real retry would be to resolve that hostname again, and retry with new IP.  ",Improvement,Trivial,Closed,"2013-10-07 10:48:18","2013-10-07 09:48:18",1
"Sonatype Nexus","remove sonatype-indexer use of _magic_ annotations","A few components use magic to imply jsr-330 annotations.  This should be fixed by putting the proper annotation on the component.    {quote}  jvm 1    | 2013-10-04 10:26:44 WARN  [jetty-main-thread-1]  org.sonatype.guice.nexus.scanners.NexusTypeVisitor - Found legacy @org.sonatype.plugin.Managed annotation: com.sonatype.index.api.SearcherRegistry  jvm 1    | 2013-10-04 10:26:44 WARN  [jetty-main-thread-1]  org.sonatype.guice.nexus.scanners.NexusTypeVisitor - Found legacy @org.sonatype.plugin.Managed annotation: com.sonatype.index.api.IndexerRegistry  jvm 1    | 2013-10-04 10:26:44 WARN  [jetty-main-thread-1]  org.sonatype.guice.nexus.scanners.NexusTypeVisitor - Found legacy component relying on @org.sonatype.plugin.Managed magic to automatically imply @javax.inject.Named @javax.inject.Singleton: com.sonatype.index.rdf.internal.DefaultRdfIndexFactory  jvm 1    | 2013-10-04 10:26:44 WARN  [jetty-main-thread-1]  org.sonatype.guice.nexus.scanners.NexusTypeVisitor - Found legacy @org.sonatype.plugin.Managed annotation: com.sonatype.index.rdf.RdfIndexFactory  jvm 1    | 2013-10-04 10:26:44 WARN  [jetty-main-thread-1]  org.sonatype.guice.nexus.scanners.NexusTypeVisitor - Found legacy component relying on @org.sonatype.plugin.Managed magic to automatically imply @javax.inject.Named @javax.inject.Singleton: com.sonatype.index.base.internal.DefaultSearcherRegistry  jvm 1    | 2013-10-04 10:26:44 WARN  [jetty-main-thread-1]  org.sonatype.guice.nexus.scanners.NexusTypeVisitor - Found legacy component relying on @org.sonatype.plugin.Managed magic to automatically imply @javax.inject.Named @javax.inject.Singleton: com.sonatype.index.base.internal.DefaultIndexerRegistry  {quote}  ",Improvement,Major,Closed,"2013-10-04 19:14:57","2013-10-04 18:14:57",1
"Sonatype Nexus","Clean up use of injection in nexus-custom-metadata-plugin","There is a lot of crude here due to legacy problems with initial plexus -> guice conversion.  These components can/should be simplified.",Improvement,Major,Closed,"2013-10-04 18:42:45","2013-10-04 17:42:45",2
"Sonatype Nexus","Replace usage of mercury in PGP plugin with Bouncy Castle",,Improvement,Minor,Closed,"2013-10-04 14:58:27","2013-10-04 13:58:27",3
"Sonatype Nexus","Remove Managed and ExtensionPoint",,Improvement,Major,Closed,"2013-10-03 21:52:52","2013-10-03 20:52:52",5
"Sonatype Nexus","improve logging for signature validation failures","Failures validating signatures on ossrh.    unfortunately the logging of the failures are not helping diagnose the issue    The current logs really don't say much of anything ... just a null message at the end of the line where one would expect something helpful.    {quote}  jvm 1    | 2013-10-03 03:55:22 DEBUG [pxpool-1-thread-20] xxxxxxxxx com.sonatype.nexus.pgp.DefaultPGPKeyManager - Signature invalid for artifact: /io/netty/netty-transport-sctp/4.0.10.Final/netty-transport-sctp-4.0.10.Final.jar: null  {quote}    See OSSRH-5675    Improve the logging so we can find out what is wrong.  ",Bug,Critical,Closed,"2013-10-03 21:07:12","2013-10-03 20:07:12",2
"Sonatype Nexus","provide option to not poll for staging operation success using nexus-staging-maven-plugin and ant tasks","In some cases, user may not want to wait to see if nexus-staging  operations are successful.    Their workflow may be that they will manually check later to see if close,promote,drop,release failed or wait for notification email. This is especially relevant where staging operations take a long time to complete.    nexus-staging-maven-plugin and nexus-ant-tasks should expose such an option, the default preserving the current behavior.   ",Improvement,Minor,Closed,"2013-10-02 19:04:48","2013-10-02 18:04:48",3
"Sonatype Nexus","Search indexes are not propagated through procurement repositories","If you create a procurement repository against a repository that has indexes the search indexes of the source are not made available through the procurement repository.    This is similar to NXCM-1593, but not quite the same.  NXCM-1593 got bogged down in a discussion about applying procurement rules to search indexes.    I don't think that is necessary.  In fact, one could argue it would be a good thing to be able to see everything that is available in the procurement repository through the indexes.  That way end users could ask their nexus administrators to allow access.    This *is* similar to NXCM-5515, in that the (partial) workaround is to allow read access to the source repository, which kind of defeats the purpose of procurement.  ",Bug,Major,Closed,"2013-10-02 17:40:04","2013-10-02 16:40:04",3
"Sonatype Nexus","defacto jetty.xml and examples need cleanup","Worked on a customer issue with our Jetty examples for https redirect. In the process discovered our example is outdated and even the defacto jetty.xml could be simplified a bit.    This issue is to note these changes are needed and tie an issue to improvements I will submit a pull request for.        ",Bug,Minor,Closed,"2013-10-02 16:53:58","2013-10-02 15:53:58",1
"Sonatype Nexus","Versioned Yum repositories are empty albeit there are packages with requested version","Using repositories via Yum works just fine but the versioned ones are always empty.    E.g. we have a repository at    http://localhost:8081/nexus/content/repositories/foo/    For this the Yum: Generate Metadata capability is enabled and it can be used as a Yum repository just fine.    When we try to access this repository via a versioned URL, e.g.    http://localhost:8081/nexus/service/local/yum/repos/foo/13.10/    we get a 404 with Couldn't find version or alias '13.10' in repository 'foo'.    In filelist.xml.gz bellow $SONATYPE_WORK/nexus/storage/foo/repodata there are entries like the following:    <package pkgid=a27c49be3c6567d4696d54b0880d9929dfbc2581a62d76c82722d27bfe43a5cf name=foo-awesome-app arch=noarch>      <version epoch=0 ver=13.10 rel=SNAPSHOT20131002080022/>    so the version is the correct one and those packages should show up in the versioned repository.    Expected result: those packages showing up when using http://localhost:8081/nexus/service/local/yum/repos/foo/13.10/ as yum repository.",Bug,Major,Open,"2013-10-02 11:18:44","2013-10-02 10:18:44",3
"Sonatype Nexus","System property http.proxyHost incompatible regular expressions, server wide","We are running nexus and jenkins on the same tomcat server.  When setting the proxy settings in nexus, these settings are saved in proxy system properties. These properties are shared for everything running in tomcat. Nexus requires the non proxy hosts to be configured as regular expressions. This leads to a system property http.nonProxyHosts=.\*\.honda-eu\.com|.\*\.eu\.honda\.com. This is however not a valid value according to http://docs.oracle.com/javase/7/docs/technotes/guides/net/proxies.html (This is a list of patterns separated by '|'. The patterns may start or end with a '*' for wildcards. Any host matching one of these patterns will be reached through a direct connection instead of through a proxy.).   In short: if nexus uses it's own proxy configuration standards, it should not modify, nor use the system properties.",Bug,Minor,Closed,"2013-10-02 10:12:34","2013-10-02 09:12:34",1
"Sonatype Nexus","Detect when smartproxy nodes have out-of-sync clocks","When smartproxy nodes have clocks which are out of sync, all sorts of strange problems can happen.  Smartproxy should try and detect if the clocks are out of sync and complain, perhaps even on handshake report failure to connect if clocks are out-of-sync?",Improvement,Minor,Closed,"2013-10-01 20:17:20","2013-10-01 19:17:20",3
"Sonatype Nexus","Yum proxy repository metadata is not refetched if request for it comes through a group repo","Create a group repository that contains a hosted repository which has yum metadata generation enabled, and also a proxy repository of a remote which contains yum metadata.  Create a merge metadata capability for this group.    Requests for metadata to the group for repodata/repomd.xml never trigger a request to the proxy repository's remote for this file, regardless of cache timeout settings.    This means that new artifacts created on the remote will never become available through the group.",Bug,Major,Closed,"2013-10-01 18:44:52","2013-10-01 17:44:52",2
"Sonatype Nexus","Old yum metadata is never cleaned up from yum proxy repository.","Every time an rpm is deployed into a yum repository it causes a brand new set of metadata files to be created (these all have sha1 sums embedded in their file names).    If you have a proxy of a yum repository, this means a new version of the metadata is downloaded every time, and after a while these consume significant space.    Maybe if repmod.xml is downloaded we should remove the rest of the metadata files from the repodata directory?    {quote}  $ ls  003bfcf89201c1a2ed591531c66effc3a4e027fe641d219377684a9aeba20169-filelists.xml.gz  08828c0881e310aa4dbee6214d077e8e15ad90b6254a01e1598cb69d3cb5c14f-other.sqlite.bz2  150aa0c323606b53090b01d44e73e58ea776df12a2523a99d82e027b908921b0-other.xml.gz  186e3ab67ffc76df9b164dc119b7a5f3cf265fde19da2531e79a9baa5068879d-filelists.sqlite.bz2  189a204d4d0469e105bba086656705cac04c3d1f2eae3b02aa5f3dc4b3b64a97-other.xml.gz  27cad8418cc46a381004ca03cc8b6cd8b74d74710b3ea034704824e45ceebd5a-filelists.sqlite.bz2  2d3d0431515ec9755030d618befb82c9fcee5c10dc6478714d639751eebb3a8b-other.sqlite.bz2  3df248f0d472c45e332dc77ce63634f1332f0a8e358c60975e312adafe0a3013-filelists.sqlite.bz2  54c03951fe73f3e64ba4025674fde4ba6165a2ea97b56c4286a084bf9baf6799-filelists.sqlite.bz2  5c7e42b0f096cbfc6fb2dec96db01164ee34fd55d5f198297b96b91aea7d79d3-filelists.xml.gz  62983c24247ac537efb30fb84e49757ee5692cc8371f278056aa5431eab55370-other.sqlite.bz2  69cc43f574f49aced9f79fb3d0935ba73201de4bde6f8eb01bfd15ee38e7a61a-primary.sqlite.bz2  6eab60c43f89ac10ee6dce5ef815428c0987afc77f09ce92176bd37ee40559c3-filelists.sqlite.bz2  70d7278e115f2d601cb50f4c9898d8bc0b16e647357d4db1423b80ce712cadf1-primary.sqlite.bz2  7b42db3950a9cd7a36f0bfeca78d84e7bd07d4f12c6a2cf2215570f9b8ec1f2a-other.sqlite.bz2  82d364e082b4d24d74a95e8fa9428cf29753252a205799b87fad8984930afd1f-primary.xml.gz  87ce8c5229877bb63e873f20cdc69a8b1d2a0678de1252702c4aed52c415fd95-other.xml.gz  8ced9f96f28df680e23529ebea075e267b4ae0756086a27c85407c93fa53bcf4-primary.xml.gz  8e2dc4494bb4ac5d799034b42bc4afab80d66ed5a466a15a7bc5f92c2b7c8a30-other.xml.gz  91610135649ef8059312f7d935860d272c759bd0edce7cd9fed2bff0b097fe29-other.xml.gz  9c20ae2b5b43e13b0d385bdb70dacaf486ca75c507a2e440c175fe635ba49cfa-other.sqlite.bz2  a87708732e325a1eeff6c3bddbba184d251c5baafcf571e687bc2238958ffc6a-primary.sqlite.bz2  a93b808d31f4cfec7b1ae8463270e0cd6fd30206a16545196c08a810d4890c9e-primary.xml.gz  b5e7ffa0b66e1199ec7580e3bd14f92d9a63cf2eedc979d53880d916f919a0c4-filelists.xml.gz  d9abd67d9db26be5e9303a529965b482505feca7e49f739ccb1a1b7794a31669-primary.sqlite.bz2  e3acecf7d4dc3d35b6757593d65d6840d17d2e68bf4aa4e33cf9b235d7ca4d44-primary.xml.gz  e5288252c53835b15d1a3cfb1ee79d9fabc7e41a4039518f2c5461b04928bc6f-primary.xml.gz  ebabb5cdcfd90b56ba9c1250958c01442f266ba5d0d4c287a99509de5f85f7b3-filelists.xml.gz  ebc9769b8b38af08a612a420bf5107b4a50f9d9517c7c218ca6bc7382aa24f7d-primary.sqlite.bz2  eda629e1037985fa72aeb80c0054d5638fcbb0265624091b369a513ffbc00399-filelists.xml.gz    {quote}",Bug,Minor,Closed,"2013-10-01 18:31:47","2013-10-01 17:31:47",3
"Sonatype Nexus","Automatic routing interferes with yum repo metadata","See here, the automatic routing prefix file contains the yum metadata files:    {quote}  ## repository-prefixes/2.0  #  # Prefix file generated by Sonatype Nexus  # Do not edit, changes will be overwritten!  /repodata/ebabb5cdcfd90b56ba9c1250958c01442f266ba5d0d4c287a99509de5f85f7b3-filelists.xml.gz  /repodata/e5288252c53835b15d1a3cfb1ee79d9fabc7e41a4039518f2c5461b04928bc6f-primary.xml.gz  /repodata/6eab60c43f89ac10ee6dce5ef815428c0987afc77f09ce92176bd37ee40559c3-filelists.sqlite.bz2  /repodata/91610135649ef8059312f7d935860d272c759bd0edce7cd9fed2bff0b097fe29-other.xml.gz  /repodata/8e2dc4494bb4ac5d799034b42bc4afab80d66ed5a466a15a7bc5f92c2b7c8a30-other.xml.gz  /archetype-catalog.xml  /repodata/62983c24247ac537efb30fb84e49757ee5692cc8371f278056aa5431eab55370-other.sqlite.bz2  /com/mycompany  /repodata/a93b808d31f4cfec7b1ae8463270e0cd6fd30206a16545196c08a810d4890c9e-primary.xml.gz  /repodata/2d3d0431515ec9755030d618befb82c9fcee5c10dc6478714d639751eebb3a8b-other.sqlite.bz2  /repodata/eda629e1037985fa72aeb80c0054d5638fcbb0265624091b369a513ffbc00399-filelists.xml.gz  /repodata/186e3ab67ffc76df9b164dc119b7a5f3cf265fde19da2531e79a9baa5068879d-filelists.sqlite.bz2  /repodata/54c03951fe73f3e64ba4025674fde4ba6165a2ea97b56c4286a084bf9baf6799-filelists.sqlite.bz2  /repodata/189a204d4d0469e105bba086656705cac04c3d1f2eae3b02aa5f3dc4b3b64a97-other.xml.gz  /repodata/9c20ae2b5b43e13b0d385bdb70dacaf486ca75c507a2e440c175fe635ba49cfa-other.sqlite.bz2  /repodata/70d7278e115f2d601cb50f4c9898d8bc0b16e647357d4db1423b80ce712cadf1-primary.sqlite.bz2  /repodata/repomd.xml  /repodata/69cc43f574f49aced9f79fb3d0935ba73201de4bde6f8eb01bfd15ee38e7a61a-primary.sqlite.bz2  /repodata/8ced9f96f28df680e23529ebea075e267b4ae0756086a27c85407c93fa53bcf4-primary.xml.gz  /repodata/d9abd67d9db26be5e9303a529965b482505feca7e49f739ccb1a1b7794a31669-primary.sqlite.bz2  /repodata/5c7e42b0f096cbfc6fb2dec96db01164ee34fd55d5f198297b96b91aea7d79d3-filelists.xml.gz  {quote}    These file names (the ones with the embedded checksums) change every time an rpm is deployed into a yum enabled repo.  This means that every time an rpm is deployed the files listed in the repomod.xml file will not be available for download until auto-routing is fetched again, regardless of cache timeout settings.",Bug,Major,Closed,"2013-10-01 18:18:50","2013-10-01 17:18:50",2
"Sonatype Nexus","@EventBus.Managed is problematic at best and should be removed","At least 11 usage of this in nexus-core, could be more in pro.  Need to remove these.",Bug,Minor,Closed,"2013-09-30 22:26:04","2013-09-30 21:26:04",2
"Sonatype Nexus","Need workaround for cases where trial installer cannot be run.","We've found that the Linux installer cannot always be run successfully.  Typically causes of this are lack of X11 libraries (NXCM-4628) or strange http proxy setups.    For cases where the installer fails we need a way to provide Nexus Pro + trial configuration without a full installer.  This could be the standard pro distribution + a trial configuration bundle for instance.    ",Improvement,Minor,Closed,"2013-09-30 14:55:52","2013-09-30 13:55:52",3
"Sonatype Nexus","enable sorting of scheduled tasks columns","Scheduled tasks are sorted by Name as default. There are no other sort options.    For a Nexus Pro with many tasks, this is very frustrating, since you often want to look at tasks by Type instead. However, there are no sort options for any of the columns. The number of task entries is quite large now due to the many Healthcheck related tasks there.    Look at RSO for an example.",Improvement,Trivial,Closed,"2013-09-30 13:43:56","2013-09-30 12:43:56",1
"Sonatype Nexus","Remove CLM config in favor of a capability","CLM configuration should be replaced with a capability.     Advantages:  * status (show connection status)  * drop code for reading xml    Disadvantages:  * requires upgrade step  * book updates?",Improvement,Major,Closed,"2013-09-29 13:45:43","2013-09-29 12:45:43",2
"Sonatype Nexus","Repository is auto-blocked if allow file browsing is disabled on remote","If you disable allow file browsing on a hosted repository, and then create a proxy repository to it in another Nexus instance the repository will be auto-blocked.    We should be able to handle this situation, there are well known paths that can be used for testing such as /.meta/repository-metadata.xml.    Rich  ",Bug,Major,Closed,"2013-09-27 15:50:28","2013-09-27 14:50:28",2
"Sonatype Nexus","Add support for tagging to capabilities","The should be possible to tag capabilities at descriptor/capability level with key/value information.    The information should be used in capabilities UI to allow grouping based on available tags.    Examples:    * mark all smart proxy capabilities with a Category Smart Proxy tag  * mark all security related capabilities with a Category Security tag  * mark all capabilities that are specific to a repository with a Repository <Repository Name> tag",Improvement,Minor,Closed,"2013-09-26 14:58:15","2013-09-26 13:58:15",1
"Sonatype Nexus","Rewrite Capabilities UI",,Improvement,Minor,Closed,"2013-09-26 12:26:09","2013-09-26 11:26:09",1
"Sonatype Nexus","Remove SimpleResourceLock, replace with sisu-locks implementation","The sisu-locks implementation based on a semephore is simpler and this framework provides JMX integration to allow for manual unlocking in the case of lockup.    We have had this code around for years now, and its exposed in NX but its defaulted to not being used.    We should make the 'local' lock the default, and remove the simple lock implementation.",Improvement,Major,Closed,"2013-09-23 21:04:27","2013-09-23 20:04:27",1
"Sonatype Nexus","expose 'userAgent' on com.sonatype.nexus.staging.client.StagingRepository model","This was requested by a customer and seemingly trivial to implement.    Per https://sonatype.zendesk.com/agent/#/tickets/2680    {quote}  Hi, we need to filter all staging repositories by userAgent. As com.sonatype.nexus.staging.client.StagingRepository is missing the userAgent we have to implement a call to Staging REST /staging/profile_repositories/{profileIdKey} while all other stuff can easily be done with the StagingWorkflowV1Service.    We would really appreciate if the class com.sonatype.nexus.staging.client.StagingRepository would get at least the field userAgent from the additional fields org.sonatype.nexus.restlight.stage.StageRepository had. Can you add it in an upcoming release?    {quote}     ",Improvement,Major,Closed,"2013-09-23 19:03:50","2013-09-23 18:03:50",1
"Sonatype Nexus","Nexus OBR shadow makes Nexus deadlock prone, while reading/writing obr.xml","And this brings down whole instance, as obr.xml processing happens as event handler execute in sync with the operation making event handler kick in (item deploy, delete or so). This leaves guava EventBus SynchronizedEventHandler locked, thunk inhibiting (and blocking) all subsequent thread trying to fire a new event, basically sends Nx down.    Related changes:    Change that went in in Nexus 2.0  https://github.com/sonatype/nexus/commit/9ec293d3728610a1fce4283b4f84931ac8f0b9bf    Issue  https://issues.sonatype.org/browse/NEXUS-4682    Notice how event inspector is _async_, exactly to avoid deadlock. Intent was to decouple shadows, as they were directly impacting Nx performance.    Then another change went in for Nexus 2.0  https://github.com/sonatype/nexus/commit/576e65750442900cbe15553e34021848624da258    Issue  https://issues.sonatype.org/browse/NEXUS-4715    Notice how we made event inspector _sync_ here, this is literally where we introduced the deadlock possibility (as OBR shadow event handling happens in the deployer thread). But, the comment states this should be async and we should resolve this.    And later, in 2.6.0, to reduce load on repository registry, a refactoring happened, but processing still kept async  https://github.com/sonatype/nexus-oss/commit/c802ac0693ed043b2c85c51c26210a6eaf906875    Related pull  https://github.com/sonatype/nexus/pull/156      As we already have issues recorded such as NEXUS-5652, NEXUS-5647 and NEXUS-5642, and many of the imply rewrite (anyway needed to support latest OSGI spec), it might be viable to simply drop OBR shadow repositories and implement them in similar way like we had done with P2 or YUM.",Bug,Major,Closed,"2013-09-23 15:32:26","2013-09-23 14:32:26",3
"Sonatype Nexus","Move nexus-custom-metadata-plugin out of _optional-plugins_ to default installed plugins",,Improvement,Minor,Closed,"2013-09-20 21:17:16","2013-09-20 20:17:16",1
"Sonatype Nexus","Move nexus-unpack-plugin out of _optional-plugins_ to default installed plugins",,Improvement,Minor,Closed,"2013-09-20 21:10:13","2013-09-20 20:10:13",1
"Sonatype Nexus","Remove nexus-user-account-plugin (ie. user sign up plugin)","This has been an _optional-plugin_ in Nexus PRO, and we are trying to remove the _optional-plugin_ concept.    There are much better choices for managing users (jira for example) and IIUC there are no significant users of this plugin.  This plugin needs to go away.",Improvement,Minor,Closed,"2013-09-20 20:53:31","2013-09-20 19:53:31",1
"Sonatype Nexus","Add releaseAfterClose option to the nexus-staging-maven-plugin","It will help our CLM evaluations/deployments a lot if we can add a mode to the nexus-staging-maven-plugin where we immediately release a staging repository if it has been successfully closed. This is because a lot of end users don't want real staging, they just want their deployed artifacts scanned by CLM.    This is possible with the current plugin, but the configuration is quite complex.    I propose doing this with a releaseAfterClose flag.  The default value for this will be false.",Improvement,Major,Closed,"2013-09-20 15:13:19","2013-09-20 14:13:19",1
"Sonatype Nexus","Remove the mirrors tab from hosted repositories","It no longer makes sense to have a mirrors tab in hosted repositories due to NEXUS-5789.    We need to remove this UI also.",Improvement,Minor,Closed,"2013-09-20 15:05:15","2013-09-20 14:05:15",2
"Sonatype Nexus","Remove ability to disable security","There is no reason that a user should disable security.  The fact that it was allowed has actually complicated things.    Users can grant the anonymous user admin role to effectively have the same envrionment which does not require authentication.",Improvement,Minor,Closed,"2013-09-19 21:59:15","2013-09-19 20:59:15",5
"Sonatype Nexus","Make connection request retry attempts work for connection reset exceptions","Currently the request retry count in Nexus http settings does not take effect if a connection reset exception is thrown.    I think we should extend the retry count to work for any SocketException received.",Improvement,Minor,Closed,"2013-09-19 17:23:08","2013-09-19 16:23:08",1
"Sonatype Nexus","Add authorization support to capabilities","Capabilities should support authorisation by being able to provide per capability type (at descriptor level) what permissions are required for a capability to be read/created/updated/deleted.    * Grid entries will be filtered out based on read permission.  * Capability types will be filtered out based on read permission.  * Capability types will be filtered out based on create permission when creating a new capability.  * Capability details will be disabled based on update permission  * Enable/disable a capability will be disabled based on update permission  * Delete button/menu will be disabled based on delete permission  * Permissions will be enforced in backend  ",Improvement,Minor,Closed,"2013-09-19 17:13:56","2013-09-19 16:13:56",5
"Sonatype Nexus","Replace move up/down ordering UX with dialog box","The ordering _feature_ of staging profiles, and ldap servers, is fundamentally broken due to the ability to sort columns.  This results in very confusing experience when anything other than the default sorting by order field is set.    Since this column is not actually shown to users, its also impossible (without reloading the browser page or re-opening the tab) to restore the default sorting order.    The dialog box should show a simple list with primary identifier, which is *not sortable* and provide options to move up/down to reorder.    Save button, will persist the change,  Cancel button (or close dialog) will abort ordering.",Improvement,Minor,Closed,"2013-09-18 21:57:16","2013-09-18 20:57:16",3
"Sonatype Nexus","Licensing page does not mask UI when loading","Should show wait mask always when loading data.",Improvement,Trivial,Closed,"2013-09-18 21:40:52","2013-09-18 20:40:52",1
"Sonatype Nexus","Add order column so that sorting can be restored to default order","If you click on a column header in the staging profiles list it will sort the column.  This is fine, but there is no way to get back to the original order.  And the original order is important, because that shows you the evaluation order.    We should add a clear sort button to the toolbar that removes any column specific sorting.",Improvement,Minor,Closed,"2013-09-17 16:25:41","2013-09-17 15:25:41",0
"Sonatype Nexus","Server form validation errors should not log at WARN level","Many simple form validation errors are logged at WARN level. These are not critical errors and should be logged at DEBUG instead since a user receives a suitable error in the UI in these cases.    Example:  ",Improvement,Major,Closed,"2011-06-21 20:27:57","2011-06-21 19:27:57",0
"Sonatype Nexus","RUTAUTH plugin should auto enable Realm when capability enabled","RUTAUTH plugin should auto enable Realm when capability enabled.    Still, as capability _has a parameter_ (the header name), I am not clear what should happen the other way: user enables the Realm without configuring capability... (to have it behave in symmetrical way: would not matter do you enable capability or the Realm, it would just work).    Maybe have some predefined default value for HTTP header like REMOTE_USER and use that to auto-activate Capability?",Improvement,Major,Closed,"2013-09-11 09:12:15","2013-09-11 08:12:15",1
"Sonatype Nexus","Scheduled task drop down is not sorted","The scheduled task drop down is not sorted, which makes it painful to add new tasks (very difficult to find some of them).",Improvement,Trivial,Closed,"2013-09-10 18:51:19","2013-09-10 17:51:19",1
"Sonatype Nexus","add a log line that prints all the permissions a subject has per request","There are various loggers that will print what permissions are needed to access a particular Nexus resource while a request is being processed.    Problem is I can find no logger that prints all the permissions ( roles/privs ) a specific authenticated principal user has.    Therefore when debugging security problems in Nexus, you effectively only have one side of equation to go by. This often leads to a bunny trail figuring out what to give a Nexus user so they can access a resource.    Please print in one line, all the permissions a requests principal has, unless there is some performance reason this cannot be done.    adding it at TRACE level is fine. DEBUG may be better.        ",Improvement,Major,Closed,"2013-09-04 18:35:46","2013-09-04 17:35:46",3
"Sonatype Nexus","Role ID field should not appear editable after save of External Role Mapping","Add External Role Mapping for crowd  1) Create Mapping  2) Before the mapping is saved, Role ID field is greyed out ( non-edtable ) as expected  3) Save Mapping  4) Role ID field is no longer greyed out, yet still is not editable.    Expected: Role ID filed to remain greyed out.",Bug,Minor,Closed,"2013-08-29 18:05:41","2013-08-29 17:05:41",1
"Sonatype Nexus","Yum Generate Metadata Task does not expose newly deployed RPMs after first metadata generation","1) Create yum-hosted repo  2) Create yum-proxy of yum-hosted  3) Deploy test-artifact rpm to Hosted  4) Generate Yum Metadata on Hosted using scheduled task  5) Notice sonatype-work/tmp/nexus-yum-plugin/.cache-yum-hosted/.packageFiles/yum-hosted.txt contains the test-artifact rpm    ----    1) Manually Update prefixes.txt/automatic routing file for yum-proxy  2) Download test-artifact rpm from Proxy  3) Generate Yum Metadata on Proxy using scheduled task  4) Notice sonatype-work/tmp/nexus-yum-plugin/.cache-yum-proxy/.packageFiles/yum-proxy.txt contains the test-artifact rpm    ----    1) Deploy test-rpm rpm to Hosted  2) Manually Update prefixes.txt/automatic routing file for yum-proxy  3) Download test-rpm rpm from yum-proxy  4) Generate Yum Metadata for yum-proxy    ----    1) Generate Yum Metadata for yum-hosted  ----    Problem: Notice the yum metadata cache for proxy does not include the new test-rpm it only includes the test-artifact rpm    Expected: The second run of generate metadata on proxy should expose metadata for newly downloaded artifacts    Could the reuse of the {{--pkglist}} option prevent the inclusion of the new artifacts?  ",Bug,Major,Closed,"2013-08-25 14:45:27","2013-08-25 13:45:27",2
"Sonatype Nexus","DN values containing , (comma) can result in improperly escaped LDAP filters","Simple concatenation filter values in getGroupMembershipFromGroups method create invalid filter when DN contains escaped characters.  Attached patch resolve this issue.  I can not create tests to demonstrate this issue and working patch because ApacheDS version 1.5.4 used in IT tests also  works incorrect with escaped DN values in attributes   (see https://issues.apache.org/jira/browse/DIRSERVER-1311).",Bug,Major,Closed,"2013-08-22 09:16:41","2013-08-22 08:16:41",1
"Sonatype Nexus","scanning empty central repo to build an index takes unusually long time","Start Nexus, Download central index. At the end of the download, a scan is performed of storage to create local merged index.    What I don't understand is why it takes 23 seconds to scan nothing?      ",Bug,Minor,Closed,"2013-08-21 19:31:29","2013-08-21 18:31:29",5
"Sonatype Nexus","Repositories -> Browse Remote uses wrong URL on remote and gets HTTP/404","Repositories -> Browse Remote uses wrong URL on remote and gets HTTP/404    I did some debugging with 'tcpdump' network packet checker to see why Remote Browse did not work when it works in Firefox.    The prefix that is configured into the remote repo URL is emitted twice:    Nexus config: Remote Storage Location => http://maven.repository.redhat.com/techpreview/all/    Actual URL in HTTP request from Nexus 2.6.1-02 is:    GET /techpreview/all//techpreview/all/?delimiter=/ HTTP/1.1    The Server then responds with HTTP/404 Not Found.",Bug,Minor,Closed,"2013-08-21 03:20:46","2013-08-21 02:20:46",1
"Sonatype Nexus","File content validation for XML files fails if file only contains whitepace","Something strange is going on with this server, it is full of artifacts like this one that contain nothing but 99 spaces:    http://repo-demo.jfrog.org/artifactory/simple/repo1-cache/com/disney/pubsys/gopublish/cms/cms/6.4.3.0002/cms-6.4.3.0002.jar    Unfortunately this is proxied by grails:    http://repo.grails.org/grails/core/    And if Nexus has a proxy of either of these it starts to store the invalid files as artifacts.    We should modify file content validation.  If a file is a candidate for validation we should first pass it through String.strip().  If the result is zero length we should reject it.    ",Bug,Trivial,Closed,"2013-08-16 21:44:43","2013-08-16 20:44:43",1
"Sonatype Nexus","[p2] serve jarred repository metadata","nexus p2 plugin should serve jarred repository metadata and not raw xml files",Improvement,Minor,Closed,"2008-11-24 17:23:45","2008-11-24 17:23:45",2
"Sonatype Nexus","/service/local/status resource creates http sessions","Starting in Nexus 2.1, authenticated requests to /service/local/status are creating http sessions, even despite a user agent that should not create sessions:    {noformat:title=Nexus 2.1}  > for i in {1..2}; do curl -u admin:admin123 http://localhost:2100/nexus/service/local/status -I -H User-Agent: curl/; done  HTTP/1.1 200 OK  Date: Fri, 16 Aug 2013 14:32:23 GMT  Set-Cookie: JSESSIONID=64b626d9-5cd4-490b-bdfc-d22221b19191; Path=/nexus; HttpOnly  Set-Cookie: rememberMe=deleteMe; Path=/nexus; Max-Age=0; Expires=Thu, 15-Aug-2013 14:32:23 GMT  Content-Type: application/xml; charset=UTF-8  Date: Fri, 16 Aug 2013 14:32:23 GMT  Vary: Accept-Charset, Accept-Encoding, Accept-Language, Accept  Server: Noelios-Restlet-Engine/1.1.6-SONATYPE-5348-V4  Content-Length: 10983    HTTP/1.1 200 OK  Date: Fri, 16 Aug 2013 14:32:24 GMT  Set-Cookie: JSESSIONID=bb59fe42-0019-4583-b1ba-ea81f0948fd7; Path=/nexus; HttpOnly  Set-Cookie: rememberMe=deleteMe; Path=/nexus; Max-Age=0; Expires=Thu, 15-Aug-2013 14:32:24 GMT  Content-Type: application/xml; charset=UTF-8  Date: Fri, 16 Aug 2013 14:32:24 GMT  Vary: Accept-Charset, Accept-Encoding, Accept-Language, Accept  Server: Noelios-Restlet-Engine/1.1.6-SONATYPE-5348-V4  Content-Length: 10983      There is a cookie IT that apparently does not check for this specific condition because it has been passing:    testsuite/legacy-testsuite/src/test/java/org/sonatype/nexus/testsuite/security/nexus4257/Nexus4257CookieVerificationIT.java    Also I can no longer find anywhere in code where specific user agents strings are checked in order to decide if a session should be created.    NexusApplication.java adds some noSessionCreation filter bits, but it is not entirely obvious how all this works.        ",Bug,Minor,Closed,"2013-08-16 15:40:16","2013-08-16 14:40:16",1
"Sonatype Nexus","Remove Releases by Time","The Remove Releases from Repository Scheduled Task only lets you choose the minimum number of GA releases to keep.  It would be nice to be able to apply an age filter as well, to keep all GA releases newer than some age (eg 6months), even it the number of releases within that age exceeds that number.    This is similar to the Remove Snapshots from Repository, and I hope that sharing the code for those options between the tasks would not be a difficult thing to add to Nexus.",Improvement,Minor,Closed,"2013-08-13 16:17:12","2013-08-13 15:17:12",2
"Sonatype Nexus","RequireJS Load timeout for modules on slow ISP","Using Nexus 2.5.1-01, RequireJS timed out due to slow ISP.        Our ISP in Indonesia is probably slow by US/EU standards, and bad latency. We're accustomed to waiting minutes for a complex page to load but this depends that the browser/scripts won't give up first. RequireJS should be configured by default to have higher timeout value.",Bug,Minor,Closed,"2013-07-19 08:14:34","2013-07-19 07:14:34",1
"Sonatype Nexus","migrate nexus-yum-plugin to nexus-oss repo","nexus-yum-plugin should be moved to nexus-oss git repo for build simplicity.    After a brief discussion with <USER> it looks like the following need to happen:    1) Make any unit tests no depend on any external cmd line tools. If the tests require repotool, then convert to ITs.  2) Move into nexus-oss, but also change the GA of the plugin to match rest of Nexus oss plugins. Also change the version to match nexus-oss version   3) Update nexus-oss bamboo.zion jobs to make sure that ITs for this plugin can run on the appropriate agents with required cmd line tool    ",Improvement,Minor,Closed,"2013-07-18 17:08:52","2013-07-18 16:08:52",2
"Sonatype Nexus","Remove use of Plexus components in Nexus","Plexus is getting just in our way lately.    I had a long time spent on changes made to Scheduler, that somehow affected Shiro (that is defined using Guice Module), and it seems it was in relation how sisu-guice-plexus components bridging are done, and in a moment you change the object graph (plexus, plexus-sisu, plexus-guice-sisu, etc), all things happen. Even worse, the problems I saw (for example, Realms not injected or discovered) are stochastic, meaning one run did pass, other run failed, etc.    We need to get rid of use of Plexus is nexus as soon as possible (naturally, leaving plexus shim around), not code against plexus anymore, and convert what we have (most hot spots are done already, mechanic changes are remaining -- mostly).",Improvement,Blocker,Closed,"2013-06-13 14:20:28","2013-06-13 13:20:28",13
"Sonatype Nexus","Add repository target setting to snapshot remover","For organizations that make heavy use of repository partitioning using repository targets it can be desirable to have different snapshot removal policies for these partitions.    We should add a repository target to the snapshot removal task's configuration.",Improvement,Major,Closed,"2013-05-17 22:17:23","2013-05-17 21:17:23",2
"Sonatype Nexus","Replace custom timing in nx components with metrics timers","Several components in NX use custom timing logic and expose via jmx, etc.  Now that we have metrics integration we should normalize all components to use this to provide a consistent and coherent view to monitoring tools.",Improvement,Minor,Closed,"2013-04-24 23:43:44","2013-04-24 22:43:44",2
"Sonatype Nexus","Add support to detect/register metrics healthcheck components","Nexus metrics integration exposes /internal/healthcheck but does not presently provide a simple mechansim to discover healthcheck compnoents and register them.    A simple sisu-mediator component would simplify implementation of new heathcheck components.",Improvement,Trivial,Closed,"2013-04-24 23:41:55","2013-04-24 22:41:55",2
"Sonatype Nexus","Update metrics integration to 3.x","metrics 2.x is no longer supported/maintained.  Need to update to 3.x.    this has some implications on the guice/aop integration which is no longer part of the main distribution.",Improvement,Major,Closed,"2013-04-24 23:39:14","2013-04-24 22:39:14",3
"Sonatype Nexus","REST API documentation for /repositories/{repositoryID}/content is missing","There isn't any documentation for the /repositories/{repositoryID}/content rest endpoint.",Bug,Major,Closed,"2013-04-18 14:03:58","2013-04-18 13:03:58",1
"Sonatype Nexus","Disabled security not happy with shiro annotations","Cannot access shiro protected jersey resources when security is disabled.",Bug,Major,Closed,"2013-04-16 12:59:55","2013-04-16 11:59:55",3
"Sonatype Nexus","Capabilities icon column showing ... on IE","Looks like extjs is rendering ... for the icon column on IE due to it thinking there is not enough room for the entire content.    Should increase the column width slightly to avoid this.",Improvement,Trivial,Closed,"2013-03-26 21:49:33","2013-03-26 21:49:33",0
"Sonatype Nexus","Ugly 404 reply from site repository","This could be cleaned up.  Not sure why the toString() value is used here.",Improvement,Trivial,Closed,"2013-03-20 02:07:29","2013-03-20 02:07:29",1
"Sonatype Nexus","Use logging framework for js","console implementations are pretty broken on some browser. UI should use a logging framework like e.g. http://log4javascript.org to have reliable logging in place.    Bonus: log4javascript would be able to log remotely to Nexus backend",Improvement,Major,Closed,"2013-02-21 18:27:45","2013-02-21 18:27:45",5
"Sonatype Nexus","improve SNAPSHOT version detection when deploying release artifact to SNAPSHOT repository","I know this is an odd case, but please bare with me.    We are evaluating using Ivy (standalone) for our dependency management in a complex project where the artifact repository manager would be Nexus.    I noticed that Nexus doesn't seem have a built-in check for what version you're trying to deploy your artifact with. For example, if you're trying to deploy an artifact with a SNAPSHOT version to a release repository, it should fail in order to preserve consistency.    I tried the following (by mistake) and it managed to successfully deploy a non-SNAPSHOT artifact to a snapshot repository:        In the example above, nexus-snapshots obviously points to a snapshot repository (which I'd forgotten to replace properly).    I believe there should be a check for whether the version of the artifact is acceptable for the repository.  ",Bug,Major,Open,"2013-02-08 15:30:59","2013-02-08 15:30:59",1
"Sonatype Nexus","Nexus upgrade does not properly back up changed configuration files.","Start with a sonatype-work directory created with Nexus 2.1.2, and then upgrade it to 2.3.0-04.    Two problems emerge.    First, nexus.xml.bak contains:    {code:XML}    <version>2.2.0</version>    <nexusVersion>2.3.0-04</nexusVersion>      Second, logback-events.xml was changed, but logback-events.xml.bak was not created.    So a user cannot role back to the previous release without manually editing two files.    ",Bug,Major,Closed,"2013-01-28 19:44:26","2013-01-28 19:44:26",2
"Sonatype Nexus","Nexus does not strip trailing spaces from URL's in proxy repository configuration","Nexus does not strip trailing spaces from remote URL's in proxy repository configuration.    Not sure if this is a regression or not.",Bug,Minor,Closed,"2013-01-22 14:58:38","2013-01-22 14:58:38",0
"Sonatype Nexus","P2 Metadata not generating for public group","I set up three M2 repositories for hosting p2 artifacts (snapshot, release, third-party). I added these three repositories to an M2 group. I then configured the P2 Metadata Generator and P2 Repository Aggregation plugins to point to the group.    The p2 repository config files (artifacts.xml and content.xml) are present in .meta/p2, but they do not contain any actual information. I've attached the generated output.    If I change the Nexus plugins to point to just one of the repositories directly, the metadata for that repository seems to be generated correctly. I also tried using a P2 group, but that produced the same results.    Let me know if I can provide more information. Thanks.",Bug,Minor,Closed,"2013-01-11 18:47:05","2013-01-11 18:47:05",1
"Sonatype Nexus","com.google.inject.internal.util.Stopwatch very very loud at DEBUG","Flip on DEBUG (in the NX UI) restart nexus, lots of these show up:        ... not super useful.",Bug,Trivial,Closed,"2012-12-15 20:46:02","2012-12-15 20:46:02",0
"Sonatype Nexus","Make easy to implement a capability","Make possible to implement capabilities just by having annotations on class/properties. This will cover most of the use cases.   For more complex implementations, one should still be able to use the current way of implementing capabilities",Improvement,Trivial,Closed,"2012-11-30 12:14:39","2012-11-30 12:14:39",5
"Sonatype Nexus","Multi selection lists field type","Add new type of property that will allow multi-selection from a list",Improvement,Trivial,Closed,"2012-11-30 11:53:31","2012-11-30 11:53:31",3
"Sonatype Nexus","[capabilities] Dynamic source for selections for combos","Dynamic source for selections = be able to define that the source for a combo or (multi)selection lists.     The field definition will have an ID or rest path to be called to get the list to be displayed. On server side there should be a rest resource that will respond with a generic list of key/value pairs.  Once this is done also the js of capabilities and tasks can be simplified by removing the internal hardcoded repositories combo handling.  Advantages are that specific lists can be done for example to only select proxy repositories/groups/...    We should consider also including some eventual filter beside of type so we do not have to define multiple sources when they return same kind of data just filtered as for example the repositories groups/proxy example.    In case of yum capabilities this will allow selection of Repository targets to be included in views concept.  In case of SP plugin this could be used to allow only proxies for Subscribe capability or select the format of File Sink.",Improvement,Major,Closed,"2012-11-30 11:49:35","2012-11-30 11:49:35",2
"Sonatype Nexus","Group Yum metadata not regenerated when a member proxy repository metadata changes","When yum metadata changes in a proxy repository (new files retrieved), that is included in a yum enabled group, the metadata for group is not regenerated",Bug,Major,Closed,"2012-11-30 11:44:47","2012-11-30 11:44:47",1
"Sonatype Nexus","LDAP Roles show a realm of Nexus when they should be LDAP","When adding an LDAP group as a Role, it still shows a realm of Nexus. We think this may be a display issue because security still functions correctly.",Bug,Minor,Closed,"2012-11-29 16:12:30","2012-11-29 16:12:30",0
"Sonatype Nexus","User able to see all contents of host when browsing remote through proxy","Hello Nexus Support Team,    We have deployed one Nexus host with multiple proxies in other locations. We have identified an issue in which a user, who is Browsing Storage of a repo on the host, is only able to see contents based on that user's defined roles (i.e. the user can only see data underneath their Repository Targets, as expected). However, when the same user goes to a Nexus Proxy and uses the Browse Remote Storage feature, they are able to see all contents of the host. Is this a bug or by design? Basically, we were expecting the same level of permissions on the host (using Browse Storage) to also apply on the proxy (using Browse Remote Storage) so that users are unable to see contents they shouldn't have access to.",Bug,Major,Closed,"2012-11-29 15:56:18","2012-11-29 15:56:18",0
"Sonatype Nexus","Nexus should lock the work directory to prevent multiple processes using it","Nexus should lock the work directory to prevent multiple processes using it.    Nexus should try to lock the workdir in a moment it's location is known, and should release the lock when it stops.    This would prevent to have multiple instances use the same workdir (by mistake, during upgrade etc).",Improvement,Major,Closed,"2012-10-15 11:38:04","2012-10-15 10:38:04",2
"Sonatype Nexus","LDAP group search should use paged result sets","When attempting to retrieve the list of users associated with a group Nexus will issue the following query if the LDAP server uses dynamic group mapping:        This can return a very large result set.  Nexus isn't currently using paged result sets, so this can result in an OOM, or in the server truncating the result set:    [DefaultLdapGroupDAO.java|https://github.com/sonatype/nexus/blob/master/nexus/nexus-core-plugins/nexus-ldap-plugin-parent/ldap-common/src/main/java/org/sonatype/security/ldap/dao/DefaultLdapGroupDAO.java#L258]    We should be using a paged result set, as shown here:    http://docs.oracle.com/javase/7/docs/api/javax/naming/ldap/PagedResultsControl.html    ",Bug,Major,Closed,"2012-10-10 19:33:52","2012-10-10 18:33:52",5
"Sonatype Nexus","simplify or replace org.sonatype.appcontext","With 51 classes under src/main/java (as of 2012-09-26), appcontext appears too big and complex for what it claims to be -- simple map of configuration sourced from multiple places. It also has bugs in basic behaviour (see test case below), which is likely a side effect of the complexity of the code.    We need to reevaluate functionality provided by appcontext and either drastically simplify the code or completely replace it with something much smaller.        ",Improvement,Major,Closed,"2012-09-27 00:45:23","2012-09-26 23:45:23",8
"Sonatype Nexus","Fix CompositeCapability","CompositeCapability is missing some parts as:    # Combine status from all member capabilities  # Combine description from all member capabilities  # Create an AND between all activation conditions  # Create an AND between all validity conditions",Improvement,Trivial,Closed,"2012-07-23 09:44:35","2012-07-23 08:44:35",0
"Sonatype Nexus","Regression Nexus3546ValidateTransitivePrivsOnGroupsIT.validateGroupsInGroups","Failed  org.sonatype.nexus.integrationtests.nexus3546.Nexus3546ValidateTransitivePrivsOnGroupsIT.validateGroupsInGroups (from Nexus3546ValidateTransitivePrivsOnGroupsIT)   https://builds.sonatype.org/job/nexus-oss-its/337/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus3546/Nexus3546ValidateTransitivePrivsOnGroupsIT/validateGroupsInGroups/  ",Bug,Major,Closed,"2012-07-09 12:04:06","2012-07-09 11:04:06",1
"Sonatype Nexus","Regression Nexus643EmptyTrashTaskIT.emptyTrashTask","Failed    org.sonatype.nexus.integrationtests.nexus643.Nexus643EmptyTrashTaskIT.emptyTrashTask (from Nexus643EmptyTrashTaskIT)      https://builds.sonatype.org/job/nexus-oss-its/337/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus643/Nexus643EmptyTrashTaskIT/emptyTrashTask/    ",Bug,Major,Closed,"2012-07-09 12:02:41","2012-07-09 11:02:41",1
"Sonatype Nexus","Regression Nexus2692EvictAllTaskIT.testEvictAllRepos","Failed  org.sonatype.nexus.integrationtests.nexus2692.Nexus2692EvictAllTaskIT.testEvictAllRepos (from Nexus2692EvictAllTaskIT)   https://builds.sonatype.org/job/nexus-oss-its/335/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus2692/Nexus2692EvictAllTaskIT/testEvictAllRepos/  ",Bug,Major,Closed,"2012-07-09 11:48:48","2012-07-09 10:48:48",1
"Sonatype Nexus","Regression Nexus2692EvictGroupTaskIT.testEvictPublicGroup","Failed  org.sonatype.nexus.integrationtests.nexus2692.Nexus2692EvictGroupTaskIT.testEvictPublicGroup (from Nexus2692EvictGroupTaskIT)   https://builds.sonatype.org/job/nexus-oss-its/335/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus2692/Nexus2692EvictGroupTaskIT/testEvictPublicGroup/  ",Bug,Major,Closed,"2012-07-09 11:46:26","2012-07-09 10:46:26",1
"Sonatype Nexus","Regression Nexus634KeepNewSnapshotsIT.keepNewSnapshots","Regression  org.sonatype.nexus.integrationtests.nexus634.Nexus634KeepNewSnapshotsIT.keepNewSnapshots (from Nexus634KeepNewSnapshotsIT)   https://builds.sonatype.org/job/nexus-oss-its/335/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus634/Nexus634KeepNewSnapshotsIT/keepNewSnapshots/  ",Bug,Major,Closed,"2012-07-09 11:45:36","2012-07-09 10:45:36",1
"Sonatype Nexus","Regression Nexus1022RebuildRepositoryMavenMetadataTaskIT.rebuildMavenMetadata","Regression    org.sonatype.nexus.integrationtests.nexus1022.Nexus1022RebuildRepositoryMavenMetadataTaskIT.rebuildMavenMetadata (from Nexus1022RebuildRepositoryMavenMetadataTaskIT)     https://builds.sonatype.org/job/nexus-oss-its/335/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus1022/Nexus1022RebuildRepositoryMavenMetadataTaskIT/rebuildMavenMetadata/    ",Bug,Major,Closed,"2012-07-09 11:44:38","2012-07-09 10:44:38",1
"Sonatype Nexus","Regression Nexus570IndexArchetypeIT.searchForArchetype","Regression  org.sonatype.nexus.integrationtests.nexus570.Nexus570IndexArchetypeIT.searchForArchetype (from Nexus570IndexArchetypeIT)   https://builds.sonatype.org/job/nexus-oss-its/335/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.integrationtests.nexus570/Nexus570IndexArchetypeIT/searchForArchetype/  ",Bug,Major,Closed,"2012-07-09 11:43:34","2012-07-09 10:43:34",1
"Sonatype Nexus","Regression Nexus384DotAndDashSearchIT.searchAll","Regression  org.sonatype.nexus.integrationtests.nexus384.Nexus384DotAndDashSearchIT.searchAll   https://builds.sonatype.org/view/nexus/job/nexus-oss-its/326/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus384/Nexus384DotAndDashSearchIT/searchAll/  ",Bug,Major,Closed,"2012-06-28 11:24:57","2012-06-28 10:24:57",1
"Sonatype Nexus","Regression: Nexus2554BrokenIndexIT.brokenIndex","Failed  org.sonatype.nexus.plugins.migration.nexus2554.Nexus2554BrokenIndexIT.brokenIndex  https://builds.sonatype.org/view/nexus/job/nexus-migration-plugin/193/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.plugins.migration.nexus2554/Nexus2554BrokenIndexIT/brokenIndex/  ",Bug,Major,Closed,"2012-06-25 15:15:08","2012-06-25 14:15:08",1
"Sonatype Nexus","P2 Proxy repository keeps huge linked hash map in memory","P2 Proxy repository keeps huge linked hash map in memory. With one P2 proxy for Indigo site, it consumes 1/4th of total heap.    By using MAT, it seems it contains all the mappings for the artifacts in memory? Does it mean that Nexus P2 proxy repository memory needs raises with _size of the proxied repository_? Seems wrong.",Bug,Minor,Closed,"2012-06-25 14:52:44","2012-06-25 13:52:44",5
"Sonatype Nexus","Regression: Nexus977GroupOfGroupsIncrementalIndexIT.validateIncrementalIndexesCreated","Regression    org.sonatype.nexus.integrationtests.nexus977.Nexus977GroupOfGroupsIncrementalIndexIT.validateIncrementalIndexesCreated    https://builds.sonatype.org/job/nexus-oss-its/319/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus977/Nexus977GroupOfGroupsIncrementalIndexIT/validateIncrementalIndexesCreated/      ",Bug,Major,Closed,"2012-06-21 10:36:17","2012-06-21 09:36:17",1
"Sonatype Nexus","Regression: Failed Nexus1329MirrorOnlyIT.@BeforeMethod oncePerClassSetUp","Failed    org.sonatype.nexus.integrationtests.nexus1329.Nexus1329MirrorOnlyIT.@BeforeMethod oncePerClassSetUp (from Nexus1329MirrorOnlyIT)     https://builds.sonatype.org/view/nexus/job/nexus-oss-its/316/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.integrationtests.nexus1329/Nexus1329MirrorOnlyIT/_BeforeMethod_oncePerClassSetUp/    ",Bug,Major,Closed,"2012-06-20 16:47:08","2012-06-20 15:47:08",1
"Sonatype Nexus","Snapshots are not correctly published in P2","The .meta/p2/artifacts.xml references wrong version of snapshot artifact if there are more than one snapshot per artifact. Basically it references the first found snapshot instead of the latest one.    For example, we have an artifact com.test-osgi version 1.0.0-SNAPSHOT and  at least 2 snapshots: one from 20120615 and the latest from 20120619.  Looking into .meta/p2/plugins/com.test-osgi_1.0.0.SNAPSHOT.jar we see that there is a proper reference to the latest snapshot:  LINK to snapshots:/com/1.0.0-SNAPSHOT/test-osgi-1.0.0-20120619.082428-7.jar    but .meta/p2/artifacts.xml still includes the oldest available:    <artifact classifier='osgi.bundle' id='com.test-osgi' version='1.0.0.SNAPSHOT'>  <properties size='4'>    <property name='artifact.size' value='2011110'/>    <property name='download.size' value='2011110'/>    <property name='download.md5' value='03e3c736168585ea944d32e004b37138'/>    <property name='repositoryPath' value='com\test-osgi-1.0.0-20120615.072346-3.jar'/>  </properties>  </artifact>      ",Bug,Minor,Closed,"2012-06-19 13:13:39","2012-06-19 12:13:39",2
"Sonatype Nexus","Purging snapshot task should take into account classifier","We deploy multiple classifiers and it would be helpful if the purging task would recognize the artifact's classifier and keep a minimum number of copies of those.    ",Improvement,Major,Closed,"2012-06-11 19:04:38","2012-06-11 18:04:38",2
"Sonatype Nexus","Block access to P2 aggregated repository when capability is disabled","When a P2 aggregator capability is disabled the P2 metadata (.meta/p2) should not be accessible (404).",Improvement,Minor,Closed,"2012-05-21 09:28:52","2012-05-21 08:28:52",1
"Sonatype Nexus","Upgrade to latest Jetty 7.x to solve known denial of service security vulnerabilities","  Upgrading to latest Jetty 7 would eliminate these vulnerabilities.      ",Improvement,Major,Closed,"2012-04-13 16:08:19","2012-04-13 15:08:19",1
"Sonatype Nexus","Regression Nexus2692EvictGroupTaskIT.testEvictPublicGroup","Regression  org.sonatype.nexus.integrationtests.nexus2692.Nexus2692EvictGroupTaskIT.testEvictPublicGroup  https://builds.sonatype.org/job/nexus-oss-its/232/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus2692/Nexus2692EvictGroupTaskIT/testEvictPublicGroup/  ",Bug,Major,Closed,"2012-03-26 13:16:58","2012-03-26 12:16:58",1
"Sonatype Nexus","SMTP config panel uses SSL and TLS incorrectly","SSL enabled and TLS enabled don't do what they say.  SSL and TLS are slight variations of basically the same authentication/privacy protocol.  What the checkboxes actually enable are:    o  (SSL) Start an SSL/TLS session (probably on alternate SMTP port 465) and then start an SMTP session inside it.  This is sometimes referred to as SSMTP.  o  (TLS) Start a plaintext SMTP session (probably on port 25) and then attempt upward negotiation to encrypted by issuing a STARTTLS verb, to start an SSL/TLS session inside the SMTP session.    May I suggest labelling these something like enable Secure SMTP and enable STARTTLS negotiation, and enhancing the tip texts to explain more fully.  (Aside:  the current tip texts essentially just repeat the field labels and add nothing to one's understanding).    Actually, come to think of it, this really should be a single three-state field:  plain SMTP, SMTP-in-TLS, STARTTLS.  It makes no sense to use SSMTP and STARTTLS independently.",Bug,Trivial,Closed,"2012-03-23 16:20:37","2012-03-23 16:20:37",1
"Sonatype Nexus","Uppercase in email domain rejected as invalid","Testing SMTP setup using my own address, which I habitually enter in mixed case (<EMAIL>) kept giving me an invalid address dialog.  It's certainly not invalid -- an RFC2822 address can contain uppercase letters.  Eventually I found SmtpSettingsValidationPlexusResource.EMAIL_PATTERN which contains only a lowercase range in the final character-class brackets.  Simplest way to prevent user surprise is probably to change [a-z] to [a-zA-Z].  (Now that many more TLDs are to be created, it may only be a matter of time before it has to be [a-zA-Z0-9].)",Bug,Minor,Closed,"2012-03-23 16:05:45","2012-03-23 16:05:45",1
"Sonatype Nexus","Get rid of duplicated classes for parsing Artifact Versions","Get rid of duplicated classes for parsing Artifact Versions.    Keep this one (comes from Aether):  org.sonatype.nexus.proxy.maven.version.GenericVersion    Ditch this one (comes from old Mercury):  org.sonatype.nexus.proxy.maven.metadata.operations.ComparableVersion",Improvement,Major,Closed,"2012-03-23 09:15:11","2012-03-23 09:15:11",1
"Sonatype Nexus","DTD in jetty.xml is wrong.","Is:        Should be:        We need to fix this for the main jetty.xml, and also the examples.",Bug,Major,Closed,"2012-03-22 13:54:32","2012-03-22 13:54:32",1
"Sonatype Nexus","Regression Nexus2379MultipleErrorReportIT.validateMultipleErrors","Regression  org.sonatype.nexus.integrationtests.nexus2379.Nexus2379MultipleErrorReportIT.validateMultipleErrors  https://builds.sonatype.org/job/nexus-oss-its/227/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus2379/Nexus2379MultipleErrorReportIT/validateMultipleErrors/  https://builds.sonatype.org/job/nexus-oss-its/227/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.integrationtests.nexus2379/Nexus2379MultipleErrorReportIT/validateMultipleErrors/  ",Bug,Major,Closed,"2012-03-22 11:50:02","2012-03-22 11:50:02",1
"Sonatype Nexus","Regression Nexus2810PluginConsoleIT.testListPluginInfos","Regression    org.sonatype.nexus.integrationtests.plugin.nexus2810.Nexus2810PluginConsoleIT.testListPluginInfos    https://builds.sonatype.org/job/nexus-oss-its/229/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.integrationtests.plugin.nexus2810/Nexus2810PluginConsoleIT/testListPluginInfos/    https://builds.sonatype.org/job/nexus-oss-its/229/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.plugin.nexus2810/Nexus2810PluginConsoleIT/testListPluginInfos/    ",Bug,Major,Closed,"2012-03-22 11:27:50","2012-03-22 11:27:50",1
"Sonatype Nexus","Revert: Link to nexus book logging section in the logger UI","Really would be nice to give user some info on this tab to explain how to further configure nexus logging. Even something pointing to an updated section of http://www.sonatype.com/books/nexus-book/reference/confignx-sect-log.html .    {quote}More information on how to configure logging can be found [here|http://www.sonatype.com/books/nexus-book/reference/confignx-sect-log.html].  {quote}  ",Bug,Major,Closed,"2012-03-22 09:59:40","2012-03-22 09:59:40",1
"Sonatype Nexus","Nexus Maven metadata merge operation should not throw errors on corrupt metadata","Nexus Maven metadata merge operation should not throw errors on corrupt metadata. Today, if you (intentionally or unintentionally) have some corruption happened in Maven Metadata, and you use repository group that tries to merge it on the fly, you will end up with HTTP 500 Internal Error.    Instead, Nexus should emit warning, and simply leave out the corrupt metadata from merge. Typical example:    Caused by: org.sonatype.nexus.proxy.maven.metadata.operations.MetadataException: Could not merge metadata with different groupId: 'rubygems' and 'itext'         at org.sonatype.nexus.proxy.maven.metadata.operations.NexusMergeOperation.perform(NexusMergeOperation.java:118) ~[nexus-proxy-2.0.2.jar:na]         at org.sonatype.nexus.proxy.maven.metadata.operations.MetadataBuilder.changeMetadata(MetadataBuilder.java:111) ~[nexus-proxy-2.0.2.jar:na]         at org.sonatype.nexus.proxy.maven.maven2.M2GroupRepository.doRetrieveMetadata(M2GroupRepository.java:280) ~[nexus-proxy-2.0.2.jar:na]         ... 96 common frames omitted  2012-03-10 12:29:12 ERROR [en-metadata.xml] - org.sonatype.nexus.rest.ContentPlexusResource - Got exception during processing request GET http://repository.sonatype.org/content/groups/sonatype-public-grid/itext/itext/maven-metadata.xml: Got MetadataException during M2 metadata merging.    Other info:    About corrupt metadata:    good one is in Central (proxied by RSO central-proxy):  https://repository.sonatype.org/content/repositories/central-proxy/itext/itext/maven-metadata.xml    But here is that wrong one:  https://repository.sonatype.org/content/repositories/<USER>releases/itext/itext/maven-metadata.xml    Both reposes are members of sonatype-public-grid group, and that's why it cracks when path is GETted:  https://repository.sonatype.org/content/groups/sonatype-public-grid/itext/itext/maven-metadata.xml    Now, unsure about <USER>releases repo but it is a proxy, and it proxies from here:  http://rubygems-proxy.torquebox.org/releases/itext/itext/maven-metadata.xml    And according to error message, the repo policy changed. Before, it was gemizing everything you asked from it (proxied central and turned JARs into GEMs on the fly), but now it seems it enforces rubygems groupId....    The <USER>releases (and I guess -snapshots exists too) should be removed from RSO group, as I guess nobody want GEMs over RSO, but this might break someone if using RSO.....        ---    In this case, Nexus should not abruptly fail with HTTP 500, but do a WARN in logs and leave the broken metadata our from processing.",Bug,Major,Closed,"2012-03-19 13:08:56","2012-03-19 13:08:56",5
"Sonatype Nexus","When setting Publish URL to false, prevent repo Summary tab from displaying 'undefined' distribution management section","If you set the *Publish URL* repository setting to *False* then when you refresh the grid, under the column *Repository Path* it renders a link named *undefined* and url *http://<host>/nexus/undefined*    Also, if the type of the repository is *Hosted* then under the *Summary* tab on the section *Distribution Management* it shows *<url>undefined</url>*    I attached a screenshot. See the red squares.    I traced the REST calls I detected that when if True the response JSON data contains the field data.contentResourceURI with the correct url, but when it is False this field doesn't exists in the response JSON. So I think the undefined showed comes from a Javascript variable concatenation that doesn't exists.    Also this behavior is the opposite of NEXUS-3574 and maybe could be the cause of NEXUS-4064 (which still happens in 2.0.2)",Bug,Minor,Closed,"2012-03-13 15:29:51","2012-03-13 15:29:51",1
"Sonatype Nexus","FSPeer wrongly assumes target.getName is always a good candidate for tmp file creation","FSPeer wrongly assumes target.getName is always a good candidate for tmp file creation.  This might not always be true (especially for non-maven layouted repositories, but even Maven layouted ones might contain such files, made by some custom Nexus plugin or external tooling).  The code in question is here: https://github.com/sonatype/nexus/blob/982f62b530768e490cf83c916d3aa2692d38ede2/nexus/nexus-proxy/src/main/java/org/sonatype/nexus/proxy/storage/local/fs/DefaultFSPeer.java#L316 ",Bug,Major,Closed,"2012-03-12 12:12:20","2012-03-12 12:12:20",1
"Sonatype Nexus","Regression ListStageRepositoriesMojoTest.mavenProxySupportWithAuth","2.0.x branch!   Regression org.sonatype.nexus.plugin.ListStageRepositoriesMojoTest.mavenProxySupportWithAuth  https://builds.sonatype.org/job/nexus-oss-its-2.0.x/23/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.plugin/ListStageRepositoriesMojoTest/mavenProxySupportWithAuth/  ",Bug,Major,Closed,"2012-03-12 09:55:43","2012-03-12 09:55:43",1
"Sonatype Nexus","Regression Nexus3082GenerateProblemReportIT.generateReport","2.0.x branch!    Regression org.sonatype.nexus.integrationtests.nexus3082.Nexus3082GenerateProblemReportIT.generateReport    https://builds.sonatype.org/job/nexus-oss-its-2.0.x/20/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus3082/Nexus3082GenerateProblemReportIT/generateReport/    ",Bug,Major,Closed,"2012-03-12 09:54:21","2012-03-12 09:54:21",1
"Sonatype Nexus","Regression Nexus4538ConcurrentDownloadIT.makeSureConcurrentDownloadisNotSerialized","2.0.x branch!    Regression org.sonatype.nexus.integrationtests.nexus4538.Nexus4538ConcurrentDownloadIT.makeSureConcurrentDownloadisNotSerialized    https://builds.sonatype.org/job/nexus-oss-its-2.0.x/21/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus4538/Nexus4538ConcurrentDownloadIT/makeSureConcurrentDownloadisNotSerialized/    ",Bug,Major,Closed,"2012-03-12 09:52:30","2012-03-12 09:52:30",1
"Sonatype Nexus","DownloadSettingsTemplateMojoTest.backupExistingSettingsInUserConfigDir may fail comparing backup settings.xml file date format","    Partial logs from test show that the date used in the backup file name is different from the date format used in the test:            ",Bug,Major,Closed,"2012-03-12 04:17:09","2012-03-12 04:17:09",1
"Sonatype Nexus","Regression: Nexus4538ConcurrentDownloadIT.makeSureConcurrentDownloadisNotSerialized fails","Windows only.  https://builds.sonatype.org/view/nexus/job/nexus-oss-its/217/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus4538/Nexus4538ConcurrentDownloadIT/makeSureConcurrentDownloadisNotSerialized/    ",Bug,Major,Closed,"2012-03-11 13:07:43","2012-03-11 13:07:43",1
"Sonatype Nexus","Concurrent modification exception in procurement","{quote}  2012-03-09 08:53:24 WARN  [c=1331301204618] - com.sonatype.nexus.procurement.rules.DefaultRuleRegistry - Could not get ArtifactResolutionSet!  java.util.ConcurrentModificationException: null   at java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372) ~[na:1.6.0_29]   at java.util.AbstractList$Itr.next(AbstractList.java:343) ~[na:1.6.0_29]   at com.sonatype.nexus.procurement.rules.DefaultRuleRegistry.matchRules(DefaultRuleRegistry.java:288) ~[nexus-procurement-plugin-2.0.jar:2.0]   at com.sonatype.nexus.procurement.treeview.ProcurementTreeNodeFactory.decorateNode(ProcurementTreeNodeFactory.java:101) [nexus-procurement-plugin-2.0.jar:2.0]   at com.sonatype.nexus.procurement.treeview.ProcurementTreeNodeFactory.decorateGNode(ProcurementTreeNodeFactory.java:43) [nexus-procurement-plugin-2.0.jar:2.0]   at org.apache.maven.index.treeview.DefaultTreeNodeFactory.createGNode(DefaultTreeNodeFactory.java:49) [indexer-core-4.1.3-SONATYPE.jar:4.1.3-SONATYPE]   at org.apache.maven.index.treeview.DefaultIndexTreeView.listNodes(DefaultIndexTreeView.java:90) [indexer-core-4.1.3-SONATYPE.jar:4.1.3-SONATYPE]   at org.sonatype.nexus.index.DefaultIndexerManager.listNodes(DefaultIndexerManager.java:2222) [nexus-indexer-lucene-plugin-2.0.jar:na]   at org.sonatype.nexus.index.DefaultIndexerManager.listNodes(DefaultIndexerManager.java:2211) [nexus-indexer-lucene-plugin-2.0.jar:na]   at com.sonatype.nexus.procurement.DefaultProcurementManager.listNodes(DefaultProcurementManager.java:269) [nexus-procurement-plugin-2.0.jar:2.0]   at com.sonatype.nexus.procurement.api.ProcurementTreeViewPlexusResource.get(ProcurementTreeViewPlexusResource.java:91) [nexus-procurement-plugin-2.0.jar:2.0]   at org.sonatype.plexus.rest.resource.RestletResource.represent(RestletResource.java:249) [plexus-restlet-bridge-1.18.jar:na]   at org.sonatype.nexus.rest.NexusRestletResource.represent(NexusRestletResource.java:44) [nexus-rest-api-2.0.jar:na]   at org.restlet.resource.Resource.getRepresentation(Resource.java:302) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.resource.Resource.handleGet(Resource.java:464) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Finder.handle(Finder.java:353) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.doHandle(Filter.java:150) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.handle(Filter.java:195) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Router.handle(Router.java:504) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.doHandle(Filter.java:150) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.handle(Filter.java:195) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Router.handle(Router.java:504) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.doHandle(Filter.java:150) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.handle(Filter.java:195) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.doHandle(Filter.java:150) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.sonatype.plexus.rest.RetargetableRestlet.doHandle(RetargetableRestlet.java:39) [plexus-restlet-bridge-1.18.jar:na]   at org.restlet.Filter.handle(Filter.java:195) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.doHandle(Filter.java:150) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.handle(Filter.java:195) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.doHandle(Filter.java:150) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.handle(Filter.java:195) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.doHandle(Filter.java:150) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at com.noelios.restlet.StatusFilter.doHandle(StatusFilter.java:130) [com.noelios.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.handle(Filter.java:195) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.doHandle(Filter.java:150) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.handle(Filter.java:195) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at com.noelios.restlet.ChainHelper.handle(ChainHelper.java:124) [com.noelios.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at com.noelios.restlet.application.ApplicationHelper.handle(ApplicationHelper.java:112) [com.noelios.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Application.handle(Application.java:341) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.doHandle(Filter.java:150) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.handle(Filter.java:195) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Router.handle(Router.java:504) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.doHandle(Filter.java:150) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.handle(Filter.java:195) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Router.handle(Router.java:504) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.doHandle(Filter.java:150) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Filter.handle(Filter.java:195) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at com.noelios.restlet.ChainHelper.handle(ChainHelper.java:124) [com.noelios.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Component.handle(Component.java:673) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Server.handle(Server.java:331) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at com.noelios.restlet.ServerHelper.handle(ServerHelper.java:68) [com.noelios.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at com.noelios.restlet.http.HttpServerHelper.handle(HttpServerHelper.java:147) [com.noelios.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at com.noelios.restlet.ext.servlet.ServerServlet.service(ServerServlet.java:881) [com.noelios.restlet.ext.servlet-1.1.6-SONATYPE-5348-V4.jar:na]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:820) [servlet-api-2.5.jar:2.5]   at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:278) [guice-servlet-3.1.1.jar:na]   at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:268) [guice-servlet-3.1.1.jar:na]   at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:180) [guice-servlet-3.1.1.jar:na]   at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:93) [guice-servlet-3.1.1.jar:na]   at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:84) [guice-servlet-3.1.1.jar:na]   at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:120) [guice-servlet-3.1.1.jar:na]   at org.sonatype.nexus.web.NexusGuiceFilter$MultiFilterChain.doFilter(NexusGuiceFilter.java:88) [nexus-web-utils-2.0.jar:na]   at org.sonatype.nexus.web.NexusGuiceFilter$MultiFilterPipeline.dispatch(NexusGuiceFilter.java:58) [nexus-web-utils-2.0.jar:na]   at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:126) [guice-servlet-3.1.1.jar:na]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1330) [jetty-servlet-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) [shiro-web-1.1.0.jar:na]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.1.0.jar:na]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.1.0.jar:na]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:81) [shiro-web-1.1.0.jar:na]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.1.0.jar:na]   at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) [shiro-web-1.1.0.jar:na]   at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) [shiro-web-1.1.0.jar:na]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:81) [shiro-web-1.1.0.jar:na]   at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) [shiro-web-1.1.0.jar:na]   at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:359) [shiro-web-1.1.0.jar:na]   at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:275) [shiro-web-1.1.0.jar:na]   at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) [shiro-core-1.1.0.jar:1.1.0]   at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) [shiro-core-1.1.0.jar:1.1.0]   at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:344) [shiro-core-1.1.0.jar:1.1.0]   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:272) [shiro-web-1.1.0.jar:na]   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:81) [shiro-web-1.1.0.jar:na]   at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1330) [jetty-servlet-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:478) [jetty-servlet-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:119) [jetty-server-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:520) [jetty-security-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:227) [jetty-server-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:941) [jetty-server-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:409) [jetty-servlet-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:186) [jetty-server-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:875) [jetty-server-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:117) [jetty-server-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:250) [jetty-server-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:110) [jetty-server-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.server.Server.handle(Server.java:345) [jetty-server-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.server.HttpConnection.handleRequest(HttpConnection.java:441) [jetty-server-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.server.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:919) [jetty-server-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:582) [jetty-http-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:218) [jetty-http-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:51) [jetty-server-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:586) [jetty-io-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:44) [jetty-io-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:598) [jetty-util-7.5.4.v20111024.jar:7.5.4.v20111024]   at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:533) [jetty-util-7.5.4.v20111024.jar:7.5.4.v20111024]   at java.lang.Thread.run(Thread.java:680) [na:1.6.0_29]  {quote}",Bug,Major,Closed,"2012-03-09 16:58:37","2012-03-09 16:58:37",0
"Sonatype Nexus","Generalize the MetadataHandler and MetadataUpdater concept by lifting it from Maven support into Core","Generalize the MetadataHandler and MetadataUpdater concept by lifting it from Maven support into Core.    {{MavenRepository}} interface exposes some handy components for managing repository metadata. See these:  https://github.com/sonatype/nexus/blob/master/nexus/nexus-proxy/src/main/java/org/sonatype/nexus/proxy/maven/MavenRepository.java#L39  https://github.com/sonatype/nexus/blob/master/nexus/nexus-proxy/src/main/java/org/sonatype/nexus/proxy/maven/MetadataManager.java  https://github.com/sonatype/nexus/blob/master/nexus/nexus-proxy/src/main/java/org/sonatype/nexus/proxy/maven/MetadataUpdater.java  etc.    This concept (of Repository offering it's metadata manager) -- while extending the metadata manager with needed methods (like {{expireMetadata()}} and {{recreateMetadata()}} -- would be to be brought level up, from Maven specific bits into Core.    Some repository will clearly have managers that are NOOP implementations (think MavenSiteRepository for example)...",Improvement,Major,Closed,"2012-03-08 19:34:17","2012-03-08 19:34:17",5
"Sonatype Nexus","DefaultMetadataUpdater.undeployArtifact() does not remove metadata.","I am writing a plugin that prunes old release candidate builds from a repository. I am using ArifactStoreHelper.deleteArtifact(..., true, true, true), and things are mostly successful. Ultimately this method calls DefaultMetadataUpdater.undeployArtifact(), and I've found a few problems with this and related methods.    First, undeployArtifact() seems to use add operations instead of remove operations (maybe C&P from deployArtifact()?) for the GA and G metadata. I initially attempted to make a fix for this by using remove operations, but this led to a few additional issues.    For the GA metadata, RemoveVersionOperation.perform() correctly removes the version from the versions collection, but there are some additional cases that aren't handled: 1) the version removed was the latest, 2) the version removed was the only version.    I found this issue in 1.9.2.4, but I've also looked at code on the master branch and it seems to be the same.    One additional question: is ArifactStoreHelper.deleteArtifact() the right API to use for deleting a GAV?  ",Bug,Major,Closed,"2012-03-07 18:16:53","2012-03-07 18:16:53",5
"Sonatype Nexus","Extend ReferenceFactory with a new method: createThisReference","Extend ReferenceFactory with a new method: createThisReference(Request)    This new method would, similarly to existing createChildReference(Request, child) create a reference (obeying force URL etc) to this.",Bug,Major,Closed,"2012-03-07 16:13:24","2012-03-07 16:13:24",1
"Sonatype Nexus","Update Nexus configuration version","nexus.xml version is 2.0.0, nexus version is 2.1-SNAPSHOT.",Bug,Minor,Closed,"2012-03-06 11:32:33","2012-03-06 11:32:33",1
"Sonatype Nexus","nexus-p2-repository-plugin 2.0.1: broken dependency on nexus 2.0.1","Trying to run Nexus-OSS version 2.0.1 with activated additional plugins  - nexus-p2-bridge-plugin-2.0.1  - nexus-p2-repository-plugin-2.0.1  results in a broken nexus-p2-repository-plugin.    It looks like this plugin has a dependency to nexus-capabilities-plugin version 2.0    The Nexus plugin console shows a missing plugin nexus-capabilities-plugin 2.0. But Nexus 2.0.1 contains nexus-capabilities-plugin version 2.0.1.    Correcting all version numbers of the contained nexus-capabilities-plugin back to 2.0, everything works fine.  But this is only a workaround hack.",Bug,Major,Closed,"2012-03-06 09:08:01","2012-03-06 09:08:01",1
"Sonatype Nexus","When I try to add a new virtual repo wrong field is focused","http://screencast.com/t/qhyGw9SH4EB    I just click repository add virtual repo  Source Nexus Repository ID got focus  When I go to the first field to start the form the validation error pops...",Bug,Major,Closed,"2012-01-12 16:31:20","2012-01-12 16:31:20",1
"Sonatype Nexus","Alarming log messages during upgrade of Nexus configuration","Upgrade logging is alarming.        * *Nexus configuration file was loaded but discarded, it has the wrong version number* sounds like Nexus just threw away all my previous configuration. Why is this warn? Isn't it just keeping the parts it can keep and merging with new config?    * two times in the above sequence we see mention of *Loading configuration* - these duplicates should be removed with just one line mentioning the config file path*    * *Nexus configuration file upgraded to current version 1.10.0 succesfully.* I thought that config version was to match Nexus version from now on?    ",Bug,Major,Closed,"2012-01-30 19:04:16","2012-01-30 19:04:16",1
"Sonatype Nexus","Regression Nexus1954DeletedArtifactsFullIndexIT.indexTest","Regression    org.sonatype.nexus.integrationtests.nexus1954.Nexus1954DeletedArtifactsFullIndexIT.indexTest    https://builds.sonatype.org/job/nexus-oss-its/204/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.integrationtests.nexus1954/Nexus1954DeletedArtifactsFullIndexIT/indexTest/    ",Bug,Major,Closed,"2012-03-05 10:58:23","2012-03-05 10:58:23",1
"Sonatype Nexus","Regression Nexus636EvictUnusedProxiedTaskIT.doNotDeleteEverythingTest","Regression  org.sonatype.nexus.integrationtests.nexus636.Nexus636EvictUnusedProxiedTaskIT.doNotDeleteEverythingTest  https://builds.sonatype.org/job/nexus-oss-its/204/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus636/Nexus636EvictUnusedProxiedTaskIT/doNotDeleteEverythingTest/  ",Bug,Major,Closed,"2012-03-05 10:55:54","2012-03-05 10:55:54",1
"Sonatype Nexus","Regression Nexus636EvictUnusedProxiedTaskIT.clearProxy","org.sonatype.nexus.integrationtests.nexus636.Nexus636EvictUnusedProxiedTaskIT.clearProxy  https://builds.sonatype.org/job/nexus-oss-its/204/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus636/Nexus636EvictUnusedProxiedTaskIT/clearProxy/  ",Bug,Major,Closed,"2012-03-05 10:54:19","2012-03-05 10:54:19",1
"Sonatype Nexus","Regression Nexus3615ArtifactInfoProviderIT.@BeforeMethod","org.sonatype.nexus.integrationtests.nexus3615.Nexus3615ArtifactInfoProviderIT.@BeforeMethod oncePerClassSetUp    https://builds.sonatype.org/job/nexus-oss-its/204/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus3615/Nexus3615ArtifactInfoProviderIT/_BeforeMethod_oncePerClassSetUp/    ",Bug,Major,Closed,"2012-03-05 10:53:13","2012-03-05 10:53:13",1
"Sonatype Nexus","Regression Nexus1329MirrorFailAndRetriesIT.downloadFromMirrorTest","org.sonatype.nexus.integrationtests.nexus1329.Nexus1329MirrorFailAndRetriesIT.downloadFromMirrorTest (from Nexus1329MirrorFailAndRetriesIT)     https://builds.sonatype.org/job/nexus-oss-its/jdk=java-6x,label=linux/212/testReport/org.sonatype.nexus.integrationtests.nexus1329/Nexus1329MirrorFailAndRetriesIT/downloadFromMirrorTest/    ",Bug,Major,Closed,"2012-03-05 10:22:05","2012-03-05 10:22:05",1
"Sonatype Nexus","Nexus should have item retrieval using only the canonical source","Even requests for nexus metadata like /.meta/repository-metadata.xml are relayed to mirrors if it is not found in the main proxy.  Could be fixed by introducing an 'canonicalOnly' flag like 'local/remoteOnly'.    {quote}  <USER> That is the real one, reason is this class [NexusRawTransport|https://github.com/sonatype/nexus/blob/master/nexus/nexus-app/src/main/java/org/sonatype/nexus/repositories/metadata/NexusRawTransport.java] that delegates to actual repository.  {quote}",Bug,Major,Closed,"2012-03-05 10:02:11","2012-03-05 10:02:11",3
"Sonatype Nexus","wrong pid file creation with long command line and narrow terminal","Symptom: Nexus startup script ($NEXUS_HOME/bin/jsw/linux-x86-{32,64}/nexus) complained $ /opt/nexus-2.0/bin/jsw/linux-x86-64/nexus start Starting Nexus OSS... Removed stale pid file: /opt/nexus-2.0/bin/jsw/linux-x86-64/./nexus.pid Failed to start Nexus OSS.  But, Nexus did startup, just no nexus.pid was created!  After debugging the startup script (with set -x), I realized that the pid test didn't work properly in my case. In function getpid():    pidtest=`$PSEXE -p $pid -o args | grep wrapper.pidfile | tail -1`  with $PSEXE==ps, the command was /bin/ps -p 6686 -o args with output: /opt/nexus-2.0/bin/jsw/linux-x86-64/./wrapper /opt/nexus-2.0/bin/jsw/linux-x86-64/../conf/wrapper.conf wrapper.syslog.ident=nexus wra  Note how the output is truncated to the width of my terminal. And the wrapper.pidfile grep pattern does not match.  One remedy is to use -w -w as additional parameters for ps so it ignores the terminal width (see [1]).  [1] http://stackoverflow.com/questions/207848/getting-the-full-result-from-ps ",Bug,Major,Closed,"2012-03-02 18:05:05","2012-03-02 18:05:05",1
"Sonatype Nexus","Nexus is generating invalid maven-metadata.xml at GA level","<<USER> <USER> http://screencast.com/t/Dp4QzP1Vn  <<USER> <USER> so, right side metadata.xml is generated by nexus  <<USER> <USER> I just wanna you confirm to me it is invalid  <<USER> <USER> no, this is GA-level metadata which never mentions timestamped snapshots  <<USER> GA-level metadata only uses the generic -SNASPHOT suffix, resolution of that to a timestamp is job of the GAV-level metadata  <<USER> <USER> thanks, I'm gonna fix this one nexus  <<USER> the presence of latest/release should be fine, although latest is normally only seen in plugin metadata  ",Bug,Major,Closed,"2012-03-02 15:59:23","2012-03-02 15:59:23",1
"Sonatype Nexus","maven-nexus-plugin breaks if proxy is required to connect to nexus instance","The plugin tests connection to the configured nexus instance. If you're on a closed system where all requests that do not go to a proxy are dropped, you will not be able to connect and see log like this:        Note the missing log information about username and proxy settings, which are written when the real client is configured:        DefaultTestClientManager$NexusTestClient class is the culprit, no ProxyConfig for that one. The IT only verifies that the proxy is hit, but not that *only* the proxy is used.",Bug,Major,Closed,"2012-03-02 15:30:30","2012-03-02 15:30:30",1
"Sonatype Nexus","Remove everything besides log level from Log Configuration UI ","Original summary was: Log Configuration UI does NOT validate the File Appender Pattern    I don't see why we let people change this,  If someone really wants to change it, they can edit the config.  But if we are going to keep it, we should have some sort of validation on the field    The pattern we use: %4d{yyyy-MM-dd HH:mm:ss} %-5p [%-15.15t] - %c - %m%n    A pattern of: !@#$%^&*()_+  Will log:  {quote}  jvm 1    | 13:01:41,615 |-ERROR in ch.qos.logback.core.joran.spi.Interpreter@22:15 - RuntimeException in Action for tag [encoder] java.lang.NumberFormatException: For input string: ^&  {quote}    or for kicks a pattern of: Hello Nexus  {quote}  jvm 1    | Hello Nexus  {quote}    Both of these would be obvious user errors, but a pattern of:  %4d{yyyy-MM-dd HH:mm:ss} %-&5p [%-15.15t] - %c - %m%n  {quote}  jvm 1    | 13:05:01,542 |-ERROR in ch.qos.logback.core.joran.spi.Interpreter@29:15 - RuntimeException in Action for tag [encoder] java.lang.NumberFormatException: For input string: -&  {quote}        ",Bug,Major,Closed,"2012-03-01 18:06:38","2012-03-01 18:06:38",1
"Sonatype Nexus","nexus-maven-plugin has dependencies on sonatype modified artifacts","The nexus-maven-plugin has dependencies on the following:    commons-beanutils:commons-beanutils:jar:1.7.0-SONATYPE  commons-beanutils:commons-beanutils-core:jar:1.7.0-SONATYPE  commons-httpclient:commons-httpclient:jar:3.1.SONATYPE    This means that it cannot be used without adding the RSO repository (even though it is deployed into central).",Bug,Major,Closed,"2012-02-15 17:35:01","2012-02-15 17:35:01",1
"Sonatype Nexus","Role Repo: All  Repositories (View) has no privileges assigned","The built-in role Repo: All  Repositories (View) should have the privilege All Repositories - (view). See attached screenshot.",Bug,Major,Closed,"2012-03-01 07:37:12","2012-03-01 07:37:12",1
"Sonatype Nexus","Regression M2RepositoryTest.testExpiration_NEXUS1675","Regression  org.sonatype.nexus.proxy.M2RepositoryTest.testExpiration_NEXUS1675 (from M2RepositoryTest)   https://builds.sonatype.org/job/nexus-oss-its/jdk=java-6x,label=win/207/testReport/org.sonatype.nexus.proxy/M2RepositoryTest/testExpiration_NEXUS1675/  ",Bug,Major,Closed,"2012-02-29 08:28:43","2012-02-29 08:28:43",1
"Sonatype Nexus","Staging upload GUI does not allow sufficient room for displaying uploaded artifacts","The Artifacts box on the Staging Upload screen is far too small for many use cases, and cannot be resized.    It should be wider, and the user should be able to make it longer.",Improvement,Major,Closed,"2012-02-28 21:48:10","2012-02-28 21:48:10",1
"Sonatype Nexus","Nexus creates useless hashes for uploaded sig files","Recently used Nexus 2.0 to upload a pom, as well as several artefacts, and also the signature (.asc) files for each.    Nexus created hashes for everything, including the .asc (signature) files.    Such hashes are useless, and just get in the way when trying to check that all the required files have been uploaded.",Improvement,Minor,Closed,"2012-02-28 21:41:16","2012-02-28 21:41:16",1
"Sonatype Nexus","Files not ending in pom or jar don't show up in new cached files system feed","Files which don't end in pom or jar don't get recorded in system feeds which record file changes.",Bug,Major,Closed,"2012-02-28 18:24:13","2012-02-28 18:24:13",1
"Sonatype Nexus","Disable ehcache call home.","It should be as simple as adding: updateCheck=true to the ehcache.xml  We should do this to any test copy of ehcache.xml as well.    http://tech.puredanger.com/2010/07/28/open-source-bargain/",Bug,Major,Closed,"2012-02-28 15:42:39","2012-02-28 15:42:39",1
"Sonatype Nexus","Nexus ITs: BindException: Address already in use caused a hang during shutdown inside sisu-jetty8","From: https://builds.sonatype.org/job/nexus-oss-its/205/    2012-02-27 02:39:03.185:WARN:oejuc.AbstractLifeCycle:FAILED SelectChannelConnector@0.0.0.0:49646: java.net.BindException: Address already in use  java.net.BindException: Address already in use   at sun.nio.ch.Net.bind(Native Method)   at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:126)   at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)   at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:173)   at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:311)   at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:251)   at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:59)   at org.eclipse.jetty.server.Server.doStart(Server.java:274)   at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:59)   at org.sonatype.sisu.jetty.Jetty8$JettyWrapperThread.run(Jetty8.java:133)  2012-02-27 02:39:03.307:WARN:oejuc.AbstractLifeCycle:FAILED org.eclipse.jetty.server.Server@1337e785: java.net.BindException: Address already in use  java.net.BindException: Address already in use   at sun.nio.ch.Net.bind(Native Method)   at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:126)   at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)   at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:173)   at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:311)   at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:251)   at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:59)   at org.eclipse.jetty.server.Server.doStart(Server.java:274)   at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:59)   at org.sonatype.sisu.jetty.Jetty8$JettyWrapperThread.run(Jetty8.java:133)  java.lang.reflect.InvocationTargetException   at sun.reflect.GeneratedMethodAccessor128.invoke(Unknown Source)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)   at java.lang.reflect.Method.invoke(Method.java:597)   at org.sonatype.nexus.test.booter.Jetty8NexusBooter.startNexus(Jetty8NexusBooter.java:202)   at org.sonatype.nexus.test.utils.NexusStatusUtil.start(NexusStatusUtil.java:140)   at org.sonatype.nexus.integrationtests.AbstractNexusIntegrationTest.startNexus(AbstractNexusIntegrationTest.java:766)   at org.sonatype.nexus.integrationtests.AbstractNexusIntegrationTest.oncePerClassSetUp(AbstractNexusIntegrationTest.java:362)   at sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)   at java.lang.reflect.Method.invoke(Method.java:597)   at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:80)   at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:525)   at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:202)   at org.testng.internal.Invoker.invokeMethod(Invoker.java:613)   at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:842)   at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1166)   at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125)   at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109)   at org.testng.TestRunner.runWorkers(TestRunner.java:1178)   at org.testng.TestRunner.privateRun(TestRunner.java:757)   at org.testng.TestRunner.run(TestRunner.java:608)   at org.testng.SuiteRunner.runTest(SuiteRunner.java:334)   at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:329)   at org.testng.SuiteRunner.privateRun(SuiteRunner.java:291)   at org.testng.SuiteRunner.run(SuiteRunner.java:240)   at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52)   at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86)   at org.testng.TestNG.runSuitesSequentially(TestNG.java:1158)   at org.testng.TestNG.runSuitesLocally(TestNG.java:1083)   at org.testng.TestNG.run(TestNG.java:999)   at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:70)   at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:158)   at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:98)   at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:111)   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)   at java.lang.reflect.Method.invoke(Method.java:597)   at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)   at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)   at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:175)   at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:107)   at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:68)  Caused by: java.net.BindException: Address already in use   at sun.nio.ch.Net.bind(Native Method)   at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:126)   at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)   at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:173)   at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:311)   at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:251)   at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:59)   at org.eclipse.jetty.server.Server.doStart(Server.java:274)   at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:59)   at org.sonatype.sisu.jetty.Jetty8$JettyWrapperThread.run(Jetty8.java:133)  Result: org.sonatype.nexus.integrationtests.nexus385.Nexus385RoutesPermissionIT.testCreatePermission() ===> skipped  Result: org.sonatype.nexus.integrationtests.nexus385.Nexus385RoutesPermissionIT.testDeletePermission() ===> skipped  Result: org.sonatype.nexus.integrationtests.nexus385.Nexus385RoutesPermissionIT.testReadPermission() ===> skipped  Result: org.sonatype.nexus.integrationtests.nexus385.Nexus385RoutesPermissionIT.testUpdatePermission() ===> skipped  2012-02-27 02:39:04,770 WARN [org.restlet] - An error occurred during the communication with the remote HTTP server.  java.net.ConnectException: Connection refused   at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.6.0_30]   at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351) ~[na:1.6.0_30]   at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213) ~[na:1.6.0_30]   at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200) ~[na:1.6.0_30]   at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366) ~[na:1.6.0_30]   at java.net.Socket.connect(Socket.java:529) ~[na:1.6.0_30]   at java.net.Socket.connect(Socket.java:478) ~[na:1.6.0_30]   at java.net.Socket.<init>(Socket.java:375) ~[na:1.6.0_30]   at java.net.Socket.<init>(Socket.java:249) ~[na:1.6.0_30]   at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(Unknown Source) ~[commons-httpclient-3.1.SONATYPE.jar:3.1]   at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(Unknown Source) ~[commons-httpclient-3.1.SONATYPE.jar:3.1]   at org.apache.commons.httpclient.HttpConnection.open(Unknown Source) ~[commons-httpclient-3.1.SONATYPE.jar:3.1]   at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(Unknown Source) ~[commons-httpclient-3.1.SONATYPE.jar:3.1]   at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(Unknown Source) ~[commons-httpclient-3.1.SONATYPE.jar:3.1]   at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(Unknown Source) ~[commons-httpclient-3.1.SONATYPE.jar:3.1]   at org.apache.commons.httpclient.HttpClient.executeMethod(Unknown Source) ~[commons-httpclient-3.1.SONATYPE.jar:3.1]   at org.apache.commons.httpclient.HttpClient.executeMethod(Unknown Source) ~[commons-httpclient-3.1.SONATYPE.jar:3.1]   at com.noelios.restlet.ext.httpclient.HttpMethodCall.sendRequest(HttpMethodCall.java:313) ~[com.noelios.restlet.ext.httpclient-1.1.6-SONATYPE-5348-V4.jar:na]   at com.noelios.restlet.http.HttpClientConverter.commit(HttpClientConverter.java:418) [com.noelios.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at com.noelios.restlet.http.HttpClientHelper.handle(HttpClientHelper.java:108) [com.noelios.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Client.handle(Client.java:157) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.restlet.Uniform.handle(Uniform.java:108) [org.restlet-1.1.6-SONATYPE-5348-V4.jar:na]   at org.sonatype.nexus.integrationtests.NexusRestClient.sendMessage(NexusRestClient.java:563) [nexus-test-utils-2.1-SNAPSHOT.jar:na]   at org.sonatype.nexus.integrationtests.NexusRestClient.sendMessage(NexusRestClient.java:543) [nexus-test-utils-2.1-SNAPSHOT.jar:na]   at org.sonatype.nexus.integrationtests.NexusRestClient.sendMessage(NexusRestClient.java:494) [nexus-test-utils-2.1-SNAPSHOT.jar:na]   at org.sonatype.nexus.integrationtests.NexusRestClient.sendMessage(NexusRestClient.java:488) [nexus-test-utils-2.1-SNAPSHOT.jar:na]   at org.sonatype.nexus.integrationtests.NexusRestClient.sendMessage(NexusRestClient.java:470) [nexus-test-utils-2.1-SNAPSHOT.jar:na]   at org.sonatype.nexus.integrationtests.NexusRestClient.doGetForStatus(NexusRestClient.java:250) [nexus-test-utils-2.1-SNAPSHOT.jar:na]   at org.sonatype.nexus.integrationtests.NexusRestClient.doGetForStatus(NexusRestClient.java:230) [nexus-test-utils-2.1-SNAPSHOT.jar:na]   at org.sonatype.nexus.test.utils.TasksNexusRestClient.waitForAllTasksToStop(TasksNexusRestClient.java:209) [nexus-test-utils-2.1-SNAPSHOT.jar:na]   at org.sonatype.nexus.test.utils.TasksNexusRestClient.waitForAllTasksToStop(TasksNexusRestClient.java:180) [nexus-test-utils-2.1-SNAPSHOT.jar:na]   at org.sonatype.nexus.test.utils.TasksNexusRestClient.waitForAllTasksToStop(TasksNexusRestClient.java:158) [nexus-test-utils-2.1-SNAPSHOT.jar:na]   at org.sonatype.nexus.test.utils.TaskScheduleUtil.waitForAllTasksToStop(TaskScheduleUtil.java:88) [nexus-test-harness-launcher-2.1-SNAPSHOT.jar:na]   at org.sonatype.nexus.integrationtests.AbstractNexusIntegrationTest.oncePerClassTearDown(AbstractNexusIntegrationTest.java:417) [nexus-test-harness-launcher-2.1-SNAPSHOT.jar:na]   at sun.reflect.GeneratedMethodAccessor135.invoke(Unknown Source) ~[na:na]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) ~[na:1.6.0_30]   at java.lang.reflect.Method.invoke(Method.java:597) ~[na:1.6.0_30]   at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:80) [testng-6.1.1.jar:na]   at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:525) [testng-6.1.1.jar:na]   at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:202) [testng-6.1.1.jar:na]   at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:130) [testng-6.1.1.jar:na]   at org.testng.internal.TestMethodWorker.invokeAfterClassMethods(TestMethodWorker.java:222) [testng-6.1.1.jar:na]   at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:112) [testng-6.1.1.jar:na]   at org.testng.TestRunner.runWorkers(TestRunner.java:1178) [testng-6.1.1.jar:na]   at org.testng.TestRunner.privateRun(TestRunner.java:757) [testng-6.1.1.jar:na]   at org.testng.TestRunner.run(TestRunner.java:608) [testng-6.1.1.jar:na]   at org.testng.SuiteRunner.runTest(SuiteRunner.java:334) [testng-6.1.1.jar:na]   at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:329) [testng-6.1.1.jar:na]   at org.testng.SuiteRunner.privateRun(SuiteRunner.java:291) [testng-6.1.1.jar:na]   at org.testng.SuiteRunner.run(SuiteRunner.java:240) [testng-6.1.1.jar:na]   at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52) [testng-6.1.1.jar:na]   at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86) [testng-6.1.1.jar:na]   at org.testng.TestNG.runSuitesSequentially(TestNG.java:1158) [testng-6.1.1.jar:na]   at org.testng.TestNG.runSuitesLocally(TestNG.java:1083) [testng-6.1.1.jar:na]   at org.testng.TestNG.run(TestNG.java:999) [testng-6.1.1.jar:na]   at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:70) [surefire-testng-2.10.jar:2.10]   at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:158) [surefire-testng-2.10.jar:2.10]   at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:98) [surefire-testng-2.10.jar:2.10]   at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:111) [surefire-testng-2.10.jar:2.10]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.6.0_30]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) ~[na:1.6.0_30]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) ~[na:1.6.0_30]   at java.lang.reflect.Method.invoke(Method.java:597) ~[na:1.6.0_30]   at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164) [surefire-api-2.10.jar:2.10]   at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110) [surefire-booter-2.10.jar:2.10]   at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:175) [surefire-booter-2.10.jar:2.10]   at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:107) [surefire-booter-2.10.jar:2.10]   at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:68) [surefire-booter-2.10.jar:2.10]  2012-02-27 02:39:04.888:INFO:oejs.Server:Graceful shutdown SelectChannelConnector@0.0.0.0:49646  2012-02-27 02:39:04.889:INFO:oejs.Server:Graceful shutdown o.e.j.w.WebAppContext{/nexus,file:/opt/grid/slave/workspace/nexus-oss-its/374c4ad3/nexus/nexus-test-harness/nexus-test-harness-its/target/nexus/nexus-oss-webapp-2.1-SNAPSHOT/nexus/},/opt/grid/slave/workspace/nexus-oss-its/374c4ad3/nexus/nexus-test-harness/nexus-test-harness-its/target/nexus/nexus-oss-webapp-2.1-SNAPSHOT/nexus  2012-02-27 02:39:07.270:INFO:oejsh.ContextHandler:stopped o.e.j.w.WebAppContext{/nexus,file:/opt/grid/slave/workspace/nexus-oss-its/374c4ad3/nexus/nexus-test-harness/nexus-test-harness-its/target/nexus/nexus-oss-webapp-2.1-SNAPSHOT/nexus/},/opt/grid/slave/workspace/nexus-oss-its/374c4ad3/nexus/nexus-test-harness/nexus-test-harness-its/target/nexus/nexus-oss-webapp-2.1-SNAPSHOT/nexus  2012-02-27 06:49:26  Full thread dump Java HotSpot(TM) 64-Bit Server VM (20.5-b03 mixed mode):  MultiThreadedHttpConnectionManager cleanup daemon prio=10 tid=0x0000000042153000 nid=0x34da in Object.wait() [0x00007f6d7b6d1000]     java.lang.Thread.State: WAITING (on object monitor)   at java.lang.Object.wait(Native Method)   - waiting on <0x00000000dc52eb20> (a java.lang.ref.ReferenceQueue$Lock)   at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:118)   - locked <0x00000000dc52eb20> (a java.lang.ref.ReferenceQueue$Lock)   at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:134)   at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$ReferenceQueueThread.run(Unknown Source)  MultiThreadedHttpConnectionManager cleanup daemon prio=10 tid=0x00007f6d752e1000 nid=0x53bb in Object.wait() [0x00007f6d7acc7000]     java.lang.Thread.State: WAITING (on object monitor)   at java.lang.Object.wait(Native Method)   - waiting on <0x00000000dbaa4c98> (a java.lang.ref.ReferenceQueue$Lock)   at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:118)   - locked <0x00000000dbaa4c98> (a java.lang.ref.ReferenceQueue$Lock)   at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:134)   at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$ReferenceQueueThread.run(Unknown Source)  Low Memory Detector daemon prio=10 tid=0x00007f6d7c004000 nid=0x52a3 runnable [0x0000000000000000]     java.lang.Thread.State: RUNNABLE  C2 CompilerThread1 daemon prio=10 tid=0x00007f6d7c001800 nid=0x52a2 waiting on condition [0x0000000000000000]     java.lang.Thread.State: RUNNABLE  C2 CompilerThread0 daemon prio=10 tid=0x000000004105f000 nid=0x52a1 waiting on condition [0x0000000000000000]     java.lang.Thread.State: RUNNABLE  Signal Dispatcher daemon prio=10 tid=0x000000004105d000 nid=0x52a0 waiting on condition [0x0000000000000000]     java.lang.Thread.State: RUNNABLE  Finalizer daemon prio=10 tid=0x000000004103a800 nid=0x529f in Object.wait() [0x00007f6d81813000]     java.lang.Thread.State: WAITING (on object monitor)   at java.lang.Object.wait(Native Method)   - waiting on <0x00000000da92c4c0> (a java.lang.ref.ReferenceQueue$Lock)   at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:118)   - locked <0x00000000da92c4c0> (a java.lang.ref.ReferenceQueue$Lock)   at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:134)   at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)  Reference Handler daemon prio=10 tid=0x0000000041038800 nid=0x529e in Object.wait() [0x00007f6d81914000]     java.lang.Thread.State: WAITING (on object monitor)   at java.lang.Object.wait(Native Method)   - waiting on <0x00000000da92c480> (a java.lang.ref.Reference$Lock)   at java.lang.Object.wait(Object.java:485)   at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)   - locked <0x00000000da92c480> (a java.lang.ref.Reference$Lock)  main prio=10 tid=0x0000000040fb1000 nid=0x529a waiting on condition [0x00007f6d86250000]     java.lang.Thread.State: WAITING (parking)   at sun.misc.Unsafe.park(Native Method)   - parking to wait for  <0x00000000ddfeefe0> (a java.util.concurrent.CountDownLatch$Sync)   at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)   at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:811)   at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:969)   at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1281)   at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:207)   at org.sonatype.sisu.jetty.Jetty8$JettyWrapperThread.stopJetty(Jetty8.java:180)   at org.sonatype.sisu.jetty.Jetty8.stopJetty(Jetty8.java:94)   - locked <0x00000000de095260> (a org.sonatype.sisu.jetty.Jetty8)   at sun.reflect.GeneratedMethodAccessor136.invoke(Unknown Source)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)   at java.lang.reflect.Method.invoke(Method.java:597)   at org.sonatype.nexus.test.booter.Jetty8NexusBooter.stopNexus(Jetty8NexusBooter.java:219)   at org.sonatype.nexus.test.utils.NexusStatusUtil.stop(NexusStatusUtil.java:146)   at org.sonatype.nexus.integrationtests.AbstractNexusIntegrationTest.stopNexus(AbstractNexusIntegrationTest.java:781)   at org.sonatype.nexus.integrationtests.AbstractNexusIntegrationTest.oncePerClassTearDown(AbstractNexusIntegrationTest.java:429)   at sun.reflect.GeneratedMethodAccessor135.invoke(Unknown Source)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)   at java.lang.reflect.Method.invoke(Method.java:597)   at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:80)   at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:525)   at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:202)   at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:130)   at org.testng.internal.TestMethodWorker.invokeAfterClassMethods(TestMethodWorker.java:222)   at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:112)   at org.testng.TestRunner.runWorkers(TestRunner.java:1178)   at org.testng.TestRunner.privateRun(TestRunner.java:757)   at org.testng.TestRunner.run(TestRunner.java:608)   at org.testng.SuiteRunner.runTest(SuiteRunner.java:334)   at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:329)   at org.testng.SuiteRunner.privateRun(SuiteRunner.java:291)   at org.testng.SuiteRunner.run(SuiteRunner.java:240)   at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52)   at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86)   at org.testng.TestNG.runSuitesSequentially(TestNG.java:1158)   at org.testng.TestNG.runSuitesLocally(TestNG.java:1083)   at org.testng.TestNG.run(TestNG.java:999)   at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:70)   at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:158)   at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:98)   at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:111)   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)   at java.lang.reflect.Method.invoke(Method.java:597)   at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)   at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)   at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:175)   at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:107)   at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:68)  VM Thread prio=10 tid=0x0000000041032000 nid=0x529d runnable   GC task thread#0 (ParallelGC) prio=10 tid=0x0000000040fc4000 nid=0x529b runnable   GC task thread#1 (ParallelGC) prio=10 tid=0x0000000040fc6000 nid=0x529c runnable   VM Periodic Task Thread prio=10 tid=0x00007f6d7c017000 nid=0x52a4 waiting on condition   JNI global references: 1833  Heap   PSYoungGen      total 180224K, used 99639K [0x00000000f3800000, 0x00000000ffdd0000, 0x0000000100000000)    eden space 156928K, 63% used [0x00000000f3800000,0x00000000f994df88,0x00000000fd140000)    from space 23296K, 0% used [0x00000000fd140000,0x00000000fd140000,0x00000000fe800000)    to   space 22336K, 0% used [0x00000000fe800000,0x00000000fe800000,0x00000000ffdd0000)   PSOldGen        total 275584K, used 61131K [0x00000000da800000, 0x00000000eb520000, 0x00000000f3800000)    object space 275584K, 22% used [0x00000000da800000,0x00000000de3b2d70,0x00000000eb520000)   PSPermGen       total 225280K, used 161060K [0x00000000ccc00000, 0x00000000da800000, 0x00000000da800000)    object space 225280K, 71% used [0x00000000ccc00000,0x00000000d69491e0,0x00000000da800000)  [ERROR] Failure: java.lang.InterruptedException  ",Bug,Major,Closed,"2012-02-27 13:42:44","2012-02-27 13:42:44",1
"Sonatype Nexus","Nexus startup: shadow repository causes InvalidConfigurationException","Sorry, was still writing the lyrics in notepad ;-)   Here we go:    Hi,    we wrote a _nexus unzip plugin_ which extends AbstractShadowRepository. It's a virtual repository and behaves like a filter on a 'real' repository. You see all contents from it's master repository plus the content of zip files (actually non-recursive).    We use repository groups as master repository for our unzip repos:  {quote}  _from conf/nexus.xml_  :      <repository>        <id>build.snapshots</id>        <name>build.snapshots</name>        <providerRole>org.sonatype.nexus.proxy.repository.GroupRepository</providerRole>        <providerHint>maven2</providerHint>        <localStatus>IN_SERVICE</localStatus>        <notFoundCacheTTL>15</notFoundCacheTTL>        <userManaged>true</userManaged>        <exposed>true</exposed>        <browseable>true</browseable>        <writePolicy>READ_ONLY</writePolicy>        <indexable>true</indexable>        <localStorage>          <provider>file</provider>        </localStorage>        <externalConfiguration>          <memberRepositories>            <memberRepository>deploy.milestones</memberRepository>            <memberRepository>deploy.snapshots</memberRepository>            <memberRepository>build.milestones.proxy</memberRepository>            <memberRepository>build.snapshots.proxy</memberRepository>          </memberRepositories>        </externalConfiguration>      </repository>  :  :      <repository>        <id>build.snapshots.unzip</id>        <name>build.snapshots.unzip</name>        <providerRole>com.sap.nexus.internal.plugin.UnzipRepository</providerRole>        <providerHint>com.sap.nexus.plugin.DefaultUnzipRepository</providerHint>        <localStatus>IN_SERVICE</localStatus>        <notFoundCacheActive>true</notFoundCacheActive>        <notFoundCacheTTL>15</notFoundCacheTTL>        <userManaged>true</userManaged>        <exposed>true</exposed>        <browseable>true</browseable>        <writePolicy>READ_ONLY</writePolicy>        <searchable>true</searchable>        <localStorage>          <provider>file</provider>        </localStorage>        <externalConfiguration>          <masterRepositoryId>build.snapshots</masterRepositoryId>           <synchronizeAtStartup>false</synchronizeAtStartup>          <useVirtualVersion>true</useVirtualVersion>        </externalConfiguration>      </repository>  :  {quote}    Seems like during startup group repositories are added after shadow repositories, so, in fact the masterRepositoryId build.snapshots is not registered when the add for the shadow repository is called:    {quote}  _From logs/nexus.log_  :  2012-02-23 14:54:34 INFO  [7-main-thread-1] - org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry - Added repository ID='build.snapshots.proxy' (contentClass='maven2', mainFacet='org.sonatype.nexus.proxy.maven.MavenProxyRepository')  2012-02-23 14:54:34 INFO  [7-main-thread-1] - org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry - Added repository ID='deploy.releases' (contentClass='maven2', mainFacet='org.sonatype.nexus.proxy.maven.MavenHostedRepository')  2012-02-23 14:54:35 INFO  [7-main-thread-1] - org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry - Added repository ID='build.releases.proxy' (contentClass='maven2', mainFacet='org.sonatype.nexus.proxy.maven.MavenProxyRepository')  2012-02-23 14:54:35 INFO  [7-main-thread-1] - org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry - Added repository ID='3rd-party.releases.manual-uploads.hosted' (contentClass='maven2', mainFacet='org.sonatype.nexus.proxy.maven.MavenHostedRepository')  2012-02-23 14:54:35 ERROR [7-main-thread-1] - org.sonatype.nexus.DefaultNexus - Could not start Nexus, user configuration exception!  org.sonatype.configuration.validation.InvalidConfigurationException: Configuration is invalid!  Validation errors follows:   o shadowOf - ResourceStore of type Repository with id='build.snapshots' not found!            at org.sonatype.nexus.proxy.repository.AbstractShadowRepositoryConfigurator.doApplyConfiguration(AbstractShadowRepositoryConfigurator.java:67) ~[nexus-proxy-2.0.jar:na]          at com.sap.nexus.internal.plugin.UnzipRepositoryConfigurator.doApplyConfiguration(UnzipRepositoryConfigurator.java:19) ~[na:na]          at org.sonatype.nexus.proxy.repository.AbstractRepositoryConfigurator.applyConfiguration(AbstractRepositoryConfigurator.java:60) ~[nexus-proxy-2.0.jar:na]          at org.sonatype.nexus.configuration.AbstractConfigurable.doConfigure(AbstractConfigurable.java:232) ~[nexus-configuration-2.0.jar:na]          at org.sonatype.nexus.configuration.AbstractConfigurable.configure(AbstractConfigurable.java:168) ~[nexus-configuration-2.0.jar:na]          at org.sonatype.nexus.configuration.application.runtime.DefaultApplicationRuntimeConfigurationBuilder.createRepositoryFromModel(DefaultApplicationRuntimeConfigurationBuilder.java:48) ~[nexus-app-2.0.jar:na]          at org.sonatype.nexus.configuration.application.DefaultNexusConfiguration.instantiateRepository(DefaultNexusConfiguration.java:601) ~[nexus-app-2.0.jar:na]          at org.sonatype.nexus.configuration.application.DefaultNexusConfiguration.createRepositories(DefaultNexusConfiguration.java:567) ~[nexus-app-2.0.jar:na]          at org.sonatype.nexus.configuration.application.DefaultNexusConfiguration.createInternals(DefaultNexusConfiguration.java:549) ~[nexus-app-2.0.jar:na]          at org.sonatype.nexus.DefaultNexus.startService(DefaultNexus.java:452) [nexus-app-2.0.jar:na]          at org.sonatype.nexus.DefaultNexus.start(DefaultNexus.java:414) [nexus-app-2.0.jar:na]  :  {quote}    I noticed that the order of these repositories in nexus.xml is ignored which is o.k.  The nature of a shadow repo is that the master repo must be accessible at least when I first try to read content (after the nexus startup).     * If I register a list of repositories and I know that there are dependencies between these repositories why does nexus not just choose a 'better' order when adding repos from the configuration?   ** via something like _shadowRepository.getMasterRepsitory()_   ** Or the infos from nexus.xml (see tag <masterRepositoryId>).  * Or if the dependency cannot be retrieved maybe a kind of queue: did not succeed to add this time, maybe once again after all others? Be aware of circles...  * Or simply have shadow repositories generally added after the groups.   * Or have a certain shadow repository type which is added after the groups  * Or first add all repos without dependency checks and in a second loop do check for all that the dependencies are fulfilled.  * Or...    Actually one cannot choose a group as master for our virtual UnzipRepo via UI - only proxy and hosted repos. This is maybe only because of the fact that the nexus startup's repo adding implementation can't cope with Shadow Repositories having groups as master? This restriction to non-group repos could then be removed, too.    regards, Stephan      PS: Btw. I wonder why nexus pro meanwhile does not provide some similar unzip functionality anyway: A special URL which allows to get single files out of a zipped file - if one has the privilege to read the zip file itself:  http://nexus:8080/nexus/content/groups/repositoryname/xxx/yyy/1.0.1/yyy-1.0.1.zip => the zip file itself  http://nexus:8080/nexus/content/unzip/repositoryname/xxx/yyy/1.0.1/yyy-1.0.1.zip => the zip file itself  http://nexus:8080/nexus/content/unzip/repositoryname/xxx/yyy/1.0.1/yyy-1.0.1.zip/ => the root dir inside the zip file  http://nexus:8080/nexus/content/unzip/repositoryname/xxx/yyy/1.0.1/yyy-1.0.1.zip/content.xml => the file content.xml from inside the zip             ",Bug,Major,Closed,"2012-02-24 16:25:13","2012-02-24 16:25:13",1
"Sonatype Nexus","Nexus should recover from invalid attribute file content","NEXUS-4871 is about Nexus not breaking with zero-length attribute files. Nexus will still break for e.g. 1-byte-sized files (or anything not parseable by the currently used attribute storage), leading to server errors every time something around the artifact with the invalid attributes file is touched (e.g. download, browsing). Only fix is for the admin to remove the invalid attribute file from storage.    There are some comments on NEXUS-4871 for and against Nexus recovering on such cases.",Bug,Major,Closed,"2012-02-23 12:12:08","2012-02-23 12:12:08",1
"Sonatype Nexus","Bookmarking search does not work for some (illegal?) values","Some search queries like '!@#$%^&*()_+}{[]|\/?><' cause a js error in the indexer plugin code for the URL bookmarks, causing bookmarked URLs like http://localhost:8081/nexus/index.html#nexus-search;quick~!@#$%^&*%28%29_+}{[]|\/?%3E%3C to not issue a search request at all.      ",Bug,Minor,Closed,"2012-02-23 10:52:16","2012-02-23 10:52:16",1
"Sonatype Nexus","DefaultTargetRegistry field 'targets' is not thread safe","There is unsynchronized write access to the private member variable DefaultTargetRegistry.targets in DefaultTargetRegistry.getRepositoryTargets(). Threads are likely backing up within the call in this method that is made to getCurrentConfiguration( false ) - assuming that is synchronized deeper in the call stack - which would cause repetitive reassignment of the targets and potentially non-deterministic behavior with multiple threads calling targets.add() concurrently. I don't know that this explains the NPE but that certainly seems plausible.    Also, it is also possible for a thread calling DefaultTargetRegistry.getRepositoryTargets() to possibly skip the entire if block associated with the null condition for DefaultTargetRepository.targets and creating the collection to be returned from a partially configured set of Target instances. This latter situation does not seem as though it would generate the NPE though.    This does not appear to be a regression and is probably the result of the addition of the new repos for Scala Tools. This also seems like it may require a potentially precarious fix with the addition of the necessary locking. The urgency of this for OSSRH is probably somewhat high as the configuration is changed quite often and the number of repositories is high. (This needs to be validated) If staging actions by users cause the configuration to be reloaded, this is very likely to be a hot spot. However, it does seem that this particular failure was coincident with the action Juven was taking at the time (certainly no fault of his).    In summary, it seems that unsafe thread operations corrupted the contents of DefaultTargetRegistry.targets. With a null value in that list, Nexus will fail.",Bug,Critical,Closed,"2012-02-22 20:16:47","2012-02-22 20:16:47",3
"Sonatype Nexus","Log lines from jetty are missing stacktrace","Example log lines:   jvm 2    | 2012-02-22 00:56:43.179:WARN:oejs.ServletHandler:/content/groups/github/com/ricoh/im/ui.flex.framework/1.2.0.13-0402/ui.flex.framework-1.2.0.13-0402.pom jvm 2    | java.lang.NullPointerException jvm 2    | 2012-02-22 00:56:43.244:WARN:oejs.ServletHandler:/content/groups/scala-tools/org/springframework/spring-parent/3.0.0.RELEASE/spring-parent-3.0.0.RELEASE.pom jvm 2    | java.lang.NullPointerException jvm 2    | 2012-02-22 00:56:43.251:WARN:oejs.ServletHandler:/content/repositories/snapshots/de/is24/maklermanager/healthcheck/properties-ws/14.0.15-SNAPSHOT/maven-metadata.xml jvm 2    | java.lang.NullPointerException jvm 2    | 2012-02-22 00:56:43.262:WARN:oejs.ServletHandler:/content/groups/scala-tools/javax/activation/activation/1.1/activation-1.1.jar jvm 2    | java.lang.NullPointerException jvm 2    | 2012-02-22 00:56:43.269:WARN:oejs.ServletHandler:/content/groups/scala-tools/com/twitter/scrooge-runtime/1.1.3-SNAPSHOT/scrooge-runtime-1.1.3-SNAPSHOT.jar jvm 2    | java.lang.NullPointerException jvm 2    | 2012-02-22 00:56:43.278:WARN:oejs.ServletHandler:/content/groups/public/org/andromda/profiles/andromda-profiles/3.4-SNAPSHOT/maven-metadata.xml.sha1 jvm 2    | java.lang.NullPointerException jvm 2    | 2012-02-22 00:56:43.323:WARN:oejs.ServletHandler:/content/groups/scala-tools/org/msgpack/msgpack-rpc/0.6.4-SNAPSHOT/maven-metadata.xml jvm 2    | java.lang.NullPointerException jvm 2    | 2012-02-22 00:56:43.352:WARN:oejs.ServletHandler:/content/groups/scala-tools/org/springframework/org.springframework.context/3.0.5.RELEASE/org.springframework.context-3.0.5.RELEASE.pom jvm 2    | java.lang.NullPointerException ",Bug,Critical,Closed,"2012-02-22 20:12:41","2012-02-22 20:12:41",1
"Sonatype Nexus","Make Jetty use slf4j as all the sonatype apps does.","Make Jetty use slf4j as all the sonatype apps does  ",Improvement,Major,Closed,"2012-02-22 14:20:35","2012-02-22 14:20:35",1
"Sonatype Nexus","PermGen OOM in org.sonatype.nexus.mock.SimpleLRTest on Windows (caused hang during tearDown)","2012-02-22 06:08:11  Full thread dump Java HotSpot(TM) 64-Bit Server VM (20.5-b03 mixed mode):    MultiThreadedHttpConnectionManager cleanup daemon prio=6 tid=0x0000000008620000 nid=0x1630 in Object.wait() [0x000000000c19f000]     java.lang.Thread.State: WAITING (on object monitor)   at java.lang.Object.wait(Native Method)   - waiting on <0x00000000c0accfe8> (a java.lang.ref.ReferenceQueue$Lock)   at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:118)   - locked <0x00000000c0accfe8> (a java.lang.ref.ReferenceQueue$Lock)   at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:134)   at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$ReferenceQueueThread.run(Unknown Source)       Locked ownable synchronizers:   - None    Low Memory Detector daemon prio=6 tid=0x0000000004eff000 nid=0x15e0 runnable [0x0000000000000000]     java.lang.Thread.State: RUNNABLE       Locked ownable synchronizers:   - None    C2 CompilerThread1 daemon prio=10 tid=0x0000000004ee5000 nid=0x15c4 waiting on condition [0x0000000000000000]     java.lang.Thread.State: RUNNABLE       Locked ownable synchronizers:   - None    C2 CompilerThread0 daemon prio=10 tid=0x000000000052b000 nid=0x15c0 waiting on condition [0x0000000000000000]     java.lang.Thread.State: RUNNABLE       Locked ownable synchronizers:   - None    Attach Listener daemon prio=10 tid=0x0000000000525800 nid=0x1410 waiting on condition [0x0000000000000000]     java.lang.Thread.State: RUNNABLE       Locked ownable synchronizers:   - None    Signal Dispatcher daemon prio=10 tid=0x0000000004ee0800 nid=0x10f8 runnable [0x0000000000000000]     java.lang.Thread.State: RUNNABLE       Locked ownable synchronizers:   - None    Finalizer daemon prio=8 tid=0x0000000000510800 nid=0x13f4 in Object.wait() [0x0000000004e9f000]     java.lang.Thread.State: WAITING (on object monitor)   at java.lang.Object.wait(Native Method)   - waiting on <0x00000000c0019218> (a java.lang.ref.ReferenceQueue$Lock)   at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:118)   - locked <0x00000000c0019218> (a java.lang.ref.ReferenceQueue$Lock)   at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:134)   at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)       Locked ownable synchronizers:   - None    Reference Handler daemon prio=10 tid=0x0000000000507800 nid=0x15b0 in Object.wait() [0x0000000004d9f000]     java.lang.Thread.State: WAITING (on object monitor)   at java.lang.Object.wait(Native Method)   - waiting on <0x00000000c009c2b0> (a java.lang.ref.Reference$Lock)   at java.lang.Object.wait(Object.java:485)   at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)   - locked <0x00000000c009c2b0> (a java.lang.ref.Reference$Lock)       Locked ownable synchronizers:   - None    main prio=6 tid=0x00000000005cb000 nid=0x1580 waiting on condition [0x000000000121d000]     java.lang.Thread.State: WAITING (parking)   at sun.misc.Unsafe.park(Native Method)   - parking to wait for  <0x00000000c28a24a8> (a java.util.concurrent.CountDownLatch$Sync)   at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)   at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:811)   at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:969)   at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1281)   at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:207)   at org.sonatype.sisu.jetty.Jetty8$JettyWrapperThread.stopJetty(Jetty8.java:180)   at org.sonatype.sisu.jetty.Jetty8.stopJetty(Jetty8.java:94)   - locked <0x00000000c2bd68b8> (a org.sonatype.sisu.jetty.Jetty8)   at org.sonatype.nexus.mock.MockNexusEnvironment.stop(MockNexusEnvironment.java:185)   at org.sonatype.nexus.mock.SimpleLRTest.tearDown(SimpleLRTest.java:84)   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)   at java.lang.reflect.Method.invoke(Method.java:597)   at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)   at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)   at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)   at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:37)   at org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)   at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)   at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)   at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)   at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)   at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)   at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)   at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)   at org.junit.runners.ParentRunner.run(ParentRunner.java:236)   at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53)   at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123)   at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104)   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)   at java.lang.reflect.Method.invoke(Method.java:597)   at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)   at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)   at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:175)   at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:107)   at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:68)       Locked ownable synchronizers:   - None    VM Thread prio=10 tid=0x00000000004ff000 nid=0x13b0 runnable     GC task thread#0 (ParallelGC) prio=6 tid=0x000000000045e000 nid=0x15b8 runnable     GC task thread#1 (ParallelGC) prio=6 tid=0x0000000000460800 nid=0x1310 runnable     VM Periodic Task Thread prio=10 tid=0x0000000004f17800 nid=0x15e4 waiting on condition     JNI global references: 1379    https://builds.sonatype.org/job/nexus-oss-its/jdk=java-6x,label=win/200/console",Bug,Major,Closed,"2012-02-22 12:10:34","2012-02-22 12:10:34",1
"Sonatype Nexus","Regression Nexus3947ArchetypeCatalogIT.testArchetypeCatalog","Failed    org.sonatype.nexus.integrationtests.nexus3947.Nexus3947ArchetypeCatalogIT.testArchetypeCatalog (from Nexus3947ArchetypeCatalogIT)     https://builds.sonatype.org/job/nexus-oss-its/199/jdk=java-6x,label=linux/testReport/org.sonatype.nexus.integrationtests.nexus3947/Nexus3947ArchetypeCatalogIT/testArchetypeCatalog/    ",Bug,Major,Closed,"2012-02-22 09:43:18","2012-02-22 09:43:18",1
"Sonatype Nexus","Failed Nexus4579OptionalTrashForSnapshotsIT.@AfterMethod cleanTrash","Failed  org.sonatype.nexus.integrationtests.nexus4579.Nexus4579OptionalTrashForSnapshotsIT.@AfterMethod cleanTrash (from Nexus4579OptionalTrashForSnapshotsIT)   https://builds.sonatype.org/job/nexus-oss-its/198/jdk=java-6x,label=linux/testReport/org.sonatype.nexus.integrationtests.nexus4579/Nexus4579OptionalTrashForSnapshotsIT/_AfterMethod_cleanTrash_2/  ",Bug,Major,Closed,"2012-02-22 09:39:43","2012-02-22 09:39:43",1
"Sonatype Nexus","Artifact paths with special characters cannot be found or deleted from UI Browse local storage","# in your local hosted releases repo create the following paths:  {{mkdir 'sonatype-work/nexus/storage/releases/>foo'}}  {{mkdir 'sonatype-work/nexus/storage/releases/&foo'}}  {{mkdir 'sonatype-work/nexus/storage/releases/%foo'}}  {{mkdir 'sonatype-work/nexus/storage/releases/\{foo'}}  # start Nexus if you haven't already. Login as admin. Browse releases repo local storage. You should see the file paths above.  # right click on each one and select delete and click Ok to confirm.   Result '&foo' can be deleted, the others cannot.  Expected any path shown in UI to be deleted and/or looked up from UI upon request.  # Also notice the '(Not Found)' text appended to tree paths when selected in the tree.    See attached video for overview.    1.9.2.4 behaved slightly different, finding more paths, but also returning server error for the one with percent sign, where 2.0 simply says Not Found.          ",Bug,Major,Closed,"2012-02-20 19:37:52","2012-02-20 19:37:52",1
"Sonatype Nexus","nexus ldap plugin should run tests use JUnit 4 runner instead of JUnit38ClassRunner","I tried adding a unit test to org.sonatype.security.ldap.dao.LdapGroupDAOTest in ldap-common module.    Since all the unit test methods are using Junit 4x annotations I assumed these were being used to run the tests. It turns out that this is not forced ( it used to be afaik ) and instead Junit delegates to org.junit.internal.runners.JUnit38ClassRunner instead since in above case depends on AbstractLdapTestEnvironment from https://github.com/sonatype/sisu-ldap-testsuite/tree/plexus-ldap-testsuite-1.4 which extends PlexusTestCase which finally extends Junit 3x TestCase. Surefire decides that Junit 3 runer must be used then.    This leads to confusion in writing additional tests and who knows if some test methods are not being run because they are not named properly.    {quote}  -------------------------------------------------------------------------------  Test set: org.sonatype.security.ldap.dao.LdapGroupDAOTest  -------------------------------------------------------------------------------  Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 2.803 sec <<< FAILURE!  testUsingInvalidGroupMemberFormat(org.sonatype.security.ldap.dao.LdapGroupDAOTest)  Time elapsed: 0.768 sec  <<< ERROR!  org.sonatype.security.ldap.dao.NoLdapUserRolesFoundException: No roles found for user: <USER>         at org.sonatype.security.ldap.dao.DefaultLdapGroupDAO.getGroupMembership(DefaultLdapGroupDAO.java:86)          at org.sonatype.security.ldap.dao.LdapGroupDAOTest.doTestWithGroupMemberFormat(LdapGroupDAOTest.java:79)          at org.sonatype.security.ldap.dao.LdapGroupDAOTest.testUsingInvalidGroupMemberFormat(LdapGroupDAOTest.java:48)          at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)          at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)          at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)          at java.lang.reflect.Method.invoke(Method.java:597)          at junit.framework.TestCase.runTest(TestCase.java:168)          at junit.framework.TestCase.runBare(TestCase.java:134)          at junit.framework.TestResult$1.protect(TestResult.java:110)          at junit.framework.TestResult.runProtected(TestResult.java:128)          at junit.framework.TestResult.run(TestResult.java:113)          at junit.framework.TestCase.run(TestCase.java:124)          at junit.framework.TestSuite.runTest(TestSuite.java:243)          at junit.framework.TestSuite.run(TestSuite.java:238)          *at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)*          at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53)          at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123)          at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104)          at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)          at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)          at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)          at java.lang.reflect.Method.invoke(Method.java:597)          at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)          at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)  {quote}",Bug,Major,Closed,"2012-02-20 15:00:17","2012-02-20 15:00:17",1
"Sonatype Nexus","When deleting repositories if there are dependencies you get an awful error message giving a bad request","It would be nicer if the dependencies were enumerated for the user so they at least know what to look at. In my case I was trying to delete the java.net repositories in the default setup but the shadow repository depended on it, but the error message didn't say that.",Bug,Major,Closed,"2012-02-20 13:39:32","2012-02-20 13:39:32",1
"Sonatype Nexus","Search error message disappears when Repository panel queries 'repository_statuses' resource","Nexus is set up with a proxy on localhost, but the port is closed. When the 'Repositories' panel is open, it queries a REST resource every few seconds (autoblock status or sth?).    That causes an invalid search query message on the search panel to disappear.    See attached video.",Bug,Minor,Closed,"2012-02-17 10:23:11","2012-02-17 10:23:11",2
"Sonatype Nexus","Add an example jetty.xml which shows how to configure access logging.","We should add an example jetty.xml into <nexus_root>/conf/examples which shows how to enable access logging.    I've attached the file which needs to be included.",Improvement,Major,Closed,"2012-02-16 17:56:32","2012-02-16 17:56:32",1
"Sonatype Nexus","Attribute storage should discard empty attribute files",,Improvement,Major,Closed,"2012-02-16 16:12:00","2012-02-16 16:12:00",2
"Sonatype Nexus","NonProxyHosts broken for HttpClient 4 remote storage","Set global proxy to something but don't start a proxy. With nexus.codehaus.org as a non-proxy host, httpclient3 remote storage is able to use the repo. httpclient4 breaks.    {code}    <globalHttpProxySettings>      <proxyHostname>localhost</proxyHostname>      <proxyPort>8888</proxyPort>      <nonProxyHosts>        <nonProxyHost>nexus.codehaus.org</nonProxyHost>      </nonProxyHosts>    </globalHttpProxySettings>  {code}    ",Bug,Major,Closed,"2012-02-16 11:32:02","2012-02-16 11:32:02",1
"Sonatype Nexus","Upgrade lucene version","Upgrade lucene to newest version (that we think is stable).",Bug,Major,Closed,"2012-02-15 20:17:24","2012-02-15 20:17:24",6
"Sonatype Nexus","Upgrade to shiro 1.2","Upgrade to latest shiro version.",Bug,Major,Closed,"2012-02-15 19:19:36","2012-02-15 19:19:36",6
"Sonatype Nexus","Nexus makes impossible to proxy Flex SWC artifacts","There is a mishap between what Nexus expects and how Nexus reports the MIME type of Flex SWC files, making impossible to proxy SWC files if on both ends (remote being proxied and local proxying remote) are Nexuses!    Circumvention: turn of content validation.    Problems are here:  https://github.com/sonatype/nexus/blob/master/nexus/nexus-api/src/main/resources/mime-types.properties#L15    So, Nexus reports downstream MIME type of application/x-compressed. This part user can customize, IF he manages the remote Nexus!    But, here:  https://github.com/sonatype/nexus/blob/master/nexus/nexus-proxy/src/main/java/org/sonatype/nexus/proxy/maven/MavenFileTypeValidator.java#L59    It is set to expect MIME type of application/zip, this part cannot be customized at all!    Hence, if you are NOT managing remote Nexus, you cannot Proxy flex stuff unless you turn content validation OFF.",Bug,Critical,Closed,"2012-02-15 17:02:58","2012-02-15 17:02:58",1
"Sonatype Nexus","Nexus Plugin Manager matches plugin interdependencies by GA only on loaded plugins","Nexus Plugin Manager matches plugin interdependencies by GA only on loaded plugins, but it should always do that. Here is a log snippet:        This clearly shows, that Indexer 2.0 is looked for (as transitive dependency of staging and other plugins) but was not found, since there was Indexer 2.1 present. Later in logs -- I assume, since it is not in snippet -- the Indexer 2.1 was loaded just fine.",Bug,Major,Closed,"2012-02-14 09:13:27","2012-02-14 09:13:27",3
"Sonatype Nexus","Snapshot remover task should not stop if it encounters a zero length file","Zero length files will get created in the storage area if a user runs out of disk space, or file handles.    The snapshot remover should not stop processing if it encounters these.    As a matter of fact, a strong argument can be made that it should just remove them.      ",Bug,Major,Closed,"2012-02-13 18:59:25","2012-02-13 18:59:25",1
"Sonatype Nexus","Permission problems upon attribute upgrades",,Bug,Major,Closed,"2012-02-10 16:43:59","2012-02-10 16:43:59",1
"Sonatype Nexus","Unable to process template logged at WARN","See a bunch of these Unable to process template messages logged as WARN on RSO.    According to SUPPORT-355, stack trace was removed ( good! ) but this message still prints at WARN. Since administrator can do nothing with Unable to process template + it appears to point to a problem which cannot be fixed +  it just fills error warning feed with useless WARNs - why don't we just remove it?",Bug,Major,Closed,"2012-02-10 16:35:38","2012-02-10 16:35:38",1
"Sonatype Nexus","Repository registry becomes a CPU hog when registry contains a lot of repositories, and does too much","Repository registry becomes a CPU hog when registry contains a lot of repositories, and does too much.    Repository registry should be smarter, and instead of creating new map instance per invocation of getRepositoriesMap() -- to which all registry method boils down, it should only recreate the read-only view on when needed basis.",Bug,Blocker,Closed,"2012-02-10 13:01:27","2012-02-10 13:01:27",1
"Sonatype Nexus","Information Panels vanish from UI when clicking on SNAPSHOT with classifier","http://screencast.com/t/qXs4oRPcrp5v    <hanzelm> can anyone confirm: selecting nexus-maven-plugin-2.1-SNAPSHOT-site.xml breaks information tab on the right https://repository.sonatype.org/index.html#nexus-search;gav~org.sonatype.plugins~nexus-maven-plugin~~~~kw,versionexpand    ",Bug,Major,Closed,"2012-02-10 12:43:49","2012-02-10 12:43:49",2
"Sonatype Nexus","Weekly tasks show next run as today","I created a task scheduled to run WEEKLY on monday, but UI shows next run as being friday.  http://screencast.com/t/IVWTU6C7",Bug,Major,Closed,"2012-02-10 11:50:03","2012-02-10 11:50:03",2
"Sonatype Nexus","M2RepositoryTest hanging test using Jetty 6x windows","Noticed nexus-oss-its was hanging for 11 hours and took a thread dump of the stuck surefire process.            ",Bug,Major,Closed,"2012-02-09 19:44:58","2012-02-09 19:44:58",3
"Sonatype Nexus","Upgrade to Jetty 8","Upgrade to latest released Jetty version.    Note: this will need to be tested against IBM JRE's.",Improvement,Major,Closed,"2012-02-09 19:34:07","2012-02-09 19:34:07",3
"Sonatype Nexus","Support using @Typed to override the role for Nexus @ExtensionPoints","Components implementing Nexus @ExtensionPoints are currently processed as Plexus components with special defaults. The role is assumed to be whatever interface in the declared implements list is marked with @ExtensionPoint; and the hint is assumed to be the fully qualified name of the implementation. The hint can be customized by adding the JSR330 @Named annotation to the implementation, but the only way to customize the role is to use a Plexus @Component annotation with a custom role and hint*. For completeness we should also look for @Typed and use that to customize the Plexus component role.    [* If the implementation extends an abstract class you could always remove the marker interface from the declared implements list since the @ExtensionPoint scanning is only done on the declared implements list and not the complete type hierarchy, but this is not always possible]",Improvement,Minor,Closed,"2012-02-09 04:40:38","2012-02-09 04:40:38",1
"Sonatype Nexus","Snapshot remover Could not find component that implements SchedulerTask of type='HealthCheckTask'","On RSO (2.0-RC1 patched with 1.6 of sisu-task-scheduler jar), upon initiation of the scheduled snapshot remover run, the following log entries showed.  This message was not in at least the last 10 days (since 01-29-2012) -- do not look further back than that.    2012-02-08 18:00:00 WARN  [pool-1-thread-5] - org.sonatype.nexus.maven.tasks.SnapshotRemoverTask - Could not find component that implements SchedulerTask of type='HealthCheckTask'!  2012-02-08 18:00:00 INFO  [pool-1-thread-5] - org.sonatype.nexus.configuration.application.DefaultNexusConfiguration - Applying Nexus Configuration due to changes in [Scheduled Task Configuration]...  2012-02-08 18:00:00 INFO  [pool-1-thread-5] - org.sonatype.nexus.maven.tasks.SnapshotRemoverTask - Scheduled task (Remove Snapshots) started :: Removing snapshots from all registered repositories  2012-02-08 18:00:00 INFO  [pool-1-thread-5] - org.sonatype.nexus.maven.tasks.DefaultSnapshotRemover - Removing old SNAPSHOT deployments from all repositories.  ",Bug,Blocker,Closed,"2012-02-09 00:11:15","2012-02-09 00:11:15",1
"Sonatype Nexus","Consolidate logging levels in Nexus Core","Consolidate logging levels in Nexus Core.    Many log entries have wrong levels (INFO instead of DEBUG), and many of them dumps stack traces at unexpected levels (like stack trace dumped on INFO level).    Chat about this at the very end of IRC https://docs.sonatype.com/display/IRC/2012-02-07",Improvement,Major,Closed,"2012-02-08 11:57:24","2012-02-08 11:57:24",1
"Sonatype Nexus","Make usernames case insensitive for the XML realm","Currently the following two usernames joe.bloggs and Joe.Bloggs are independant users within the user database. Some users add uppercase characters to their username even when given in all lowercase which can cause some problems in logging into the system.    By making the username case insensitive this will ensure this confusion cannot occur.    NOTE: we need to make sure this solution will work for cases where the realm implementation expects case sensitive IDs (not sure on that use case though)    (my guess is this is just a simple toLower() fix before we lookup the userID in hashmap in memory)  ",Improvement,Minor,Closed,"2012-02-08 09:29:19","2012-02-08 09:29:19",1
"Sonatype Nexus","Log spam","should be DEBUG in my opinion      And        ",Improvement,Major,Closed,"2012-02-08 02:21:46","2012-02-08 02:21:46",1
"Sonatype Nexus","Checksum search 'Browse' applet certificate has expired","Click on 'Browse' button for checksum search. The applet that launches is signed by an expired certificate.    See attached screenshot.    Other than lack of trust, user can still accept the cert.",Bug,Major,Closed,"2012-02-07 13:49:13","2012-02-07 13:49:13",1
"Sonatype Nexus","UI Server Administration role does not contain all privs required by that screen","When i have a user with only the UI Server Administration role (along with the the UI base role), i get a 403 when attempting to click open the role selector for notifications (click on add button), or if i attempt to validate smtp settings, requests listed below each got 403 response    http://localhost:8081/nexus/service/local/check_smtp_settings?undefined  http://localhost:8081/nexus/service/local/rolesAndPrivs?start=0&limit=25&sort=name&dir=ASC",Bug,Major,Closed,"2012-02-06 19:36:45","2012-02-06 19:36:45",1
"Sonatype Nexus","UI User Administration role does not allow all privs required by that screen","When i have a user with only the UI User Administration role (along the the UI base role), i get a 403 when attempting to click open the role selector for a user (click on add button)    http://localhost:8081/nexus/service/local/rolesAndPrivs?start=0&sort=name&dir=ASC",Bug,Major,Closed,"2012-02-06 19:31:28","2012-02-06 19:31:28",1
"Sonatype Nexus","Failed Nexus3882IPAtAthenticationFailureFeedIT.failAuthentication","Failed    org.sonatype.nexus.integrationtests.nexus3882.Nexus3882IPAtAthenticationFailureFeedIT.failAuthentication (from Nexus3882IPAtAthenticationFailureFeedIT)     https://builds.sonatype.org/job/nexus-oss-its/183/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus3882/Nexus3882IPAtAthenticationFailureFeedIT/failAuthentication/    ",Bug,Major,Closed,"2012-02-06 11:19:20","2012-02-06 11:19:20",1
"Sonatype Nexus","Failed Nexus3670IndexTreeViewIT.@BeforeMethod oncePerClassSetUp","Failed    org.sonatype.nexus.integrationtests.nexus3670.Nexus3670IndexTreeViewIT.@BeforeMethod oncePerClassSetUp (from Nexus3670IndexTreeViewIT)     https://builds.sonatype.org/job/nexus-oss-its/183/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus3670/Nexus3670IndexTreeViewIT/_BeforeMethod_oncePerClassSetUp/    ",Bug,Major,Closed,"2012-02-06 11:17:04","2012-02-06 11:17:04",1
"Sonatype Nexus","Failed Nexus4593NoAutoblockFor403IT.testNoAutoblockOn403","Failed    org.sonatype.nexus.integrationtests.nexus4593.Nexus4593NoAutoblockFor403IT.testNoAutoblockOn403 (from Nexus4593NoAutoblockFor403IT)     https://builds.sonatype.org/job/nexus-oss-its/183/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.integrationtests.nexus4593/Nexus4593NoAutoblockFor403IT/testNoAutoblockOn403/    ",Bug,Major,Closed,"2012-02-06 11:08:21","2012-02-06 11:08:21",1
"Sonatype Nexus","remove org.jsecurity from logback-nexus.xml","This should have never made it into the logback config,    we may want to evaluate why we originally set that logger to warn, and do the same for org.apache.shiro",Improvement,Major,Closed,"2012-02-03 21:04:43","2012-02-03 21:04:43",0.1
"Sonatype Nexus","Nexus 2.0 doesn't run under IBM java ","Nexus 2.0 won't start when running under IBM java.  Tried both version 7.0.0.0 and 6.0.10.0.    Logs attached.",Bug,Major,Closed,"2012-02-03 21:01:59","2012-02-03 21:01:59",1
"Sonatype Nexus","Nexus 2.0 won't start on Resin 4.0.25","Nexus 2.0 won't run in Resin 4.0.25.    Note that this is logged as a warning, but because of this problem attempts to access Nexus return error 503.    This is a regression, 1.9.2.4 works fine with this version of Resin.    {quote}  2012-02-03 11:21:38 WARN  [http://*:8080-1] - com.caucho.server.webapp.ErrorPageManager - javax.servlet.ServletException: javax.enterprise.inject.UnsatisfiedResolutionException: org.sonatype.nexus.web.NexusGuiceFilter.pipelines: Can't find a bean for 'interface java.util.List<interface com.google.inject.servlet.FilterPipeline>' because no beans implementing that class have been registered with the injection manager InjectManager[web-app:production/webapp/default/nexus].  javax.servlet.ServletException: javax.enterprise.inject.UnsatisfiedResolutionException: org.sonatype.nexus.web.NexusGuiceFilter.pipelines: Can't find a bean for 'interface java.util.List<interface com.google.inject.servlet.FilterPipeline>' because no beans implementing that class have been registered with the injection manager InjectManager[web-app:production/webapp/default/nexus].   at com.caucho.server.dispatch.FilterManager.createFilter(FilterManager.java:233) ~[resin.jar:4.0.25]   at com.caucho.server.dispatch.FilterMapper.buildDispatchChain(FilterMapper.java:169) ~[resin.jar:4.0.25]   at com.caucho.server.webapp.WebApp.buildInvocation(WebApp.java:3820) ~[resin.jar:4.0.25]   at com.caucho.server.webapp.WebAppContainer.buildInvocation(WebAppContainer.java:781) ~[resin.jar:4.0.25]   at com.caucho.server.host.Host.buildInvocation(Host.java:752) ~[resin.jar:4.0.25]   at com.caucho.server.host.HostContainer.buildInvocation(HostContainer.java:319) ~[resin.jar:4.0.25]   at com.caucho.server.cluster.Server.buildInvocation(Server.java:912) ~[resin.jar:4.0.25]   at com.caucho.server.dispatch.InvocationServer.buildInvocation(InvocationServer.java:247) ~[resin.jar:4.0.25]   at com.caucho.server.dispatch.InvocationServer.buildInvocation(InvocationServer.java:220) ~[resin.jar:4.0.25]   at com.caucho.server.http.AbstractHttpRequest.buildInvocation(AbstractHttpRequest.java:1492) ~[resin.jar:4.0.25]   at com.caucho.server.http.AbstractHttpRequest.getInvocation(AbstractHttpRequest.java:1465) ~[resin.jar:4.0.25]   at com.caucho.server.http.HttpRequest.handleRequest(HttpRequest.java:793) ~[resin.jar:4.0.25]   at com.caucho.network.listen.TcpSocketLink.dispatchRequest(TcpSocketLink.java:1221) [resin.jar:4.0.25]   at com.caucho.network.listen.TcpSocketLink.handleRequest(TcpSocketLink.java:1177) [resin.jar:4.0.25]   at com.caucho.network.listen.TcpSocketLink.handleRequestsImpl(TcpSocketLink.java:1161) [resin.jar:4.0.25]   at com.caucho.network.listen.TcpSocketLink.handleRequests(TcpSocketLink.java:1084) [resin.jar:4.0.25]   at com.caucho.network.listen.TcpSocketLink.handleAcceptTask(TcpSocketLink.java:907) [resin.jar:4.0.25]   at com.caucho.network.listen.AcceptTask.doTask(AcceptTask.java:74) [resin.jar:4.0.25]   at com.caucho.network.listen.ConnectionTask.runThread(ConnectionTask.java:97) [resin.jar:4.0.25]   at com.caucho.network.listen.ConnectionTask.run(ConnectionTask.java:80) [resin.jar:4.0.25]   at com.caucho.network.listen.AcceptTask.run(AcceptTask.java:59) [resin.jar:4.0.25]   at com.caucho.env.thread.ResinThread.runTasks(ResinThread.java:164) [resin.jar:4.0.25]   at com.caucho.env.thread.ResinThread.run(ResinThread.java:130) [resin.jar:4.0.25]  Caused by: javax.enterprise.inject.UnsatisfiedResolutionException: org.sonatype.nexus.web.NexusGuiceFilter.pipelines: Can't find a bean for 'interface java.util.List<interface com.google.inject.servlet.FilterPipeline>' because no beans implementing that class have been registered with the injection manager InjectManager[web-app:production/webapp/default/nexus].   at com.caucho.config.inject.InjectionTargetBuilder$FieldInjectProgram.bind(InjectionTargetBuilder.java:986) ~[resin.jar:4.0.25]   at com.caucho.config.inject.CandiProducer.bind(CandiProducer.java:144) ~[resin.jar:4.0.25]   at com.caucho.config.inject.InjectionTargetBuilder.bind(InjectionTargetBuilder.java:198) ~[resin.jar:4.0.25]   at com.caucho.config.inject.InjectionTargetBuilder.produce(InjectionTargetBuilder.java:215) ~[resin.jar:4.0.25]   at com.caucho.server.dispatch.FilterManager.createFilter(FilterManager.java:189) ~[resin.jar:4.0.25]   ... 22 common frames omitted  Caused by: javax.enterprise.inject.UnsatisfiedResolutionException: Can't find a bean for 'interface java.util.List<interface com.google.inject.servlet.FilterPipeline>' because no beans implementing that class have been registered with the injection manager InjectManager[web-app:production/webapp/default/nexus].   at com.caucho.config.inject.InjectManager.unsatisfiedException(InjectManager.java:2367) ~[resin.jar:4.0.25]   at com.caucho.config.inject.InjectManager.resolveByInjectionPoint(InjectManager.java:2552) ~[resin.jar:4.0.25]   at com.caucho.config.inject.InjectManager.getReferenceFactory(InjectManager.java:2510) ~[resin.jar:4.0.25]   at com.caucho.config.inject.InjectManager.getReferenceFactory(InjectManager.java:2489) ~[resin.jar:4.0.25]   at com.caucho.config.inject.InjectionTargetBuilder$FieldInjectProgram.bind(InjectionTargetBuilder.java:978) ~[resin.jar:4.0.25]   ... 26 common frames omitted  {quote}",Bug,Major,Closed,"2012-02-03 17:39:32","2012-02-03 17:39:32",1
"Sonatype Nexus","Final bundle for Nexus needs to include the free binary license","The RHC plugin is licensed using the free license, so the final bundle must also include this license. The text is available here:https://docs.sonatype.com/display/ProdMgmt/Sonatype+Free+Plugin+License",Improvement,Major,Closed,"2012-02-03 16:01:26","2012-02-03 16:01:26",1
"Sonatype Nexus","Failed GroupReindexIndexerManagerTest.testGroupReindex","Failed    org.sonatype.nexus.index.GroupReindexIndexerManagerTest.testGroupReindex (from GroupReindexIndexerManagerTest)     https://builds.sonatype.org/job/nexus-oss-its/180/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.index/GroupReindexIndexerManagerTest/testGroupReindex/    ",Bug,Major,Closed,"2012-02-03 10:37:39","2012-02-03 10:37:39",1
"Sonatype Nexus","Regression GroupMetadataMergeTest.testGAVMergeWithNewBuildNumberAndOldTimestamp","Regression    org.sonatype.nexus.proxy.maven.metadata.GroupMetadataMergeTest.testGAVMergeWithNewBuildNumberAndOldTimestamp (from GroupMetadataMergeTest)     https://builds.sonatype.org/job/nexus-oss-its/178/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.proxy.maven.metadata/GroupMetadataMergeTest/testGAVMergeWithNewBuildNumberAndOldTimestamp/    ",Bug,Major,Closed,"2012-02-03 10:35:01","2012-02-03 10:35:01",1
"Sonatype Nexus","Minor recommended changes to logging configuration UI","See attached image",Improvement,Minor,Closed,"2012-02-01 23:58:00","2012-02-01 23:58:00",1
"Sonatype Nexus","Regression MavenRepositoryTemplateTest.testAvailableRepositoryTemplateCount","Regression  org.sonatype.nexus.templates.repository.maven.MavenRepositoryTemplateTest.testAvailableRepositoryTemplateCount (from MavenRepositoryTemplateTest)   ",Bug,Major,Closed,"2012-02-01 14:25:44","2012-02-01 14:25:44",1
"Sonatype Nexus","Regression DefaultNexusTest.testRepositoryTemplates","Regression org.sonatype.nexus.DefaultNexusTest.testRepositoryTemplates (from DefaultNexusTest)  https://builds.sonatype.org/job/nexus-oss/778/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus/DefaultNexusTest/testRepositoryTemplates/  ",Bug,Major,Closed,"2012-02-01 14:24:52","2012-02-01 14:24:52",1
"Sonatype Nexus","Repositories on removal from System does not get unregistered from Plexus container ","Repositories on removal from System does not get unregistered from Plexus container.    This is causing slow leak (a proper leak, but grows slowly), since all the created and dropped repositories are actually kept pinned in memory and in plexus, queued for potential lifecycle management.    Think any use cases, where repositories are created and dropped at fast pace (ie. staging).",Bug,Blocker,Closed,"2012-01-31 16:49:24","2012-01-31 16:49:24",1
"Sonatype Nexus","Nexus Configuration version should match Nexus version","This has slipped again in latest builds. Apparently we agreed that Nexus configuration version should match the version of Nexus core to simplify things. However Nexus configuration version remains at 1.10.0 when we have moved to 2.0 - you notice this in particular when upgrading from a previous Nexus version.    This version mangling should be automated and tested with unit test if we are sticking to this rule.",Bug,Major,Closed,"2012-01-31 15:28:23","2012-01-31 15:28:23",1
"Sonatype Nexus","Unable to deploy a project to m1 hosted repository","While testing NXCM-3145 I tried to deploy a project to m1 hosted repository and got the following error:      Out of curiosity I changed the layout to RELEASE and then nothing was deployable:      So it looks like the problem only occur with SNAPSHOT artifact WITH classifier.",Bug,Major,Closed,"2012-01-31 13:01:10","2012-01-31 13:01:10",1
"Sonatype Nexus","Tabs on repository panel do not scroll","The upper tab pane ('Welcome', 'Repositories', ...) will offer scroll buttons, but the repository tab pane is just out of reach.",Bug,Minor,Closed,"2012-01-31 11:47:43","2012-01-31 11:47:43",1
"Sonatype Nexus","Failed  Nexus4341RunningTaskNotEditableIT.testNoUpdateForRunningTasks","Failed on windows:  org.sonatype.nexus.integrationtests.nexus4341.Nexus4341RunningTaskNotEditableIT.testNoUpdateForRunningTasks    https://builds.sonatype.org/job/nexus-oss-its/jdk=java-6x,label=win/174/testReport/org.sonatype.nexus.integrationtests.nexus4341/Nexus4341RunningTaskNotEditableIT/testNoUpdateForRunningTasks/    ",Bug,Major,Closed,"2012-01-31 10:47:27","2012-01-31 10:47:27",1
"Sonatype Nexus","Proxy attributes in virtual repositories don't get upgraded","After upgrading from 1.9.2.4 to 2.0 the proxy/attributes in my central-m1 shadow repository were not upgraded.    ",Bug,Major,Closed,"2012-01-30 19:19:01","2012-01-30 19:19:01",1
"Sonatype Nexus","Attributes upgrade logs exception when it doesn't encounter README.txt","Attributes upgrade blows up when README.txt isn't at root of old directory:    {quote}  jvm 1    | 2012-01-27 16:40:53 ERROR [host-1-thread-3] - org.sonatype.nexus.proxy.attributes.upgrade.DefaultAttributeUpgrader - Unable to perform file read from legacy attributes directory: /home/<USER>test/nexus/nexus-professional-2.0-SNAPSHOT/./../sonatype-work/nexus/proxy/attributes  jvm 1    | java.io.FileNotFoundException: /home/<USER>test/nexus/nexus-professional-2.0-SNAPSHOT/./../sonatype-work/nexus/proxy/attributes/README.txt (No such file or directory)  jvm 1    |  at java.io.FileInputStream.open(Native Method) ~[na:1.6.0_29]  jvm 1    |  at java.io.FileInputStream.<init>(FileInputStream.java:120) ~[na:1.6.0_29]  jvm 1    |  at org.codehaus.plexus.util.FileUtils.fileRead(FileUtils.java:383) ~[plexus-utils-2.1.jar:na]  jvm 1    |  at org.codehaus.plexus.util.FileUtils.fileRead(FileUtils.java:359) ~[plexus-utils-2.1.jar:na]  jvm 1    |  at org.sonatype.nexus.proxy.attributes.upgrade.DefaultAttributeUpgrader.isUpgradeDone(DefaultAttributeUpgrader.java:269) [nexus-proxy-2.0-SNAPSHOT.jar:na]  jvm 1    |  at org.sonatype.nexus.proxy.attributes.upgrade.DefaultAttributeUpgrader.isUpgradeFinished(DefaultAttributeUpgrader.java:136) [nexus-proxy-2.0-SNAPSHOT.jar:na]  jvm 1    |  at org.sonatype.nexus.proxy.attributes.upgrade.DefaultAttributeUpgrader.upgradeAttributes(DefaultAttributeUpgrader.java:221) [nexus-proxy-2.0-SNAPSHOT.jar:na]  jvm 1    |  at org.sonatype.nexus.proxy.attributes.upgrade.DefaultAttributeUpgrader.upgradeAttributes(DefaultAttributeUpgrader.java:202) [nexus-proxy-2.0-SNAPSHOT.jar:na]  jvm 1    |  at org.sonatype.nexus.proxy.attributes.upgrade.AttributesUpgradeEventInspector.inspect(AttributesUpgradeEventInspector.java:47) [nexus-proxy-2.0-SNAPSHOT.jar:na]  jvm 1    |  at org.sonatype.nexus.events.DefaultEventInspectorHost$EventInspectorHandler.run(DefaultEventInspectorHost.java:164) [nexus-app-2.0-SNAPSHOT.jar:na]  jvm 1    |  at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) [na:1.6.0_29]  jvm 1    |  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) [na:1.6.0_29]  jvm 1    |  at java.lang.Thread.run(Thread.java:662) [na:1.6.0_29]  {quote}",Bug,Major,Closed,"2012-01-27 22:43:25","2012-01-27 22:43:25",1
"Sonatype Nexus","Only proxy repositories should participate in not found cache (NFC) to improve performance","NFC was used (entries were put into it) by _all_ repositories present in System, even by those that actually _neglected_ the NFC -- group repositories.    Also, hosted repositories NFC use has low impact, since FS file lookup will fairly quickly bounce back the request as not found.    Hence, it is reasonable to have proxy repositories use NFC only, especially since NFC is made _shared_ across all repositories, and all repositories were fighting about 100k entries (default size).    Before this change, it was totally plausible to have _groups_ -- that are even not using NFC -- fill up the cache, not even letting 10% of cache to proxy repositories, where lack of NFC hurts performance much (ie. remote request is not cheap measured in time). Now, only proxy repositories are sharing all of the single NFC, hence their use of it is drastically increased.",Bug,Major,Closed,"2012-01-27 14:24:59","2012-01-27 14:24:59",1
"Sonatype Nexus","RecreateMavenMetadata always overwrites checksum files","RecreateMavenMetadata always overwrites checksum files, even if they are correct.    This was a long outstanding issue, not a regression.",Bug,Major,Closed,"2012-01-27 14:19:43","2012-01-27 14:19:43",1
"Sonatype Nexus","Form values are HTML encoded multiple times on save","The REST layer encodes special characters in message payload as HTML entities as a means to protect the UI from XSS attacks.  The encoded values are rendered ok, but configuration pages send the literal (still encoded with html entities) values by default.  These values will be encoded again.    ||Location||First save||Second Save||Third Save||  |Form Field||||  |Value returned via REST||||  |Displayed in other UI||||    See attached video.    This is already fixed in some places (Repository Name, generated fields like parts of the task and capabilities configuration, custom metadata grid).  See the htmlDecode configuration for Ext.form.TextField. Consider making that true by default.  ",Bug,Major,Closed,"2012-01-27 10:37:05","2012-01-27 10:37:05",3
"Sonatype Nexus","Add NexusStoppingEvent to work around order issues for NexusStoppedEvent","... slightly hacky, but allows components to quickly stop/suspend remote connections or do any other quick about to shutdown steps, before handling NexusStoppedEvent which will actually tear down components.",Improvement,Minor,Closed,"2012-01-26 22:06:30","2012-01-26 22:06:30",1
"Sonatype Nexus","Fix repository fields value","Currently the UI is adding repo_ or group_ in front of repository id for repository type fields. This may be from the times when the two were separated but is no longer necessary and is actually unwanted as this wil require every capability to take extra care to encode/decode this value.",Improvement,Minor,Closed,"2012-01-26 13:55:52","2012-01-26 13:55:52",1
"Sonatype Nexus","Extend task UI to allow for automatically scheduled system tasks.","We have a use case where a task gets run periodically by the Nexus system.  We want the user to be able to disable, cancel or stop this task, but not change other aspects of it.    Currently there is no good way to accomplish this.  We need to make changes to the Nexus core to allow for this.",Improvement,Major,Closed,"2012-01-25 19:51:05","2012-01-25 19:51:05",3
"Sonatype Nexus","Add Logback JMX configuration",https://github.com/sonatype/nexus/pull/228,Improvement,Minor,Closed,"2012-01-25 19:30:32","2012-01-25 19:30:32",1
"Sonatype Nexus","Remote storage settings change detected is being logged over and over on RSO","The RSO logs are showing these messages a lot since we put the 2.0 build on it.  We need to investigate.    {quote}  2012-01-24 17:04:09 INFO  [oviders-1.3.pom] - org.sonatype.nexus.proxy.storage.remote.commonshttpclient.CommonsHttpClientRemoteStorage - Remote storage settings change detected for ProxyRepository ID=mc-repo (mc-repo), updating HttpClient...  2012-01-24 17:04:09 INFO  [oviders-1.3.pom] - org.sonatype.nexus.proxy.storage.remote.commonshttpclient.CommonsHttpClientRemoteStorage - Remote storage settings change detected for ProxyRepository ID=spring (Spring External), updating HttpClient...  2012-01-24 17:04:09 INFO  [-dao-1.1.28.jar] - org.sonatype.nexus.proxy.storage.remote.commonshttpclient.CommonsHttpClientRemoteStorage - Remote storage settings change detected for ProxyRepository ID=GWT-plugin-repo (GWT Plugin Repo), updating HttpClient...  2012-01-24 17:04:09 WARN  [oviders-1.3.pom] - org.sonatype.nexus.proxy.storage.remote.commonshttpclient.CommonsHttpClientRemoteStorage - The proxy repository Spring External (ID=spring) is backed by Amazon S3 service. This means that Nexus can't reliably detect the validity of your setup (baseUrl of proxy repository)!  2012-01-24 17:04:09 INFO  [oviders-1.3.pom] - org.sonatype.nexus.proxy.storage.remote.commonshttpclient.CommonsHttpClientRemoteStorage - Remote storage settings change detected for ProxyRepository ID=github-oss (github (from oss)), updating HttpClient...  2012-01-24 17:04:10 INFO  [model-1.0.1.jar] - org.sonatype.nexus.proxy.storage.remote.commonshttpclient.CommonsHttpClientRemoteStorage - Remote storage settings change detected for ProxyRepository ID=eclipselink (EclipseLink), updating HttpClient...  2012-01-24 17:04:10 ERROR [urces-1.5.8.jar] - org.sonatype.nexus.rest.repositories.RepositoryContentPlexusResource - Got exception during processing request HEAD http://repository.sonatype.org/service/local/repositories/central/content/org/slf4j/slf4j-api-sources/1.5.8/slf4j-api-sources-1.5.8.jar: Access denied on repository ID='central', path='/org/slf4j/slf4j-api-sources/1.5.8/slf4j-api-sources-1.5.8.jar', action='read'!  2012-01-24 17:04:10 ERROR [urces-1.5.8.jar] - org.sonatype.nexus.rest.repositories.RepositoryContentPlexusResource - Got exception during processing request HEAD http://repository.sonatype.org/service/local/repositories/jboss/content/org/slf4j/slf4j-api-sources/1.5.8/slf4j-api-sources-1.5.8.jar: Access denied on repository ID='jboss', path='/org/slf4j/slf4j-api-sources/1.5.8/slf4j-api-sources-1.5.8.jar', action='read'!  2012-01-24 17:04:10 INFO  [0.1-sources.jar] - org.sonatype.nexus.proxy.storage.remote.commonshttpclient.CommonsHttpClientRemoteStorage - Remote storage settings change detected for ProxyRepository ID=central-proxy (Central Proxy), updating HttpClient...  2012-01-24 17:04:10 INFO  [0.1-sources.jar] - org.sonatype.nexus.proxy.storage.remote.commonshttpclient.CommonsHttpClientRemoteStorage - Remote storage settings change detected for ProxyRepository ID=atlassian (<USER>), updating HttpClient...  2012-01-24 17:04:10 INFO  [0.1-sources.jar] - org.sonatype.nexus.proxy.storage.remote.commonshttpclient.CommonsHttpClientRemoteStorage - Remote storage settings change detected for ProxyRepository ID=aduna (Aduna Software), updating HttpClient...  2012-01-24 17:04:10 INFO  [-1.0.1.jar.sha1] - org.sonatype.nexus.proxy.storage.remote.commonshttpclient.CommonsHttpClientRemoteStorage - Remote storage settings change detected for ProxyRepository ID=apache-staging (Apache Staging), updating HttpClient...  {quote}",Bug,Major,Closed,"2012-01-24 23:14:00","2012-01-24 23:14:00",3
"Sonatype Nexus","Log spam if someone proxies repositories from the /service rest endpoint","Not sure how this happened, but someone is making a lot of GET requests RSO on the /service/local/repositories/<repoid> rest endpoint.    This isn't valid, but the in any case log message shouldn't be an ERROR, it should be DEBUG.    {quote}  2012-01-24 17:03:30 ERROR [adoc-2.3.15.jar] - org.sonatype.nexus.rest.repositories.RepositoryContentPlexusResource - Got exception during processing request HEAD http://repository.sonatype.org/service/local/repositories/central/content/freemarker/freemarker-javadoc/2.3.15/freemarker-javadoc-2.3.15.jar: Access denied on repository ID='central', path='/freemarker/freemarker-javadoc/2.3.15/freemarker-javadoc-2.3.15.jar', action='read'!  2012-01-24 17:03:30 ERROR [adoc-2.3.15.jar] - org.sonatype.nexus.rest.repositories.RepositoryContentPlexusResource - Got exception during processing request HEAD http://repository.sonatype.org/service/local/repositories/jboss/content/freemarker/freemarker-javadoc/2.3.15/freemarker-javadoc-2.3.15.jar: Access denied on repository ID='jboss', path='/freemarker/freemarker-javadoc/2.3.15/freemarker-javadoc-2.3.15.jar', action='read'!  2012-01-24 17:03:36 ERROR [i-1.5.8-ivy.xml] - org.sonatype.nexus.rest.repositories.RepositoryContentPlexusResource - Got exception during processing request HEAD http://repository.sonatype.org/service/local/repositories/central/content/org/slf4j/slf4j-api/1.5.8/slf4j-api-1.5.8-ivy.xml: Access denied on repository ID='central', path='/org/slf4j/slf4j-api/1.5.8/slf4j-api-1.5.8-ivy.xml', action='read'!  2012-01-24 17:03:36 ERROR [i-1.5.8-ivy.xml] - org.sonatype.nexus.rest.repositories.RepositoryContentPlexusResource - Got exception during processing request HEAD http://repository.sonatype.org/service/local/repositories/jboss/content/org/slf4j/slf4j-api/1.5.8/slf4j-api-1.5.8-ivy.xml: Access denied on repository ID='jboss', path='/org/slf4j/slf4j-api/1.5.8/slf4j-api-1.5.8-ivy.xml', action='read'!  2012-01-24 17:03:38 ERROR [4-1.1.0-ivy.xml] - org.sonatype.nexus.rest.repositories.RepositoryContentPlexusResource - Got exception during processing request HEAD http://repository.sonatype.org/service/local/repositories/central/content/org/jboss/javaee/jboss-jacc-api_JDK4/1.1.0/jboss-jacc-api_JDK4-1.1.0-ivy.xml: Access denied on repository ID='central', path='/org/jboss/javaee/jboss-jacc-api_JDK4/1.1.0/jboss-jacc-api_JDK4-1.1.0-ivy.xml', action='read'!  2012-01-24 17:03:38 ERROR [4-1.1.0-ivy.xml] - org.sonatype.nexus.rest.repositories.RepositoryContentPlexusResource - Got exception during processing request HEAD http://repository.sonatype.org/service/local/repositories/jboss/content/org/jboss/javaee/jboss-jacc-api_JDK4/1.1.0/jboss-jacc-api_JDK4-1.1.0-ivy.xml: Access denied on repository ID='jboss', path='/org/jboss/javaee/jboss-jacc-api_JDK4/1.1.0/jboss-jacc-api_JDK4-1.1.0-ivy.xml', action='read'!  2012-01-24 17:03:51 ERROR [t-1.5.8-ivy.xml] - org.sonatype.nexus.rest.repositories.RepositoryContentPlexusResource - Got exception during processing request HEAD http://repository.sonatype.org/service/local/repositories/central/content/org/slf4j/slf4j-parent/1.5.8/slf4j-parent-1.5.8-ivy.xml: Access denied on repository ID='central', path='/org/slf4j/slf4j-parent/1.5.8/slf4j-parent-1.5.8-ivy.xml', action='read'!  2012-01-24 17:03:51 ERROR [t-1.5.8-ivy.xml] - org.sonatype.nexus.rest.repositories.RepositoryContentPlexusResource - Got exception during processing request HEAD http://repository.sonatype.org/service/local/repositories/jboss/content/org/slf4j/slf4j-parent/1.5.8/slf4j-parent-1.5.8-ivy.xml: Access denied on repository ID='jboss', path='/org/slf4j/slf4j-parent/1.5.8/slf4j-parent-1.5.8-ivy.xml', action='read'!  2012-01-24 17:03:53 ERROR [t-1.6.5-ivy.xml] - org.sonatype.nexus.rest.repositories.RepositoryContentPlexusResource - Got exception during processing request HEAD http://repository.sonatype.org/service/local/repositories/central/content/ant/ant/1.6.5/ant-1.6.5-ivy.xml: Access denied on repository ID='central', path='/ant/ant/1.6.5/ant-1.6.5-ivy.xml', action='read'!  2012-01-24 17:03:53 ERROR [t-1.6.5-ivy.xml] - org.sonatype.nexus.rest.repositories.RepositoryContentPlexusResource - Got exception during processing request HEAD http://repository.sonatype.org/service/local/repositories/jboss/content/ant/ant/1.6.5/ant-1.6.5-ivy.xml: Access denied on repository ID='jboss', path='/ant/ant/1.6.5/ant-1.6.5-ivy.xml', action='read'!  {quote}",Bug,Major,Closed,"2012-01-24 23:12:00","2012-01-24 23:12:00",1
"Sonatype Nexus","Upgrade to ehcache version 2.5.x","We are currently using a dated version (1.6.x) of ehcache and there have been significant performance improvements in the more recent versions (2.5.x).  However, although there is purportedly API compatibility with the newer versions, concerns have been raised regarding potential impact on how Nexus security interacts with the current cache version.  It's noted in the comments below, but we should also make the JMX information accessible as part of this effort.    Extra credit:  As part of this effort, it would be good to evaluate some of the newer ehcache functionality and determine whether or not we can benefit from it (any potential implementation should be documented in a separate ticket).",Improvement,Major,Closed,"2012-01-24 19:52:07","2012-01-24 19:52:07",3
"Sonatype Nexus","Regression DefaultWastebasketTest.testPurgeAllLegacyTrash","https://builds.sonatype.org/job/nexus-oss-its/jdk=java-6x,label=win/166/testReport/org.sonatype.nexus.proxy.wastebasket/DefaultWastebasketTest/testPurgeAllLegacyTrash/    org.sonatype.nexus.proxy.wastebasket.DefaultWastebasketTest.testPurgeAllLegacyTrash (from DefaultWastebasketTest)    ",Bug,Major,Closed,"2012-01-24 10:18:04","2012-01-24 10:18:04",1
"Sonatype Nexus","Capability lower display area heading should be cleared when Advanced button unchecked","See attached image.  If you click to check the Show Advanced button in the capabilities pane, selected an advanced item and then uncheck Show Advanced, the heading is not cleared.",Bug,Minor,Closed,"2012-01-21 20:00:49","2012-01-21 20:00:49",1
"Sonatype Nexus","Add support for Jetty JMX into Nexus Bundle.","We should allow people to turn on Jetty JMX support in the Nexus server.    Two changes needed:    1) Add org.eclipse.jetty:jetty-jmx:7.4.2.v20110526 into the <nexus-root>/lib directory  2) Provide a sample jetty.xml that shows how to enable it      jetty-jmx.xml has been attached, the new configuration is at the bottom.    Note:  This issue is for Nexus 2.0, which uses Jetty 7.4.2",Improvement,Major,Closed,"2012-01-20 22:12:16","2012-01-20 22:12:16",1
"Sonatype Nexus","The location of the temp directory makes no sense in the new layout","The default temp directory location in Nexus 2.0 is still <nexus_root>/runtime/tmp.    This makes no sense given the new bundle layout.  Location should be (in order of preference):    1) sonatype-work/nexus/tmp  2) <nexus_root>/nexus/tmp    I think there is a reason why option #1 isn't possible, but I can't remember why at the moment.",Bug,Major,Closed,"2012-01-20 01:04:02","2012-01-20 01:04:02",1
"Sonatype Nexus","Regression  org.sonatype.nexus.integrationtests.nexus4674.Nexus4674UpdateGAVIndexIT.searchTest ","https://builds.sonatype.org/view/nexus/job/nexus-oss-its-feature/172/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus4674/Nexus4674UpdateGAVIndexIT/searchTest/    Error Message    Expected: a collection with size <5>      but: collection size was <3>    Stacktrace    ",Bug,Major,Closed,"2012-01-19 16:14:18","2012-01-19 16:14:18",1
"Sonatype Nexus","Regression: org.sonatype.nexus.plugin.ListStageRepositoriesMojoTest.baseUrlWithTrailingSlash (from ListStageRepositoriesMojoTest) failed to connect to Nexus","  https://builds.sonatype.org/job/nexus-oss/693/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.plugin/ListStageRepositoriesMojoTest/baseUrlWithTrailingSlash/      Could this be related to NEXUS-4611? Similar type of error.    ",Bug,Major,Closed,"2012-01-19 11:57:54","2012-01-19 11:57:54",1
"Sonatype Nexus","Ugly error  message if there is a circular dependency in guice component graph","We should log this at DEBUG:      ",Improvement,Major,Closed,"2012-01-18 20:33:52","2012-01-18 20:33:52",1
"Sonatype Nexus","INFO log message from NettyAsyncHttpProvider on every click of remote repository browser tree node","Every mouse click of the remote repository browser tree node in the UI prints one log line at INFO level. Here I expanded three nodes:        Why isn't this using httpclient? Why print this line at INFO. If it must stay, please explain the value of it in solving customer issues. At the least move the category log level to WARN by default.",Bug,Major,Closed,"2012-01-18 20:09:26","2012-01-18 20:09:26",1
"Sonatype Nexus","Create Repository UI for each type of repository","There are two options for this.  1.) Allow each repository type to contribute its own UI  2.) Create a generic descriptor used to generate a UI (e.g. like scheduled tasks, rules, etc)    The current UI is VERY tied to maven2 repositories, all other repository implementations hack around this fact.",Improvement,Major,Closed,"2012-01-18 16:31:14","2012-01-18 16:31:14",40
"Sonatype Nexus","Delete capability confirmation dialog uses description of capability rather than capability type","If a capability is created and then encounters a configuration error, the description will contain the word FAILED: followed by the class name of the exception.( see NXCM-3681 )  When trying to delete the capability you will be asked for confirmation with a message such as Delete the FAILED: java.lang.IllegalStateException capability?  It would be more logical to use the capability type instead of description here, or neither of these.  See attached screenshot for an example of how this looks.",Bug,Major,Closed,"2012-01-18 04:25:28","2012-01-18 04:25:28",1
"Sonatype Nexus","Attributes Upgrader logs duplicate stack trace when a file is not found and stops","Noticed duplicate logging with stack of same problem at INFO and WARN by the background attributes upgrader task.    This in my Nexus logs after upgrading from 1.9.2 WAR file running in tomcat.        Would like to understand why it seemed to abort because of some missing file. And would also like to see only one log of this message at the correct log level if possible. I didn't notice the attributes upgrader ever try to rerun itself - is that expected? Can it be a little more forgiving?",Bug,Blocker,Closed,"2012-01-18 02:53:41","2012-01-18 02:53:41",2
"Sonatype Nexus","Building wrong Maven metadata for a classifier with dots","When having a classifier with dots (classifier.with.dots) and an extension with or without dots (e.g. tar.gz), the recreation of snapshot metadata will change classifier and type/extension to something clearly not intended:    ||Coordinate||Maven deploy||Nexus rebuilt metadata||  |classifier|classifier.with.dots|classifier|  |type|tar.gz|with.dots.tar.gz|    We have this issue trying to switch to Maven 3 with it's unique snapshot feature - the Rebuild Metadata and Remove Snapshots jobs destroy the whole metadata of some of our snapshot dependencies.     This is a blocker for us since we cannot switch to Maven 3 and it's unique snapshot policy. I tried to use the Maven system property {{-Dmaven.metadata.legacy=true}} in our Jenkins job - but the Maven deployment is done by Jenkins separately after the actual Maven build (which is configured to install only) and does not seem to respect the property set in the Maven build options (MAVEN_OPTS).    I attached two metadata files - one after maven deploy, the other after Rebuild metadata task was triggered and finished manually.",Bug,Critical,Closed,"2012-01-16 16:18:05","2012-01-16 16:18:05",6
"Sonatype Nexus","Cannot rename file IOException when uploading duplicate GAV under load","Was performing deploys using multiple threads (users) of the same set of release artifacts to a releases repo.     File locking seemed to fail avoiding IOException:        See attached wrapper.log for complete log where this happened twice",Bug,Major,Closed,"2012-01-12 19:26:35","2012-01-12 19:26:35",2
"Sonatype Nexus","Regression  org.sonatype.nexus.integrationtests.nexus3670.Nexus3670IndexTreeViewIT.testTreeWithoutHint","https://builds.sonatype.org/job/nexus-oss-its/147/jdk=java-6x,label=linux/testReport/org.sonatype.nexus.integrationtests.nexus3670/Nexus3670IndexTreeViewIT/testTreeWithoutHint/    Error Message    There is three versions of &quot;nexus3670:known-artifact-a&quot; artifact! expected:&lt;3&gt; but was:&lt;2&gt;    Stacktrace  ",Bug,Major,Closed,"2012-01-12 10:34:10","2012-01-12 10:34:10",1
"Sonatype Nexus","Generated All <type> Repositories View is empty if there are no repositories of that type ","we should not validate read only roles.  This will hide the error, and it will appear as everything is working fine (which in this case it is)",Bug,Major,Closed,"2012-01-05 17:12:20","2012-01-05 17:12:20",1
"Sonatype Nexus","duplicate sometimes triplicate logging of errors inside Nexus","When an exception is thrown inside nexus, there is usually duplicate or even triplicate logging of it's stack trace.    Usually logged at source, logged by jetty, and thirdly logged by problem reporter.    Can this be reduced safely?      If you are looking for examples, see the log files inside this tar file:     https://github.com/sonatype/nexus-grid/blob/master/scenarios/smartproxy/results/1.10.0-SNAPSHOT/20120102-01/nexus1-nexus-logs.tar.gz        On Wed, Jan 4, 2012 at 11:47 PM, <USER><<EMAIL>> wrote:  When something bad happens, looks like NX is logging the exception twice... why?    Once here:    jvm 1    | ERROR [5b6ff421345874?] DefaultErrorReportingManager - Detected Error in Nexus    and another here:    jvm 1    | ERROR [5b6ff421345874?] NexusApplication - Unhandled exception or error intercepted    ","Technical Debt",Major,Closed,"2012-01-05 12:03:39","2012-01-05 12:03:39",2
"Sonatype Nexus","IndexOutOfBoundsException: Index: 2, Size: 0 org.sonatype.nexus.configuration.model.AbstractXpp3DomExternalConfigurationHolder editing group membership","This was seen running the load test described in NEXUS-4744          h3. Variations of the same theme      ",Bug,Major,Closed,"2012-01-03 19:08:12","2012-01-03 19:08:12",5
"Sonatype Nexus","deploying artifacts under load gives org.sonatype.nexus.proxy.attributes.LegacyFSAttributeStorage.getFileFromBase NullPointerException NPE","While exercising a load test of sorts on Nexus, I got this exception trying to deploy artifacts.    The following simulation was running:    30 users fetching artifacts from releases  30 users deploying artifacts to releases  10 users deleting artifacts from releases  10 users adding and removing releases repo from public group repo  10 users expiring NFC cache of individual artifacts in releases repo    Up to 100 users were also requesting uncached artifacts via a proxy repo for 'releases' on another machine.    Nexus had smartproxy installed, but disabled.    The releases repo configuration was as below:    {code:xml}  <repository>        <id>releases</id>        <name>Releases</name>        <providerRole>org.sonatype.nexus.proxy.repository.Repository</providerRole>        <providerHint>maven2</providerHint>        <localStatus>IN_SERVICE</localStatus>        <notFoundCacheActive>true</notFoundCacheActive>        <notFoundCacheTTL>1</notFoundCacheTTL>        <userManaged>true</userManaged>        <exposed>true</exposed>        <browseable>true</browseable>        <writePolicy>ALLOW_WRITE</writePolicy>        <indexable>true</indexable>        <searchable>true</searchable>        <localStorage>          <provider>file</provider>        </localStorage>        <externalConfiguration>          <proxyMode>ALLOW</proxyMode>          <artifactMaxAge>-1</artifactMaxAge>          <itemMaxAge>1440</itemMaxAge>          <cleanseRepositoryMetadata>false</cleanseRepositoryMetadata>          <downloadRemoteIndex>false</downloadRemoteIndex>          <checksumPolicy>WARN</checksumPolicy>          <repositoryPolicy>RELEASE</repositoryPolicy>        </externalConfiguration>      </repository>    {code}    Let me know if you want the test code.     h3. First Exception in logs ( maybe related to adding and removing repo from public group )          h3. Second Exception further down looks like it was the put causing the real problem.          ",Bug,Major,Closed,"2011-12-30 19:05:05","2011-12-30 19:05:05",2
"Sonatype Nexus","Regression  org.sonatype.nexus.integrationtests.proxy.nexus3915.Nexus3915ContentValidationFeedIT.contentValidationFeed","https://builds.sonatype.org/job/nexus-oss-its/135/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.proxy.nexus3915/Nexus3915ContentValidationFeedIT/contentValidationFeed/      Error Message    Expected more then 1 entries, but got 0 - [] expected:&lt;true&gt; but was:&lt;false&gt;    ",Bug,Major,Closed,"2012-01-03 11:02:47","2012-01-03 11:02:47",1
"Sonatype Nexus","Deploying to root of repository ( / ) returns a 500","Found while testing NXCM-3600 against a staging repository       This should return a 400, as this is a use error.",Bug,Major,Closed,"2011-12-28 14:14:56","2011-12-28 14:14:56",1
"Sonatype Nexus","PUT, POST, and DELETE requests to a non exposed repository return a 404, it should return a 405","Found while testing NXCM-3600.  GET requests return correctly with a 200 (and the content of course) this implies that that PUT, POST, and DELETE should return a 405 (method not allowed)",Bug,Trivial,Closed,"2011-12-28 14:12:18","2011-12-28 14:12:18",1
"Sonatype Nexus","Add extra columns to the repository targets view","There isn't enough information shown in the repository target table, trying to figure out what targets in the system might apply to a particular artifact involves clicking on each target in turn and looking at the regex's.    There's lots of space in the table, we should add columsn for the repository type and the pattern expressions.  Note that there won't always be enough room to display all of the pattern expressions, but it will still help a lot.",Improvement,Major,Closed,"2011-12-27 14:46:15","2011-12-27 14:46:15",1
"Sonatype Nexus","random failure org.sonatype.nexus.integrationtests.nexus3082.Nexus3082GenerateProblemReportIT.generateReport expected response status 200 got 400","https://builds.sonatype.org/view/nexus/job/nexus-oss-its/129/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.integrationtests.nexus3082/Nexus3082GenerateProblemReportIT/generateReport/        ",Bug,Major,Closed,"2011-12-27 13:17:41","2011-12-27 13:17:41",1
"Sonatype Nexus","random failure Nexus4635OldNexusVersionIT @BeforeMethod oncePerClassSetUp nexus.log unable to be deleted","https://builds.sonatype.org/view/nexus/job/nexus-oss-its/131/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus4635nexusVersion/Nexus4635OldNexusVersionIT/_BeforeMethod_oncePerClassSetUp/    ",Bug,Major,Closed,"2011-12-27 13:10:29","2011-12-27 13:10:29",1
"Sonatype Nexus","Content-Type is incorrect for ?describe requests","https://repository.sonatype.org/content/repositories/central-proxy/junit/junit/3.8.2/junit-3.8.2.pom?describe  or  https://repository.sonatype.org/content/repositories/central-proxy/junit/junit/3.8.2/junit-3.8.2.pom?describe=info          The Content-Type should be: application/json  ",Bug,Major,Closed,"2011-12-22 14:39:55","2011-12-22 14:39:55",3
"Sonatype Nexus","Regression  org.sonatype.nexus.plugins.mavenbridge.ResolvingLRTest.testAetherResolveAgainstPublicGroup","https://builds.sonatype.org/job/nexus-oss-its/jdk=java-6x,label=linux/126/testReport/org.sonatype.nexus.plugins.mavenbridge/ResolvingLRTest/testAetherResolveAgainstPublicGroup/    Failed to collect dependencies for org.apache.maven:apache-maven::3.0-<USER>1 (compile)    ",Bug,Major,Closed,"2011-12-22 08:44:43","2011-12-22 08:44:43",1
"Sonatype Nexus","Show the path in the delete artifact confirmation dialog.","See screenshot.  We should add the path to the delete artifact confirmation dialog.",Improvement,Minor,Closed,"2011-12-20 17:04:20","2011-12-20 17:04:20",1
"Sonatype Nexus","If a Nexus task throws something that does not extend Exception, will get stuck in bad state","If I have a task that throws an exception that doesnt extend Exception the AbstractNexusTask won't catch this (since it only looks for Exception) and thus won't mark the task in a broken state, and swallows the error",Bug,Major,Closed,"2011-12-19 17:19:37","2011-12-19 17:19:37",1
"Sonatype Nexus","Make Feeds UI resilient to 404","Make Feeds UI resilient to 404, since it might become a normal state of an instance to operate without feeds present (they are in a removable plugin!).    Also, we might consider the Feed UI move into the timeline plugin too, if it proves that UI is actually not a generic and fully capable RSS reader (but it actually relies on some DTOs present in timeline REST API).",Improvement,Major,Closed,"2011-12-19 11:10:07","2011-12-19 11:10:07",2
"Sonatype Nexus","Use alias for capabilities-list/data/... for CapabilityListItemResource","    ",Improvement,Major,Closed,"2011-12-18 00:21:51","2011-12-18 00:21:51",1
"Sonatype Nexus","Make test related REST helper classes usable in tests based on nexus-launcher","Make possible to reuse existing utilities to make REST calls to Nexus from integration tests outside of tests based on AbstractNexusIntegrationTest.  This will be used for writing smart proxy ITs that require spanning off multiple Nexus instances and communicate with them via REST and for NuGet ITs.    This will require:  * create a new nexus-test-utils module that will contain this utilities. Classes will be moved into this new module when needed (see bellow).  * change current *MessageUtils classes to be able to work without referencing the AbstractNexusIntegrationTest and TestContainer. To do so the main change will be to provide constructors that take as params the needed information for them to function.   * Keep as much as possible the current ITs unchanged. If doing above change will imply major changes to tests, create a copy of util class and make teh current util class delegate to new class.  ",Improvement,Major,Closed,"2011-12-17 16:22:09","2011-12-17 16:22:09",3
"Sonatype Nexus","Cancel of capability behaves oddly if selected more than one capability to view","If you select a few capabilities, then click cancel, it takes you back to the previous capability you were looking at vs. back to select a capability view.  Seems a bit odd to me.",Improvement,Minor,Closed,"2011-12-16 23:02:09","2011-12-16 23:02:09",1
"Sonatype Nexus","Update LDAP Group Member Format help to include ${dn}","Current text:   Maybe something like: ",Bug,Minor,Closed,"2011-12-16 21:42:30","2011-12-16 21:42:30",1
"Sonatype Nexus","Decouple shadow repository actions from their master repositories, take 2","Decouple shadow repository actions from their master repositories, take 2.    Take one was NEXUS-4682 but we backed out from it, pull request:  https://github.com/sonatype/nexus/pull/156    Is putting them back to sync for now. It's mostly due to our ITs having some expectations (checking shadow reposes too after running a job against other repository), but bigger problem is that in case of async mode, the create and delete income order might change, and we leave shadow in inconsistent state.    So, we are back, and the original statement in NEXUS-4682 still stands: a repo is slowed down as much, as much shadows it has (linearly).","Technical Debt",Major,Closed,"2011-12-16 16:53:47","2011-12-16 16:53:47",6
"Sonatype Nexus","Repository UI triggers validates when opened","Just open repository UI  ID and name validation will complain about the fields being blank.    http://screencast.com/t/0H6sdzczg",Bug,Major,Closed,"2011-12-16 10:12:38","2011-12-16 10:12:38",1
"Sonatype Nexus","random NullPointerException in org.sonatype.nexus.error.reporting.DefaultErrorReportingManagerLRTest.testTaskFailure","https://builds.sonatype.org/job/nexus-oss/645/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.error.reporting/DefaultErrorReportingManagerLRTest/testTaskFailure/      ",Bug,Major,Closed,"2011-12-15 12:57:45","2011-12-15 12:57:45",1
"Sonatype Nexus","Do not propagate undefined factory for a capability back to UI","When a capability factory does not exist do not propagate the exception back to UI  ",Improvement,Minor,Closed,"2011-12-14 08:27:02","2011-12-14 08:27:02",1
"Sonatype Nexus","Add support to declare a global capability as a singleton","Some capabilities can only be added once, need some way to configure this and prevent duplicates.    For this issue I'm only talking about global capabilities, per-repository singletons will eventually be required, so perhaps keep that in mind, but not required to implement the global singleton capabilities.",Improvement,Major,Closed,"2011-12-13 03:23:27","2011-12-13 03:23:27",3
"Sonatype Nexus","M1-M2 Shadow repository NFC can cause excessive network traffic","The NFC for an M1-M2 shadow repository is 15 minutes.    If you have an M1-M2 shadow of an M2 proxy repository Nexus makes a remote network call through the M2 proxy repository every time this limit is reached.    Note that we ship with an M1-M2 shadow of maven central.",Bug,Major,Closed,"2011-12-12 22:08:07","2011-12-12 22:08:07",2
"Sonatype Nexus","Avoid empty Settings box for capability which has no configuration (ie. only lifecycle)","Similar to status only show when there is content, otherwise hide.",Improvement,Major,Closed,"2011-12-12 21:25:17","2011-12-12 21:25:17",1
"Sonatype Nexus","Capability description should always get refreshed from component when loading","Right now the capability description, which is auto generated, is stored in the configuration file.  If the capability code changes and the configuration is the same (ie. no need to reconfigure to trigger save) then the description can't update to reflect any changes.    Perhaps description asis now since its generated shouldn't be persisted at all?",Improvement,Major,Closed,"2011-12-12 21:24:21","2011-12-12 21:24:21",1
"Sonatype Nexus","Synchronize Shadow Repository task can be applied to repository types other than shadow ( virtual ) repositories","Create a Synchronize Shadow Repository. In the repository selection list, all repositories are shown - however this task only applies to Virtual/Shadow repositories.    Expected only the repository type that applies to this task to be listed.    *Clarification:* setting up the task against a repo that does not apply does no harm - those repos are just ignored.",Bug,Major,Closed,"2011-12-12 12:46:39","2011-12-12 12:46:39",3
"Sonatype Nexus","Regression: org.sonatype.nexus.integrationtests.nexus2692.Nexus2692EvictGroupTaskIT.testEvictPublicGroup","https://builds.sonatype.org/view/nexus/job/nexus-oss-its/114/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus2692/Nexus2692EvictGroupTaskIT/testEvictPublicGroup/    org.sonatype.nexus.integrationtests.nexus2692.Nexus2692EvictGroupTaskIT.testEvictPublicGroup (from Nexus2692EvictGroupTaskIT)  Failing for the past 1 build (Since Failed#114 )  Took 11 sec.  add description  Error Message    The following files should have been deleted: central-m1/org.apache.maven.shared/poms/maven-shared-components-8.pom.sha1  expected:&lt;true&gt; but was:&lt;false&gt;    ",Bug,Major,Closed,"2011-12-12 08:44:04","2011-12-12 08:44:04",1
"Sonatype Nexus","Log configuration UI shows log4j string","The log configuration UI mentions Log4j Configuration as the title.  This should be Log Configuration.",Bug,Major,Closed,"2011-12-09 19:20:17","2011-12-09 19:20:17",1
"Sonatype Nexus","Log Configuration panel still says Log4j","Under the covers its Logback now.  Should simply omit the provider name here.",Bug,Major,Closed,"2011-12-09 19:19:03","2011-12-09 19:19:03",1
"Sonatype Nexus","4 files for logback configuration seem like overkill","Currently has these files:    * logback-default.xml  * logback-events.xml  * logback.properties  * logback.xml    This is IMO way overkill to configure logging, which is essentially a very simple configuration.     I understand we want to retain the properties to cope with the simlpe 4 parameter Log Configuration panel, so that would be:    * logback.properties  * logback.xml    Why is this configuration so complicated?    Solution from kick off:  1.) Add DO NOT TOUCH messages to top of files (except the logback-nexus.xml which should tell users what to do.)  2.) Add good documentation to logback.xml to tell a user what to do to change the logging levels  3.) rename logback-default.xml to logback-nexus.xml (this is the one the users can edit)    ",Bug,Major,Closed,"2011-12-09 19:18:01","2011-12-09 19:18:01",1
"Sonatype Nexus","Capability type needs a description in addition to the capability instance","Currently capability has a dynamic description which is generated for an instance configuration.  This is nice to document what the instance of the capability does, but we need some way to generically provide documentation/description/help information about what type of capability is.    When browsing the list of capabilities to add, there is no way except for the name currently to provide details to the user as to what the capability is, and often the name doesn't really provide enough detail to explain what its for.    CapabilityDescriptor should get description() field (or something) which can return the static multi-line content with rich details about the capability type (ie. not about created instances, like describe(Map) does.  ",Improvement,Minor,Closed,"2011-12-09 18:49:28","2011-12-09 18:49:28",1
"Sonatype Nexus","User can get to a log in state in the UI even if he doesn't have that priv","For a user account that does not have the Login to UI priv, it is possible to get into a logged in state.    To reproduce:  1. Create a user account that has the Nexus Anonymous Role.  2. Try logging in with that user. You will get an error message saying no permission to use the UI. Then click ok and close the log in window by clicking the 'X' button in upper right corner.  3. Now refresh the browser window. The UI will now say that the user is logged in.    Not sure if this is just a UI issue or even a server side issue.",Bug,Major,Closed,"2011-10-06 12:46:18","2011-10-06 11:46:18",2
"Sonatype Nexus","CI failure: org.sonatype.nexus.integrationtests.nexus2692.Nexus2692EvictAllTaskIT.testEvictAllRepos","https://builds.sonatype.org/view/nexus/job/nexus-oss-its/112/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus2692/Nexus2692EvictAllTaskIT/testEvictAllRepos/    org.sonatype.nexus.integrationtests.nexus2692.Nexus2692EvictAllTaskIT.testEvictAllRepos (from Nexus2692EvictAllTaskIT)  Failing for the past 1 build (Since Failed#112 )  Took 12 sec.  add description  Error Message    The following files should have been deleted: [central-m1/org.codehaus.plexus/poms/plexus-container-default-1.0-alpha-7.pom.sha1] expected:&lt;true&gt; but was:&lt;false&gt;    Stacktrace  ",Bug,Major,Closed,"2011-12-09 15:38:33","2011-12-09 15:38:33",1
"Sonatype Nexus","Rationalize Nexus Core dependencies and components","Rationalize Nexus Core dependencies and components. Core is currently bloated, and contains many key dependencies pinned in, that simply prevents plugin developers easy upgrades (to follow their own dependencies). On the other hand, key dependencies that are extensively used in key features like Maven Repository Support are moved out into foreign projects, pinning our core to depend on foreign release lifecycle, but also forcing us on compromises needed to maintain backward compatibility with other non-nexus integration for that 3rd party library.",Improvement,Major,Closed,"2011-12-09 11:21:42","2011-12-09 11:21:42",6
"Sonatype Nexus","Add password text field","Add a password masking text field.  ie. StringTextFormField which uses * or something to mask the input.",Improvement,Minor,Closed,"2011-12-08 20:48:22","2011-12-08 20:48:22",1
"Sonatype Nexus","Add enable/disable context menu item to capabilities table","... to quickly enable or disable a capability.  This is a short-cut of selecting the entry, toggling the enabled checkbox and clicking save.",Improvement,Major,Closed,"2011-12-08 20:40:43","2011-12-08 20:40:43",2
"Sonatype Nexus","Add multiline text field","Need a multiline text field for use in capabilities.",Improvement,Major,Closed,"2011-12-08 20:39:31","2011-12-08 20:39:31",1
"Sonatype Nexus","Nexus 1.9.2.4 release","Nexus 1.9.2.4 release needed to consolidate patches given out since the 1.9.2.3 release.",Improvement,Major,Closed,"2011-12-07 23:02:36","2011-12-07 23:02:36",2
"Sonatype Nexus","Interal 2.0 Milestone Release","We need to do an internal 2.0 release.  Once this is done (and sanity checked) we should install it on RSO.  ",Improvement,Major,Closed,"2011-12-07 22:58:44","2011-12-07 22:58:44",12
"Sonatype Nexus","Make HTTPClient 4.1 the default transport in Nexus","Current plan is to provide HTTPClient 4.1 as an alternate transport for repositories in the 2.0 release.     Once we have enough confidence in this new implementation we should make it the default.  This will be done in the following (2.1) release at the earliest.",Improvement,Major,Closed,"2011-12-07 21:05:52","2011-12-07 21:05:52",3
"Sonatype Nexus","Nexus4529HighlyConcurrentRepoAdditionsAndRemovalsIT.doTheTest triggers NullPointerException in ProgressListener","https://builds.sonatype.org/view/nexus/job/nexus-oss-its/107/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus4529/Nexus4529HighlyConcurrentRepoAdditionsAndRemovalsIT/doTheTest/          There is more to this than it appears. Was this caused by some other test's failure? Testng does weird things when @Before executions fail.",Bug,Major,Closed,"2011-12-07 14:46:36","2011-12-07 14:46:36",1
"Sonatype Nexus","Gather all the HTTP Client uses from Nexus (aside of RRS), and create a shim component for that","Gather all the HTTP Client uses from Nexus (aside of RRS), and create a shim component for that.    Right now, AHC is used in everything else part of Nexus (not remote repository storage), meaning all the AHC/HttpClient API is littered all over the place.    Just gather all the uses of HTTP clients in Nexus, and create a component that would provide a simple client interface (a facade actually) that would provide whatever implementation (HttpClient, AHC or foo baz), preconfigured with all needed (Nexus global HTTP Proxy, etc) for use in these places, making it super-simple to swap actual implementations. Unlike today, it's not a small effort to do.",Improvement,Major,Closed,"2011-12-06 14:30:24","2011-12-06 14:30:24",2
"Sonatype Nexus","Better errors when access is denied because of routing settings","I've opened three support cases here already because of issues which were caused by routing settings.    My main problem is that when access is denied because of routing settings, you get a 404 or a 504 (Gateway timeout) but nothing in the error log of Nexus, not even when I enable debugging.",Improvement,Major,Closed,"2011-12-02 16:50:56","2011-12-02 16:50:56",3
"Sonatype Nexus","Tool import-ssl does not work through proxied connections","I have to access any server (HTTP/HTTPS) through a proxy.  Running the tool import-ssl always terminates with a java.net.ConnectException: Connection refused: connect error.  Setting the Java properties http.proxyHost, http.proxyPort, https.proxyHost, or https.proxyPort when running the tool does not have any influence.",Bug,Major,Closed,"2011-12-02 09:58:07","2011-12-02 09:58:07",2
"Sonatype Nexus","Nexus doesn't work through NTLM proxy which redirects","This may also affect non-ntlm usage. Underlying bug is here:    https://issues.apache.org/jira/browse/HTTPCLIENT-856    This is fixed in HttpClient 4.x.      Note the last comment on the above bug, in June 2009 the developer says that HttpClient 3.1 is EOL.   I think it's time we considered upgrading.",Bug,Major,Closed,"2011-12-01 17:08:14","2011-12-01 17:08:14",1
"Sonatype Nexus","Decouple shadow repository actions from their master repositories","Decouple shadow repository actions from their master repositories.    Right now, every shadow repository maintains itself _synchronously_ based on incoming content changes from master repository. This is bad, since the number of attached shadow repositories _directly affects_ the performance of master repository (shadow activity is done as part of master repository activity, ie. if you deploy to a M2 repository that has M1 shadow, the M2 deploy processing time _will contain_ the M1 processing time too).    Since in above example, the creation (or deletion) of the symlink in M1 shadow repository does not have to occur immediately as M2 repository got deployed (removed) something, we should make shadows process master events asynchronously.",Improvement,Major,Closed,"2011-12-01 14:05:45","2011-12-01 14:05:45",1
"Sonatype Nexus","failed: org.sonatype.nexus.integrationtests.nexus4066.Nexus4066TaskMutualExclusionIT","org.sonatype.nexus.integrationtests.nexus4066.Nexus4066TaskMutualExclusionIT.run (from Nexus4066TaskMutualExclusionIT)  Failing for the past 1 build (Since Failed#100 )  Took 10 sec.  add description  Error Message    Repo1: repo2 repo2: GofG2 shouldWait: true    Stacktrace          java.lang.RuntimeException: Repo1: repo2 repo2: GofG2 shouldWait: true   at org.sonatype.nexus.integrationtests.nexus4066.Nexus4066TaskMutualExclusionIT.run(Nexus4066TaskMutualExclusionIT.java:87)   at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:70)   at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:157)   at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:97)   at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:111)   at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)   at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)   at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:172)   at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:104)   at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:70)  Caused by: java.lang.AssertionError:   Expected: SLEEPING       but: was RUNNING   at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)   at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:8)   at org.sonatype.nexus.integrationtests.nexus4066.Nexus4066TaskMutualExclusionIT.run(Nexus4066TaskMutualExclusionIT.java:78)   ... 35 more  ... Removed 26 stack frames      ",Bug,Major,Closed,"2011-12-01 12:19:48","2011-12-01 12:19:48",1
"Sonatype Nexus","Creating a repo with id equal to existing repo group id does not result in an error message","If you create a repo with id A and then try to create a repo group with id A, you will get a form error when trying to save the repo group indicating a repo already exists.      However, if you create a repo group with id A and then try to create a repo with id A, you will NOT get a form error when trying to save the repo - instead the form *appears* to save without error, yet once the repo list is refreshed, you still only have the conflicting repo group and no repo.  ",Bug,Major,Closed,"2011-12-01 04:52:34","2011-12-01 04:52:34",1
"Sonatype Nexus","IT failed: Nexus4341RunningTaskNotEditableIT.testNoUpdateForRunningTasks","https://builds.sonatype.org/job/nexus-oss-its-feature/81/    debug build for that branch: https://builds.sonatype.org/job/nexus-oss-its-debug-4341/    ",Bug,Major,Closed,"2011-11-30 14:25:43","2011-11-30 14:25:43",1
"Sonatype Nexus","Reindexing one GAV of a GA removes other versions from index","This needs to be verified, <USER>F. noticed this on RAO.    * Right click and reindex a single version of a GA  What you see: The other versions of that GA have been removed from the index    Expected: Previous versions to remain in index, the right-clicked version to be added to index.",Bug,Major,Closed,"2011-11-30 14:20:27","2011-11-30 14:20:27",1
"Sonatype Nexus","regression: latest version check never works","Cannot seem to get the latest version checker in Nexus to work - it never displays any message there is a newer version available.  Attaching proxy to nexus, I see requests are made to http://www.sonatype.com/products/nexus/product-versions.properties, however this responds with a moved permanently (301) to http://www.sonatype.com/downloads/products/nexus/product-versions.properties. Not sure our plugin code handles this redirect even though comments in code says it does.  Simple verification: send a get to http://localhost:8081/nexus/service/local/lvo/nexus-oss/1.9.2.1 Two redirects are received by nexus but afaict none are followed to correct location.  Also look at NEXUS-3292 as well.  ",Bug,Major,Closed,"2011-11-29 14:51:18","2011-11-29 14:51:18",1
"Sonatype Nexus","failed on CI: DefaultFSLocalRepositoryStoragePerformanceTest.testRetieveItemWithLastAccessUpdate, DefaultFSLocalRepositoryStoragePerformanceITTest.validateRetieveItemWithLastAccessUpdate","The tests check for update of item access time. Access time did not change, it seems unlikely that the grid slave was so fast (retrieveItem in between with string checks etc., but nothing really slow, so this still might be the case here).    https://builds.sonatype.org/job/nexus-oss-its/jdk=java-6x,label=win/lastCompletedBuild/testReport/org.sonatype.nexus.proxy.storage.local.fs.perf/DefaultFSLocalRepositoryStoragePerformanceTest/testRetieveItemWithLastAccessUpdate/  https://builds.sonatype.org/job/nexus-oss-its/jdk=java-6x,label=win/lastCompletedBuild/testReport/org.sonatype.nexus.proxy.storage.local.fs.perf/DefaultFSLocalRepositoryStoragePerformanceITTest/validateRetieveItemWithLastAccessUpdate/        ",Bug,Major,Closed,"2011-11-28 10:13:52","2011-11-28 10:13:52",1
"Sonatype Nexus","Nexus537RepoTargetsIT.artifactUplaodTest failed","https://builds.sonatype.org/view/nexus/job/nexus-oss-its/94/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.integrationtests.nexus537/Nexus537RepoTargetsIT/artifactUplaodTest/    ",Bug,Major,Closed,"2011-11-25 10:15:16","2011-11-25 10:15:16",1
"Sonatype Nexus","Improve repository attributes implementation","Improve repository attributes implementation.    * Let multiple serialization engines handle attributes  * Cleanly separate _data_ from _domain_  * Move attributes under repository, making a repo folder being self complete (everything is in one place, it's enough just to move a repository folder)    etc",Improvement,Major,Closed,"2011-11-24 16:58:31","2011-11-24 16:58:31",7
"Sonatype Nexus","Upgrade maven-aether-provider to fix MNG-4987","Nexus is affected by this metadata merge bug:  http://jira.codehaus.org/browse/MNG-4987    We need to upgrade the maven-aether-provider to fix this.",Bug,Major,Closed,"2011-11-22 17:26:15","2011-11-22 17:26:15",1
"Sonatype Nexus","failure: org.sonatype.nexus.integrationtests.nexus4579.Nexus4579OptionalTrashForSnapshotsIT.removeAllSnapshotsDirectly fails with files in trash","https://builds.sonatype.org/job/nexus-oss-its/jdk=java-6x,label=win/lastCompletedBuild/testReport/org.sonatype.nexus.integrationtests.nexus4579/Nexus4579OptionalTrashForSnapshotsIT/removeAllSnapshotsDirectly/    ",Bug,Blocker,Closed,"2011-11-22 10:34:15","2011-11-22 10:34:15",1
"Sonatype Nexus","Abstract* integration tests are being run as regular tests","It seems the failsafe config is messed up when running ITs - at least in migration plugin. This was corrected with NXCM-3473 in pro - seems we need same for OSS.    Noticed this on grid as of https://builds.sonatype.org/job/nexus-oss-its/88/jdk=java-6x,label=linux/console",Improvement,Major,Closed,"2011-11-21 18:37:41","2011-11-21 18:37:41",1
"Sonatype Nexus","Local Timezone description should be displayed in screens editing times of a scheduled task","When creating or editing a scheduled task that is not manually run, a Start Time field is shown in the south panel ( edit panel ).    This time is displayed relative to the logged in UI user's timezone.    We have NEXUS-4616, which attempts to ensure display of the time value is proper.    *This issue is about appending the user's timezone description ( as it is currently displayed in grid ) after the Start Time field's value to help the user understand the context in which they are setting up the scheduled task to run.",Improvement,Major,Closed,"2011-11-21 14:54:22","2011-11-21 14:54:22",1
"Sonatype Nexus","As a user developing a nexus plugin I want an easy way to add settings ","Objective: Provide a trivial way for users to write basic plugins that provide simplistic generated UI for configuration, rest and persistence.    Generated UI should be available globally, and also at the repository configuration level.  It should be possible to have contributions conditionally available based on the type of repository selected.    ",Improvement,Major,Closed,"2011-11-18 20:38:15","2011-11-18 20:38:15",12
"Sonatype Nexus","Logout link is not visible if user do not have Status - (read)","Nexus UI depends on Status - (read) to show logout link.  But users can login w/o that priv, which makes impossible to log out.  We need to handle this.",Improvement,Major,Closed,"2011-11-18 15:26:15","2011-11-18 15:26:15",1
"Sonatype Nexus","Delete artifact from UI Delete button causes location to be lost","This relates to https://issues.sonatype.org/browse/NEXUS-3992 which has been fixed, but now when deleting via the Delete button in the Artifact Information panel, the position in the Browse Storage panel is lost.    It is then necessary to repeat the process of finding the folder.    This make the button all but useless.    The right-click delete option does not have this problem. so it ought to be fixable for the delete button.",Bug,Major,Closed,"2011-11-18 15:08:46","2011-11-18 15:08:46",2
"Sonatype Nexus","Uploading a Bundle creates hashes for all content","Recently tried uploading a bundle I'd created.    Nexus added .md5 and .sha1 hashes for the .asc files.    Previously I had created the bundle which already contained the .md5 and .sha1 hashes, and Nexus created hashes for those too.    Nexus should either require (and check) hashes, but not create them, or it should create any required missing hashes.",Improvement,Minor,Closed,"2011-11-18 14:41:07","2011-11-18 14:41:07",1
"Sonatype Nexus","Concurrent modification exception when adding repositories","If you add two repositories at the same time you get a concurrent modification exception.  This occurred when using a script which creates release and snapshot repositories simultaneously using the REST API:    ",Bug,Major,Closed,"2011-11-17 21:15:19","2011-11-17 21:15:19",3
"Sonatype Nexus","Empty trash removes sonatype-work/nexus/trash directory if age is set to -1","If the Purge items older than (days) is set to -1 the empty trash task removes the sonatype-work/nexus/trash directory.      This causes a problem if this has been symlinked to another directory.      Note that you must set the age to -1 to have this directory emptied due to NEXUS-4468",Bug,Major,Closed,"2011-11-17 17:41:56","2011-11-17 17:41:56",1
"Sonatype Nexus","app-lifecycle Maven plugin does not handle non-ascii chars correctly","For a Nexus plugin I have some Swedish (non-ascii) chars in the description of the Maven project. These chars are not handled correctly by the app-lifecycle Maven plugin.",Bug,Major,Closed,"2011-11-17 09:10:58","2011-11-17 09:10:58",1
"Sonatype Nexus","Very slow performance of snapshot remover","I've been getting quite a few reports of snapshot removal tasks taking a very long time to run (over 24 hours in some cases).  On RSO the weekly snapshot removal job takes around 4 hours.    This is far too slow.  We need to do some profiling, figure out why this takes so long, and see if we can implement some improvements.",Bug,Major,Closed,"2011-11-17 01:28:36","2011-11-17 01:28:36",15
"Sonatype Nexus","Exception In log caused by an EventInpecter not initiallized when Warning is logged while Nexus starts up","(I purposely corrupted the access log file to make this happen )      ",Bug,Minor,Closed,"2011-11-16 19:51:35","2011-11-16 19:51:35",3
"Sonatype Nexus","Anonymous user sporadically gets authorization errors downloading artifacts","Placeholder issue for SUPPORT-1109, once we get latest logs we'll be able to start work on this.",Improvement,Major,Closed,"2011-11-10 22:26:40","2011-11-10 22:26:40",5
"Sonatype Nexus","org.sonatype.nexus.integrationtests.nexus977tasks.Nexus977GroupOfGroupsDownloadIndexesTaskIT.downloadIndexes fails on grid","https://builds.sonatype.org/job/nexus-oss-its/75/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.integrationtests.nexus977tasks/Nexus977GroupOfGroupsDownloadIndexesTaskIT/downloadIndexes/      ",Bug,Major,Closed,"2011-11-10 21:15:30","2011-11-10 21:15:30",1
"Sonatype Nexus","Change proxy attributes lastRequestTime to only be updated once ever 12 hours","Work was done as part of: NXCM-3492 to figure out how to make the proxy attributes faster.  We came to the conclusion that this is NOT the best place to optimize.  However there are a few things we could do to improve performance.  One of the standouts is change the lastRequestTime to only be updated every 12 hours (this time may change, but will be somewhere between 12 and 24)    This should NOT be configurable via the UI, but we should consider keeping it as a system property.  See the work that was done on the attribute-performance-test branch (The performance tests should be merged to master, the extra cruft for Jackson json/xml should be thrown out)      NOTE: we may need to strip the time portion off the last access date on the UI info panel",Improvement,Major,Closed,"2011-11-10 16:31:36","2011-11-10 16:31:36",2
"Sonatype Nexus","Use downgradable locking implementation in Nexus","We have a fixed locking implementation available which should solve quite a few problems with the current implementation.    https://docs.sonatype.com/display/Nexus/Distributed+Locking    If we're going to move to this implementation we should do it sooner rather than later, and should do an internal release of Nexus at least a month before the official release so we can get experience with it running on our servers.    The change introduces downgrading of locks (in both, Nexus own SimpleLockResource and in wrapper wrapping sisu-locks).    The use of distributed locks was already possible by a system property switch.",Improvement,Major,Closed,"2011-11-09 22:19:19","2011-11-09 22:19:19",3
"Sonatype Nexus","Regression: org.sonatype.nexus.integrationtests.nexus3626.Nexus3626SimpleSearchIT.wagonDeploy fails","https://builds.sonatype.org/view/nexus/job/nexus-oss-its/73/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.integrationtests.nexus3626/Nexus3626SimpleSearchIT/wagonDeploy/  ",Bug,Major,Closed,"2011-11-09 12:30:11","2011-11-09 12:30:11",1
"Sonatype Nexus","HTTP header: Accept: text/css on CSS file results in a 406 (CSS not loaded)","When CSS files hosted below a 'maven-site' repo (any sub folder) are requested with Accept text/css a 406 response for the CSS file is returned - this means the CSS file in question will not be loaded by the browser. (This happens when IE9 is configured to use browser modus IE9 and document modus IE9-Standards.)    When the same CSS file is requested with Accept \*/\* (e.g. via a direct URL) the CSS file is delivered correctly with Content-Type text/css in the response header.    shell log:    > curl -u <user> -H Accept:\*/\* https://<site-repo>/x.css -D -    HTTP/1.1 200 OK  Date: Fri, 04 Nov 2011 18:02:08 GMT  Server: Noelios-Restlet-Engine/1.1.6-SONATYPE-5348-V4  Content-Type: text/css  Last-Modified: Thu, 27 Oct 2011 17:39:32 GMT  ETag: eebcd5378dc6c17685ffa4694a12580723fdcf2a  Vary: Accept-Charset,Accept-Encoding,Accept-Language,Accept  Content-Length: 222  Set-Cookie: JSESSIONID=81c0d344-0296-42fe-9e0d-581d37ede4f6; Path=/nexus; HttpOnly  Set-Cookie: rememberMe=deleteMe; Path=/nexus; Max-Age=0; Expires=Thu, 03-Nov-2011 18:02:08 GMT  Connection: close    #banner, #footer, #leftcol, #breadcrumbs, .docs #toc, .docs .courtesylinks, #leftColumn, #navColumn {          display: none !important;  }  #bodyColumn, body.docs div.docs {          margin: 0 !important;          border: none !important  }    > curl -u <user> -H Accept:text/css https://<site-repo>/x.css -D -    HTTP/1.1 406 The resource identified by the request is only capable of generating response entities which have content characteristics not acceptable according to the accept headers sent in the request  Date: Fri, 04 Nov 2011 18:03:05 GMT  Server: Noelios-Restlet-Engine/1.1.6-SONATYPE-5348-V4  Content-Type: text/html; charset=iso-8859-1  Cache-Control: must-revalidate,no-cache,no-store  Content-Length: 1782  Set-Cookie: JSESSIONID=898ee864-ec6a-4bce-8daf-4d98d6585531; Path=/nexus; HttpOnly  Set-Cookie: rememberMe=deleteMe; Path=/nexus; Max-Age=0; Expires=Thu, 03-Nov-2011 18:03:05 GMT  Connection: close    <html>  [...]    ",Bug,Critical,Closed,"2011-11-04 18:15:31","2011-11-04 18:15:31",3
"Sonatype Nexus","Reduce the thread baseline for Nexus","There are two threads created for every repository in a Nexus instance.  We should investigate whether we can eliminate these.    Description is below, from Tamas on development list.    {quote}    * One thread per indexed repository (so basically one for every repo), used to keep the lucene cache warm    Maven Indexer keeps one thread per IndexingContext (which maps 1:1 to repositories in Nx), to implement the async commit feature. The fact that indexer are warmed upon commit is just a bonus. Lucene writer writes synchronously the change to index, but to have readers up to date, they need to be reopened, and reopening Lucene readers are expensive. Hence, Maven Indexer does this async commit thing (async reader reopening more precisely), with assumptions that index changes has to go out, and the fact that readers (and components consuming them, like search UI and archetype catalog) may lag behind is not a big concern and problem. Simply put, what you deploy is not searchable immediately (talking about millis), but only after async commit happened (in silent period). Also, this requires context locking, hence no search or any other index consumption might be running in that moment. This is the implication of having IndexerContext being able to handle one repository (was designed as such) and Maven Indexer's incapability to have multiple contexts in single Lucene index.     * One thread per proxy repository to check the status of the remote.    These threads are mostly dormant (timed wait), until UI pulls the status, and status cache is invalidated (in most cases UI gets the cached remote status, except in very 1st request or when forced the cache purge). Again, since the REST exposes this for each repo as separate resource, and the remote checks might take long time (see NEXUS and old NX Jiras), this was the one of the ways to fulfill acceptable UI response, to have dedicated thread doing remote checks.    Initially remote status was handled by one thread, but the UI delay it caused (one bad remote might delay all the others for more minutes) was noted as problematic, not acceptable and then we switched to per-repo threads.    {quote}",Improvement,Major,Closed,"2011-11-03 19:11:12","2011-11-03 19:11:12",5
"Sonatype Nexus","Scheduled Tasks start/run times should be displayed with local timezone","The next run/last run columns values are calculated on the server, using the servers timezone.",Improvement,Major,Closed,"2011-11-03 14:29:25","2011-11-03 14:29:25",5
"Sonatype Nexus","Change default routing URL patterns","I think that the default routing URL patterns should be changed to  and , respectively. The reason is that this is likely what most people want and the existing url patterns could match more than expected as it is not matched strictly to the beginning of the url.",Improvement,Major,Closed,"2011-11-03 08:04:52","2011-11-03 08:04:52",1
"Sonatype Nexus","org.sonatype.nexus.plugin.CloseStageRepositoryMojoTest.mavenProxySupportWithoutAuth failing on grid","Fails on win and linux.    Reference: https://builds.sonatype.org/view/nexus/job/nexus-oss/521/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.plugin/CloseStageRepositoryMojoTest/mavenProxySupportWithoutAuth/    ",Bug,Major,Closed,"2011-11-03 02:14:33","2011-11-03 02:14:33",1
"Sonatype Nexus","Ensure Nexus is compatible with multi-byte encodings","Nexus should be able to display and encode multi-byte languages in a consistent and predictable manner. Essentially this means encoding display text as UTF-8 and persisting configuration data as UTF-8. Generally *ids* for repositories, users, roles, scheduled tasks and other Nexus model elements should use only characters from ASCII.      ",Improvement,Major,Closed,"2011-11-01 17:25:33","2011-11-01 17:25:33",10
"Sonatype Nexus","org.sonatype.nexus.plugins.migration.nexus3301.Nexus3301MavenDownloadRedirectSecurityIT.downloadWithPermition fails retrieving artifacts","Reference: https://builds.sonatype.org/view/nexus/job/nexus-oss-its/57/jdk=java-6x,label=win/testReport/junit/org.sonatype.nexus.plugins.migration.nexus3301/Nexus3301MavenDownloadRedirectSecurityIT/downloadWithPermition/    Please change the method name when this gets fixed.        Assigning fix version as possible regression.",Bug,Major,Closed,"2011-10-31 15:22:30","2011-10-31 15:22:30",1
"Sonatype Nexus","/service/local/lucene/search docs indicate wrong result type","https://repository.sonatype.org/nexus-indexer-lucene-plugin/default/docs/rest.lucene.search.html states that the output payload should be <search-results> (i.e. searchResponse). However as can be seen https://repository.sonatype.org/service/local/lucene/search?repositoryId=central-proxy&g=commons-logging&v=1.1.1 returns <searchNGResponse>. The <data> section contains a list of <artifact> while it should then according to the XSD return <nexusNGArtifact>. I downloaded the XSD and compiled corresponding java classes using xjc and obviously am not able to unmarshal the data correctly as the result is mixed.",Bug,Major,Closed,"2011-10-30 22:17:33","2011-10-30 22:17:33",1
"Sonatype Nexus","Using an LDAP filter to allow certain user to connect","I'm trying to set a filter on LDAP configuration to restrict the users allowed to use nexus.  The LDAP have users that don't have to use nexus. The users allowed to use nexus have a attribut set.     In the configuration, it is not possible to create such a filter. I found this on internet but no way to make it working: http://code.google.com/p/nexus-ldap/wiki/SearchFilterExpressionConfig",Bug,Critical,Closed,"2011-10-27 17:25:55","2011-10-27 16:25:55",1
"Sonatype Nexus","Requests to an auto-blocked repository are added to NFC","Requests which come into a proxy repository while it is auto-blocked are being added to NFC.  This is a big problem, because we no longer clear caches when it is un-blocked.  {quote}  2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2Repository - aaa.retrieveItem() :: /foo/bar/5.0/bar-5.0.jar 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2Repository - /foo/bar/5.0/bar-5.0.jar :: localOnly=false, remoteOnly=false, ProxyMode=BLOCKED_AUTO 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.storage.local.fs.DefaultFSLocalRepositoryStorage - /foo/bar/5.0/bar-5.0.jar --> /Users/<USER>nexus/nexus-professional-webapp-1.9.2.3/./../sonatype-work/nexus/storage/aaa/foo/bar/5.0/bar-5.0.jar 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2Repository - Item /foo/bar/5.0/bar-5.0.jar not found in local storage. 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.storage.local.fs.DefaultFSLocalRepositoryStorage - /foo/bar/5.0/bar-5.0.jar --> /Users/<USER>nexus/nexus-professional-webapp-1.9.2.3/./../sonatype-work/nexus/storage/aaa/foo/bar/5.0/bar-5.0.jar 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2Repository - Item /foo/bar/5.0/bar-5.0.jar not found in local storage. 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2Repository - Item /foo/bar/5.0/bar-5.0.jar does not exist locally and cannot go remote, throwing ItemNotFoundException. 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2Repository - aaa retrieveItem() :: NOT FOUND aaa:/foo/bar/5.0/bar-5.0.jar 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2Repository - Adding path /foo/bar/5.0/bar-5.0.jar to NFC. 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2Repository - bbb.retrieveItem() :: /foo/bar/5.0/bar-5.0.jar 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2Repository - The serving of item /foo/bar/5.0/bar-5.0.jar is forbidden by Maven repository policy. 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2Repository - bbb retrieveItem() :: NOT FOUND bbb:/foo/bar/5.0/bar-5.0.jar 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2Repository - Adding path /foo/bar/5.0/bar-5.0.jar to NFC. 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2GroupRepository - public retrieveItem() :: NOT FOUND public:/foo/bar/5.0/bar-5.0.jar 2011-10-26 11:31:16 DEBUG [5.0/bar-5.0.jar] - org.sonatype.nexus.proxy.maven.maven2.M2GroupRepository - Adding path /foo/bar/5.0/bar-5.0.jar to NFC. {quote}",Bug,Blocker,Closed,"2011-10-26 17:33:17","2011-10-26 16:33:17",1
"Sonatype Nexus","Nexus auto-blocks repositories if a request for an artifact fails with access denied (403)","Was attempting to build against the rso nexus-private-dev group.  Found this to be extremely unstable, it kept being auto-blocked.    Root cause is that every time an artifact request comes in which is blocked by the repository target privileges in that repo we're auto-blocking the proxy.    Make a proxy for this URL in your local nexus (note, you will need to supply authorization credentials) : https://repository.sonatype.org/content/groups/private-nexus-dev/    Request something through it that there isn't a repository target privilege for:    http://localhost:8081/nexus/content/repositories/private-nexus-dev-proxy/foo/bar/1.0/bar-1.0.jar    In local Nexus log you will see we auto-block:    {quote}  2011-10-26 11:21:15 WARN  [p-1312724941-50] - org.sonatype.nexus.proxy.maven.maven2.M2Repository - Remote peer of proxy repository aaa (id=aaa) threw a org.sonatype.nexus.proxy.RemoteAccessDeniedException exception. Please set up authorization information for this repository. Auto-blocking this repository to prevent further connection-leaks and known-to-fail outbound connections until administrator fixes the problems, or Nexus detects remote repository as healthy. - Cause(s): Forbidden  2011-10-26 11:21:15 INFO  [atusChecker-aaa] - org.sonatype.nexus.proxy.registry.DefaultRepositoryRegistry.aaa - Next attempt to auto-unblock the aaa (id=aaa) repository by checking it's remote peer health will occur in 40 seconds.    {quote}      ",Bug,Critical,Closed,"2011-10-26 17:24:55","2011-10-26 16:24:55",1
"Sonatype Nexus","org.sonatype.nexus.integrationtests.nexus983.Nexus983IndexArtifactsWihoutPomIT.copyPomlessArtifact fails on grid","Reference:   https://builds.sonatype.org/view/nexus/job/nexus-oss-its/48/jdk=java-6x,label=linux/testReport/junit/org.sonatype.nexus.integrationtests.nexus983/Nexus983IndexArtifactsWihoutPomIT/copyPomlessArtifact/    ",Bug,Major,Closed,"2011-10-21 12:07:45","2011-10-21 11:07:45",1
"Sonatype Nexus","Hosted maven-site repository summary Distribution Management section wrong - refers to snapshotRepository","On a maven-site repository, when viewing in the repository browser and selecting the Summary tab, the distrib management snippet is incorrect:        The {{<snapshotRepository>}} tag should be a {{<site>}} tag",Bug,Major,Closed,"2011-10-18 18:00:34","2011-10-18 17:00:34",1
"Sonatype Nexus","Empty trash task should allow specifying repositories","Users will likely want different trash removal policies for release and snapshot repositories.  The empty trash task should allow specifying a target repository.    Upgrade of existing tasks could specify all repositories.",Improvement,Major,Closed,"2011-10-18 17:14:35","2011-10-18 16:14:35",2
"Sonatype Nexus","Snapshot removal task should make moving to trash optional","Snapshot removal is typically done to free disk space, and snapshots are not necessarily valuable commodities. We should add a flag to the snapshot removal task to make moving them to the trash optional (default value of true).",Improvement,Major,Closed,"2011-10-18 17:12:57","2011-10-18 16:12:57",5
"Sonatype Nexus","Authorization rejection is logged at the wrong level","Seeing a lot of this on RSO:      {quote}  2011-09-26 08:17:28 INFO  [1305124728-3756] - org.sonatype.nexus.security.filter.authz.NexusTargetMappingAuthorizationFilter - Unable to authorize user [xxxxxxx] for read(HTTP method GET) to /content/groups/private-nexus-dev/com/atlassian/jira/jira-project/4.4.1/jira-project-4.4.1.pom.sha1 from IP Address 198.240.128.752011-09-26 08:17:28 INFO  [1305124728-3756] - org.sonatype.nexus.security.filter.authc.NexusSecureHttpAuthenticationFilter - Request processing is rejected because user xxxxxxx lacks permissions.2011-09-26 08:17:33 INFO  [1305124728-3733] - org.sonatype.nexus.security.filter.authz.NexusTargetMappingAuthorizationFilter - Unable to authorize user [xxxxxxx] for read(HTTP method GET) to /content/groups/private-nexus-dev/com/atlassian/jira/jira-func-tests/4.4.1/jira-func-tests-4.4.1.pom from IP Address 198.240.128.752011-09-26 08:17:33 INFO  [1305124728-3733] - org.sonatype.nexus.security.filter.authc.NexusSecureHttpAuthenticationFilter - Request processing is rejected because user xxxxxxx lacks permissions.  {quote}    This is correct, repo target privileges don't allow users of that group to read this artifact.  But we need to move this to DEBUG, it's filling up the logs.",Bug,Major,Closed,"2011-09-26 14:46:19","2011-09-26 13:46:19",1
"Sonatype Nexus","Index is still active for out of service repositories, searches result in a 503","RSO has the java.net m2 repo Out of Service.    Searching for: com.sun.xml.fastinfoset in the UI (i.e.)  https://repository.sonatype.org/index.html#nexus-search;quick~com.sun.xml.fastinfoset    will result in a 503 when displaying the artifact details      ",Bug,Major,Closed,"2011-09-13 22:47:13","2011-09-13 21:47:13",2
"Sonatype Nexus","Rename jetty.properties to nexus.properties","<bundle-root>/conf/jetty.properties needs to be named <bundle-root>/conf/nexus.properties  ",Bug,Blocker,Closed,"2011-08-30 14:20:11","2011-08-30 13:20:11",1
"Sonatype Nexus","Nexus does not follow static nested LDAP groups","Hello,    I am having an issue with LDAP configuration of our Nexus OSS instance and don't see a documented way to get out of it.  I was under the impression that my setup was fairly common, but perhaps this is not so...    Our (OpenLDAP) directory uses static, nested groups.  The users are all in one tree under ou=Users and all the groups are under ou=Groups (there is no nesting of group levels).  Each project has a set of groupOfUniqueNames under ou=Groups such as:    acme-users  acme-developers  acme-administrators    The groups follow the standard method of nesting static groups and use a DN to point to the nested group.   Example:    In cn=acme-users,ou=Groups,dc=my,dc=site,dc=com:   uniqueMember: uid=user1, ou=Users, dc=my, dc=site, dc=com   uniqueMember: uid=user2, ou=Users, dc=my, dc=site, dc=com   uniqueMember: uid=user3, ou=Users, dc=my, dc=site, dc=com   uniqueMember: cn=acme-developers, ou=Groups, dc=my, dc=site, dc=com    In cn=acme-developers,ou=Groups,dc=my,dc=site,dc=com:   uniqueMember: uid=developer1, ou=Users, dc=my, dc=site, dc=com   uniqueMember: uid=developer2, ou=Users, dc=my, dc=site, dc=com   uniqueMember: cn=acme-administrators, ou=Groups, dc=my, dc=site, dc=com    In cn=acme-administrators,ou=Groups,dc=my,dc=site,dc=com:   uniqueMember: uid=admin1, ou=Users, dc=my, dc=site, dc=com    In our other LDAP-enabled applications, this works perfectly well.  There are options to configure nested groups, and if you were to query the contents of acme-users, you would see the user records for     user1, user2, user3, developer1, developer2, admin1    However, in Nexus OSS (at least), there doesn't seem to be any recognition that nested memberships are allowed.  that same admin1 user only shows up in the directory in which he actually exists:    admin1   ....     Roles: acme-administrators    Looking at the DefaultLdapGroupDAO, it appears to me that Nexus is probably not currently capable of handling this user setup. This is making permissions much more difficult to organize than they should be, as some of our project administrators (tech leads) are also developers.    I realize that converting the userbase to use dynamic groups is a possible workaround, but that isn't a method I want to explore right now; it hides the problem rather than fixing it.  Is there any possible filter magic I can use to make this work properly, or does nested group support simply need to be added to the LDAP implementation?  ",Improvement,Major,Closed,"2011-08-22 21:04:57","2011-08-22 20:04:57",5
"Sonatype Nexus","org.sonatype.nexus.integrationtests.nexus1197.Nexus1197CheckUserAgentIT.setUp throws BindException Address already in use",,Bug,Major,Closed,"2011-08-15 19:14:05","2011-08-15 18:14:05",1
"Sonatype Nexus","Next run is wrong for scheduled tasks using advanced cron expression","I have 2 snapshots cleanup jobs I'm launching one day on two. For that I have one of these tasks with the following cron : 0 0 20 ? * TUE,THU,SAT I start nexus and it says that the next launched is scheduled to the 10 august (where are on 27th july) It worked with nexus &lt; 1.9.2 It seems that if I launch manually the job the next run is back to the good value (I have to reverify it)",Bug,Blocker,Closed,"2011-08-10 15:23:20","2011-08-10 14:23:20",1
"Sonatype Nexus","Can't start Nexus 1.9.2  with Java 7","So far I'm using Nexus OSS 1.9.2 on Tomcat 7.0.19 under Java 6; 1.6.0_26, to be exact. JAVA_HOME points to the Java 6 installation on my machine when I start Tomcat. Everything works fine.    Today I installed Java 7 that was released today. With JAVA_HOME pointing to the new Java 7 installation, Nexus won't start anymore when Tomcat is (re-)started. Instead a couple of exceptions are shown in the logs; see attachment.",Bug,Minor,Closed,"2011-07-28 19:26:34","2011-07-28 18:26:34",1
"Sonatype Nexus","REST API documentation for /repositories/{repositoryID}/content is missing","There isn't any documentation for the /repositories/{repositoryID}/content rest endpoint.",Bug,Major,Closed,"2011-07-25 20:30:20","2011-07-25 19:30:20",1
"Sonatype Nexus","Tweaks related to solaris scripts","There are two tweaks to the solaris scripts that are included with the build that would prevent errors when running the script as a different user.    1. change the nexus scripts  they are under:  {quote}  <nexus package>/bin/jsw/solaris-x86-32/nexus  <nexus package>/bin/jsw/solaris-x86-64/nexus  <nexus package>/bin/jsw/solaris-x86-32/nexus  {quote}    by changing the following line:  {code}  su -m $RUN_AS_USER -c \$REALPATH\ $2   {code}  this does not work in solaris since it does not recognize the '-m' switch. The script runs fine if the '-m' switch is removed    2. Change the SMF script  It is found under:  {quote}  <nexus package>/bin/jsw/solaris-x86-32/sample-smf/app.xml  {quote}  The way is is now, if the smf script is set to run as a user other than root, it will fail.    change:  {code:xml}   <method_context>    <method_credential user='nexus' group='nexus'      privileges='basic,!proc_session,!proc_info,!file_link_any,net_privaddr' />  </method_context>  {code}  to  {code:xml}   <method_context>    <method_credential user='nexus' group='nexus'      privileges='basic,!proc_session,proc_info,!file_link_any,net_privaddr' />  </method_context>  {code}  ",Bug,Major,Closed,"2011-07-22 14:46:46","2011-07-22 13:46:46",1
"Sonatype Nexus","Rename NexusClient.getRespositories() to NexusClient.getRepositories()",,Improvement,Trivial,Closed,"2011-06-07 09:17:46","2011-06-07 08:17:46",1
"Sonatype Nexus","The way nexus processes metadata requests can cause build timeout failures","When Nexus receives an artifact level maven-metadata.xml request against a group repository it iterates against all repositories in the group.    For proxy repositories, this means checking the metadata and NFC timeouts, and if they have expired it goes remote.  By default these expire in 24 hours, so once a day Nexus will issue GET requests against all remotes.    If this request is for something fairly commonly requested then most likely these will return fairly quickly.    However, if it is for something unusual, then most likely all the remote Nexus instances will also have reached their timeouts, and will be forced to go remote to all their proxy's.    If there is a slowly responding node in the resulting graph which is commonly found in Nexus groups (such as repository.apache.org), then this can cause a cascade of slow response times.    This can be mitigated to some degree by intelligent use of routing rules, however these are difficult to set up, and if a user has too many rules they run the risk of them becoming obsolete as the contents on the remotes changes.    Proposed solution:    Nexus goes through the repository list and figures out all the GET requests that will need to be issued, and then issues them all simultaneously.  After this, it processes the repositories in the list normally.      This will mean that the total request time will be bounded by the Nexus request timeout settings, which default to 20 seconds timeout with 3 retries.  So total request time shouldn't exceed one minute.        ",Bug,Major,Closed,"2011-06-06 15:58:23","2011-06-06 14:58:23",7
"Sonatype Nexus","Upload hangs forever if the user does not have sufficient privileges","Consider we have a user that has the Artifact Upload privilege and their upload rights are restricted by a repository target. If that user tries to upload an artifact which they are not allowed to, they are presented with an upload progress bar that stays there forever. The only way to get rid of this is to close the browser window/tab. The user should be presented a reasonable error message instead.   In order to find out what was going on I had to turn on debug logging. I'd say such things should be logged at least at info level. Generally, I think the info level logging could be a little bit more talkative.",Bug,Major,Closed,"2011-06-01 14:31:03","2011-06-01 13:31:03",1
"Sonatype Nexus","Concurrent modification exception in security","Concurrent modification exception in security (see NXCM-2918 for logs).    ",Bug,Major,Closed,"2011-05-30 15:10:10","2011-05-30 14:10:10",2
"Sonatype Nexus","Download button's URL should be copy-able (into mails, jira comments, ...)","To reproduce, go to:    https://repository.jboss.org/nexus/index.html#nexus-search;quick~drools-distribution  Now select an entry (for example 5.2.0-SNAPSHOT)  then open tab Artifact information  then right click on the button Download  and there 's no Copy link location.    So how can I mail someone the link to that zip/jar/pom?  For now, there's a complex way of getting that download URL, or I could mail them a link of hudson to the zip.  Note: nexus's main task is to distribute our binaries, so it's a good way to distribute our nightly zips too, no?",Improvement,Major,Closed,"2011-05-13 08:11:44","2011-05-13 07:11:44",1
"Sonatype Nexus","If index download fails due to error then download index task should end in broken state.","If a remote index fails to download due to 401/403/50x problems we should end the download index task with a broken state.      Note that 403 is very common when going through a proxy that blocks .gz downloads.    ",Bug,Major,Closed,"2011-05-05 15:48:29","2011-05-05 14:48:29",1
"Sonatype Nexus","Change -1 Transaction Aborted message to something more user friendly","  Change it to something like:  The request has timed out.    ",Bug,Major,Closed,"2011-05-04 15:05:05","2011-05-04 14:05:05",1
"Sonatype Nexus","Allow UI upload of artifacts with new classifiers","We should allow uploading of addition artifacts which differ by classifer.  The typical use case for this would be when someone wants to add javadoc or sources to an existing released artifact.    Currently, if a user wants to upload an additional artifact into a GAV using the UI they currently have to:    # Change the release repository's deployment policy to allow redeploy  # Download the pom file for the GAV  # Upload the new artifact along with the old pom file  # Change the release repository's deployment policy back to disallow redeploy    ",Improvement,Major,Closed,"2011-04-12 17:23:07","2011-04-12 16:23:07",5
"Sonatype Nexus","Add a component to nexus that allows or disallow some clients based on it's UA","Add a component to nexus that allows or disallow some clients based on it's UA.    Typically [INFRA-3151|https://issues.apache.org/jira/browse/INFRA-3151] for example.    Maven 2.2.0 is known to be bad. Simply, by _excluding_ it's UA would help a lot maintaining healthy repository.",Improvement,Major,Closed,"2011-04-12 09:53:27","2011-04-12 08:53:27",5
"Sonatype Nexus","Documentation for data_index REST endpoint should indicate that it is deprecated","The data_index endpoint is slated for removal.  We should indicate that it is deprecated in the documentation.    https://repository.sonatype.org/nexus-indexer-lucene-plugin/default/docs/rest.data_index.html",Bug,Major,Closed,"2011-04-11 17:56:03","2011-04-11 16:56:03",1
"Sonatype Nexus","Unable to update proxy repository's configuration for minutes after adding it.","I added a proxy repositories for http://repository.jboss.org/nexus/content/groups/public and https://repository.jboss.org/nexus/content/repositories/releases/    Immediately after, I tried to change the public URL to use https.  The save timed out.  It was nearly 5 minutes before I could get it to go through.    ",Bug,Major,Closed,"2011-04-11 15:34:46","2011-04-11 14:34:46",5
"Sonatype Nexus","Redirect from http to https breaks remote repository browser","Add a proxy repository for:    http://repository.jboss.org/nexus/content/groups/public      Request from Nexus is sent as:  http://repository.jboss.org/nexus/content/groups/public/https://repository.jboss.org/nexus/content/groups/public/activespace/?delimiter=/    If you add the proxy for the https url it works.         ",Bug,Major,Closed,"2011-04-11 15:26:37","2011-04-11 14:26:37",2
"Sonatype Nexus","nexus is silent when it does not have permissions to update security.xml","so last night oss.sonatype.org is rebooted and today I got many complaints from ossrh users, saying they are having 401 errors  then I found their roles are lost and the cause is:        and        Nexus should return something like 500 error when it can not persist security data.",Bug,Major,Closed,"2011-04-07 13:28:49","2011-04-07 12:28:49",1
"Sonatype Nexus","Suppress generation of maven 3 metadata when older maven versions are detected","If you rebuild metadata on a hosted snapshot repository that has artifacts with multiple classifiers Nexus will generate the new maven-metadata.xml file with classifier information.    Since many customers are reluctant to change their Maven version on older branch builds, we should provide an option to suppress this.",Improvement,Major,Closed,"2011-04-06 19:57:08","2011-04-06 18:57:08",1
"Sonatype Nexus","Browse Remote tab does not shows upon adding Proxy repository","Browse Remote tab does not shows upon adding Proxy repository.    Steps to reproduce:    * start clean Nexus  * log in as admin  * click Repositories  * add proxy repository (just another for central, fill all in as usual)  * click Save  * the lower half of panel is focused on Browse Storage, but there is no Browse Remote tab  * highlight another repository, come back to newly added (to force UI refresh), still no Browse Remote  * close the whole Repositories tab, open it again, click newly added repo, there is it!",Bug,Trivial,Closed,"2011-04-06 11:30:55","2011-04-06 10:30:55",1
"Sonatype Nexus","artifact ignored due to failing content validation is logged as cached in feed","If enabled File content validation for a proxy repo for Maven central. Nexus retrieves files through a virus scanner, which returns html error page for some artifacts.  Nexus correctly ignores these invalid downloaded files (the error page) as I can't see it cached, but in the feeds (e.g. CachedArtifacts) is says that the artifact was cached. This is not correct.",Bug,Minor,Closed,"2011-04-06 10:14:10","2011-04-06 09:14:10",2
"Sonatype Nexus","FileItems generated by ContentGenerator has wrong behavior wrt conditional GETs, they always report 304 Not Modified","FileItems generated by ContentGenerator has wrong behavior wrt conditional GETs, they always report 304 Not Modified. I bet this is true for all Nexus version since we introduces ContentGenerators (Nexus 1.4 or so?).    With normal File items, the file's timestamp is taken to compare with timestamp sent by conditional GETs, and this works with normal files (like maven metadata or JARs), since in case of deploy/redeploy, the file timestamp did change (nexus maintains filestamps, and set's it to either the sent value or now).    But, ContentGenerator generated files are almost exactly same to File items, except their -- usually just placeholder with component's id -- content is discarded, and ContentGenerator component is invoked to generate content on the fly. But there is a problem: their timestamp _never changes_, since they got created.    Browsers and clients, that tries to optimize traffic best, once fetch generated content, will never be able to refetch it! Proof (reproduce steps):    * start up _empty_ Nexus OSS with factory config  * use Chrome to fetch {{archetype-catalog.xml}} of third-party repository, should be empty  * upload over UI an artifact that has packaging maven-archetype (POM and JAR).  * refetch the archetype catalog in browser. _No way_ to get new content  * try {{wget}} (or some similar tool that issues unconditional GET), voila, it's there!    Note about archetype catalog: how it went unnoticed? The trick is, that Archetype Catalog plugin _installs_ (simply put, saves the {{archetype-catalog.xml}} generated file _as part of boot process_ of Nexus! Meaning, the file timestamp would actually change and actualized on every boot. Testers and QAs would hardly notice this. But on long running instances with Chrome makes your head dizzy.  ",Bug,Major,Closed,"2011-04-05 12:22:45","2011-04-05 11:22:45",1
"Sonatype Nexus","make default value of Publish URL True when creating a group repository","When creating a group, provide default value for Publish URL.    In 99.8% of cases it's true",Improvement,Major,Closed,"2011-04-04 18:42:59","2011-04-04 17:42:59",1
"Sonatype Nexus","Enable file content validation for new proxy repositories.","Seems to me that the file content validation feature is pretty well proven at this point.    I think we should enable it by default for new proxy repositories (and for the proxy's that ship in the default configuration).",Improvement,Minor,Closed,"2011-04-04 17:00:16","2011-04-04 16:00:16",1
"Sonatype Nexus","Bad class version in .war 1.9.0.2 release","Nexus.war won't start on Tomcat running on Java 1.5:    java.lang.UnsupportedClassVersionError: Bad version number in .class file (unable to load class org.sonatype.nexus.web.PlexusContainerContextListener)    My best guess is it's probably compiled on Java 1.6.",Bug,Major,Closed,"2011-04-04 14:54:02","2011-04-04 13:54:02",1
"Sonatype Nexus","Nexus uses wrong content-type from Index GZ files","Nexus uses wrong content-type from Index GZ files.    See http://jira.codehaus.org/browse/MINDEXER-13 for details.    In short, Nexus serves Index GZ files with content-type of {{application/x-compressed}} that is usually associated with Unix old {{compress}} utility.    It should use {{application/x-gzip}} instead (or some variant).",Bug,Major,Closed,"2011-03-30 11:28:48","2011-03-30 10:28:48",1
"Sonatype Nexus","As a user, I would like to be able to override the location of the storage directory.","It's increasingly common for Nexus to be run on machines which have most of their storage on network mounted drives (san, iscsi, etc.).      Ideally in this situation most of the work directory should be stored on local disk for high performance, but the storage directory should be placed on the larger external drive.    Currently we recommend use of symlinks to achieve this configuration, but this isn't possible for users who run Nexus on older versions of Windows.  So they must manually override all of the local storage settings for every repository, which is very tedious, and can't even be done for some types of repositories (such as staging).    We should provide a setting for this.      ",Improvement,Major,Closed,"2011-03-23 17:25:14","2011-03-23 17:25:14",3
"Sonatype Nexus","Menu option run disappears from right-click menu in Scheduled tasks after running a task","When manually executing a task in the scheduled tasks screen by right-clicking and selecting run, that option then disappears (for that specific task) unless I refresh.    To re-produce:  * Create a scheduled task. The ones I've seen this issue with are scheduled daily/weekly, but I would assume a manual execution task would also show it.  * Click refresh.  * Select the task and right-click. Select run.  * Now, right-click again. The run options is now gone. The only way to get it back is to hit refresh.  ",Bug,Minor,Closed,"2011-03-15 09:47:48","2011-03-15 09:47:48",1
"Sonatype Nexus","Role UI: LDAP Admin grants access to Administration - Server link, but results with 403 when opening it","Role UI: LDAP Admin grants access to Administration - Server link, but results with 403 when opening it.    I took new deployment of Nexus OSS trunk build, started it up. As admin, I granted UI: LDAP Admin role to user deployment. Logged out. Logged in as deployment user. The Administration -> Server became visible -- along with the expected Security -> LDAP Configuration. But opening Server administration page results in 403 Forbidden popup error presented by UI.",Bug,Major,Closed,"2011-03-11 13:24:20","2011-03-11 13:24:20",1
"Sonatype Nexus","Documentation for role-request XML payload is incorrect","The role-request XML payload is not documented correctly.           This should be:        ",Bug,Major,Closed,"2011-03-10 22:37:38","2011-03-10 22:37:38",1
"Sonatype Nexus","External role mapping UI doesn't scale well","It isn't uncommon for a large LDAP system to have hundreds of groups.      The external role mapping UI loads all of these into a droplist.  Loading this list can take a very long time.     It is also very cumbersome to find roles in this list since there is no search capability.    ",Bug,Major,Closed,"2011-03-09 21:03:04","2011-03-09 21:03:04",8
"Sonatype Nexus","Upgrade Shiro version to 1.1.0 ( removes log spam )","Roughly every 5 minutes we're getting this error logged:    2011-03-08 13:29:16 WARN  [tomcat-http--45] - o.a.s.m.DefaultSecu~          - Delegate RememberMeManager instance of type [org.apache.shiro.web.mgt.CookieRememberMeManager] threw an exception during getRememberedPrincipals().  org.apache.shiro.crypto.CryptoException: Unable to correctly extract the Initialization Vector or ciphertext.   at org.apache.shiro.crypto.JcaCipherService.decrypt(JcaCipherService.java:381)   at org.apache.shiro.mgt.AbstractRememberMeManager.decrypt(AbstractRememberMeManager.java:491)   at org.apache.shiro.mgt.AbstractRememberMeManager.convertBytesToPrincipals(AbstractRememberMeManager.java:431)   at org.apache.shiro.mgt.AbstractRememberMeManager.getRememberedPrincipals(AbstractRememberMeManager.java:398)   at org.apache.shiro.mgt.DefaultSecurityManager.getRememberedIdentity(DefaultSecurityManager.java:567)   at org.apache.shiro.mgt.DefaultSecurityManager.resolvePrincipals(DefaultSecurityManager.java:434)   at org.apache.shiro.mgt.DefaultSecurityManager.createSubject(DefaultSecurityManager.java:335)   at org.apache.shiro.subject.Subject$Builder.buildSubject(Subject.java:819)   at org.apache.shiro.web.subject.WebSubject$Builder.buildWebSubject(WebSubject.java:149)   at org.apache.shiro.web.servlet.AbstractShiroFilter.createSubject(AbstractShiroFilter.java:202)   at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:269)   at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:83)   at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:244)   at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)   at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:240)   at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:161)   at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:164)   at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:100)   at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:541)   at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)   at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:383)   at org.apache.coyote.http11.Http11NioProcessor.process(Http11NioProcessor.java:388)   at org.apache.coyote.http11.Http11NioProtocol$Http11ConnectionHandler.process(Http11NioProtocol.java:357)   at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1569)   at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)   at java.lang.Thread.run(Thread.java:662)  Caused by: java.lang.ArrayIndexOutOfBoundsException   at java.lang.System.arraycopy(Native Method)   at org.apache.shiro.crypto.JcaCipherService.decrypt(JcaCipherService.java:373)   ... 26 more    It started when we moved Nexus from one host to another and upgraded from 1.8 to 1.9.0.1    As far as we can tell it's not stopping anything from working",Bug,Minor,Closed,"2011-03-08 13:31:31","2011-03-08 13:31:31",1
"Sonatype Nexus","Nexus creates zero byte files in /content if content type header is in correct","I'm not sure yet how widespread this problem is, but at least in some cases Nexus silently creates files with no content if the Content-Type header is set incorrectly.    The following gives a zero byte file in the snapshots repository:        Set the content type correctly (to application/xml) and it works correctly.    This was very difficult to diagnose because we are returning 201 created, and no log message can be found about the failure, even at DEBUG level.    If we are going to reject based on content type we should return 400, and log an appropriate message.    ",Bug,Major,Closed,"2011-03-04 20:33:32","2011-03-04 20:33:32",1
"Sonatype Nexus","Browse remote doesn't seem to be working for https url's","The request sent from Nexus to the remote is incorrect if the remote URL is using https.    Here's a request sent to central for the org node:    http://repo1.maven.org/maven2/org/?delimiter=/    Here's a request to apache snapshots for the org node:    http://repository.apache.org/snapshots/https://repository.apache.org/content/groups/snapshots/org/?delimiter=/    The apache snapshots request returns 404.    ",Bug,Major,Closed,"2011-03-04 19:11:13","2011-03-04 19:11:13",2
"Sonatype Nexus","REST documentation for repo-group XML payload is incorrect.","The REST documentation for the XML payload of type repo-group is incorrect.    It only shows the repositories list, it does not show any of the required/optional attributes for the group itself.",Bug,Major,Closed,"2011-02-23 22:49:09","2011-02-23 22:49:09",1
"Sonatype Nexus","REST documentation for user-to-role XML payload is incorrect.","The XML payload shown for user-to-role is incorrect.  It shows:        This should be:    ",Bug,Major,Closed,"2011-02-23 22:46:24","2011-02-23 22:46:24",1
"Sonatype Nexus","Documentation for repositories REST XML payload is incorrect.","If you attempt to create a repository using the XML payload described in the documentation it fails, you get error 400.  No further information is printed in the log, even at debug level.    This is due to missing required fields.  If you send up all fields that come from GET request it works.    ",Bug,Major,Closed,"2011-02-23 14:22:46","2011-02-23 14:22:46",1
"Sonatype Nexus","Update Shiro to latest version","I think the latest released is 1.1.1  There are a bunch of fixes we want to consume.",Improvement,Major,Closed,"2011-02-22 16:40:31","2011-02-22 16:40:31",1
"Sonatype Nexus","Move toward removing Plexus entirely","We need to start using JSR330 annotations within Nexus, analyze to determine which components needs to be converted, and stop using the Plexus app booter.",Improvement,Major,Closed,"2011-02-21 22:57:27","2011-02-21 22:57:27",40
"Sonatype Nexus","NPE deleting group repositories if route list is empty","Remove all repository Routes from Nexus.    You will get an NPE when trying to visit the routing screen.  You will also get an NPE if you attempt to delete a repository from the repositories view.    This cannot be worked around in the UI, attempts to add new routes will fail.    ",Bug,Major,Closed,"2011-02-16 15:27:05","2011-02-16 15:27:05",1
"Sonatype Nexus","Empty trash shouldn't break if it is not able to delete a directory.","There is always the possibility of new artifacts entering the trash while we are running the empty trash task, this shouldn't break the task.      ",Bug,Major,Closed,"2011-02-16 14:51:20","2011-02-16 14:51:20",1
"Sonatype Nexus","Nexus should print required privileges in log at DEBUG level when denying access to something","This is a regression.  The new security does not print the privileges it is looking for (even at DEBUG) before issuing a 403.      It is extremely difficult to figure out what privileges are needed for specific operations because of this.",Bug,Major,Closed,"2011-02-15 17:46:05","2011-02-15 17:46:05",3
"Sonatype Nexus","UI broken in nexus 1.9 with repository group all","just tried to upgrade to 1.9 and found an critical error for us. All repostories besides the group all are not shown in the ui. After some try and error i figured out.   If you add an repository group with the id all, this error occurs. Maven works, just the ui is broken, so it renders this version useless for us.  Can be reproduced with an clean installation.  ",Improvement,Blocker,Closed,"2011-02-14 09:47:51","2011-02-14 09:47:51",1
"Sonatype Nexus","Sonatype repositories - cant browse repositories","Cant browse remote repositories:    https://repository.sonatype.org/content/repositories/central/  https://repository.sonatype.org/content/repositories/flexmojos-releases/  https://repository.sonatype.org/content/repositories/flexmojos-snapshots/  https://repository.sonatype.org/content/repositories/flex/",Bug,Critical,Closed,"2011-02-08 09:41:30","2011-02-08 09:41:30",2
"Sonatype Nexus","Artifact maximum age has no effect for release repositories, but is enabled.","Artifact maximum age does not have any effect for proxied release artifacts (NEXUS-3069).    However, the UI element for this is still enabled.     We need to revisit the reason for NEXUS-3069 (and it's original reason NEXUS-3065), and if possible restore this functionality (since it breaks staging).  If we cannot restore it, we should at least disable the UI.",Bug,Major,Closed,"2011-02-01 23:00:18","2011-02-01 23:00:18",1
"Sonatype Nexus","Possible to create cycle of group repositories, results in stack overflow","# create a maven 2 repository group child  # crate a maven 2 repository group parent, add child as it's only member  # attempt to add parent to the child group. This fails with an error, as it should.    Now create a Maven 2 hosted repository.    After this, the parent is a member of child.  Attempting to access either group results in a stack overflow.    ",Bug,Major,Closed,"2011-01-25 21:40:40","2011-01-25 21:40:40",1
"Sonatype Nexus","Expire cache from local storage tab fails with 403 error even when user has Clear Repository Caches privilege","Running Expire cache by right clicking on the local storage tab's tree fails with 403 error even when user has Clear Repository Caches privilege    It appears that the reason for this is the DELETE request is sent without a trailing /?    DELETE http://loclahost:8081/nexus/service/local/data_cache/repositories/releases/content  ",Bug,Major,Closed,"2010-12-15 01:03:26","2010-12-15 01:03:26",1
"Sonatype Nexus","Add pagination to the user/role/priv grids",,Improvement,Major,Closed,"2010-12-14 22:26:24","2010-12-14 22:26:24",3
"Sonatype Nexus","Nexus log too many message: Basic authentication scheme selected [ENH]","There are many and many log entry with this message:  {quote}  ...  2010-12-10 09:58:29 INFO  [l-2-thread-3526] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3531] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3533] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3535] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3538] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3540] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3543] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3534] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3541] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3530] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3542] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3550] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3553] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3527] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3545] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3544] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3555] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3558] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3554] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  2010-12-10 09:58:29 INFO  [l-2-thread-3529] - o.a.c.h.a.AuthChall~          - Basic authentication scheme selected  ...  {quote}    It should be into debug mode (or deleted) because there is no interesting information into this message to take an action.    Regards.  ",Bug,Major,Closed,"2010-12-10 09:08:42","2010-12-10 09:08:42",1
"Sonatype Nexus","Error creating scheduled task","I tried to create a scheulded task:  Type: Reindex  Repo: all  Reoccurrence: Once  Date: 12/08/2010 (today, this is key)  time: 17:00 (current local time: ~15:10, server time Wed Dec  8 14:09:47 CST 2010)      ",Bug,Major,Closed,"2010-12-08 20:21:28","2010-12-08 20:21:28",1
"Sonatype Nexus","Delete artifact from UI (button) causes 500","See: https://issues.apache.org/jira/browse/INFRA-3194  ",Bug,Major,Closed,"2010-12-06 18:04:02","2010-12-06 18:04:02",1
"Sonatype Nexus","RequestProcessor plugins not executed on GroupRepository requests.","Request processor plugins are not executed on requests that originate from a group repository.    Setup:  Nexus is configured with a hosted M2Repository with RequestProcessor plugin which is a member of a MavenGroupRepository.    Steps:  1. Add the group repository to you maven project / settings and not the individual repository.  2. Build the maven project to execute a request on the group.    Expected:  1. The group repository will forward on the request to the maven repository  2. the maven repository will execute the request and execute the request processors associated to it.    Actual:  1. The group repository forwards the request but the request processor is never invoked.  This is because the group repository calls org.sonatype.nexus.proxy.repository.AbstractRepository.retrieveItem(boolean, ResourceStoreRequest) which does not invoke AbstractRepository.checkConditions(ResourceStoreRequest, Action) and the RequestProcessors.    ",Bug,Major,Closed,"2010-12-06 12:04:31","2010-12-06 12:04:31",1
"Sonatype Nexus","Redesign the Security UI","Need to redesign the users page to support huge numbers of users/roles/privileges.    Currently when there are a large number or users/roles/privileges the pages become non-manageable",Improvement,Major,Closed,"2010-12-03 17:18:38","2010-12-03 17:18:38",20
"Sonatype Nexus","Allow to stop or suspend tasks","For now it is impossible to stop or suspend a task which is started.  If a long task is running but an important one is coming (for exemple internal tasks related to staging repositories management) we have to wait the end of the one running and we have an unstable repository because internal tasks aren't done.  It could be manual to llow to stop/suspend it if it things somethings goes wrong or it could be automated to let internal tasks automatically launched when they are triggered.",Improvement,Major,Closed,"2010-12-03 09:48:45","2010-12-03 09:48:45",20
"Sonatype Nexus","Home page has wrong link for upgrading info in left-hand menu","Per Nov 30, 2010, UPDATING NEXUS in the left-hand menu points at http://nexus.sonatype.org/updating-nexus.html, which doesn't include info about any version of Nexus greater than 1.0.1. However, there is a page http://nexus.sonatype.org/upgrading-nexus.html which should be used instead, as in includes some significant steps when upgrading between specific version beyond 1.0.1.    So, change UPDATING NEXUS to UPGRADING NEXUS and point it at http://nexus.sonatype.org/upgrading-nexus.html.",Bug,Major,Closed,"2010-11-30 11:49:15","2010-11-30 11:49:15",1
"Sonatype Nexus","Content-Type problems mirroring XML based artifacts between nexus instances","Based on the email thread I started on the Nexus mailing list, I'm raising this as a ticket regarding problems setting a Nexus->Nexus mirror and dealing with XML based artifacts repository artifacts.    After some packet sniffing and testing I found that requesting our Karaf feature file, which is a XML based artifact with a classifier:    curl -v http://remote:8081/nexus/content/repositories/smxmavenrepo/smx3/smx3.demobrands/3.0.27/smx3.demobrands-3.0.27-features.xml        I get a 404 and no upstream is checked, however when requesting an a jar artifact for the same thing:    curl -v http://remote:8081/nexus/content/repositories/smxmavenrepo/smx3/smx3.demobrands/3.0.27/smx3.demobrands-3.0.27.jar        This led to me think there was something about the content type of the artifact, and after putting the nexus logging into DEBUG I see the following:        So it looks like my LOCAL Nexus ( 1.5 ) isn't sending the correct Content-Type headers for the XML files, and the remote Nexus is rejecting it.  The local nexus appears to be sending application/xml, but it looks like the remote nexus wants text/xml when checking the incoming InputStream.  Looking at the Nexus JIRA I see NEXUS-2416 [1] and NEXUS-2688 [2] related to Content-Type issues, as mentioned in NEXUS-2688 I added a mime-types.properties file to my local Nexus to send out .xml files as text/xml ( and saw that coming out fine ), expired the remote servers cache and saw it get the same problems as the original request without any change.    The problem looks to be in AbstractFileTypeValidator#isExpectedFileType when Nexus calls out to eu.medsea.mimeutil.MimeUtil2, I wonder if wrapping the InputStream with a BufferedInputStream is triggering MimeUtil2 to only see the stream as an octet/stream rather than what it should be?    Hopefully there's enough info here for someone to make an informed response - shall I raise this entire email into a JIRA ticket?    <USER>   [1] https://issues.sonatype.org/browse/NEXUS-2416  [2] https://issues.sonatype.org/browse/NEXUS-2688  ",Bug,Major,Closed,"2010-11-30 05:27:24","2010-11-30 05:27:24",1
"Sonatype Nexus","Information unnecessarily logged as ERROR when repository put out of service","# Open Repositories tab  # Select Maven Central  # Right Click Maven Central in the list of repos and choose the Put Out of Service menu item.    As requests are sent from the ui to refresh the screen, you get some concerning ERROR messages.  I don't think these one liners are errors. ERRORs are typically runtime exceptions that are not expected. All of these look like checked exceptions to me.    ",Bug,Major,Closed,"2010-11-16 05:41:36","2010-11-16 05:41:36",1
"Sonatype Nexus","Change references of project.version in nexus pom's to use a property 'nexus.version'","We have project.version in the dependency management of the parent poms, this is bad.  Because of this we cannot release a subsection of the tree, as the dependencies point to versions that have not been created.    The proposed work around is create a property 'nexus.version' (or something similar) set that value to project.version, and use 'nexus.version' everywhere.  This way if we need to release a subset of the source tree we can just set a property.    ",Improvement,Major,Closed,"2010-11-22 16:03:13","2010-11-22 16:03:13",1
"Sonatype Nexus","Wrong default value in Viewing Repository list","After a search for an artifact that provides results from different repositories (here one proxy and one hosted), there's a pick list labeled Viewing Repository: which contains the different repositories concerned by the search.    See in the attached image that by choosing the version 1.15.0-SNAPSHOT which is contained in the hosted repo, I have by default selected the proxy repo. It lists the artifacts available but not my artifact. I have to select the other one to display it.    This pick list should be in the upper section to filter results (show only results within one of the repo and have a all entry as well) or should change its default selection when the user choose a different entry in the search results.",Improvement,Minor,Closed,"2010-11-17 16:17:12","2010-11-17 16:17:12",1
"Sonatype Nexus","prepare nexus-archetype-plugin for official nexus release","We desire to release the nexus-archetype-plugin as an optional Nexus OSS and Commercial plugin.    There are  some key tasks to complete before it is ready for release.    This issue is meant to track these tasks.",Improvement,Blocker,Closed,"2010-11-16 19:01:02","2010-11-16 19:01:02",5
"Sonatype Nexus","Add robot.txt to default bundle","It should be:    User-agent: *  Disallow: /content/  Disallow: /service/  Allow: /      *NOTE:* This needs to be in the release notes, and needs to say something about how this will only take effect if the webapp context is '/'    ",Improvement,Major,Closed,"2010-11-15 16:42:55","2010-11-15 16:42:55",1
"Sonatype Nexus","Repository deployment policy always shows as Disable Redeploy after login, even if it is actually something else.","Reproduce steps:    # Change deployment policy of releases repository to Allow Redeploy  # Log out of nexus, log back in    The deployment policy shows as Disable Redeploy.  Note that you must log out to see this bug, refresh of the page isn't enough.    This is a UI bug, the values written to the nexus.xml are correct, and the deployment policy works properly.",Bug,Major,Closed,"2010-11-11 16:50:43","2010-11-11 16:50:43",1
"Sonatype Nexus","Error 500 downloading file due to corrupt proxy attributes file","Due to a server crash, a corrupt proxy attributes file for a snapshot pom file was written out, it only had this content:    {code}  <file  {code}    After this the snapshot could not be downloaded from Nexus.    We should be able to recover from this situation.    Also, note that there is no stack trace logged for the NPE.  This made it much harder to diagnose the problem.    ",Bug,Blocker,Closed,"2010-11-03 21:28:48","2010-11-03 21:28:48",2
"Sonatype Nexus","repository CYCLE detected log message is misleading","As per NEXUS-2852, it is possible for the same repo to be added twice to a group or via routing rule. The log message for when a request is being processed in this case are as in the below examples:        This issue is about changing the wording of the message. CYCLE is not what is happening. CYCLE implies an infinite loop that needs to be broken out of, something much worse than performing duplicate work processing a request.    Something like Repository ID='central' in group ID='nar-group' will be ignored while retrieving '/org/bouncycastle/bcmail-jdk14/1.38/bcmail-jdk14-1.38.pom.md5' since repository ID='central' was processed earlier in this request. might be more accurate.            ",Bug,Trivial,Closed,"2010-11-03 16:39:37","2010-11-03 16:39:37",2
"Sonatype Nexus","Re-establish running of existing Nexus Selenium tests for OSS","The Nexus Selenium tests have been in broken state ever since the core of Nexus started using Guice instead of Plexus.    We value highly the automated tests of Nexus UI - we need to re-establish the successful execution of Selenium Tests both locally for a developer and on the CI grid.",Improvement,Major,Closed,"2010-10-29 14:57:24","2010-10-29 13:57:24",10
"Sonatype Nexus","Searching more incorrect than ever","Searching changed significantly from version 1.7 and we were very motivated to update our running instance. When we realized that the search algorithms do not get better but worsen in terms of overview and transparency we drew back and since work with the older version.    What is most detaining to us is that if you search for a certain keyword you do not get the same results you were getting in version 1.6.x.    For example: we have a lot of artifacts with the keyword 'solution' in both groupId's and artifactId's. when in version 1.6.x you are searching for 'solution' you get:  - com.solution.one:this:1.x  - com.one:solution.this:1.x  - com.one:this_solution:1.x  - com:one.solution.this:1.x    when you search for 'solution' in version 1.7.x and higher you only get:  - com.one:solution.this:1.x    why is that? if i search a keyword the index should filter groupId's as well as artifactId's and the filter must not stop when the string does not start with the keyword.     maybe you a are positive about the concept of searching as it currently is. but we cannot offer this mess of search results to our customers, nobody would find what he / she is looking for. so we keep on using a shortly outdated version of nexus.",Bug,Major,Closed,"2010-10-27 15:48:34","2010-10-27 14:48:34",1
"Sonatype Nexus","Re-enabling anonymous access requires user to enter the anonymous user password","The user shouldn't need to type in the anonymous users password to enable anonymous access",Bug,Minor,Closed,"2010-10-26 18:22:29","2010-10-26 17:22:29",1
"Sonatype Nexus","Reordering Repository Entries in Repo Group causes Error","When I try to reorder the Maven Central Entry, I get the following Stacktrace. The change itself is done by Nexus.     2010-10-25 10:16:45 INFO  [qtp-29781703-25] - o.s.n.c.a.DefaultNe~          - Applying Nexus Configuration...  2010-10-25 10:16:45 ERROR [qtp-29781703-25] - o.s.n.c.v.DefaultAp~          - * * * * * * * * * * * * * * * * * * * * * * * * * *  2010-10-25 10:16:45 ERROR [qtp-29781703-25] - o.s.n.c.v.DefaultAp~          - Nexus configuration has validation errors/warnings  2010-10-25 10:16:45 ERROR [qtp-29781703-25] - o.s.n.c.v.DefaultAp~          - * * * * * * * * * * * * * * * * * * * * * * * * * *  2010-10-25 10:16:45 ERROR [qtp-29781703-25] - o.s.n.c.v.DefaultAp~          - The ERRORS:  2010-10-25 10:16:45 ERROR [qtp-29781703-25] - o.s.n.c.v.DefaultAp~          -  o 1 - Repository central declared more than once!  2010-10-25 10:16:45 ERROR [qtp-29781703-25] - o.s.n.c.v.DefaultAp~          - * * * * * * * * * * * * * * * * * * * * *  2010-10-25 10:16:45 ERROR [qtp-29781703-25] - o.s.n.c.a.DefaultNe~          - Saving nexus configuration caused unexpected error:  org.sonatype.nexus.configuration.validator.ApplicationValidationResponse@3f6c10  2010-10-25 10:16:45 WARN  [qtp-29781703-25] - o.s.n.r.g.Repositor~          - Got IO Exception!  java.io.IOException: Saving nexus configuration caused unexpected error:  org.sonatype.nexus.configuration.validator.ApplicationValidationResponse@3f6c10   at org.sonatype.nexus.configuration.application.DefaultNexusConfiguration.saveConfiguration(DefaultNexusConfiguration.java:252)   at org.sonatype.nexus.rest.groups.AbstractRepositoryGroupPlexusResource.updateRepositoryGroup(AbstractRepositoryGroupPlexusResource.java:151)   at org.sonatype.nexus.rest.groups.AbstractRepositoryGroupPlexusResource.createOrUpdateRepositoryGroup(AbstractRepositoryGroupPlexusResource.java:125)   at org.sonatype.nexus.rest.groups.RepositoryGroupPlexusResource.put(RepositoryGroupPlexusResource.java:159)   at org.sonatype.plexus.rest.resource.RestletResource.storeRepresentation(RestletResource.java:351)   at org.sonatype.nexus.rest.NexusRestletResource.storeRepresentation(NexusRestletResource.java:84)   at org.restlet.resource.Resource.put(Resource.java:706)   at org.restlet.resource.Resource.handlePut(Resource.java:603)   at org.restlet.Finder.handle(Finder.java:359)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Router.handle(Router.java:504)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Router.handle(Router.java:504)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.sonatype.plexus.rest.RetargetableRestlet.doHandle(RetargetableRestlet.java:39)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Filter.doHandle(Filter.java:150)   at com.noelios.restlet.StatusFilter.doHandle(StatusFilter.java:130)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at com.noelios.restlet.ChainHelper.handle(ChainHelper.java:124)   at com.noelios.restlet.application.ApplicationHelper.handle(ApplicationHelper.java:112)   at org.restlet.Application.handle(Application.java:341)   at org.restlet.ext.wadl.WadlApplication.handle(WadlApplication.java:705)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Router.handle(Router.java:504)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Router.handle(Router.java:504)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at com.noelios.restlet.ChainHelper.handle(ChainHelper.java:124)   at org.restlet.Component.handle(Component.java:673)   at org.restlet.Server.handle(Server.java:331)   at com.noelios.restlet.ServerHelper.handle(ServerHelper.java:68)   at com.noelios.restlet.http.HttpServerHelper.handle(HttpServerHelper.java:147)   at com.noelios.restlet.ext.servlet.ServerServlet.service(ServerServlet.java:881)   at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)   at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)   at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)   at org.jsecurity.web.servlet.FilterChainWrapper.doFilter(FilterChainWrapper.java:52)   at org.jsecurity.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:105)   at org.jsecurity.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:135)   at org.jsecurity.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:180)   at org.jsecurity.web.servlet.FilterChainWrapper.doFilter(FilterChainWrapper.java:57)   at org.jsecurity.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:105)   at org.jsecurity.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:135)   at org.jsecurity.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:180)   at org.jsecurity.web.servlet.FilterChainWrapper.doFilter(FilterChainWrapper.java:57)   at org.jsecurity.web.servlet.JSecurityFilter.doFilterInternal(JSecurityFilter.java:382)   at org.jsecurity.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:180)   at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1148)   at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:387)   at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)   at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)   at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)   at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)   at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)   at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)   at org.mortbay.jetty.Server.handle(Server.java:326)   at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)   at org.mortbay.jetty.HttpConnection$RequestHandler.content(HttpConnection.java:879)   at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:747)   at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:218)   at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)   at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)   at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:520)  2010-10-25 10:16:45 ERROR [qtp-29781703-25] - o.s.n.e.r.DefaultEr~          - Detected Error in Nexus  org.restlet.resource.ResourceException: The server encountered an unexpected condition which prevented it from fulfilling the request   at org.sonatype.nexus.rest.groups.AbstractRepositoryGroupPlexusResource.updateRepositoryGroup(AbstractRepositoryGroupPlexusResource.java:193)   at org.sonatype.nexus.rest.groups.AbstractRepositoryGroupPlexusResource.createOrUpdateRepositoryGroup(AbstractRepositoryGroupPlexusResource.java:125)   at org.sonatype.nexus.rest.groups.RepositoryGroupPlexusResource.put(RepositoryGroupPlexusResource.java:159)   at org.sonatype.plexus.rest.resource.RestletResource.storeRepresentation(RestletResource.java:351)   at org.sonatype.nexus.rest.NexusRestletResource.storeRepresentation(NexusRestletResource.java:84)   at org.restlet.resource.Resource.put(Resource.java:706)   at org.restlet.resource.Resource.handlePut(Resource.java:603)   at org.restlet.Finder.handle(Finder.java:359)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Router.handle(Router.java:504)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Router.handle(Router.java:504)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.sonatype.plexus.rest.RetargetableRestlet.doHandle(RetargetableRestlet.java:39)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Filter.doHandle(Filter.java:150)   at com.noelios.restlet.StatusFilter.doHandle(StatusFilter.java:130)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at com.noelios.restlet.ChainHelper.handle(ChainHelper.java:124)   at com.noelios.restlet.application.ApplicationHelper.handle(ApplicationHelper.java:112)   at org.restlet.Application.handle(Application.java:341)   at org.restlet.ext.wadl.WadlApplication.handle(WadlApplication.java:705)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Router.handle(Router.java:504)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at org.restlet.Router.handle(Router.java:504)   at org.restlet.Filter.doHandle(Filter.java:150)   at org.restlet.Filter.handle(Filter.java:195)   at com.noelios.restlet.ChainHelper.handle(ChainHelper.java:124)   at org.restlet.Component.handle(Component.java:673)   at org.restlet.Server.handle(Server.java:331)   at com.noelios.restlet.ServerHelper.handle(ServerHelper.java:68)   at com.noelios.restlet.http.HttpServerHelper.handle(HttpServerHelper.java:147)   at com.noelios.restlet.ext.servlet.ServerServlet.service(ServerServlet.java:881)   at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)   at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)   at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)   at org.jsecurity.web.servlet.FilterChainWrapper.doFilter(FilterChainWrapper.java:52)   at org.jsecurity.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:105)   at org.jsecurity.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:135)   at org.jsecurity.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:180)   at org.jsecurity.web.servlet.FilterChainWrapper.doFilter(FilterChainWrapper.java:57)   at org.jsecurity.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:105)   at org.jsecurity.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:135)   at org.jsecurity.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:180)   at org.jsecurity.web.servlet.FilterChainWrapper.doFilter(FilterChainWrapper.java:57)   at org.jsecurity.web.servlet.JSecurityFilter.doFilterInternal(JSecurityFilter.java:382)   at org.jsecurity.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:180)   at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1148)   at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:387)   at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)   at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)   at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)   at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)   at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)   at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)   at org.mortbay.jetty.Server.handle(Server.java:326)   at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)   at org.mortbay.jetty.HttpConnection$RequestHandler.content(HttpConnection.java:879)   at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:747)   at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:218)   at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)   at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)   at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:520)  Caused by: java.io.IOException: Saving nexus configuration caused unexpected error:  org.sonatype.nexus.configuration.validator.ApplicationValidationResponse@3f6c10   at org.sonatype.nexus.configuration.application.DefaultNexusConfiguration.saveConfiguration(DefaultNexusConfiguration.java:252)   at org.sonatype.nexus.rest.groups.AbstractRepositoryGroupPlexusResource.updateRepositoryGroup(AbstractRepositoryGroupPlexusResource.java:151)   ... 75 more  ",Improvement,Major,Closed,"2010-10-25 09:19:17","2010-10-25 08:19:17",5
"Sonatype Nexus","Remove unused properties from IndexTreeView DTO, to lessen huge payload size","Remove unused properties from IndexTreeView DTO, to lessen huge payload size.    We have reported about 100k of JSON response payload sizes, since all the node types (except type G) carries what is know up to that level (A: GA, V: GAV, artifact:GAV+), but the UI uses only properties supplied on artifact type nodes.    By removing other properties, we may lessen the payload size a lot.",Improvement,Major,Closed,"2010-10-22 18:31:19","2010-10-22 17:31:19",3
"Sonatype Nexus","As a user, I am confused by the re-index task and schedule it unnecessarily.","Many of our users mistakenly think that the lucene indexes need to be completely rebuilt periodically.    We need to make it clear that this isn't necessary.    Here's a proposal to start the discussion.  Existing re-index task goes away, and the new set of tasks looks like this:    *Update Indexes*    Proxy Repositories:  This will check for updates on the remote, and download and process them as appropriate  Hosted Repositories: No-Op    Existing re-index jobs would be converted to update index jobs.    *Repair Indexes*    Proxy Repositories:  Download and process full index from remote.  Hosted Repositories: Rebuild index from information on disk    We might want to consider prohibiting users from scheduling this task to execute periodically.  If we did this it would impact a few customers who deploy directly to local storage, these would need to run the repair index task via REST.      *Publish Indexes*    Same as today, publishes indexes for downstream consumption      ",Improvement,Major,Closed,"2010-10-08 17:49:37","2010-10-08 16:49:37",3
"Sonatype Nexus","Backport the rev7251 change to 1.7.2 branch","Backport the rev7251 change to 1.7.2 branch.",Improvement,Major,Closed,"2010-09-30 16:24:56","2010-09-30 15:24:56",3
"Sonatype Nexus","Manually uploaded artifacts do not show uploaded by in artifact information","I have manually uploaded an artifact to a hosted repo and the upload by field remains empty although I was logged in and anonymous access has been disabled.",Bug,Major,Closed,"2010-08-19 08:20:27","2010-08-19 07:20:27",1
"Sonatype Nexus","Generic source of options for combo/multi selection field","Currently there is only one combo selection type repo-or-group. The handling of this is hardcoded in UI so adding a new combo type is impossible without changing the UI = not a pluggable solution.  Solution is to change the combo type to not be related to a specific resource but make type returning the url of a rest resource that can provide possible options values. The rest resource will be expected to return resources of type id/description.",Improvement,Major,Closed,"2010-08-17 15:05:49","2010-08-17 14:05:49",3
"Sonatype Nexus","Capability validation","There should be possible for a capability to provide additional validations such as for example not allowing multiple capabilities for same repository or value validation beside the regex value validator.  This could be archived by capability provider providing a validator implementation related to capability via capability id (same as for factory). If available, before saving a capability the validator is asked to validate create/update values.",Improvement,Major,Closed,"2010-08-17 15:04:20","2010-08-17 14:04:20",2
"Sonatype Nexus","Multi select form field","The UI / backend form field should support multi selection type. This allows choosing from a list of possible options similar to combo type only that it allows more then one selection.  The list of possible options should be provided via a rest resource.",Improvement,Major,Closed,"2010-08-17 15:02:56","2010-08-17 14:02:56",3
"Sonatype Nexus","Update Nexus to use latest Shiro",,Improvement,Major,Closed,"2010-08-02 15:19:14","2010-08-02 14:19:14",10
"Sonatype Nexus","Integrate Aether into Nexus",,Improvement,Major,Closed,"2010-07-20 10:01:01","2010-07-20 09:01:01",13
"Sonatype Nexus","java.util.zip.ZipException while parsing Maven plugin","This problem existed also in 1.7.0 (but I didn't reported it).  I have a proxy for Apache Snapshots.  In my logs I have many errors like:     But the archive is good :  ",Bug,Major,Closed,"2010-07-19 10:36:16","2010-07-19 09:36:16",1
"Sonatype Nexus","When downloading artifacts through REST redirect the user is not prompted for authorization.","If a user attempts to download an artifact using the redirect service and they do not have authorization, they get a page saying access denied.    They should get an authorization dialog.",Bug,Major,Closed,"2010-04-14 22:53:54","2010-04-14 21:53:54",1
"Sonatype Nexus","Add Clear Cache method to SecuritySystem","Should be simple to do, its basically what the .start() method does in the default impl.",Improvement,Major,Closed,"2010-04-09 18:54:22","2010-04-09 17:54:22",1
"Sonatype Nexus","Improvements to left nav","Move System Files and  Licensing to the administration tab.  Move Repository Targets to Security    Under Help have:  About Nexus  Documentation  Browse Issue Tracker    Documentation should open a new tab like About Nexus does. Here we should have the rest of the links currently under help.    Administration, Security and Help should be collapsed by default.",Improvement,Major,Closed,"2010-03-18 17:24:59","2010-03-18 17:24:59",3
"Sonatype Nexus","New Version Notification config is not persisted","Turning off the new version notification through the server admin screen is not persisted. The configuration seems to be stored in memory (or similar) as the ui looks ok when configuring. But if restarting Nexus it is lost. Also, by verifying in the lvo-plugin.xml file I see that it is still enabled (even though I turn it off).    To reproduce:  * Log into Nexus UI as admin  * Go to Server screen  * Disable New Version Notification. Click Save.  * Look in the lvo-plugin.xml file you see that the config change has not been persisted.  * You can also restart Nexus and go into the Server screen to see that the config change has been lost.  ",Bug,Major,Closed,"2010-02-09 10:43:32","2010-02-09 10:43:32",1
"Sonatype Nexus","Log spam about LegacyAuthorizationManager when LDAP realm is enabled","I'm seeing multiple lines like this in the log after enabling the LDAP realm:    2010-01-15 16:36:22 WARN  [tp-1328231241-4] - o.s.s.a.Authorizati~          - LegacyAuthorizationManager is not configured, it should be removed.    I don't see any side effects from this, but I'm filing this issue because it looks like it is possible that LegacyAuthorizationManager should be removed. :-)    ",Bug,Major,Closed,"2010-01-16 00:40:21","2010-01-16 00:40:21",1
"Sonatype Nexus","Show status (active/disbaled) of user in the list of users (in the Users panel)","Any users managed by the default Nexus realm can be in an active or disabled status. It would be nice if this info is shown in the Users panel listing all users, e.g. by adding a 'Status' column.",Improvement,Minor,Closed,"2009-12-17 08:10:36","2009-12-17 08:10:36",1
"Sonatype Nexus","Authentication error shows up as 400 bad request during smtp validation.","In the log after hitting Test SMTP Settings.        So we know that the problem is an authentication error.  However the user sees 400 bad request (see screenshot).    We should give a reasonable error message in this case.",Bug,Minor,Closed,"2009-10-25 21:22:26","2009-10-25 21:22:26",0
"Sonatype Nexus","Update docs for disable redeployment",,Improvement,Major,Closed,"2009-07-27 16:10:40","2009-07-27 15:10:40",1
"Sonatype Nexus","Repositories: Creating new repository returns nothing","I created a repository using the test harness, and nothing was returned.    The other API's return the created object back,  this is important because some default values might be set or something changed.     This also effects the Groups",Bug,Major,Closed,"2008-08-14 15:14:26","2008-08-14 14:14:26",1
